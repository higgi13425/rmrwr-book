[["index.html", "Reproducible Medical Research with R Chapter 1 Preface 1.1 Who This Book is For 1.2 Prerequisites 1.3 The (Upward) Spiral of Success Structure 1.4 Motivation for this Book 1.5 The Scientific Reproducibility Crisis 1.6 Features of a Bookdown electronic book 1.7 What this Book is Not 1.8 Some Guideposts 1.9 Helpful Tools", " Reproducible Medical Research with R Peter D.R. Higgins, MD, PhD, MSc 2025-04-12 Chapter 1 Preface Welcome to Reproducible Medical Research with R (RMRWR). I hope that this book is helpful to you. 1.1 Who This Book is For This is a book for anyone in the medical field interested in analyzing the data available to them to better understand health, disease, or the delivery of care. This could include nurses, dieticians, psychologists, and PhDs in related fields, as well as medical students, residents, fellows, or doctors in practice. I expect that most learners will be using this book in their spare time at night and on weekends, as the health training curricula are already packed full of information, and there is no room to add skills in reproducible research to the standard curriculum. This book is designed for self-teaching, and many hints and solutions will be provided to avoid roadblocks and frustration. Many learners find themselves wanting to develop reproducible research skills after they have finished their training, and after they have become comfortable with their clinical role. This is the time when they identify and want to address problems faced by patients in their practice with the data they have before them. This book is for you. 1.2 Prerequisites Thank you for giving this e-book a try. This is designed for physicians and others analyzing health data who are interested in pursuing this field using the R computer language. We will assume that: You have access to a computer You have access to the internet You can download and install software from the internet to your computer How to download and install R and RStudio will be addressed, step by step, in Chapter 2. 1.3 The (Upward) Spiral of Success Structure This book is structured on the concept of a “spiral of success”, with readers learning about topics like data visualization, data wrangling, data modeling, reproducible research, and communication of results in repeated passes. These will initially be at a superficial level, and at each pass of the spiral, will provide increasing depth and complexity. This means that the chapters on data wrangling will not all be together, nor the chapters on data visualization. Our goal is to build skills gradually, and return to (and remind students of) their previously built skills in one area and to add to them. The eventual goal is for learners to be able to produce, document, and communicate reproducible research to their community. 1.4 Motivation for this Book Most medical providers who learn R to do their own data analysis do it on their own time. They rarely have time for a semester-long course, as their clinical schedules usually will not allow it. Fortunately, a lot of people learn R on their own, and there is a strong and supportive R community to help new learners. A 2019 Twitter survey conducted by @RLadies found that more than half of respondents were largely self-taught, from books and online resources. There are a lot of good resources for learning R, so why one more? In part, because the needs of a medical audience are often different. There are distinct needs for protecting health information, generating a descriptive Table One, using secure data tools like REDCap, and creating standard medical journal and meeting output in Word, Powerpoint, and poster formats. Further, while learning from a textbook can be helpful, this e-book has the ability to include interactive features that are important for learning to write your own analysis code. Informative flipbook demonstrations will show you what steps in R code do, and learnr exercises will give you a chance to do your own coding to solve problems, right within this e-book. More and more, all science is becoming data science. We are able to track patients, their test results, and even the individual voxels of their CT scans electronically, and use those data points to develop new knowledge. While one could argue that health care workers should collect data and bring it to trained statisticians, this does not work nearly as well as you might expect. Most academic statisticians are incentivized to develop new statistical methods, and are not very interested (nor incentivized) to do the hand-holding required to wrangle messy clinical data into a manuscript. There also are simply not enough statisticians to meet the needs of medical science. Having clinicians on the front lines with some data science training makes a big difference, whether in 1854 in London (John Snow, tracking a cholera outbreak to a water pump) or in 2014 in Flint, Michigan (Mona Hanna-Atisha, showing a rise in blood levels in children after a change i the water supply). Having more clinicians with some data science training will impact medical care, as they will identify local problems that would have otherwise never reached a statistician, and probably never been addressed with data otherwise. 1.5 The Scientific Reproducibility Crisis Beginning as far back as 1989, with the David Baltimore case, in which NIH-funded cancer research was only documented on a pile of paper towels, there has been a rising tide of realization that a lot of taxpayer-funded science is done sloppily. Increasingly and publicly through the 2010s, there has been a realization that manuscripts don’t document the scientific process well, and that our standards as scientists need to be higher. The line between carelessly-done science and outright fraud is a thin one, and the case can be made that doing science in a sloppy fashion defrauds the funders, as it leads to results that can not be reproduced by the authors nor replicated by others. Particularly in medicine, where incorrect findings can cause great harm, we should take special care to do scientific research which is well-documented, reproducible, and replicable. Several examples of science that was sloppily done vs outright fraud involved mis-use of spreadsheets or sloppy coding. Anil Potti at Duke made several errors in spreadsheets that led to claims that tumor multi-omics could guide chemotherapy which were clearly wrong and likely harmed patients in clinical trials. Aboumatar and colleagues at Johns Hopkins published a study of an intervention for COPD in JAMA in 2018 that they claimed improved outcomes, but had to retract this paper in 2019 when they discovered that they had mis-coded the intervention, and that the intervention was actually harmful. The topic of coding correctly, and rooting out errors as a motivating force for doing careful medical research will be expanded upon in Chapter 1. 1.6 Features of a Bookdown electronic book Icons There are several icons at the top left of the main column, to the right of the sidebar, that can be helpful: 1. The Table of Contents Sidebar - Click on the ‘hamburger’ menu icon (three horizontal lines) or the s key to toggle the sidebar (table of contents, on the left) on and off. Within the sidebar, you can click on whichever chapter or subsection you want and go directly to it. 2. This book is Searchable - Click on the magnifying glass or use the f key to toggle the Find box and search for whatever you need to find. 3. You can change the font size, font, and background by clicking on the A icon. 4. You can download the chapter with the download icon (downward arrow into a file tray) in PDF or EPUB formats. Sharing At the top right of the main column, there are several icons for sharing links to the current chapter through social media. Scrolling/Paging You can scroll up and down within a chapter with your mouse, or use the up and down arrow keys. You can page through chapters with the left and right arrow keys. 1.7 What this Book is Not 1.7.1 This Book is Not A Statistics Text This is not an introduction to statistics. I am assuming that you have learned some statistics somewhere in secondary school, undergraduate studies, graduate school, or even medical school. There are lots of statisticians with Ph.D.s who can certainly teach statistics much more effectively than I can. While I have a master’s degree in Clinical Research Design and Statistical Analysis (isn’t that a mouthful!) from the University of Michigan, I will leave formal teaching of statistics to the pros. If you need to brush up on your statistics, no worries. There are several excellent (and free!) e-books on that very topic, using R. Some good examples include (go ahead and click through the colored links to explore): Learning Statistics with R (LSR) Open Intro Statistics Modern Dive Teacup Giraffes We will cover much of the same material as these books, but with a less theoretical and more applied approach. I will focus on specific medical examples, and emphasize issues (like Protected Health Information) that are particularly important for medical data. I am assuming that you are here because you want to analyze your own data in your (probably) very limited free time. 1.7.2 This Book Does Not Provide Comprehensive Coverage of the R Universe This book is also far from comprehensive in teaching what is available in the R ecosystem. This book should be considered a launch pad. Many of the later chapters will give you a taste of what is available in certain areas, and guide you to resources (and links) that you can explore to learn more and do more beyond the scope of this book. The R computer language has expanded far beyond statistics, and allows you to do many powerful things to improve your workflow, make amazing graphics, and share results with others. 1.8 Some Guideposts Keep an eye out for helpful Guideposts, which look like this: Warnings - These are common “gotchas” to watch out for This indicates a common syntax error, especially for beginners. Watch out for this. Tips - These are helpful items to remember This is a helpful tip for debugging. Try It Out - This is an example to apply what you have learned Take what you have learned and try it yourself on your own computer. Challenge - These are usually at the end of a chapter, to try a more challenging example and consolidate what you have learned Take the next step, and try this more complicated example. Explore More - These are resources for learning more about a particular topic. If you want to learn more about Shiny apps, go to https://mastering-shiny.org to see an entire book on the topic. 1.9 Helpful Tools Throughout this book you will find flipbook code demonstrations and learnr code interactive exercises in which you can practice writing R code right in the book. Let’s explain how to use these demonstration flipbooks and learnr exercises. 1.9.1 Demonstrations in Flipbooks Flipbooks are windows in this book in which you can watch R code being built into pipelines, and see the results at each step. Each flipbook demonstrates some important code concepts, and often new functions in R. You can click on the window to activate it, and the fullscreen (4 arrows) icon to expand it to the full screen. Then use the left and right arrow keys to go forward and back in the code, one step at a time. You will want to go through these slowly, and make sure that you understand what is happening in each step. You may even want to take notes, particularly on the function syntax, as you will likely coding exercises with these functions shortly after the flipbook demonstration. Take a look at the example of a flipbook below. Activate it by clicking on it, and use the expand icon (4 arrows at the lower right) to make it full screen. You can step forward and backward through the pipeline of code with the right and left arrow keys. Watch the results of each step. 1.9.2 Learnr Coding Exercises Learnr coding exercises are windows in this book in which you can write your own R code to solve a problem. Each learnr exercise tests whether you have mastered important code concepts, and often new functions in R. If needed, you can reset to a fresh code window with the Start Over button. You can type lines of code into the window, then click on the Run Code button at the top right to run the code and get your results. Your code may not produce the right result the first time, and you will have to interpret the error message to figure out how to fix it. Rely on the text and your notes and the demonstrations to help you. If you are stuck, you can click on the Hint button to see an example of correct code, and compare it to your own. If you would like, you can even copy this code to the clipboard with the Copy button and Take a look at the example of a learnr exercise below. There is a dataset (prostate) piped into a function (‘select’), with three blanks (3 arguments to this function). Fill in the blanks with the 3 listed variables (age, fam_hx, and t_stage are the variable names). Then run your code with the Run Code button to get a result. Practice using the Start Over button, the Hint button (there may be more than one - usually the last one is the solution), and the Copy To Clipboard button, then paste the solution in if you are stuck, and then Run Code. Then try out Exercise 2 to select columns related to Gleason Score. When you get a table of data as a result from a code pipeline, it may have more columns (variables) than can be displayed easily. When this is the case, there will be a black arrow pointing rightward at the top right of the table of results. Click on this to scroll right and see more columns. A table of data as a result from a code pipeline may also have more rows (observations) than can be displayed easily. When this is the case, the table will be paginated, with 10 rows per page. At the bottom right of the table, there will be a clickable listing of pages, along with Previous and Next buttons. Click on these buttons (or the page number buttons) to see more pages of data to inspect and check your results. 1.9.3 Coding An important note on writing your own code: you should always have an internet search window open when you are writing code. No one can remember every function, nor the correct arguments and syntax of each function. A critical skill in writing code is searching for how to do something correctly. This is not a sign of weakness. Professional programmers google “how do I do x?” many times each day. This is how programming is done. You will often search for things like “how do I do x in R?” or “how to x in tidyverse”. This is completely normal, and to be expected. You do not have time to memorize hundreds of functions, and you may have days or even weeks between coding sessions (because of your day job), making it hard to remember all the details from your last coding session. This is not a problem. There are lots of websites that can help you solve specific problems, as you will find in the How to Find Help chapter. "],["getting-started-and-installing-your-tools.html", "Chapter 2 Getting Started and Installing Your Tools 2.1 Goals for this Chapter 2.2 Website links needed for this Chapter 2.3 Pathway for this Chapter 2.4 Installing R on your Computer 2.5 Windows-Specific Steps for Installing R 2.6 Mac-specific Installation of R 2.7 Installing RStudio on your Computer 2.8 Installing Git on your Computer 2.9 Getting Acquainted with the RStudio IDE", " Chapter 2 Getting Started and Installing Your Tools One of the most intimidating parts of getting started with something new is the actual getting started part. Don’t worry, I will walk you through this step-by step. 2.1 Goals for this Chapter Install R on your Computer Install RStudio on your Computer Install Git on your Computer Get Acquainted with the RStudio IDE 2.2 Website links needed for this Chapter While in many chapters, I will list the R packages you need, in this chapter, you will be downloading and installing new software, so I will list the links here for your reference. https://www.r-project.org https://rstudio.com/products/rstudio/download/ https://git-scm.com/downloads 2.3 Pathway for this Chapter This Chapter is part of the TOOLS pathway. Chapters in this pathway include Getting Started and Installing Your Tools Using the RStudio IDE Updating R, RStudio, and Your Packages Advanced Use of the RStudio IDE When You Don’t Want to Update Packages (Using renv) Major R Updates (Where Are My Packages?) 2.4 Installing R on your Computer R is a statistical programming language, designed for non-programmers (statisticians). It is optimized to work with data in rectangular tables of rows (observations) and columns (variables). It is a fast and powerful programming engine, but it is not terribly comfortable or convenient. Base R itself is not terribly user-friendly. It is a lot like a drag racing car, which is basically a person with a steering wheel strapped to an airplane engine. drag racer Very aerodynamic and fast, but not comfortable for the long run (more than about 8 seconds). You will need something more like a production car, with a nice interior and a dashboard, and comfy leather seats. dashboard This equivalent of a comfy coding environment is provided by the RStudio IDE (Integrated Developer Environment). I want you to install both the R statistical language and the RStudio IDE, in that order. Note that serious computer programmers do not consider R a fast coding language. R was designed by statisticians for managing data and running models, and is not optimizedW like languages like C++ and Julia for modern computers. If you have really big data, R will slow down, and using R packages like {arrow} and {data.table} will dramatically increase the speed of R. Let’s start with installing R. R is free and available for download on the web. Click on the following link to go to the r-project website to get started. This screen will look like this You can see from the blue link (download R) that you can use this link to download R, but you will be downloading it faster if you pick a local CRAN mirror. You might be wondering what CRAN and CRAN Mirrors are. Nothing to do with cranberries, fortunately. CRAN is the Comprehensive R Archive Network. Each site (mirror) in the network contains an archive of all R versions and packages, and the sites are scattered over the globe. A CRAN Mirror maintains an up-to-date copy of all of the R versions and packages on CRAN. If you use the nearest CRAN mirror, you will generally get faster downloads. At this point, you might be wondering what a package is… A package is a set of functions and/or data that you can download to upgrade and add features to R. It is like a downloadable upgrade to a Tesla vehicle that lets you play the video game The Witcher 3 on your console, but more useful. Another useful analogy for packages is that they are like apps for a smartphone. When you buy a new smartphone, it only comes with the basic apps that allow it to work as a phone, and a few other things, like a notepad and a calculator. If you want to do cool things with your smartphone, you download additional apps that allow your smartphone to have new capabilities. That is what packages do for your installation of R. Now let’s get started. Click on the blue link that says “download R”. This will take you to a page to select your local CRAN Mirror , from which you will download R. cran Scroll down to your local country (yes, the USA is at the bottom), and a CRAN mirror near you. This is an example from the state of Michigan, in the USA. usa-mirrors Once you click on a CRAN Mirror site to select the location, you will be taken to the actual Download site. install Select the link for the operating system you want to use. We will walk through this with Windows first, then Mac. If you are using a Mac, skip forward to the Mac install directions in section 2.6. If you are computer-savvy enough to be using Linux, you can probably figure it out on your own (it will look a lot like these). 2.5 Windows-Specific Steps for Installing R If you are installing R on a Mac, jump ahead to the Mac-specific version below in section 2.6. On Windows, once you have clicked through, your next screen will look like this: install2 You want to download both base and Rtools (you might need Rtools later to build packages for Windows). The base link will take you to the latest version, which will look something like this. install3 Click on this link, and you will be able to save the latest version to a file named R-N.N.N-win.exe (N values vary depending on the latest version number, recent versions look like R-4.1.2-win.exe) to your Downloads folder. Click on the Save button to save it. install4 Now, go to your Downloads folder in Windows, and double click on the the latest version of the R installation file (something like R-N.N.N-win.exe. Recent versions have looked something like R-4.1.2.exe). Click Yes to allow this to install. install5exe Now select your language option. install_language You will be asked to accept the GNU license - do so. Click Yes to allow this to install. Then select where to install - generally use the default- a local (often C) drive - we usually do not install on a shared network drive or in the cloud. install_drive Then select the Components - generally use the defaults, but newer computers can skip the 32 bit version. install_components In the next dialog box, accept the default startup options. install_defaults You can choose the start menu folder. The default R folder is fine. install_start If you want a shortcut icon for R on your desktop, you can leave this checked. But most people start RStudio, with R running within RStudio, rather than directly starting R. You can choose to create an R shortcut on your desktop in the next dialog box. You can delete it later if you don’t like it. install_addltasks Then the Setup Wizard will appear - click Finish, and the rest of the installation will occur. install_wizard 2.5.1 Testing R on Windows Now you want to test whether your Windows installation was successful. Can you find R and make it work? This is easy if you chose to make an R shortcut. If not, hunt for your C folder, then for OS-APPS within that folder. Keep drilling down to the Program Files folder. Then the R folder, and the current version folder within that one (R-N.N.N). Within that folder will be the bin folder, and within that will be your R-N.N.N.exe file. Double click on this to run it. The example paths below can help guide you. install_path2 install_path Opening the exe file will open a classic year 2000-era terminal window, called Rterm, with 64 bit if that is what your computer uses. The version number should match what you downloaded. The messaging should end with a “&gt;” prompt. install_term At this prompt, type in: paste(“Two to the seventh power is”, 2^7) (don’t leave out the comma or the quotes) - then press the Enter key. This should produce the following: Two to the seventh power is 128 install_test Note that you have explained what is being done in the text, and computed the result and displayed it. 2.6 Mac-specific Installation of R The installation for Mac is very similar, but the windows look a bit different. If you are working with Windows, jump ahead at this point to Installing RStudio in section 2.7. At the Download Version page, you click on the Mac Download. You will then click on the link for the latest version of R, which will look something like R-N.N.N.pkg (recent versions have been something like R-4.1.2.pkg), and allow downloads from CRAN. install_path Then go to Finder, and navigate to the Downloads folder. Click on R-N.N.N.pkg You will then click on the link for R-N.N.N.pkg, and allow downloads from CRAN. install_downloadmac Click on Continue on 2 consecutive screens to download cont1_mac cont2_mac Then you need to agree with the License Agreement, mac_license then Click on Install, and provide your Mac password for permission to install. cont1_mac When the installation is complete, click on the Close button. Accept the prompt to move the installer file to the trash. 2.6.1 Testing R on the Mac If you chose to create an R desktop shortcut, double-click on this to start. If not, go to Finder, and then your Applications folder. Scroll down to the R file. Double click on this to run it. findrmac You should get this 2000-era terminal window named R Console. The version number should match what you downloaded, and the messaging should end with a “&gt;” prompt. At this prompt, type in paste(“Two to the seventh power is”, 2^7) (DON’T leave out the comma or the quotes) rconsolemac This should result in mactestR 2.6.2 Successful testing! Awesome. You are now Ready to R! ready2R 2.7 Installing RStudio on your Computer Now that R is working, we will install RStudio. This is an IDE (Integrated Development Environment), with lots of bells and whistles to help you do reproducible medical research. teslax_dash This is a lot like adding a dashboard with polished walnut panels, a large video screen map, and heated car seats with Corinthian Leather. Not absolutely necessary, but nice to have. The RStudio IDE wraps around the R engine to make your experience more comfortable and efficient. camry_dash Fortunately, RStudio is a lot cheaper than any of these cars. In fact, it is free and open source. You can download it from the web at: rstudio Click on the RStudio Desktop icon to begin. download This will take you to a new site, where you will select the Open Source Edition of RStudio Desktop open_source This will take you to a new site, where you will select the Free Version of RStudio Desktop free Now select the right version for your Operating syxtem - Windows or Mac. 2.7.1 Windows Install of RStudio If you are installing on a Mac, jump ahead now to the Mac-specfic installation instructions. Now save the RStudio.N.N.N.exe file (Ns will be digits representing the version number) to your downloads folder. winsave Now go to your downloads folder, and double click on the RStudio.N.N.N.exe file. winlaunch Allow this app to make changes. Click Next to Continue, and Agree to the Install Location. wininstall Click Install to put RStudio in the default Start Menu Folder, and when done, click the Finish button. winsave winfinish Now select your preferred language option, accept the GNU license, Click Yes to allow this to install. Select where to install. This is generally on a local (often C:) drive, and usually not a shared network drive or in the cloud. 2.7.2 Testing Windows RStudio Now you should be ready to test your Windows installation of RStudio. Open your Start menu Program list, and find RStudio. Pin it as a favorite now. Click to Open RStudio. Within the Console window of RStudio, an instance of R is started up. Check that the version number matches the version of R that you downloaded. Now run a test at the prompt (“&gt;”) in the Console window. Type in paste(\"Three to the 5th power is\", 3^5) do not leave out the quotes or the comma Then press the enter key and this should be your result: test_result35 A successful result means that you are ready to roll in RStudio and R! 2.7.3 Installing RStudio on the Mac Start at this link: RStudio Download Select the Free RStudio Desktop Version mac_download Then click on the big button to Download RStudio for Mac. mac_download2 After the Download is complete, go to Finder and the Downloads Folder. Double click on the RStudio.N.N.N.dmg file in your Downloads folder. mac_dmg This will open a window that looks like this mac_apps Use your mouse to drag the RStudio icon into the Applications folder. Now go back to Finder, then into the Applications folder. Double click on the RStudio icon, and click OK to Open. Pin your RStudio to the Dock. Double Click to run RStudio. RStudio will open an instance of R inside the Console pane of RStudio with the version number of R that you installed, and a “&gt;” prompt. 2.7.4 Testing the Mac Installation of RStudio Type in paste(\"Three to the 5th power is\", 3^5) do not leave out the quotes or the comma Then press the enter key and this should be your result. test_result35 A successful result means that you are ready to roll in RStudio and R! ready 2.7.5 Critical Setup - Tuning Up Your RStudio Installation You now have ~ 7 adjustments that you need to make in your RStudio Global Settings for optimal R and RStudio use. At this point, it is a good idea to jump out of RStudio and create an “Rcode” folder on your computer, in a place that is easy to find, often at the top level in your Documents folder, to make all of your future projects easy to find. Once this Rcode folder is in place, switch back to RStudio. In the top bar of RStudio Menus, go to Tools/Global Options. A new Global Options window will open up. Click on the General tab on the left. At the top, there is a small window for identifying your Default working directory. Click on the Browse button, and browse to your new “Rcode” folder and select it. From now on, your R files and Projects will all be in one place and easy to find. In the same General tab, de-select the first 3 options turn off Restore most recently opened project at startup turn off Restore previously open source documents at startup turn off Restore .RData into workspace In the same General tab, find Save workspace to .RData on exit. Click on the dropdown menu to select “Never” These tune-ups (#2 and #3) to your RStudio will mean you will always start with a clean workspace in a new RStudio session, which will help avoid a lot of potential problems later. In the same General tab, at the top, click on the Advanced tab. Then select the box for Show full path to project in window title. This will show your working directory at the top of your Console Pane. This can prevent confusion and problems later. On the left, click on the Rmarkdown tab. Then de-select the option for Show output inline for all Rmarkdown documents. This will put your temporary output from Code Chunks into the larger and nicer Viewer tab. Take a look at the Appearance tab. You can change your code font, the font size, and the theme. I wouldn’t make any drastic changes at this point, but it is good to know that these options are available. Any changes here are entirely optional (and cosmetic) at this point. in the RStudio menus, select Tools/Global Options/Code, then check/select three options to turn these on: In the Editing tab - select Soft Wrap Long Lines - so that your code does not get too wide In the Editing tab - select Use Native Pipe Operator, |&gt; (requires R &gt; 4.1+) to get the modern pipe operator In the Display tab - select Rainbow Parentheses - this option color-codes parentheses so that you can keep track of whether you have closed all of your open parentheses (a common source of errors). When your last close parenthesis is red, all is well. Now your RStudio installation is tuned and ready to go! 2.8 Installing Git on your Computer The software program, git, is a version control system. It is the most common version control system in the world. It is free and open source, and is the foundation of reproducible computing. We won’t be doing a lot with git just yet, but it is helpful to get this installation done and out of the way. It will come up a lot when we start to discuss reproducible research and collaboration. 2.8.1 Installing Git on macOS If you are using Windows, jump ahead to Installing Git on Windows. The easiest approach on the macOS is to go to the Terminal tab in the Console pane (lower left) in RStudio. A prompt will appear that ends in a $. At that prompt, type git --version note that there are 2 dashes before version. This will tell you the current version of git (2.29.2 as of January 1, 2021), or prompt you to install git. If you want the current version of git, you can install this yourself. a. First, let’s check if you have homebrew installed. Go to the Terminal tab in the Console pane (lower left) in RStudio. A prompt will appear that ends in a $. at the prompt, type command -v brew This should return “/usr/local/bin/brew” if homebrew is installed, or will tell you “brew not found” or something similar. b. Installing homebrew At the terminal prompt($), paste in the following: /bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot; Then press Enter to run it. This installs the homebrew program, which allows you to install software on macOS that does not come from the Apple App Store This will take a couple of minutes. c. Installing git Once you have homebrew installed, installing git is straightforward. At the Terminal prompt (the prompt looks like a dollar sign $), type brew install git and this will quickly install. You will be returned to the Terminal prompt ($) when installation is complete. Check your installation. At the Terminal prompt ($), type git --version and this should return a result like “git version 2.29.2”, depending on the most recent version number. 2.8.2 Installing Git on Windows If you are using Windows, go to the website, https://git-scm.com/download/win. This will start the download automatically Go to your downloads folder and install the downloaded .exe file by clicking on it Check your installation. At the Terminal prompt ($), type git --version and this should return a result like “git version 2.29.2”, depending on the version number. 2.8.3 Installing Git on Linux If you are using Fedora, or a related version of Linux like RHEL or CentOS, use dnf At the $ prompt, type sudo dnf install git-all If you are using a Debian-based version of Linux like Ubuntu, use apt At the $ prompt, type sudo apt install git-all For other distributions of Linux, follow the instructions at https://git-scm.com/download/linux. Check your installation. At the Terminal prompt ($), type git --version and this should return a result like “git version 2.29.2”, depending on the version number. 2.9 Getting Acquainted with the RStudio IDE When you first open the RStudio IDE (Integrated Development Environment), there will be a left side pane, with tabs for Console, Terminal, and Jobs. This is called the Console pane. Just for fun, go to the RStudio menus, and choose File/New File/RScript. This will open a new pane at the top left, which we will call the top left pane, or the Source pane. This pane will contain tabs for each active script or document, along with tabs for any datasets you have opened up to have a look at. The Console pane, with tabs for Console, Terminal, and Jobs, has now been pushed to the lower left quadrant. You will use the Console pane for interactive programming, and as a “sandbox” to test out new code. When your code works and is good enough to save, you will move it to the Source pane and save it to a Script or an Rmarkdown document. Any code that is not saved to Source will be lost (actually it will be somewhere in the History, but it can be a pain to find the version that works later - it is best to save the good stuff to an R Script or .Rmd (rmarkdown) document). The top right pane includes tabs for your Environment (objects, like datasets, functions, and variables you have defined), History (saving the past in case you forget to, but messy), and Connections tabs for connections to databases. Later a Git tab will be added for version control (backup) of your Source documents. The bottom right pane contains tabs for your Files, Plots, Packages, Help, and a Viewer for HTML output. This is material that is also well described in the “Basic Basics 1” section of RLadiesSydney. Check it out at Basic Basics 1. There is a nice ~ 15 minute video by Jen Richmond worth watching if you are just getting started. Note that a lot of the other material on this website (RYouWithMe) is very helpful for getting started with R. For a more complete introduction to the RStudio IDE, see Chapter TBD, titled Using the RStudio IDE. "],["a-tasting-menu-of-r.html", "Chapter 3 A Tasting Menu of R 3.1 Setting the Table 3.2 Goals for this Chapter 3.3 Packages needed for this Chapter 3.4 Website links needed for this Chapter 3.5 Setting up RPubs 3.6 Open a New Rmarkdown document 3.7 Knitting your Rmarkdown document 3.8 Your Turn to Write Text 3.9 Wrangle Your Data 3.10 Summarize Your Data 3.11 Visualize Your Data 3.12 Statistical Testing of Differences 3.13 Publish your work to RPubs 3.14 The Dessert Cart", " Chapter 3 A Tasting Menu of R In this chapter, we will introduce you to a lot of neat things that you can do with R and RStudio, and you will publish a simple data analysis on the Internet that you can share with friends and family. 3.1 Setting the Table In this chapter, you will get a rapid overview of the kind of things you can do with R. You will create an Rmarkdown document read in data wrangle your data create a data visualization and publish your findings. At the end of this chapter, you will publish your data analysis to RPubs, a free website site where you can share your data analyses and visualizations. 3.2 Goals for this Chapter Set up an RPubs account Open a New Rmarkdown document Read in Data from a file Wrangle Your Data Visualize Your Data Publish your work to RPubs Check out Interactive Plots Check out Animated Graphics Check out a Clinical Trial Dashboard Check out a Shiny App 3.3 Packages needed for this Chapter In this chapter, we will use the following R packages: tidyverse janitor rstatix medicaldata If you have not installed these packages on your computer already, we will walk you through installation after you open your Rmarkdown document (see below). 3.4 Website links needed for this Chapter In this chapter, you will need to access the RPubs website. https://rpubs.com/ 3.5 Setting up RPubs First you will need to set up a free account on RPubs. Start by opening a new tab in your browser, and navigating to this link RPubs link. It should look like the image below. Enter your name, email, username and password, (remember these, you will need them later) and click on the Register Now button, and you will be set up to use RPubs . This will bring you to this page. In the image below, we have set up an account for pdr. Click on the Here’s How You Get Started link (blue text). You are now all set up and ready to go. Now you have a place on the internet to share your R creations. On to the creation part! 3.6 Open a New Rmarkdown document Let’s get started in R. Turn on your computer, and open the RStudio application. You should see the familiar panes for the Console, Environment, and Files. You need to open up a new document to activate the Source pane. While in RStudio, click on File/New File/RMarkdown. It should look like this. Opening a New Rmarkdown Document Now you will see the window below. Rename the document from “Untitled” to “Tasting”. Enter your own name as the Author, and click the OK button. Adding Title and Author Now the file is open, and looks like the window below (with title “Tasting” and author “Peter Higgins”. Click on the save icon (like a floppy disk in the top left), and save this document as my_data_analysis.Rmd. What Your New Rmarkdown Document Looks Like You have created a new Rmarkdown document. An Rmarkdown document lets you mix data, code, and descriptive text. It is very helpful for presenting and explaining data and visualizations. An Rmarkdown document can be converted (Knit) to HTML for a web page, or to Microsoft Word, Powerpoint, PDF, and several other output formats. artwork by Allison Horst, @allison_horst Code chunks are in a gray color, and both start and end with 3 backticks (```), like this. code goes here Text can be body text, or can be headers and titles. The number of hashtags before some header text defines what level the header is. You can insert links, images, and even YouTube videos into Rmarkdown documents if it is helpful to explain your point. You can change the way that the Rmarkdown document is displayed with two buttons in the top right of the new Tasting document tab. The button with several horizontal lines that looks like an outline can be clicked to toggle an outline pane on and off. When the outline pane is on, you can click on the entries to go to a different part of your document quickly. The button that looks a bit like an Angstrom symbol (A with a circle on top), or perhaps it looks like a compass to you, allows you to turn on Visual Editing, or WYSIWIG (what you see is what you get) visual editing. When this is off, you can see the markdown codes that make the words “R Markdown” a level 2 header (right after the setup chunk), with two hashtags right before the text. But when the Visual Editing button is turned on, you can see the formatting as it will appear in the output document, and a new formatting bar appears at the top of the document below the Knit button. This formatting bar adds the ability to select text and change the heading level (top left), or make text bold, italic, underlined, etc. The formatting bar also lets you insert images, links, and tables into your document, much like you would with a word processor. The first code chunk in each Rmarkdown document is named setup. Find this code chunk in your “Tasting” document. The code chunk name (in this case, setup) comes after the left curly brace and the r ({r) at the beginning of the each code chunk. The letter r tells RStudio that what is coming on the next line is R code (RStudio can also use SQL, C++, python, and several other commputer languages). After a comma, you can define options for this code chunk. In the case of this setup chunk, the option include is set to FALSE, so that when this Rmarkdown document is knitted, this code chunk will run, but no output or warnings or messages will appear in the output document. 3.7 Knitting your Rmarkdown document While this is just an example template, you can see that there is some explanatory text, some formatting, and two code chunks. One code chunk has the option, echo = FALSE, which means that the code in that code chunk will not appear in the output document, but the results of the code chunk will appear. To see what the output of this Rmarkdown document looks like, click on the Knit button - this is at the top center of your Tasting document next to a blue ball of yarn with a knitting needle. When you knit the Rmarkdown document, the default result is an HTML output document. Notice that you can see the code for the cars code chunk, but that the setup code chunk and pressure code chunk do not appear. But you do get results: a summary of the cars dataset and a plot of the pressure data. You also have the option of knitting Rmarkdown documents to other kinds of output, including Microsoft Word, Microsoft Powerpoint, posters for medical meetings, books (like this book), and pdf documents. 3.7.1 Installing Packages Before we begin working on your Rmarkdown document, you will need to install a few R packages on your computer. Go to your Console tab (lower left in RStudio), and type in (or copy and paste in) the following 5 lines: install.packages(&#39;tidyverse&#39;) install.packages(&#39;janitor&#39;) install.packages(&#39;rstatix&#39;) install.packages(&#39;remotes&#39;) remotes::install_github(&#39;higgi13425/medicaldata&#39;) Press Enter to run these functions. These will install the 5 packages, {tidyverse}, {janitor}, {rstatix}, {remotes}, and {medicaldata}. Installing packages is like buying apps for your phone. But these apps are not loaded into your current R session unless you tell R and RStudio that you want them loaded in the current session. You do this with the library() function. 3.7.2 Loading Packages with library() Copy and paste to add the following 5 lines to your setup chunk in your “Tasting.Rmd” Rmarkdown document: library(tidyverse) library(janitor) library(rstatix) library(medicaldata) prostate &lt;- medicaldata::blood_storage %&gt;% clean_names() These functions will load 4 packages and read in data from a study of prostate cancer and blood storage into the prostate object. Now run these functions, by clicking on the green rightward arrow at the top right of the setup code chunk in your Rmarkdown document. The installation of the {tidyverse} package (it is actually a meta-package that contains multiple packages) will be quite chatty, telling you which packages are being attached, and when conflicts with identically-named functions in the {stat} package have occurred. When you call the functions, filter() and lag(), the versions from the {tidyverse} package will be used by default, and the versions from the {stats} package will be masked. The {janitor} package will tell you that it has 2 conflicts with the {stats} package, and will supercede (mask) the {stats} functions for chisq.test() and fisher.test(). If you really want to access the versions from the {stats} package, you can do so by using the package::function construction, e.g. stats::chisq.test(), which tells R that you want to use the version of the function from the {stats} package, rather than the {janitor} package. If you check the Environment tab in the top right pane of RStudio, you will find that you now have a prostate object under the Data header. You can click on the white-on-blue arrow to the left of the word prostate to get an overview of each variable, the variable type (numeric, string, etc.), and the first few values of each variable. You can also click on the word prostate in the Environment window to open up a View of the whole dataset in the Source pane (top left). You can scroll up and down the rows, or right and left in the columns to inspect the data. If you check the Console tab (lower left), you will see that when you clicked on prostate, this sent a function to the console to View(prostate). You can view any dataset in the Environment tab with this function. You can also look at your data in the Console, by running (type in and press Enter for each line) glimpse(prostate) summary(prostate) to provide some information on the contents of the prostate dataframe, and a summary of the data. 3.8 Your Turn to Write Text Underneath the setup chunk, change the text of the first header (“R Markdown”) to “Analysis of Prostate Data”. Now delete the next two paragraphs of Normal text and write something about the prostate dataset, based on the summary in the console . You write body text for your documents in Normal text, and you can add new headers by starting a line with 2 hashtags, a space, and text like this ## Headline about Prostate data Write a few sentences after your heading. You can add italics or bold text by wrapping the text to be highlighted in underscores or 2 asterisks, respectively. If you are using the Visual Editor mode, you can do these things more easily by selecting your text, and clicking on the bold or italic icons in the formatting bar. You can also change a line of text to a header by selecting it, then clicking the dropdown arrow next to the word “Normal” at the top left of the formatting bar. You can make this into one of 6 levels of Headings, or a code chunk. We often reserve the level 1 Heading for the title. Try adding some text and formatting to your text. 3.9 Wrangle Your Data Find the {r cars} code chunk. Edit the name “cars” to “wrangle” Delete the one line of code from the template - “summary(cars)” We will replace this with a few lines of code to improve the data in the prostate dataset. We will be modifying the prostate dataset (with the mutate function), particularly the variables aa and fam_hx into properly labeled categorical variables, called factors in R. Then we will save (assign) the result to the prostate_factors object, while retaining the previous version in the prostate object. Copy the lines of code below and paste them into the new wrangle code chunk. You can see in the code that we start with the prostate dataset, and then (the pipe symbol [%&gt;%] is read as “and then”) mutate the aa variable to a labelled factor, and then mutate the fam_hx variable to a labelled factor. Then the resulting dataframe is assigned to the new prostate_factors object. This version of the data will be helpful for plotting later. prostate %&gt;% mutate(aa = factor(aa, levels = c(0,1), labels = c(&quot;White&quot;, &quot;African-American&quot;))) %&gt;% mutate(fam_hx = factor(fam_hx, levels = c(0,1), labels = c(&quot;No Family History&quot;, &quot;FHx of Prostate Cancer&quot;))) -&gt; prostate_factors Note that R will not ask you if you want to over-write an object. This is just a reminder to be careful when you assign data to an object. You don’t want to re-use an object name (like prostate) and inadvertently over-write your previous work. It is fine if this is what you intended, but make sure it is that this is you want to do. It is generally a good practice to assign data to well-named objects, so that you know what they are, where they came from, and how they have changed since the last data wrangling iteration. It is generally not a good idea to over-write your data. 3.10 Summarize Your Data Now you will Insert a new R code chunk, after the wrangle chunk. First, click with your mouse to place your cursor on a blank line below the wrangle chunk. Now open a new code chunk. To do this, find the green code (C) button in the menu bar at the top of your Rmarkdown document. Click on it and select R as the language being used. You will get a gray code chunk with the {r} label at the top. Insert your cursor after the r, and before the closing brace. Add a space, then type the name, summarize. In this chunk, we will run some code to summarize three variables. Paste the four lines of code below into your new code chunk. prostate %&gt;% select(age, p_vol, preop_psa, aa, fam_hx) %&gt;% group_by(aa, fam_hx) %&gt;% summarize(across(age:preop_psa, mean, na.rm=TRUE)) This code starts with the prostate dataset, and then selects 5 of the variables. Then it groups the observations by African-American race and Family history of prostate cancer. Then it summarizes across 3 variables to get the mean value of each one (after removing any missing values). Try this out by clicking on the rightward green arrow at the top right of your summarize code chunk. This should produce a summary table of results for age, prostate volume, and preoperative PSA. Add some body text below the code chunk, with your interpretation of these results, and some hypotheses about these summary results, including the contrasts by family history and race. Depending on the sample size, some of these differences might be statistically significant. Which ones would you like to test? 3.11 Visualize Your Data Now let’s plot the prostate_factors data. Change the name of the previous plot chunk to “visualize”. Delete the one line of code from the example. We will produce a scatterplot, faceted by African-American race and Family History. Copy and paste the code below into your Rmarkdown document in this visualize code chunk. ggplot(prostate_factors) + aes(x = p_vol, y = preop_psa, col = aa) + geom_point() + geom_smooth(method = &quot;lm&quot;) + facet_grid(aa ~ fam_hx) + labs(x = &#39;Prostate Volume&#39;, y = &quot;Preoperative PSA&quot;, title = &#39;Relationship Between Prostate Volume and Preop PSA,\\nSubdivided by Family History and Race&#39;) + theme(legend.position = &quot;bottom&quot;) This will run the code to generate a plot. Note that these steps for a ggplot are connected with + signs, while the data wrangling steps are connected with the pipe ( %&gt;% ) symbol. Let’s walk through each step of the code. First you are stating the dataset to plot, with ggplot(prostate), and then the aesthetic mappings are stated, with p_vol mapped to x, preop_psa mapped to y, and the aa variable mapped to color. This all happens in the aes(x = p_vol, y = preop_psa, col = aa) step. Then these are plotted as scatterplot points with geom_point, and linear regression lines are added with geom_smooth(method = \"lm\") (method = “lm” is for linear model). Then the plot is faceted (broken into comparison plots) by the aa and fam_hx variables with facet_grid(aa ~ fam_hx). Then labels for x and y and the title are added. Then a theme option is used to move the legend position to the bottom. You can run the visualize code chunk and see the plot by clicking on the green arrow at the top right of the code chunk. Do you think that the slopes of the linear regression lines are all the same? Are there differences or patterns? Add some text below your plot stating your interpretation of these plots, and any hypotheses generated by this visualization of the data. 3.12 Statistical Testing of Differences Based on the previous summary, it looks like the African-American patients in this dataset may have, on average, a higher preoperative PSA level. We can test this with Student’s t test. Insert a new header for Statistical Testing (or T testing). Make sure it is in the Heading 2 format. Then insert some Normal text in which you state your hypothesis. Then insert a code chunk (green C button, select the R language). Name this new code chunk “t-test”. Paste in the three lines of code below to get the results of a t test comparing preop_psa levels between African-Americans and Whites in this dataset. prostate_factors %&gt;% t_test(formula = preop_psa ~ aa, detailed = TRUE) Now write some body text below the results, with your interpretation for this result in this dataset and sample size. 3.13 Publish your work to RPubs Now you have a complete data analysis, including data wrangling, summarizing, plotting, and statistical testing. Your report combines code, results, graphics, and text introduction of the questions, and text interpretation of the results. Go ahead and Knit this Rmarkdown document to see the final result. Use the Knit button (blue ball of yarn with knitting needle) near the top left of your Rmarkdown document. Now you can share this document with others, by publishing your results and interpretation on the web. Now that you have a knitted HTML document, look for the Publish button at the top right of the HTML output (it looks sort of like a blue eye, or two blue semicircles wrapped around a blue dot). Click on this and select RPubs. The knitted HTML document will now be uploaded to RPubs, and your result can be found at https://rpubs.com/username, based on your RPubs username. You may have to click on the username dropdown at the top right to reach View Profile, which will show the documents that you have published. Click on the thumbnail of your new document to go to the full link and see it in its full HTML glory. This page will have a specific link, which will be something like at [[https://rpubs.com/username](https://rpubs.com/username/123456)](https://rpubs.com/username)/123456 , which is a dedicated link you can share with other people who want to see your results. You can share this link via email, and anyone (collaborators, mentors, friends) can see your results report from anywhere with a web connection. You did it! You should feel like an Rmarkdown rock star! artwork by Allison Horst, @allison_horst You can also knit Rmarkdown documents to: Microsoft Word (1st draft of manuscript) Microsoft Powerpoint (1st draft of presentation) Posterdown (a poster-making package - for meeting posters) so that you don’t need to copy/paste your results or plots, and you can easily re-run your analyses and produce new outputs if you get more data. This chapter should give you a taste of the powerful tools for research reproducibility in R that can make your research work more efficient and more reproducible. 3.14 The Dessert Cart Below are some examples of more neat things you can do with medical data in R. These are more advanced approaches, but completely doable when you have more experience with R. 3.14.1 Interactive Plots Below is an interactive plot. Click on the plot to activate it. Then you can hover your mouse over each point to get more details about the data. You can also use the crosshairs to draw a zoom rectangle, or use the plotly menu bar at top right to zoom in or out of a region of the data. 3.14.2 Animated Graphics Here is an example of animated graphics that you can create in R to illustrate changes in data over time. 3.14.3 A Clinical Trial Dashboard Below is an screen capture picture of a web flexdashboard to track the data in an ongoing clinical trial (which is now completed and published). You can see the actual web dashboard here. Check out the various tabs. Imagine how useful it would be to track enrollment, exclusions, missing data, and outcomes in real time. Details on how this is done can be found here, and the underlying code here. All of this work was done in R by Jenn Thompson. 3.14.4 A Shiny App The frame below shows a publicly available Shiny web application, built with R, which can help clinicians calculate the probablity of intestinal TB vs. Crohn’s disease with available clinical data. And to determine how new test results would change this estimate. The web app can be accessed here. 3.14.5 An Example of Synergy in the R Community One of the remarkable things about the open source R community is that people build all kinds of new R functions and packages that are useful to them, and then share them publicly with tools like Github so that they can be useful to others. Often combining bits of several packages leads to emergent properties - completely new creations that can only occur because all of the parts (packages) are present. The collaborative nature of the R community, in this case on Twitter (follow the #rstats hashtag), can lead to surprising collaborations and outcomes. Go ahead and play the example below, which uses rayrendering (all coded entirely in R) to show a 3D map of John Snow’s cholera case data in 1854, which led him to identify the Broad Street water pump as the source of the cholera outbreak, and led to the removal of the pump handle and the end of outbreak. If you are not familiar with John Snow and the Broad Street pump, there is a fun series of YouTube animations (parts 1-3 and an epilogue) to explain the history. Start by clicking here. "],["introduction-to-reproducibility.html", "Chapter 4 Introduction to Reproducibility 4.1 First Steps to Research Reproducibility 4.2 The Foundations of Reproducibility", " Chapter 4 Introduction to Reproducibility One of the major goals of this book is to help medical researchers make their research projects reproducible. This means being able to take the original raw data, and replicate each step of the data cleaning and analysis to produce the same end products, including tables, figures, and the full manuscript. This requires: Robust sharing of data, materials, software, and code Documenting the data collection and data analysis processes Using authenticated biomaterials, and validated measurement instruments Using valid statistical methods and study design Pre-registration of studies, including detailed protocols and statistical plans, to avoid p-hacking and HARK-ing (Hypothesizing After the Results are Known (aka post-hoc analyses)) Publishing (even if only on MedRxiv, or in the American Journal of Gastroenterology Black Issue) well-designed negative studies This book largely focuses on computational reproducibility, as this is rarely taught in medical training, and intense pressure to publish leads the untrained into dark practices. 4.1 First Steps to Research Reproducibility 4.1.1 Have a Plan The first steps toward research reproducibility come in planning for reproducibility. This means having a clear design and statistical plan, proven methods of data collection and recording, and preserving your raw data in a secure, locked state. 4.1.2 Treat Your Raw Data Like Gold Largely because you spend a lot of money (often other peoples’ \\[grant\\] money) and your own time (and the time of the people who work for you on the studies) in collecting it - you and others have invested a lot of gold to collect this. Once it is collected, it should be protected, backed up, and kept in a safe repository. Seriously consider having off-site backups for major projects to protect your data from local natural disasters. No one at Tulane expected Hurricane Katrina to destroy decades of research data. No one at NYU realized that the backup generators (in the basement) would be flooded by Hurricane Sandy. No one expects that their data and biosamples will be destroyed. But in an era (2022) when major natural disasters are increasing rapidly, it is important to plan for Black Swan events. Protect your research and protect your career. 4.1.3 Cleaning and Analyzing Your Data There are a number of levels of reproducibility, and the following figure/meme illustrates these. Levels of Reproducibility While an amusing meme, the image above does illustrate the arc of progress we hope to make as we move from ‘back of the envelope/Excel’ research to reproducible research. You don’t have to be making encapsulated research environments right away, but you can work up to that level. Working in Excel, or any other point-and-click environment, is not fundamentally reproducible. There are multiple steps that are not recorded, calculations that are not transparent, and formulas that difficult to check (thus, forensic accounting is a growing field). Working in Excel leads to many, many errors, which have caused significant damage. Excel was never designed for research. It was designed for exploring data for small businesses, and it does not scale well. going off on a tangent on the Perils of Excel, with examples Working in a free, open-source coding language like R greatly eases the transition to reproducible research. It provides tools, accessible to anyone with an internet connection, to make science reproducible and transparent. 4.1.4 The First Level of Reproducibility Working in the Console Pane in RStudio allows you to test code, trying out functions on your data. This is a good sandbox where you can do little harm, and is helpful when you are using a new package or function, and figuring out the syntax. You may need to get help for the function (?function_name), and it may take several iterations to get it to do what you want. You may jump over to a browser window to google something from RStudio Community, StackOverflow, or a good blog post to find an example. You can even save the results (a table, a figure) to a folder with functions like this in a code chunk. save(table, file = &quot;table.csv&quot;) ggsave(plot, filename = &quot;figure1.jpg&quot;, device = &quot;jpeg&quot;, width = 8, height = 5, units = &quot;inches&quot;) This is a good start, and your code is logged in the History, but it is not saved in a named file that you can go back to, and re-run. If your data changes, you have to start all over, and re-write the code. This is not very reproducible. 4.1.5 The Second Level of Reproducibility You can bridge from the sandbox of the Console pane to reproducible, saved code. There are a couple of nice features in the History tab (top right in RStudio) to help you. To get started, you need to Open a File to save your code in. As a default, we will start with RMarkdown files. In the RStudio menu, select ** File/New File/Rmarkdown… and give it a title, like “My First Analysis”. This will open a file in the RStudio Source pane (top left). Note that this title (“My First Analysis”) is the title at the top of the resulting document, not the name of the file itself. Once the file opens, you can see a header at the top, with Title, Author, Date, and Output Fields. This is called the YAML header, and it gives instructions for how the document will be processed to make a manuscript or HTML page. The YAML header is fenced with both an opening and a closing line of 3 dashes ---. To save the file itself, you can use Cmd-S(Mac)/Ctrl-S(Windows), or click on the Save icon at the top of the file, then give it a filename, which is generally in lower case, with no numbers or spaces, and no punctuation except for underscores and hyphens. Each Rmarkdown filename ends with .Rmd The first code chunk - the setup chunk - is provided for you in the Rmarkdown template, just below the YAML header. This is where you load packages, with the library(_packagename_) function. You want to load your packages at the beginning of the file, so that the functions and data from these packages are available later in the file. Notice that code chunks are set off with 3 backticks at the beginning and end. The first set of backticks is followed by a letter r inside of curly braces, like this: {r}. This tells Rstudio that the following code will be in the R language. The {r} can be followed by an (optional) chunk name (like setup), then a comma, and a number of (optional) code chunk options. Sometimes the code chunk options can get a bit ungainly, and you can enter them like comment lines at the top of the code chunk, before the code actually starts, using the hash-pipe marker, with commas between each option, like this: ```{r example} #| echo = TRUE, #| eval = FALSE medicaldata::cytomegalovirus %&gt;% head() ``` You can insert new Code chunks with the green button that has a white letter C on it, and a plus sign at the top left corner of the button, at the top of the Source pane. When you click on it, R is the first option, but other computer languages are available. Often, when you are writing code, you will start with experiments in the Console pane (lower left). Each time it does not quite work, you can use the up-arrow to pull down the most recent entry, to edit it and try again. Another helpful tip, if you want to find code that you ran a few steps ago, is to press the up arrow (and down arrow) a few times until you reach the code you want. If it was a while back, it may be helpful to enter the first few characters of the code, then use Cmd-UpArrow(Mac) or Ctrl-UpArrow(Win) use those characters to search through the history for what you want. Another helpful tip is that when you are running a function, and trying to get all the arguments set properly (between the parentheses), you can ask RStudio to prompt you for the remaining arguments. If you have your cursor between the parentheses, you can press the tab key and RStudio will give you a list of possible arguments for the function. You can select one and set it to an appropriate value. After each argument is set, you can enter a comma, and press the tab key again to get the list of arguments for that function. Try this out with the code chunk named cars in the Rmarkdown template. Insert your cursor after the word cars, before the close-parenthesis. Add a comma, then press the tab key. Set the digits argument to 2 or 5, then run the chunk (with the green arrow to the right) to see how the results change. Once you have worked out how to run a bit of code in the Console, it is helpful to click on the History tab. You will see all of your prior attempts. You can scroll up and down to find a working version of your code, and then click on buttons at the top of the window to send that line of code to either the - Console, or - Source pane If your cursor was in the code chunk you want in the Rmarkdown file, your working version will be copied from the History to your code chunk. Rmarkdown is designed to be literate code, with the default for headers and explanatory text, as shown in the Rmarkdown template, and a few code chunks inserted into the manuscript where needed. Note that there are three other options of document types to save your reproducible code. - R script (.R) - R notebook (.nb) - Quarto document (*.qmd) An R script just has code, with minimal explanation or documentation. This is limiting for reproducible research. You can add a few comments, but it is a long way from an understandable workflow or a manuscript. An R notebook is a hybrid, with an R script and HTML output as an option. The Rmarkdown documemt can be processed (knitted) to create Word documents, pdfs, Poerpoint presentations, and HTML web pages. Quarto documents are a newer version of code documentation that has a lot of the function of Rmarkdown. 4.2 The Foundations of Reproducibility To make your data cleaning and analysis reproducible, you depend on several layers of reproducibility, several of which are out of your control. The hardware that you work on - think of this as the foundation. We expect and assume that the hardware will not make computational errors, and will not differ between an Intel chip vs. an AMD chip vs. a Mac M-series chip. This is usually true, but the Pentium FDIV bug is a famous example of a hardware error that caused problems for a small number of users, but caused huge reputational damage to Intel, which changed their approach to hardware testing. The hardware is the foundation of reproducibility. The operating system that you work on. There are differences between Windows, Linux, Mac, and other OSes. Hopefully these differences do not change computational results. The statistical programming language that you use. R is a programming language, and it is open source, so it is constantly being updated and tested by the public. The R Foundation has a commitment to reproducibility and the R Core team works hard to ensure that computational results are reproducible across versions of R. There are slight differences between R, SAS, Stata, and other statistical programming languages, which can affect outputs, usually based on slightly different defaults in particular computations. It is important to be aware of these, and when in doubt, to check the CAMIS project, which has a goal “to demystify conflicting results between software and to help ease the transitions to new languages by providing comparison and comprehensive explanations.” These differences are usually small, and can often be resolved by choosing a different computational option in the function arguments. The R version that you are using. R is constantly being updated, and the R Foundation has a commitment to reproducibility and the R Core team works hard to ensure that the results are reproducible across versions of R. But it is still possible that switching from R 3.1 to R 5.2 will produce different results. The R packages and versions that you use. R is a package-based language, and the packages are constantly being updated. Each package developer is aiming for reproducibility, but they may make major breaking changes between package versions that can make your code fail or produce different output. Each package team works hard to ensure that the results are reproducible across versions. But it is still possible that switching from {dplyr} 1.0.0 to {dplyr} 2.0.0 will cause your code to fail (most often) or produce different results (rarely). You can protect your projects from this problem by using the {renv} package, which will save the versions of the packages you are using in a project-specific library. This is a good practice for reproducibility, and is especially important when you are working on a project with multiple collaborators. Your code. This is the most important part of reproducibility, and the part that you have the most control over. Your code should be well documented, and should be able to be run by someone else without any changes (including changes to paths, which may require the {here} package to work on different computers). Being able to produce the same results with the same data and code on any computer is the goal of reproducible research. Future steps/goals in Reproducibility: building Projects in RStudio, using the {here} package for file paths documenting multiple code files in order with README saving interim clean/restructured data files backing up / collaborating / code sharing on GitHub code review with colleagues to check/test your analysis sharing deidentified data and code publicly preserving your project package environment with {renv} building an encapsulated coding environment with Docker and sharing on DockerHub "],["importing-your-data-into-r.html", "Chapter 5 Importing Your Data into R 5.1 Reading data with the {readr} package 5.2 Reading Excel Files with readxl 5.3 Bringing in data from other Statistical Programs (SAS, Stata, SPSS) with the {haven} package 5.4 Other strange file types with rio 5.5 Data exploration with glimpse, str, and head/tail 5.6 More exploration with skimr and DataExplorer 5.7 Practice loading data from multiple file types 5.8 Practice saving (writing to disk) data objects in formats including csv, rds, xls, xlsx and statistical program formats 5.9 How do readr and readxl parse columns? 5.10 What are the variable types? 5.11 Controlling Parsing 5.12 Chapter Challenges 5.13 Future forms of data ingestion", " Chapter 5 Importing Your Data into R For most of this book, we will be using datasets from the {medicaldata} package. These are easy to load. If you type into the Console pane medicaldata::scurvy , you will get James Lind’s scurvy dataset (actually, a reconstruction of what it might have looked like for his 12 participants). If you want to save this data to an object in your work environment, you just need to assign this to a named object, like scurvy, like so, with an assignment arrow, composed of a less than sign (&lt;) and a hyphen (-): scurvy &lt;- medicaldata::scurvy # now print the columns for id and treatment scurvy %&gt;% select(study_id:treatment) |&gt; #this selects columns slice_tail(n = 7) #slices last seven rows ## # A tibble: 7 × 2 ## study_id treatment ## &lt;chr&gt; &lt;fct&gt; ## 1 006 vinegar ## 2 007 sea_water ## 3 008 sea_water ## 4 009 citrus ## 5 010 citrus ## 6 011 purgative_mixture ## 7 012 purgative_mixture There are a number of medical datasets to explore and learn with, within the {medicaldata} package. However, at some point, you will want to use R to work on your own data. You may already be itching to get started on your own data. This is a good thing. Working with your own data, toward your own goals, will be a motivating example, and will help you learn R. As you go through the different chapters, use the example data and exercises to get you started and to learn the principles, and then try what you have learned on your own data. Reproducibility and Raw Data It is an important principle to always save an untouched copy of your raw data. You can copy it to a new object, and experiment with modifying it, cleaning it, making plots, etc., but always leave the original data file untouched. You want to create a completely reproducible, step-by-step, scripted trail from your raw data to your finished analysis and final report, and you can only do that if you preserve the original raw data. That is the cornerstone of your analysis. It is tempting to fix minor data entry errors, or other aspects of the raw data. Do not do this - leave all errors intact in your raw data, and explicitly make edits with explanations of who made the edit when it was made what was changed and why the edit was made. You should provide a justification for each change, and identify source documents to support the rationale. Every edit should be documented in your code, with who, when, what, and why. Now, on to the fun part. Let’s read in some data! 5.1 Reading data with the {readr} package Many of the standard data formats can be read with functions in the {readr} package. This package is part of the {tidyverse} meta-package. These functions include: read_csv() for comma-separated values (*.csv) files read_tsv() for tab-separated values (*.tsv) files read_delim() for files with a different delimiter that you can specify (instead of commas or tabs, there might be semicolons), or you can let {readr} guess the delimiter in readr 2.0. read_fwf() for fixed width files read_table() for tabular files where columns are separated by white-space. read_log() is specifically for web log files Let’s read a csv file. First, make sure that you have the {readr} package loaded (or the {tidyverse} meta-package, which includes {readr}). You can load {readr} with the library() function, if you have already installed this package. library(readr) # or you can use library(tidyverse) # which will load 8 packages, including readr # the other 7 packages are ggplot, tibble, tidyr, dplyr, purrr, stringr, and forcats Note that this will not work if you do not already have the {readr} package installed on your computer. You will get an error, like this: Error in library(readr) : there is no package called 'readr' This is not a big problem - but you have to install the package first, before you can load it. You only need to do this once, like buying a book, and putting it in your personal library. Each time you use the package, you have to pull the book off the shelf, with library(packagename). To install the {readr} package, we can install the whole {tidyverse} package, which will come in handy later. Just enter the following in your Console pane to install the {tidyverse} meta-package: install.packages('tidyverse') Note that quotes around ‘tidyverse’ are required, as tidyverse is not yet a known object or package in your working environment. Once the {tidyverse} package is installed, you can use library(tidyverse) without quotes, as it is a known (installed) package. We will also want to use the {glue} package shortly to access files on the web. Practice installing this package. Copy and run the code chunk below in your RStudio Console panel to install and load the {glue} package. install.packages(&#39;glue&#39;) library(glue) OK, after that detour, we should be all caught up - you should be able to run library(tidyverse) or library(readr) or library(glue) without an error. Now that you have {readr} loaded, you can read in some csv data. Let’s start with a file named scurvy.csv in a data folder on GitHub. You will need to glue together the url_stem (the first part of the path to the web address) and “data/scurvy.csv” (the folder and file name) to get the full web address. Copy and run the code chunk below to see the url_stem and the dataset. url_stem &lt;- &quot;https://raw.githubusercontent.com/higgi13425/rmrwr-book/master/&quot; url_stem ## [1] &quot;https://raw.githubusercontent.com/higgi13425/rmrwr-book/master/&quot; read_csv(glue(url_stem, &#39;data/scurvy.csv&#39;)) ## Rows: 12 Columns: 8 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (8): study_id, treatment, dosing_regimen_for_scurvy, gum_rot_d6, skin_so... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. ## # A tibble: 12 × 8 ## study_id treatment dosing_regimen_for_s…¹ gum_rot_d6 skin_sores_d6 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 001 cider 1 quart per day 2_moderate 2_moderate ## 2 002 cider 1 quart per day 2_moderate 1_mild ## 3 003 dilute_sulfuric_acid 25 drops of elixir of… 1_mild 3_severe ## 4 004 dilute_sulfuric_acid 25 drops of elixir of… 2_moderate 3_severe ## 5 005 vinegar two spoonfuls, three … 3_severe 3_severe ## 6 006 vinegar two spoonfuls, three … 3_severe 3_severe ## 7 007 sea_water half pint daily 3_severe 3_severe ## 8 008 sea_water half pint daily 3_severe 3_severe ## 9 009 citrus two lemons and an ora… 1_mild 1_mild ## 10 010 citrus two lemons and an ora… 0_none 0_none ## 11 011 purgative_mixture a nutmeg-sized paste … 3_severe 3_severe ## 12 012 purgative_mixture a nutmeg-sized paste … 3_severe 3_severe ## # ℹ abbreviated name: ¹​dosing_regimen_for_scurvy ## # ℹ 3 more variables: weakness_of_the_knees_d6 &lt;chr&gt;, lassitude_d6 &lt;chr&gt;, ## # fit_for_duty_d6 &lt;chr&gt; Let’s look at what was extracted from the csv file. This starts after the url_stem (web address) is printed out. The Console pane has a the number of rows (12) and columns (8) in the dataset. The Column specification, followed by the data in rectangular format. In the Column specification, the delimiter between items of data is identified (a comma), and a listing of variables with the character (chr) data type is printed. There are no non-character data types in this particular dataset. The ‘guessing’ of what data type is appropriate for each variable is done ‘automagically’, as the read_csv() function reads the first 1000 rows, then guesses what data type is present in each column (variable). It is often conservative, and in this case, made all of these columns into character variables (also called strings). You could argue that the col_character() assignment should be numeric for the study_id variable, or that the Likert scales used for outcomes like gum_rot_d6 and skin_sores_d6 should be coded as ordinal categorical variables, known as ordered factors in R. You will learn to control these data types during data import with the spec() argument. The last piece of output is the data rectangle itself. This is first identified as a ‘tibble’, which is a type of data table, with 12 rows and 8 columns, in # A tibble: 12 x 8. This is followed by a header row of variable names, and just below that is the data type (&lt;chr&gt; for character) for each column. Then, on the left are gray row numbers (which are not actually part of the data set), followed by (to the right) rows of data. A tibble, by default, only prints out only as many rows of data as will fill the console, and no more columns than will fill the width of your current console window. The other columns (variable names) are listed in order at the bottom of the tibble in gray type. Now, by simply reading in the data, you can look at it, but you can’t do anything with it, as you have not saved it as an object in your working Environment. If you want to do things with this data, and make them last, you have to assign the data to an object, and give it a name. To do this, you need to use an assignment arrow, as below, where the data is assigned to the object, scurvy_data. scurvy_data &lt;- read_csv(glue(url_stem, &#39;data/scurvy.csv&#39;)) ## Rows: 12 Columns: 8 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (8): study_id, treatment, dosing_regimen_for_scurvy, gum_rot_d6, skin_so... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. Now this is saved to scurvy_data in your working Environment. You can now look in the Environment tab (top right pane in RStudio) and see that scurvy_data has now appeared in the Data section, with 12 observations of 8 variables. This is not a file written (saved) to disk, but this dataset is now available in the working environment as an assigned data object. You can click on the blue arrow next to scurvy_data to show the variable names and variable types for this dataset. You can also click on the name scurvy_data to open up a Viewer window in the top left (Source) pane. You can scroll around to inspect all of the data. You can also get this view by typing View(scurvy_data) into the Console pane. You can also print out the data to the Console pane at any time by typing scurvy_data into the Console, or into a script. Try this out in the Console pane. 5.1.1 Test yourself on scurvy Inspect the data in the Viewer, and find each answer. How many limes did the British seamen in the citrus arm receive each day? 32zero1.5 You can also start with the scurvy_data object, and do things to this data object, like summarize it, or graph it, or calculate total_symptom_score in a data pipeline. Once you have assigned your data to an object, it will stick around in that R session for later use. Your changes will disappear when you close the session, unless you save it to disk, with functions like save() or write_csv(). The csv (comma separated values) format is a very common data format, and most data management programs have a way to export *.csv files. The csv format is simple, is not owned by anyone, and works across platforms. However, it can occasionally be tricky if you have commas in the middle of a variable like degree, with entries like ‘md, phd’ in a column that is mostly ‘md’. The read_csv function is pretty smart, and usually gets the number of columns right, but this is something to watch out for. Notice that read_csv had no problem with the dosing of vinegar (“two spoonfuls, three times a day”) in the scurvy dataset, despite multiple commas. If you happen to come across a tab-separated values file, read_tsv() works the same way. Both of these functions have reasonable defaults, so that most of the time, you just have to use the path to your file (usually on your hard drive, rather than on the web) as the only argument. On occasion, though, you will want to take control of some of the other arguments, and use something other than the defaults. 5.1.2 What is a path? A path is the trail through the folders in your hard drive (or on the web) that the computer needs to follow to find a particupar file. Paths can look something like: C:/Documents/Rcode/my_file.R ~/User/Documents/Rcode/my_file.R and can get pretty complicated to keep track of. One particularly nice feature of Projects in RStudio is that the project directory is always your home, or root directory. You can make your life easier by using the {here} package, which memorizes the path to your project, so you can just write here(my_file.R), and not have to worry about making a typo in a long path name. When your data has no column names (headers), read_csv will (by default) assume that the first row of the data is the column names. To fix this, add the argument, col_names = FALSE. You can also assign your own col_names by setting a vector, like c(“patient_id”, “treatment”, “outcome”) [note that c() concatenates data items into a vector] equal to to col_names, as below. Copy and run this code chunk in your RStudio Console pane to see how the output is different. read_csv(file = glue(url_stem, &#39;data/scurvy.csv&#39;), col_names = c(&quot;pat_id&quot;, &quot;arm&quot;, &quot;dose&quot;, &quot;gums&quot;, &quot;skin&quot;, &quot;weak&quot;, &quot;lass&quot;, &quot;fit&quot;)) ## Rows: 13 Columns: 8 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (8): pat_id, arm, dose, gums, skin, weak, lass, fit ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. ## # A tibble: 13 × 8 ## pat_id arm dose gums skin weak lass fit ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 study_id treatment dosing_regimen_f… gum_… skin… weak… lass… fit_… ## 2 001 cider 1 quart per day 2_mo… 2_mo… 2_mo… 2_mo… 0_no ## 3 002 cider 1 quart per day 2_mo… 1_mi… 2_mo… 3_se… 0_no ## 4 003 dilute_sulfuric_acid 25 drops of elix… 1_mi… 3_se… 3_se… 3_se… 0_no ## 5 004 dilute_sulfuric_acid 25 drops of elix… 2_mo… 3_se… 3_se… 3_se… 0_no ## 6 005 vinegar two spoonfuls, t… 3_se… 3_se… 3_se… 3_se… 0_no ## 7 006 vinegar two spoonfuls, t… 3_se… 3_se… 3_se… 3_se… 0_no ## 8 007 sea_water half pint daily 3_se… 3_se… 3_se… 3_se… 0_no ## 9 008 sea_water half pint daily 3_se… 3_se… 3_se… 3_se… 0_no ## 10 009 citrus two lemons and a… 1_mi… 1_mi… 0_no… 1_mi… 0_no ## 11 010 citrus two lemons and a… 0_no… 0_no… 0_no… 0_no… 1_yes ## 12 011 purgative_mixture a nutmeg-sized p… 3_se… 3_se… 3_se… 3_se… 0_no ## 13 012 purgative_mixture a nutmeg-sized p… 3_se… 3_se… 3_se… 3_se… 0_no In this case, when we set our own col_names, there are now 13 rows in our data rectangle, and the original column headers are now listed as the first row of data. We can fix this with the skip argument within the parentheses of the read_csv() function, which has a default of 0. We can skip as many lines as we want, which can be helpful if you have an Excel file with a lot of blank lines or commentary at the top of the spreadsheet. When we set skip = 1 in this case, we get a cleaner dataset, without variable names as data. read_csv(file = glue(url_stem, &#39;data/scurvy.csv&#39;), col_names = c(&quot;pat_id&quot;, &quot;arm&quot;, &quot;dose&quot;, &quot;gums&quot;, &quot;skin&quot;, &quot;weak&quot;, &quot;lass&quot;, &quot;fit&quot;), skip = 1) ## Rows: 12 Columns: 8 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (8): pat_id, arm, dose, gums, skin, weak, lass, fit ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. ## # A tibble: 12 × 8 ## pat_id arm dose gums skin weak lass fit ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 001 cider 1 quart per day 2_mo… 2_mo… 2_mo… 2_mo… 0_no ## 2 002 cider 1 quart per day 2_mo… 1_mi… 2_mo… 3_se… 0_no ## 3 003 dilute_sulfuric_acid 25 drops of elixir… 1_mi… 3_se… 3_se… 3_se… 0_no ## 4 004 dilute_sulfuric_acid 25 drops of elixir… 2_mo… 3_se… 3_se… 3_se… 0_no ## 5 005 vinegar two spoonfuls, thr… 3_se… 3_se… 3_se… 3_se… 0_no ## 6 006 vinegar two spoonfuls, thr… 3_se… 3_se… 3_se… 3_se… 0_no ## 7 007 sea_water half pint daily 3_se… 3_se… 3_se… 3_se… 0_no ## 8 008 sea_water half pint daily 3_se… 3_se… 3_se… 3_se… 0_no ## 9 009 citrus two lemons and an … 1_mi… 1_mi… 0_no… 1_mi… 0_no ## 10 010 citrus two lemons and an … 0_no… 0_no… 0_no… 0_no… 1_yes ## 11 011 purgative_mixture a nutmeg-sized pas… 3_se… 3_se… 3_se… 3_se… 0_no ## 12 012 purgative_mixture a nutmeg-sized pas… 3_se… 3_se… 3_se… 3_se… 0_no Now we don’t have extra column names as data, and we are back to 12 rows. Also note that in this code chunk, we put each argument to the function on its own line, with commas between them. This is a good practice, to make your code more readable. More arguments to read_csv(): you can also set n_max to a particular number of rows to be read in (the default is infinity, or Inf) You might want a smaller number if you have a very large dataset and limited computer memory. Another important argument (option) for both read_csv and read_tsv is col_types, which lets you take control of the column types during the data What if you want to take more control of the import process with read_csv()? You can add acol_typesargument to theread_csv()function. You can copy the Column specifications from the first attempt at importing, and then make some edits. You can get the column specifications as guessed by {readr} by running thespec()` function on the scurvy_data object. Try this out in the code chunk below. spec(scurvy_data) ## cols( ## study_id = col_character(), ## treatment = col_character(), ## dosing_regimen_for_scurvy = col_character(), ## gum_rot_d6 = col_character(), ## skin_sores_d6 = col_character(), ## weakness_of_the_knees_d6 = col_character(), ## lassitude_d6 = col_character(), ## fit_for_duty_d6 = col_character() ## ) This sets the data type for each column (variable). This is helpful if you want to change a few of these. Take a look at the next code chunk below. I have added the col_types argument to read_csv(), and set it equal to the Column specifications (copied from above). Then I edited study_id to col_integer(), and treatment to col_factor(). Run the code chunk below to see how this works. The glimpse function will give an overview of the new scurvy_cols object that I assigned the data to. scurvy_cols &lt;- read_csv( file = glue(url_stem, &#39;data/scurvy.csv&#39;), col_types = cols( study_id = col_integer(), treatment = col_factor(), dosing_regimen_for_scurvy = col_character(), gum_rot_d6 = col_character(), skin_sores_d6 = col_character(), weakness_of_the_knees_d6 = col_character(), lassitude_d6 = col_character(), fit_for_duty_d6 = col_character() ) ) glimpse(scurvy_cols) ## Rows: 12 ## Columns: 8 ## $ study_id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12 ## $ treatment &lt;fct&gt; cider, cider, dilute_sulfuric_acid, dilute_s… ## $ dosing_regimen_for_scurvy &lt;chr&gt; &quot;1 quart per day&quot;, &quot;1 quart per day&quot;, &quot;25 dr… ## $ gum_rot_d6 &lt;chr&gt; &quot;2_moderate&quot;, &quot;2_moderate&quot;, &quot;1_mild&quot;, &quot;2_mod… ## $ skin_sores_d6 &lt;chr&gt; &quot;2_moderate&quot;, &quot;1_mild&quot;, &quot;3_severe&quot;, &quot;3_sever… ## $ weakness_of_the_knees_d6 &lt;chr&gt; &quot;2_moderate&quot;, &quot;2_moderate&quot;, &quot;3_severe&quot;, &quot;3_s… ## $ lassitude_d6 &lt;chr&gt; &quot;2_moderate&quot;, &quot;3_severe&quot;, &quot;3_severe&quot;, &quot;3_sev… ## $ fit_for_duty_d6 &lt;chr&gt; &quot;0_no&quot;, &quot;0_no&quot;, &quot;0_no&quot;, &quot;0_no&quot;, &quot;0_no&quot;, &quot;0_n… You can see that study_id is now considered the integer data type (&lt;int&gt;), and the treatment variable is now a factor (&lt;fct&gt;). You can choose as data types: col_integer () col_character() col_number() (handles #s with commas) col_double() (to specify decimal #s) col_logical() (only TRUE and FALSE) col_date(format = ““) - may need to define format col_time(format = ““) - col_datetime(format =”“) col_factor(levels = ““, ordered = TRUE) - you may want to set levels and ordered if ordinal. col_guess() - is the default col_skip() if you want to skip a column The read_csv() guesses may be fine, but you can take more control if needed. This col_types() approach gives you fine control of each column. But it is a lot of typing (even with copy-paste from spec()). Sometimes you want to set all the column types with a lot less typing, and you don’t need to set levels for factors, or formats for dates. You can do this by setting col_types to a string, in which each letter specifies the column type for each column. Run the example below by clicking on the green arrow at the top right of the code chunk, in which I use i for col_integer, c for col_character, and f for col_factor. scurvy_cols2 &lt;- read_csv( file = glue(url_stem, &#39;data/scurvy.csv&#39;), col_types = &quot;ifcffff&quot;) glimpse(scurvy_cols2) ## Rows: 12 ## Columns: 8 ## $ study_id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12 ## $ treatment &lt;fct&gt; cider, cider, dilute_sulfuric_acid, dilute_s… ## $ dosing_regimen_for_scurvy &lt;chr&gt; &quot;1 quart per day&quot;, &quot;1 quart per day&quot;, &quot;25 dr… ## $ gum_rot_d6 &lt;fct&gt; 2_moderate, 2_moderate, 1_mild, 2_moderate, … ## $ skin_sores_d6 &lt;fct&gt; 2_moderate, 1_mild, 3_severe, 3_severe, 3_se… ## $ weakness_of_the_knees_d6 &lt;fct&gt; 2_moderate, 2_moderate, 3_severe, 3_severe, … ## $ lassitude_d6 &lt;fct&gt; 2_moderate, 3_severe, 3_severe, 3_severe, 3_… ## $ fit_for_duty_d6 &lt;chr&gt; &quot;0_no&quot;, &quot;0_no&quot;, &quot;0_no&quot;, &quot;0_no&quot;, &quot;0_no&quot;, &quot;0_n… 5.1.3 Try it Yourself Now try this yourself with a *.tsv file. The file strep_tb.tsv is located in the same GitHub folder, and you can use the same url_stem. In the example code chunk below, there are several blanks. Copy this code chunk (use the copy button in the top right of the code chunk - hover to find it) to your RStudio Console pane. Edit it to make the three changes listed, and run the code chunk as directed below. Fill in the second part of the read_xxx() function correctly to read this file Fill in the correct file name to complete the path This version of the code chunk will read in every column (all 13 variables) as the character data type. This is OK, but not quite right. Now edit the col_types string to make: both doses numeric (n or d) (variables 3,4) gender a factor (f) (var 5) all 4 of the baseline variables into factors (var 6-9) skip over strep_resistance and radiologic_6m - set as hyphens (-) (var 10-11) rad_num into an integer (i) (var 12) improved into a logical (l) (var 13) strep_tb_cols &lt;- read_---( file = glue(url_stem, &#39;data/----.tsv&#39;), col_types = &quot;ccccccccccccc&quot;) glimpse(strep_tb_cols) Show the Solution strep_tb_cols &lt;- read_tsv( file = glue(url_stem, &#39;data/strep_tb.tsv&#39;), col_types = &quot;ccddfffff--il&quot;) glimpse(strep_tb_cols) ## Rows: 107 ## Columns: 11 ## $ patient_id &lt;chr&gt; &quot;0001&quot;, &quot;0002&quot;, &quot;0003&quot;, &quot;0004&quot;, &quot;0005&quot;, &quot;0006&quot;, &quot;0… ## $ arm &lt;chr&gt; &quot;Control&quot;, &quot;Control&quot;, &quot;Control&quot;, &quot;Control&quot;, &quot;Contr… ## $ dose_strep_g &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ dose_PAS_g &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ gender &lt;fct&gt; M, F, F, M, F, M, F, M, F, M, F, M, F, M, F, M, F,… ## $ baseline_condition &lt;fct&gt; 1_Good, 1_Good, 1_Good, 1_Good, 1_Good, 1_Good, 1_… ## $ baseline_temp &lt;fct&gt; 1_98-98.9F, 3_100-100.9F, 1_98-98.9F, 1_98-98.9F, … ## $ baseline_esr &lt;fct&gt; 2_11-20, 2_11-20, 3_21-50, 3_21-50, 3_21-50, 3_21-… ## $ baseline_cavitation &lt;fct&gt; yes, no, no, no, no, no, yes, yes, yes, yes, no, y… ## $ rad_num &lt;int&gt; 6, 5, 5, 5, 5, 6, 5, 5, 5, 5, 6, 5, 5, 5, 5, 6, 5,… ## $ improved &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR… 5.2 Reading Excel Files with readxl While file types like *.csv and *.tsv are common, it is also common to use Microsoft Excel or an equivalent for data entry. There are a lot of reasons that this is not a great idea (see the video at link), but Excel is so ubiquitous that it is often used for data entry. Fortunately, the {readxl} package provides functions for reading excel files. The read_excel() function works nearly the same as read_csv(). But there are a few bonus arguments (options) in read_excel() that are really helpful. The read_excel() function includes helpful arguments like skip, col_names, col_types, and n_max, much like read_csv(). In addition, read_excel() has a sheet argument, which lets you specify which sheet in an excel workbook you want to read. The default is the first worksheet, but you can set this to sheet = 4 for the 4th worksheet from the left, or sheet = “raw_data” to get the correct worksheet named “raw_data”. You can also set the range argument to only read in a particular range of cells, like range = “B2:G14”. Let’s set up your local RStudio to read in a spreadsheet named paulolol.xlsx. Copy and run the code below in your local version of RStudio to prepare the file. This will pull an excel file from the web and write a copy to your local storage. library(httr) github_raw_link &lt;- &quot;https://github.com/higgi13425/rmrwr-book/raw/master/data/paulolol.xlsx&quot; paulolol_xlsx &lt;- tempfile(fileext = &quot;.xlsx&quot;) req &lt;- httr::GET(github_raw_link, # write result to disk write_disk(path = paulolol_xlsx)) Below is an example of how to read in this Excel worksheet. Copy and run this code locally, and see what you get in the Console for output. library(readxl) read_excel(paulolol_xlsx, sheet = 1, skip = 0) ## New names: ## • `` -&gt; `...2` ## • `` -&gt; `...3` ## • `` -&gt; `...4` ## • `` -&gt; `...5` ## • `` -&gt; `...6` ## # A tibble: 14 × 6 ## `Data for my study` ...2 ...3 ...4 ...5 ...6 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Paul Investigator MD &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 2 44338 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 3 pat_id SBP_start SBP_end HR_start HR_end treatment ## 4 1 145 120 92 78 paulolol ## 5 2 147 148 88 87 placebo ## 6 3 158 139 96 80 paulolol ## 7 4 167 166 87 88 placebo ## 8 5 154 131 84 72 paulolol ## 9 6 178 177 99 97 placebo ## 10 7 151 134 101 86 paulolol ## 11 8 149 148 92 93 placebo ## 12 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; sbp hr &lt;NA&gt; ## 13 &lt;NA&gt; mean paulolol &lt;NA&gt; 131 79 &lt;NA&gt; ## 14 &lt;NA&gt; mean placebo &lt;NA&gt; 159.75 91.25 &lt;NA&gt; You will notice that a lot of the variable names became ..2 , ..3, etc. the first two rows have a lot of NAs (??). the last 3 rows have a lot of NAs, and some mean values(!?). This is because the person who created this spreadsheet did not make this a clean rectangle of data. This is a common problem with Excel. It is easy to add extra, descriptive header lines, and the variable names don’t even appear until row 3. Further, the user calculated some mean values for sbp and hr in rows 12-14, which are being read in like regular observations (because while you can figure out what happened, Excel can’t). This is a problem. We want a clean rectangle of data, with the true variable names at the top. There are actually only 8 rows of observations in this Excel spreadsheet. Try editing the skip and n_max arguments until you can read in a clean rectangle of data below. Copy the code hung read_excel(paulolol_xlsx, sheet = 1, skip = ___, n_max = ___) Show Solution read_excel(paulolol_xlsx, sheet = 1, skip = 3, n_max = 8) 5.2.1 Test yourself on read_excel() which argument in read_excel lets you jump past initial rows of commentary? jumpsheetskippath which argument in read_excel lets you pick which spreadsheet tab to read? picksheetskippath How many missing (NA) values are in the paulolol dataset when run with skip = 1? what should the range argument be to read in these data cleanly (without needing n_max or skip)? B2:F8A4:F12A1:L30B4:K15 5.3 Bringing in data from other Statistical Programs (SAS, Stata, SPSS) with the {haven} package It is common to have the occasional collaborator who still uses one of the older proprietary statistical packages. They will send you files with filenames like data.sas7bdat (SAS), data.dta (Stata), or data.sav (SPSS). The {haven} package makes reding in these data files straightforward. ** Set up with web files** Copy and run the code chunk below to import a web file for SAS. The {haven} package provides functions like read_sas(), read_dta() and read_sav() to enable you to read proprietary file formats into R. url_stem &lt;- &quot;https://raw.githubusercontent.com/higgi13425/rmrwr-book/master/&quot; haven::read_sas(glue(url_stem, &quot;data/blood_storage.sas7bdat&quot;)) ## # A tibble: 316 × 20 ## rbc_age_group median_rbc_age age aa fam_hx p_vol t_vol t_stage b_gs ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 3 25 72.1 0 0 54 3 1 3 ## 2 3 25 73.6 0 0 43.2 3 2 2 ## 3 3 25 67.5 0 0 103. 1 1 3 ## 4 2 15 65.8 0 0 46 1 1 1 ## 5 2 15 63.2 0 0 60 2 1 2 ## 6 3 25 65.4 0 0 45.9 2 1 1 ## 7 3 25 65.5 1 0 42.6 2 1 1 ## 8 1 10 67.1 0 0 40.7 3 1 1 ## 9 1 10 63.9 0 0 45 2 1 1 ## 10 2 15 63 1 0 67.6 2 1 2 ## # ℹ 306 more rows ## # ℹ 11 more variables: bn &lt;dbl&gt;, organ_confined &lt;dbl&gt;, preop_psa &lt;dbl&gt;, ## # preop_therapy &lt;dbl&gt;, units &lt;dbl&gt;, s_gs &lt;dbl&gt;, any_adj_therapy &lt;dbl&gt;, ## # adj_rad_therapy &lt;dbl&gt;, recurrence &lt;dbl&gt;, censor &lt;dbl&gt;, ## # time_to_recurrence &lt;dbl&gt; Similarly, you can read and write Stata files with read_dta() and write_dta(). Try out the example below. haven::read_dta(glue(url_stem, &quot;data/blood_storage.dta&quot;)) ## # A tibble: 316 × 20 ## rbc_age_group median_rbc_age age aa fam_hx p_vol t_vol t_stage b_gs ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 3 25 72.1 0 0 54 3 1 3 ## 2 3 25 73.6 0 0 43.2 3 2 2 ## 3 3 25 67.5 0 0 103. 1 1 3 ## 4 2 15 65.8 0 0 46 1 1 1 ## 5 2 15 63.2 0 0 60 2 1 2 ## 6 3 25 65.4 0 0 45.9 2 1 1 ## 7 3 25 65.5 1 0 42.6 2 1 1 ## 8 1 10 67.1 0 0 40.7 3 1 1 ## 9 1 10 63.9 0 0 45 2 1 1 ## 10 2 15 63 1 0 67.6 2 1 2 ## # ℹ 306 more rows ## # ℹ 11 more variables: bn &lt;dbl&gt;, organ_confined &lt;dbl&gt;, preop_psa &lt;dbl&gt;, ## # preop_therapy &lt;dbl&gt;, units &lt;dbl&gt;, s_gs &lt;dbl&gt;, any_adj_therapy &lt;dbl&gt;, ## # adj_rad_therapy &lt;dbl&gt;, recurrence &lt;dbl&gt;, censor &lt;dbl&gt;, ## # time_to_recurrence &lt;dbl&gt; You can also read and write SPSS files with read_sav() and write_sav(). Try out the example below. haven::read_sav(glue(url_stem, &quot;data/strep_tb.sav&quot;)) ## # A tibble: 107 × 13 ## patient_id arm dose_strep_g dose_PAS_g gender baseline_condition ## &lt;chr&gt; &lt;dbl+lbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; ## 1 0001 2 [Control] 0 0 2 [M] 1 [1_Good] ## 2 0002 2 [Control] 0 0 1 [F] 1 [1_Good] ## 3 0003 2 [Control] 0 0 1 [F] 1 [1_Good] ## 4 0004 2 [Control] 0 0 2 [M] 1 [1_Good] ## 5 0005 2 [Control] 0 0 1 [F] 1 [1_Good] ## 6 0006 2 [Control] 0 0 2 [M] 1 [1_Good] ## 7 0007 2 [Control] 0 0 1 [F] 1 [1_Good] ## 8 0008 2 [Control] 0 0 2 [M] 1 [1_Good] ## 9 0009 2 [Control] 0 0 1 [F] 2 [2_Fair] ## 10 0010 2 [Control] 0 0 2 [M] 2 [2_Fair] ## # ℹ 97 more rows ## # ℹ 7 more variables: baseline_temp &lt;dbl+lbl&gt;, baseline_esr &lt;dbl+lbl&gt;, ## # baseline_cavitation &lt;dbl+lbl&gt;, strep_resistance &lt;dbl+lbl&gt;, ## # radiologic_6m &lt;dbl+lbl&gt;, rad_num &lt;dbl&gt;, improved &lt;dbl&gt; You can learn more about how to read and write other data file types at haven 5.4 Other strange file types with rio Once in a while, you will run into a strange data file that is not a csv or Excel or or a proprietary format from a common statistical package (SAS, Stata, SPSS). These might include data formats from Systat, Minitab, RDA, feather, or others. This is when the {rio} package comes to the rescue. The name, rio, stands for R Input and Output. The {rio} package looks at the file extension (like .csv, .xls, .dta) to guess the file type, and then applies the appropriate method to read in the data. The import() function in {rio} makes data import much easier. You don’t always have the fine control seen in {readr} or {readxl}, but {rio} is an all-purpose tool that can get nearly any data format into R. Try this out with the code chunk below. Just replace the filename in the code chunk with one of the files named below. Try to use the same import() function to read scurvy.csv strep_tb.tsv paulolol.xlsx blood_storage.sas7bdat rio::import(glue(url_stem, &quot;data/filename&quot;)) ## Error in remote_to_local(file, format = format): Unrecognized file format. Try specifying with the format argument. It can be very convenient to use {rio} for unusual file types. You can read more about the rio package 5.5 Data exploration with glimpse, str, and head/tail Once you have a dataset read into your working Environment (see the Environment tab in RStudio), you will want to know more about it. There are several helpful functions and packages to get you started in exploring your data. 5.5.1 Taking a glimpse with glimpse() The glimpse() function is part of the tidyverse, and is a helpful way to see a bit of all of the variables in a dataset. Let’s try this with the scurvy dataset, which we have already assigned to the object scurvy in the working Environment. Just put the object name as an argument within the glimpse() function (inside the parentheses), as below. Run the code chunk below to get the glimpse() output. glimpse(scurvy) ## Rows: 12 ## Columns: 8 ## $ study_id &lt;chr&gt; &quot;001&quot;, &quot;002&quot;, &quot;003&quot;, &quot;004&quot;, &quot;005&quot;, &quot;006&quot;, &quot;0… ## $ treatment &lt;fct&gt; cider, cider, dilute_sulfuric_acid, dilute_s… ## $ dosing_regimen_for_scurvy &lt;chr&gt; &quot;1 quart per day&quot;, &quot;1 quart per day&quot;, &quot;25 dr… ## $ gum_rot_d6 &lt;fct&gt; 2_moderate, 2_moderate, 1_mild, 2_moderate, … ## $ skin_sores_d6 &lt;fct&gt; 2_moderate, 1_mild, 3_severe, 3_severe, 3_se… ## $ weakness_of_the_knees_d6 &lt;fct&gt; 2_moderate, 2_moderate, 3_severe, 3_severe, … ## $ lassitude_d6 &lt;fct&gt; 2_moderate, 3_severe, 3_severe, 3_severe, 3_… ## $ fit_for_duty_d6 &lt;fct&gt; 0_no, 0_no, 0_no, 0_no, 0_no, 0_no, 0_no, 0_… The glimpse() function output tells you that there are 12 rows (observations) and 8 columns (variables). Then it lists each of the 8 variables, followed by the data type, and the first few values (or as much as will fit in the width of your Console pane). We can see that study_id and dosing_regimen_for_scurvy are both of the character (aka string) data type, and the other 6 variables are factors. 5.5.2 Try this out yourself. What can you learn about the strep_tb dataset with glimpse()? Copy and edit the code chunk below in your local RStudio and run it to find out about the strep_tb dataset, using glimpse(). library(tidyverse) glimpse(----) 5.5.3 Test yourself on strep_tb which variable is the logical data type? baseline_esrimprovedpatient_idbaseline_condition which variable is the dbl numeric data type? armpatient_idrad_numbaseline_temp How many observations are in this dataset? 5.5.4 Examining Structure with str() The str() function is part of the {utils} package in base R, and can tell you the structure of any object in R, whether a list, a dataset, a tibble, or a single variable. It is very helpful for reality-checking your data, especially when you are getting errors in your code. A common source of errors is trying to run a function that requires a particular data structure or data type on the wrong data structure or data type. Sometimes just checking the data structure will reveal the source of an error. The str() function does largely what glimpse() does, but provides a bit more detail, with less attractive formatting. Run the code chunk below to see the output of str() on the scurvy dataset. str(scurvy) ## tibble [12 × 8] (S3: tbl_df/tbl/data.frame) ## $ study_id : chr [1:12] &quot;001&quot; &quot;002&quot; &quot;003&quot; &quot;004&quot; ... ## $ treatment : Factor w/ 6 levels &quot;cider&quot;,&quot;citrus&quot;,..: 1 1 3 3 6 6 5 5 2 2 ... ## $ dosing_regimen_for_scurvy: chr [1:12] &quot;1 quart per day&quot; &quot;1 quart per day&quot; &quot;25 drops of elixir of vitriol, three times a day&quot; &quot;25 drops of elixir of vitriol, three times a day&quot; ... ## $ gum_rot_d6 : Factor w/ 4 levels &quot;0_none&quot;,&quot;1_mild&quot;,..: 3 3 2 3 4 4 4 4 2 1 ... ## $ skin_sores_d6 : Factor w/ 4 levels &quot;0_none&quot;,&quot;1_mild&quot;,..: 3 2 4 4 4 4 4 4 2 1 ... ## $ weakness_of_the_knees_d6 : Factor w/ 4 levels &quot;0_none&quot;,&quot;1_mild&quot;,..: 3 3 4 4 4 4 4 4 1 1 ... ## $ lassitude_d6 : Factor w/ 4 levels &quot;0_none&quot;,&quot;1_mild&quot;,..: 3 4 4 4 4 4 4 4 2 1 ... ## $ fit_for_duty_d6 : Factor w/ 2 levels &quot;0_no&quot;,&quot;1_yes&quot;: 1 1 1 1 1 1 1 1 1 2 ... The str() output starts by telling you that scurvy is a tibble, which is a modern sort of data table. A tibble will by default only print 10 rows of data, and only the number of columns that will fit in your Console pane. Then you see [12 x 8], which means that there are 12 rows and 8 columns - the default in R is to always list rows first, then columns (R x C notation). Then you learn that this is an S3 object, that is a tbl_df (tibble), and also a tbl, and also a data.frame). Then you get a listing of each variable, data type, and a bit of the data, much like glimpse(). Another extra detail provided by str() is that it tells you some of the levels of each factor variable, and then shows these as integers (note that the data for factors is actually stored as integers [in part to save storage space]). 5.5.5 Test yourself on the scurvy dataset what is the dose of cider? 25 drops1 quart per dayone-half rood3 gtt how many levels of gum_rot are there? Which numeric value indicates ‘fit for duty’? Note that you can also use str() and glimpse() on a single variable. You often use this approach when you get an error message that tells you that you have the wrong data type. Try this with the strep_tb dataset variable patient_id by running the code chunk below. Imagine that you wanted to get the mean of patient_id. You got a warning that pointed out that the argument is not numeric or logical. So you run str() to find out the data structure of this variable. mean(medicaldata::strep_tb$patient_id) ## [1] 54 str(medicaldata::strep_tb$patient_id) ## int [1:107] 1 2 3 4 5 6 7 8 9 10 ... This shows you that patient_id is actually a character variable. If you wanted to find the mean value, you would have to change it to numeric (with as.numeric()) first. The glimpse() function provides identical output to str() for a variable in a table. glimpse(medicaldata::strep_tb$patient_id) ## int [1:107] 1 2 3 4 5 6 7 8 9 10 ... You can choose whether you prefer the details of str() or the nicer formatting of glimpse() for yourself. 5.5.6 Examining a bit of data with head() and tail() Oftentimes, you want just a quick peek at your data, especially after a merge or a mutate, to make sure that things have gone as expected. This is where the base R functions head() and tail() can be helpful. As you might have guessed, these functions give you a quick view of the head (top 6 rows) and tail (last 6 rows) of your data. Try this out with scurvy or strep_tb. head(medicaldata::scurvy) ## # A tibble: 6 × 8 ## study_id treatment dosing_regimen_for_sc…¹ gum_rot_d6 skin_sores_d6 ## &lt;chr&gt; &lt;fct&gt; &lt;chr&gt; &lt;fct&gt; &lt;fct&gt; ## 1 001 cider 1 quart per day 2_moderate 2_moderate ## 2 002 cider 1 quart per day 2_moderate 1_mild ## 3 003 dilute_sulfuric_acid 25 drops of elixir of … 1_mild 3_severe ## 4 004 dilute_sulfuric_acid 25 drops of elixir of … 2_moderate 3_severe ## 5 005 vinegar two spoonfuls, three t… 3_severe 3_severe ## 6 006 vinegar two spoonfuls, three t… 3_severe 3_severe ## # ℹ abbreviated name: ¹​dosing_regimen_for_scurvy ## # ℹ 3 more variables: weakness_of_the_knees_d6 &lt;fct&gt;, lassitude_d6 &lt;fct&gt;, ## # fit_for_duty_d6 &lt;fct&gt; tail(medicaldata::strep_tb) ## patient_id arm dose_strep_g dose_PAS_g gender baseline_condition ## 102 100 Streptomycin 2 0 M 3_Poor ## 103 101 Streptomycin 2 0 F 3_Poor ## 104 104 Streptomycin 2 0 M 3_Poor ## 105 105 Streptomycin 2 0 F 3_Poor ## 106 106 Streptomycin 2 0 F 3_Poor ## 107 107 Streptomycin 2 0 F 3_Poor ## baseline_temp baseline_esr baseline_cavitation strep_resistance ## 102 2_99-99.9F/37.3-37.7C 4_51+ yes 3_resist_100+ ## 103 4_&gt;=101F/38.3C 4_51+ yes 3_resist_100+ ## 104 4_&gt;=101F/38.3C 4_51+ yes 3_resist_100+ ## 105 4_&gt;=101F/38.3C 4_51+ yes 3_resist_100+ ## 106 4_&gt;=101F/38.3C 4_51+ yes 3_resist_100+ ## 107 4_&gt;=101F/38.3C 4_51+ yes 3_resist_100+ ## radiologic_6m rad_num improved ## 102 4_No_change 4 FALSE ## 103 2_Considerable_deterioration 2 FALSE ## 104 5_Moderate_improvement 5 TRUE ## 105 2_Considerable_deterioration 2 FALSE ## 106 1_Death 1 FALSE ## 107 6_Considerable_improvement 6 TRUE Note that since these are tibbles, they will only print the columns that will fit into your Console pane. You can see all variables and the whole width (though it will wrap around to new lines) by either (1) converting these to a data frame first, to avoid tibble behavior, or (2) by using print, which has a width argument that allows you to control the number of columns (it also has an n argument that lets you print all rows). Run the code chunk below to see how this is different. head(as.data.frame(medicaldata::scurvy)) ## study_id treatment ## 1 001 cider ## 2 002 cider ## 3 003 dilute_sulfuric_acid ## 4 004 dilute_sulfuric_acid ## 5 005 vinegar ## 6 006 vinegar ## dosing_regimen_for_scurvy gum_rot_d6 skin_sores_d6 ## 1 1 quart per day 2_moderate 2_moderate ## 2 1 quart per day 2_moderate 1_mild ## 3 25 drops of elixir of vitriol, three times a day 1_mild 3_severe ## 4 25 drops of elixir of vitriol, three times a day 2_moderate 3_severe ## 5 two spoonfuls, three times daily 3_severe 3_severe ## 6 two spoonfuls, three times daily 3_severe 3_severe ## weakness_of_the_knees_d6 lassitude_d6 fit_for_duty_d6 ## 1 2_moderate 2_moderate 0_no ## 2 2_moderate 3_severe 0_no ## 3 3_severe 3_severe 0_no ## 4 3_severe 3_severe 0_no ## 5 3_severe 3_severe 0_no ## 6 3_severe 3_severe 0_no print(tail(medicaldata::strep_tb, width = Inf)) ## patient_id arm dose_strep_g dose_PAS_g gender baseline_condition ## 102 100 Streptomycin 2 0 M 3_Poor ## 103 101 Streptomycin 2 0 F 3_Poor ## 104 104 Streptomycin 2 0 M 3_Poor ## 105 105 Streptomycin 2 0 F 3_Poor ## 106 106 Streptomycin 2 0 F 3_Poor ## 107 107 Streptomycin 2 0 F 3_Poor ## baseline_temp baseline_esr baseline_cavitation strep_resistance ## 102 2_99-99.9F/37.3-37.7C 4_51+ yes 3_resist_100+ ## 103 4_&gt;=101F/38.3C 4_51+ yes 3_resist_100+ ## 104 4_&gt;=101F/38.3C 4_51+ yes 3_resist_100+ ## 105 4_&gt;=101F/38.3C 4_51+ yes 3_resist_100+ ## 106 4_&gt;=101F/38.3C 4_51+ yes 3_resist_100+ ## 107 4_&gt;=101F/38.3C 4_51+ yes 3_resist_100+ ## radiologic_6m rad_num improved ## 102 4_No_change 4 FALSE ## 103 2_Considerable_deterioration 2 FALSE ## 104 5_Moderate_improvement 5 TRUE ## 105 2_Considerable_deterioration 2 FALSE ## 106 1_Death 1 FALSE ## 107 6_Considerable_improvement 6 TRUE It is actually much easier to see the full width and height of a data set by scrolling, which you can do when you View() a dataset in the RStudio viewer. Try this out in the Console pane, with View(strep_tb). 5.5.7 Test yourself on the printing tibbles What function (and argument) let you print all the columns of a tibble? print(x, width=Inf)filter(starts_with(“width”))sum(na.rm=TRUE)print(wide) What function (and argument) let you print all the rows of a tibble? filter(ends_with(“all”))median(na.rm=TRUE)print(x, n=Inf)print(long) If you just want a quick view of a few critical columns of your data, you can obtain this with the select() function, as in the code chunk below. Note that if you want to look at a random sample of your dataset, rather than the head or tail, you can use slice_sample() to do this. This sampling can be helpful if your data are sorted, or the head and tail rows are not representative of the whole dataset. See how this is used by running the code chunk below, which uses a 10% random sample of strep_tb to check that the mutate steps to generate the variables rad_num and improved worked correctly. #check that radiologic_6m, rad_num, and improved all match medicaldata::strep_tb %&gt;% slice_sample(prop = 0.1) %&gt;% select(radiologic_6m, rad_num, improved) ## radiologic_6m rad_num improved ## 1 5_Moderate_improvement 5 TRUE ## 2 6_Considerable_improvement 6 TRUE ## 3 6_Considerable_improvement 6 TRUE ## 4 5_Moderate_improvement 5 TRUE ## 5 4_No_change 4 FALSE ## 6 6_Considerable_improvement 6 TRUE ## 7 2_Considerable_deterioration 2 FALSE ## 8 5_Moderate_improvement 5 TRUE ## 9 1_Death 1 FALSE ## 10 3_Moderate_deterioration 3 FALSE 5.6 More exploration with skimr and DataExplorer Once you have your data read in, you usually want to get an overview of this new dataset. While there are many ways to explore a dataset, I will introduce two: skim() from the {skimr} package create_report() from the {DataExplorer} package You can get a more detailed look at a dataset with the {skimr} package, which has the skim() function, gives you a quick look at each variable in the dataset, with simple output in the Console. Try this out with the strep_tb dataset. Run the code chunk below, applying the skim() function to the strep_tb dataset. library(skimr) skimr::skim(medicaldata::strep_tb) Table 5.1: Data summary Name medicaldata::strep_tb Number of rows 107 Number of columns 13 _______________________ Column type frequency: character 8 logical 1 numeric 4 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace arm 0 1.00 7 12 0 2 0 gender 0 1.00 1 1 0 2 0 baseline_condition 0 1.00 6 6 0 3 0 baseline_temp 0 1.00 14 34 0 6 0 baseline_esr 1 0.99 5 7 0 3 0 baseline_cavitation 0 1.00 2 3 0 2 0 strep_resistance 0 1.00 10 13 0 3 0 radiologic_6m 0 1.00 7 28 0 6 0 Variable type: logical skim_variable n_missing complete_rate mean count improved 0 1 0.51 TRU: 55, FAL: 52 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist patient_id 0 1 54.00 31.03 1 27.5 54 80.5 107 ▇▇▇▇▇ dose_strep_g 0 1 1.03 1.00 0 0.0 2 2.0 2 ▇▁▁▁▇ dose_PAS_g 0 1 0.00 0.00 0 0.0 0 0.0 0 ▁▁▇▁▁ rad_num 0 1 3.93 1.89 1 2.0 5 6.0 6 ▇▅▁▆▇ 5.6.1 Test yourself on the skim() results How many females participated in the strep_tb study? 52594837 What proportion of subjects in strep_tb were improved? 0.710.4930.5140.55 What is the mean value for rad_num in strep_tb? 7.443.931.894.7 A fancier approach is taken by the DataExplorer package, which can create a full html report with correlations and PCA analysis. Copy and run the chunk below to see what the Data Profiling Report looks like. DataExplorer::create_report(medicaldata::strep_tb) 5.6.2 Test yourself on the create_report() results What percentage of the baseline_esr values were missing? 9.3%0.09%0.93%1% How many total data points (‘observations’) are there in the strep_tb dataset? 10,0001071,39117 You can choose which you prefer, the simpler approach of {skimr} vs the fancier reports of {DataExplorer.} 5.7 Practice loading data from multiple file types 5.8 Practice saving (writing to disk) data objects in formats including csv, rds, xls, xlsx and statistical program formats 5.9 How do readr and readxl parse columns? 5.10 What are the variable types? Variable Type Long form Abbreviation Logical (TRUE/FALSE) col_logical() l Integer col_integer() i Double col_double() d Character col_character() c Factor (nominal or ordinal) col_factor(levels, ordered) f Date col_date(format) D Time col_time(format) t Date &amp; Time col_datetime(format) T Number col_number() n Don’t import col_skip() - Default Guessing col_guess() ? 5.11 Controlling Parsing 5.12 Chapter Challenges There is a file named “paulolol.xlsx” with the path of ‘data/paulolol.xlsx’. A picture of this problematic file is shown below. paulolol Read in this file with the {readxl} package. Just for fun, try this see how this turns out with no additional arguments. Be sure to skip the problematic non-data first few rows Be sure to exclude the problematic non-data calculations below the table. Solution to Challenge 1: paulolol.xlsx Show Me Solution 1 read_excel(path = &#39;data/paulolol.xlsx&#39;, skip = 3, n_max = 8) ## # A tibble: 8 × 6 ## pat_id SBP_start SBP_end HR_start HR_end treatment ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 145 120 92 78 paulolol ## 2 2 147 148 88 87 placebo ## 3 3 158 139 96 80 paulolol ## 4 4 167 166 87 88 placebo ## 5 5 154 131 84 72 paulolol ## 6 6 178 177 99 97 placebo ## 7 7 151 134 101 86 paulolol ## 8 8 149 148 92 93 placebo Our intrepid Investigator has inserted a chart in place of his data table on sheet 1, and moved the data table to a 2nd sheet named ‘data’, and placed in the top left corner, at the suggestion of his harried statistician, in a new file with the path of ’data/paulolol2.xlsx” Try reading this file in with read_excel() read the help file help(read_excel) to figure out how to read in the data from this excel file. Solution to Challenge 2: paulolol2.xlsx Show Me Solution 2 read_excel(path = &#39;data/paulolol2.xlsx&#39;, sheet = &#39;data&#39;) ## # A tibble: 8 × 6 ## pat_id SBP_start SBP_end HR_start HR_end treatment ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 145 120 92 78 paulolol ## 2 2 147 148 88 87 placebo ## 3 3 158 139 96 80 paulolol ## 4 4 167 166 87 88 placebo ## 5 5 154 131 84 72 paulolol ## 6 6 178 177 99 97 placebo ## 7 7 151 134 101 86 paulolol ## 8 8 149 148 92 93 placebo 5.13 Future forms of data ingestion https://www.datacamp.com/community/tutorials/r-data-import-tutorial?utm_source=adwords_ppc&amp;utm_campaignid=1658343521&amp;utm_adgroupid=63833880415&amp;utm_device=c&amp;utm_keyword=%2Bread%20%2Bdata%20%2Br&amp;utm_matchtype=b&amp;utm_network=g&amp;utm_adpostion=&amp;utm_creative=469789579368&amp;utm_targetid=aud-392016246653:kwd-309793905111&amp;utm_loc_interest_ms=&amp;utm_loc_physical_ms=9016851&amp;gclid=Cj0KCQjwxJqHBhC4ARIsAChq4auwh82WzCiJsUDzDOiaABetyowW0CXmTLbUFkQmnl1pn4Op9xcCcdQaAhMWEALw_wcB reading data from the web with readr reading data from Google Sheets with {googlesheets} reading data from REDCap, and tidying reading data from web tables with rvest "],["wrangling-rows-in-r-with-filter.html", "Chapter 6 Wrangling Rows in R with Filter 6.1 Goals for this Chapter 6.2 Packages needed for this Chapter 6.3 Pathway for this Chapter 6.4 Logical Statements in R 6.5 Filtering on Numbers - Starting with A Flipbook 6.6 Filtering on Multiple Criteria with Boolean Logic 6.7 Filtering Strings 6.8 Filtering Dates 6.9 Filtering Out or Identifying Missing Data 6.10 Filtering Out Duplicate observations 6.11 Slicing Data by Row 6.12 Randomly Sampling Your Rows 6.13 Further Challenges 6.14 Explore More about Filtering", " Chapter 6 Wrangling Rows in R with Filter In this chapter, we will introduce you ways to wrangle rows in R. You will often want to focus your analysis on particular observations, or rows, in your dataset. This chapter will show you how to include the rows you want, and exclude the rows you don’t want. The main function in the tidyverse for doing this is filter(). The filter() function uses logical statements, or conditions, to decide whether to keep or exclude rows in your dataset. Figure 6.1: Artwork by Allison Horst, https://www.allisonhorst.com 6.1 Goals for this Chapter Understand logical statements Filter rows based on numeric values Filter rows based on string values and regex Filter rows based on dates Combine filters with boolean logic symbols, like AND (&amp;) and OR(|) Filter on missing (NA) values Filter rows for duplicates/distinct observations Slicing rows based on row number/position Sampling rows as random samples 6.2 Packages needed for this Chapter {tidyverse} {lubridate} {medicaldata} 6.3 Pathway for this Chapter This Chapter is part of the DATA WRANGLING pathway. Chapters in this pathway include What is Tidy Data? Filtering Rows Counting, Grouping, and Summarizing Rows Arranging and Ranking Rows Selecting Columns Mutating to Make New Variables Rearranging Untidy data with {tidyr} and {pivotr} 6.4 Logical Statements in R Logical statements in R are important for defining something that is TRUE or FALSE for each row, or observation, in your data. A typical logical statement involves a variable, and some criteria to test each observation of that variable, resulting in a TRUE or FALSE for each row. Typical examples of logical statements include: sbp &gt; 140 troponin_i &gt; 9.0 creatinine &gt;= 2.5 gfr &lt;= 60 Each of these examples tests each row in the database with the stated criterion, and results in a vector of TRUE or FALSE values for each row (observation) of the variable in the logical statement. The filter() function will act on these TRUE and FALSE values to include (TRUE) or exclude (FALSE) the observations from the result. 6.5 Filtering on Numbers - Starting with A Flipbook This flipbook will show you step-by-step examples of how to filter rows of observations based on logical statements involving numbers. In each logical statement, a variable will be compared with a numeric value via a mathematical operator. These operators can include comparisons with greater than (&gt;) greater than or equal to (&gt;=) less than (&lt;) less than or equal to (&lt;=) equal to (==) notice two equals signs to test equality near() - an equality test that works with tiny decimal differences The general format for filter statements is: filter(variable [comparison operator] value), like filter(sbp &gt; 140) will keep only rows with systolic blood pressure values greater than 140. If you have not used a flipbook before, you can click on the frame below to activate it, then use the right and left arrow keys to move forward and back through the examples. With each forward step in the code on the left, examine the resulting output on the right. Make sure you understand how the output was produced. In many of the examples, a select() function is used to reduce the number of columns before the filter() step to make the results more clear. You saw several examples of filtering, including Example Code equality to a value filter(recurrence == 1) greater than a value filter(preop_psa &gt; 20) near a value filter(near(preop_psa, 10)) near a value with a set tolerance filter(near(preop_psa, 17, tol = 1.5)) between 2 values filter(between(preop_psa, 10, 13)) in a list of values filter(preop_psa %in% c(10,13,17)) 6.5.1 Your Turn - learnr exercises Try this out yourself, with interactive coding exercises below, written with the {learnr} package. For each exercise, you can type in the code required,by the instructions, then click on the blue Run Code button at the top right of the exercise to test your code. Watch out for a red x in the left margin - that identifies a coding error - hover over it for an explanation of what is wrong. If you get stuck, you can click on the Hint button to get a hint, and if needed, the Copy Clipboard button to copy the hint so that you can paste it into the Exercise box. 6.6 Filtering on Multiple Criteria with Boolean Logic You can use multiple filters on your data, and combine these with the boolean symbols AND (symbol &amp;) OR (symbol | ) - the vertical line, often on the keyboard above the backslash character ( \\ ) XOR - exclusive OR, so that the whole logical statement is true if either statement A is true, or statement B is true, but NOT if both are true. parentheses and combinations thereof. NEGATION - an exclamation point ( ! ) placed before an equals sign or a variable in a logical statement makes it mean the opposite. and you can use parentheses as well, to control the order of operations. You saw several examples of filtering, including Example Code AND filter(age &gt; 65 &amp; t_vol&gt;1) OR filter(age &gt; 69 | t_vol &gt; 1) exclusive OR (XOR) filter(xor(age &gt; 69, t_vol &gt; 1)) AND with negation (!) filter(age &gt; 64 &amp; aa != 1) 6.6.1 Your Turn - learnr exercises Try this out yourself, with interactive coding exercises below, written with the {learnr} package. For each exercise, you can type in the code required,by the instructions, then click on the blue Run Code button at the top right of the exercise to test your code. Watch out for a red x in the left margin - that identifies a coding error - hover over it for an explanation of what is wrong. If you get stuck, you can click on the Hint button to get a hint, and if needed, the Copy Clipboard button to copy the hint so that you can paste it into the Exercise box. 6.7 Filtering Strings You can use == to test exact equality of strings, but you can also use str_detect from the {stringr} package for more flexible matching, and combine it with the magic of regex (regex ~ Regular expressions) to do complicated filtering on character string variables in datasets. The typical formats for string filtering are filter(variable == “string”) for an exact match, or filter(str_detect(variable, pattern = “string”)) [note two parentheses at the end to completely close the parentheses with str_detect] You saw several examples of filtering strings, including Example Code matches “oma” filter(str_detect(diagnosis, “oma”)) negated match filter(!str_detect(diagnosis, pattern = “Hodgkin”)) regex for wild card filter(str_detect(diagnosis, pattern = “lympho.+ic”)) regex wild card filter(str_detect(diagnosis, “myelo.*”)) exact match filter(diagnosis == “myelofibrosis”) 6.7.1 Your Turn - learnr exercises Try matching strings yourself, in the interactive coding exercises below, written with the {learnr} package. For each exercise, you can type in the code required,by the instructions, then click on the blue Run Code button at the top right of the exercise to test your code. Watch out for a red x in the left margin - that identifies a coding error - hover over it for an explanation of what is wrong. If you get stuck, you can click on the Hint button to get a hint, and if needed, the Copy Clipboard button to copy the hint so that you can paste it into the Exercise box. 6.8 Filtering Dates You can use the {lubridate} package to format strings for logical tests, and filter your observations by date, month, year, etc. Dates are commonly formatted in ISO 8601 format, or YYYY-MM-DD, for 4-digit year, 2-digit month, and 2-digit day. The {lubridate} package can convert these to dates if the ymd() function is applied to a string formatted this way. The typical formats for date filtering are filter(date == ymd(“2002-10-06”)) for an exact match, or filter(between(datevar, ymd(“2020-01-01”, ymd(“2020-06-30”)) filter(datevar &gt; today() - years(1)) for the past year &lt;&lt;&lt;&lt;&lt;&lt;&lt; Updated upstream You saw several examples of filtering dates, including Example Code between 2 dates filter(between(fake_date, ymd(“2020-03-01”), ymd(“2020-03-31”) 24 months prior to today filter(fake_agvhd_date &gt; today() - months(24)) filter to weekdays 1 or 7 (weekend) filter(wday(fake_bmt_date) %in% c(1,7)) 6.8.1 Your Turn - learnr exercises Try matching dates yourself, in the interactive coding exercises below, written with the {learnr} package. For each exercise, you can type in the code required,by the instructions, then click on the blue Run Code button at the top right of the exercise to test your code. Watch out for a red x in the left margin - that identifies a coding error - hover over it for an explanation of what is wrong. If you get stuck, you can click on the Hint button to get a hint, and if needed, the Copy Clipboard button to copy the hint so that you can paste it into the Exercise box. 6.9 Filtering Out or Identifying Missing Data You can use the is.na(), drop_na() and negation with ! to help identify and filter out (or in) the missing data, or observations that are incomplete. Common formats for this include is.na(variable) - filters for observations where the variable is missing !is.na(variable) - filters for observations where the variable is not missing janitor::remove_empty(“rows”) - removes completely empty rows (helpful if you are importing a messy dataset) drop_na() - without filter, this drops any observations with at least one NA value in the row. drop_na(variable1, variable2) - without filter, this drops any observations with at least one NA value iin the variable1 or variable2 columns. 6.9.1 Working with Missing data A common need when doing DEV (Data Exploration and Validation) is to find your missing datapoints, so that you can figure out why they are missing, and whether you can fix this using other records, including the medical record. Another common scenario, when you can’t find or fix missing data, is that you want to drop observations which are missing in a particular variable. Sometimes you will need to drop whole empty rows, which usually happens because of poor formatting of the data (often in a spreadsheet). Sometimes you will need to drop observations that have missing data in any field, which is important in modeling. Linear and logistic models generally only run on complete cases, where all predictors and outcomes are non-missing. You can also impute missing data points, if there are not too many (&lt;10%), and these are truly missing completely at random (MCAR), which is often not the case. Usually there is a bias, so that particular types of study participants have more missing data than others. The packages {missForest} and {mice} can be helpful for imputation when MCAR assumptions are met. Imputation is beyond the scope of this chapter, and should generally be done in consultation with a statistician, as the assumptions involved are very important. You saw several examples of filtering missing data, including Example Code filtering for the missing observations in a variable fi lter(is.na(fake_date)) filter for the non-missing data in a variable filter (!is.na(fake_dx_date)) removing empty rows remove_empty(“rows”) removing incomplete cases drop_na() 6.9.2 Your Turn - learnr exercises 6.10 Filtering Out Duplicate observations You can use the distinct() function and the {janitor} package to help you find duplicated observations/rows for fixing or removal from your dataset. Common formats for this include distinct(dataset) - filters for rows that are distinct from all the other rows (non-duplicates). janitor::get_dupes(dataset) - filters for observations that are duplicated in all variables, counts them, and displays them in duplicated groups. You saw several examples of filtering duplicate data, including Example Code distinct observations distinct(dataset) finding duplicates get_dupes(dataset) making the complementary dataset dataset_whole %&gt;% anti_join(data_subset) 6.11 Slicing Data by Row You can use the slice() family of functions to cut out a chunk of your observations/rows by position in the dataset.. Common formats for this include slice(X:Y) - filters for rows X to Y by position (row number). slice_max(variable, n = N) - filters for observations with the maximum N values for a single variable. slice_min(variable, prop = 0.0N) - filters for observations with the minimum proportion of 0.0N values for a single variable. slice_head and slice_tail - filter for observations by position in the top (or bottom) N or top/bottom proportion. You saw several examples of slicing data, including Example Code slice by position slice(100:200) slice by top values in variable slice_max(age, n=20) slice by bottom values in variable slice_min(pan_day, prop = 0.01) slice by top or bottom position slice_tail(prop = 0.01) 6.12 Randomly Sampling Your Rows You can use the slice_sample() function to take a random subset of large datasets, or to build randomly selected training and testing sets fo modeling. Common formats for this include slice_sample(prop = 0.N) - randomly samples N % of your rows. slice_sample(n = N) - randomly samples N of your rows. You saw several examples of sampling data, including Example Code sampling a proportion slice_sample(prop = 0.3) sampling N rows slice_sample(n = 50) 6.12.1 Your Turn - learnr exercises 6.13 Further Challenges Try filtering on your own computer. Install R and Rstudio, as in Chapter 2. Then make sure you have the following packages installed, as in the Installing Packages chapter: tidyverse medicaldata Read in data from the medicaldata datasets with data(name) Then try some of the following challenges filter the cytomegalovirus dataset for rows with time to acute gvhd &lt; 6 months and CD3 dose &gt; 4 filter the opt dataset for Birthweight between 2500 grams and 3500 grams, or Apgar &gt;=6 filter the covid_testing dataset for females tested in the first 30 days of the pandemic with positive results 6.14 Explore More about Filtering Some helpful resources include: Suzan Baert’s blog series on dplyr, part 3 about filtering is found here. The tidyverse guide to filtering, found here. A blog post on filtering by Michael Toth, found here. The RYouWithMe series from RLadiesSyndey post on filtering here. "],["the-basics-of-r.html", "Chapter 7 The Basics of R 7.1 Why Programming? 7.2 Programming Fears 7.3 Thinking about Wofkflow 7.4 Files in R 7.5 Paths in R 7.6 Creating variables in R 7.7 The Pipe Operator 7.8 R Dialects", " Chapter 7 The Basics of R R is a programming language launched on February 29, 2000, by Ross Ihaka and Rpbert Gentleman. It was developed specifically to enable programming for statistics, and to focus on data handling and manipulation, which was not a focus of general computer languages. R is a dialect of the S language, which was developed at Bell Labs in the 1970s. R is a free software environment, and is available for Windows, Mac, and Linux. 7.1 Why Programming? For many people, spreadsheets are their first introduction to data analysis. Spreadsheets combine data entry and storage, data display, programming (formulas) to analyze and summarize data, and graphical plotting of data in one format. Spreadsheets are a great way to get started, but compromises are needed for this all-in-one approach, and they have major limitations. Spreadsheets are not reproducible for data points. If you make a change to a data point in a spreadsheet, it can be hard to remember what you did, and why you did it. There is no audit trail to track who changed the data point, when it was changed, and why. Dedicated data storage programs, like REDCap, do this much better. Data manipulation in spreadsheets is not reproducible. It is mostly point-and-click, with some hidden programming (in formulas) which is fine for simple manipulations, but becomes hard to reproduce exactly when you have 10 (or 100) steps. The programming in spreadsheets is hidden in formulas. It can be hard to find the formulas, and hard to test/debug them, or even to detect when they are doing the wrong thing. There are many famous Excel errors that have been resulted in spectacular failures. See the ‘London Whale’ $6 billion loss at JP Morgan The programming in spreadsheets is limited. You can’t write a loop in a spreadsheet, or a function. You can’t write a program that will run on a schedule, or write a program to produce the same kind of graph or to reproducibly do tha same data manipulation. All of the graphical user interface (GUI) features are convenient, but are hard to reproduce. You can look at a graph in Excel easily, but even if you made it yourself, it can be difficult to figure out how to reproduce it exactly. Each step in the point and click workflow has to be reproduced, and these are not recorded anywhere. If someone else made the plot, it can be nearly impossible to reproduce it. Programming is the process of creating a specific list of instructions for a computer to load a dataset, manipulate it, then generate summaries, tables, and plots, which then go into manuscripts, posters, and presentations. The computer can do all of this reproducibly, and the written instructions (code) can be saved, shared, and reused. The computer can reproduce your entire manuscript from the raw data at the push of a button. And anyone given the same data and instructions can: reproduce all of your tables, plots, and manuscripts check the validitty of your analysis. extend your analysis to new data, or new questions. This approach makes medical research more reliable and more reproducible. It also makes it easier to collaborate with others, and to share your work with the world. 7.2 Programming Fears If you have never written code (programs) before, it can be a bit intimidating at first. There is a lot of mythology about programming. People think you have to be a genius, or a math whiz, or a computer scientist to write code. This is not true. Programming is a skill, like any other, that can be learned. It is a bit like learning a new language, or learning to play a musical instrument. It takes time, and practice, but anyone can do it. Importantly, computers are very literal. They do exactly what you tell them to do, and nothing else. This can be frustrating, but it is also a great advantage. If you can learn to write code, you can get the computer to do exactly what you want, every time. This is a powerful tool, and can save you a lot of time and effort. Perhaps the most important part of programming is getting the details of the syntax right. Syntax is the grammar of the programming language. It is the rules that you have to follow to get the computer to understand what you want it to do. If you get the syntax wrong, the computer will not understand you, and will not do what you want. This can be frustrating, but folks who are detail-oriented, and are used to checking their work, are often very good at programming. This is why a lot of medical people find that the approaches used in medicine (attention to detail, checking your work, being careful) are very helpful in programming. Remember, you can do this, and that there are a lot of tools and community resources to help you. It will be frustrating at first, but with time and practice, you will gain a great power - the ability to take data on medical topics and turn it into useful knowledge that can help people. 7.3 Thinking about Wofkflow When you are programming, you are creating a workflow. A workflow is a series of steps that you take to get from raw data to a finished product. This can be a manuscript, a poster, or a presentation. The workflow is the series of steps that you take to get from the raw data to the finished product. A typical workflow might look like this: Load/import the data Explore and Validate the data Clean the data as needed to get to a Tidy format Merge with other datasets as needed Transform the data - wrangle or reshape as needed Analyze the data Descriptive statistics like Table 1 Inferential statistics like t-tests, or chi-squared tests, for primary and secondary endpoints. Advanced analyses like linear or logistic models of outcomes Descriptive counts of adverse events Generate Outputs to Communicate the Results Tables of data - table 1, tables of adverse events, and regression tables Graphs - histograms, scatterplots, jittered/violin plots, and survival curves Complete manuscripts (with RMarkdown and Quarto) Posters and presentations All of the programming we do with data will be done in order to achieve this sort of workflow with your data. We will start with the basics of R, and then move on to more advanced topics as we go. 7.4 Files in R There are generally two major categories of files that you will work with in R: 1. Data files 2. Script (or code) files 7.4.1 Data Files Data files are files that contain data. They can be in many formats (named as file.extension), but the most common are: .csv files - comma separated values .xlsx files - Excel files .RDS files - R data files .Rda files - R data that can bundle multiple files into one file - these are used less often arrow files - these are a new format that is very fast for big data (similar to feather or parquet files) and you can import data files from other programs, like .sav files - SPSS files .dta files - Stata files .sas7bdat files - SAS files Most of your data importing can be accomplished with the {readr} package, though the {readxl} and {haven} packages are very useful for data coming from Excel, SPSS, Stata, and SAS. 7.4.2 Script files Script files are files that contain code. They can be in many formats, but the most common are: .R files - R script files These .R files are nearly all code, and to write a comment in the file about your code you need to use a hashtag(#) before the text. Writing comments is important for reproducibiiity, as it helps you remember what you were doing, and helps others understand your code. There are also specialized script files that make it easier to include comments, or even to write a whole manuscript (with R code chunks mixed in to produce the output). These include: .Rmd files - RMarkdown files .qmd files - Quarto files This kind of script file enables you to create a variety of outputs, including manuscripts, presentations, websites, and live web applications that users can interact with. 7.4.3 Other files You will also see other files in R projects, including: .html files - web page output for sharing .docx files - Microsoft Word files .pptx files - Microsoft PowerPoint files .xlsx files - Microsoft Excel files .pdf files - Adobe Acrobat files .png, .jpg, .svg files - image files .csv files - comma separated values files .yaml files - Yet Another Markup Language files - to format output like HTML, Word, or powerpoint .Rproj files - R project files - an anchor indicator file used to organize projects .git files - git version control files - used to track changes in your code .log files - log files that record the output of your code 7.5 Paths in R Paths are how the computer keeps track of where your files are stored. Paths can be relative or absolute. Relative paths are paths that are relative to the current working directory. Absolute paths are paths that are the full path from the root directory of the computer to the file. A typical absolute path might look like this: C:/Users/username/Documents/MyData/mydata.csv while a typical relative path, while you are working in your Documents folder, might look like this: MyData/mydata.csv Making sure that you have the right path to read or write a file is very important in all programming languages. If you get the path wrong, R will not be able to find the file, and will give you an error. This can be frustrating, but with practice, you will get better at managing paths. At times you may need to jump into your file system to track down a particular file that is not in the path that you expected. 7.6 Creating variables in R Unlike some computer languages, you do not have to ‘declare’ variables in R. You can just start using them. This is called ‘dynamic typing’. You can create a variable by assigning a value to it with the &lt;- (assignment) operator (often called the arrow). For example, in the code chunk below: my_variable &lt;- 5 we are creating a variable called my_variable and assigning it the value 5. You can also use the = or the -&gt; operator to assign values to variables, but the &lt;- operator is more common in R. The rightward arrow operator -&gt; can be handy if you have used multiple steps to wrangle some data, and you want to assign the result to a new variable. For example, in the code chunk below: library(palmerpenguins) # 1 ## ## Attaching package: &#39;palmerpenguins&#39; ## The following objects are masked from &#39;package:datasets&#39;: ## ## penguins, penguins_raw penguins |&gt; # 2, # 3 filter(species == &quot;Adelie&quot;) |&gt; # 4 select( # 5 species, bill_length_mm, bill_depth_mm ) -&gt; adelie_penguins # 6 head(adelie_penguins) # 7 ## # A tibble: 6 × 3 ## species bill_length_mm bill_depth_mm ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie 39.1 18.7 ## 2 Adelie 39.5 17.4 ## 3 Adelie 40.3 18 ## 4 Adelie NA NA ## 5 Adelie 36.7 19.3 ## 6 Adelie 39.3 20.6 We 1. loaded the palmerpenguins package with library 2. started with the penguins dataset 3. Used the pipe operator |&gt; to pass the penguins data to the filter function 4. Filtered the data to only include the Adelie species 5. Selected only the species, bill_length_mm, and bill_depth_mm variable columns 6. Assigned the result with the rightward arrow to a new variable called adelie_penguins 7. Printed the first 6 rows (the head) of the adelie_penguins dataset 7.7 The Pipe Operator The pipe is a tool to feed the result of the prior step of code into the next step. This is often very helpful in cleaning and reshaping data (often called wrangling data). The pipe operator can be written as %&gt;% or |&gt; and is read as and then. It is a way to make your code more readable, and to avoid having to nest functions inside each other. The pipe operator is part of the magrittr package, which is loaded by default with the tidyverse package. Making your code more readable by humans (not just by computers) is the idea behind literate programming, which is a programming philosophy. A program written with literate programming principles is easier for humans to read, to check the validity of, and easier to debug if there are problems. 7.8 R Dialects Most of the R code you will see is written in the tidyverse dialect of R. This is a set of packages that are designed to work together to make data wrangling and visualization easier. However, for many years before the tidyverse was created, the base R dialect was the most common. The base R dialect is still used in many packages, and is the underlying structure of R. The base R dialect is more verbose, and often requires more code to accomplish the same task as the tidyverse dialect. However, the base R dialect is also more explicit, and there are times when using the base R dialect is an easier way to solve a specific problem. In base R, a variable is referred to in the context of its dataset, so you would write penguins$species to refer to the species variable in the penguins dataset. Base R also uses brackets to refer to specific data values in a dataset. For example, to refer to the first row of the species variable in the penguins dataset, you would write penguins$species[1]. Or to refer to the value in the 5th row and the 3rd column in the penguins dataset, you would write penguins[5,3]. The bracket notation assumes that you always list rows first, then columns. In the base dialect, you can create a new variable by assigning it, just like in the tidyverse dialect. In the code chunk below, you can see two ways to create a new variable in the penguins dataset, one using the base R dialect, and one using the tidyverse dialect: # base R version penguins$bill_ratio &lt;- penguins$bill_length_mm / penguins$bill_depth_mm # tidyverse version penguins &lt;- penguins |&gt; mutate(bill_ratio = bill_length_mm / bill_depth_mm) Both approaches work. At times, you may need to use the base R dialect, to get specific tasks done that are simply easier in base R. While we will be largely focused on the tidyverse dialect in this course, it is important to be aware of the base R dialect, and to be able to read and write code in both dialects. "],["wrangling-columns-in-r-with-select-rename-and-relocate.html", "Chapter 8 Wrangling Columns in R with Select, Rename, and Relocate 8.1 Goals for this Chapter 8.2 Packages needed for this Chapter 8.3 Pathway for this Chapter 8.4 Tidyselect Helpers in R 8.5 Selecting a Column Variables 8.6 Selecting Columns that are Not Contiguous 8.7 Selecting Columns With Logical Operators 8.8 Further Challenges 8.9 Explore More about Filtering", " Chapter 8 Wrangling Columns in R with Select, Rename, and Relocate In this chapter, we will introduce you ways to wrangle columns in R. Data wrangling refers broadly to the many things you might do to make disorderly data more organized and tidy. You will often want to focus your analysis on particular variables, or columns, in your dataset. This chapter will show you how to include the columns you want, and exclude the columns you don’t want. You will also learn how to rename and relocate your columns in your dataset. We will also learn some good general practices for column naming, which is often more important than people realize. The main functions in the tidyverse for doing column functions are select(), rename(), rename_with(), and relocate(). The select() function can use a number of logical statements, and functional helpers, to decide whether to keep or exclude rows in your dataset. Figure 6.1: Artwork by Allison Horst, https://www.allisonhorst.com 8.1 Goals for this Chapter Understand select statements Select rows based on name and number Select rows with helpers including starts_with(), ends_with() Select rows with helpers including contains(), matches() Relocate column variables within your dataset with relocate Rename column variables within your dataset with rename() and rename_with() 8.2 Packages needed for this Chapter {tidyverse} {janitor} {medicaldata} 8.3 Pathway for this Chapter This Chapter is part of the DATA WRANGLING pathway. Chapters in this pathway include What is Tidy Data? Selecting, Renaming, and Relocating Columns Filtering Rows Counting, Grouping, and Summarizing Rows Arranging and Ranking Rows Mutating to Make New Variables Rearranging Untidy data with {tidyr} and {pivotr} 8.4 Tidyselect Helpers in R Tidyselect helpers in R are functions that help you select a specfic group of columns. A typical tidyselect helper function defines which variables match your criteria. Typical examples of tidyselect helper functions include: starts_with(“preop”) - matches preop_bp, preop_hr, preop_psa ends_with(“pain”) - matches abd_pain, extremity_pain, wound_pain contains(“bp”) - matches bp_screening, end_bp, first_bp_am matches(“week[0-9]”) - matches week4, week8, week0 everything() - all columns last_col() - the last column num_range(“wk”, 1:6) - matches wk1, wk3, wk6, but not wk7 where(is.numeric) - selects variables of numeric type Each of these examples of logical tests will each column in your dataframe with the included argument - the criteria within the parentheses, and results in a vector of TRUE or FALSE values for each column (variable) of the dataframe. The select() function will act on these TRUE and FALSE values to include (TRUE) or exclude (FALSE) the column variables from the resulting dataframe. 8.5 Selecting a Column Variables The general format for select statements is: select(variable1, variable_name3:variable_name17, variable55), which selects by name the first variable, the 3rd through the 17th, and the 55th variable (you use just the variable names, the numbers are just to illustrate how to use the colon operator), and drops the rest. You can also negatively select against variables, with the negative sign, as in select(-sbp, -hr) These logical statements can even be sequential within a select() function, to help clarify selections, as in when you want “age” but not “stage”. select(contains(\"age\"), -stage) You can also select variables by their column number, (though this can get ugly if column numbers change), as in select(1:5, 17:22) 8.5.1 Try this out Copy the code block below to your RStudio Console, and run it to get started. library(tidyverse) library(medicaldata) medicaldata::blood_storage %&gt;% select(everything()) %&gt;% head() Now replace the argument to the select statement (everything()) with 1:5. Run this - you should get only the first 5 columns, instead of all the columns. Now try this with AnyAdjTherapy:TimeToRecurrence as the argument to get the last 5 columns. You can use the colon operator to get any continguous group of columns between the start:end columns (inclusive of the start and end columns). Experiment for yourself to get specific groups of contiguous columns. 8.6 Selecting Columns that are Not Contiguous You can select any non-contiguous columns by inserting a comma between the columns selected. You can even select one column at a time. For example medicaldata::blood_storage %&gt;% select(1, bGS:sGS, 3, AA) %&gt;% head() RBC.Age.Group bGS BN+ OrganConfined PreopPSA PreopTherapy Units sGS Age AA 1 3 3 0 0 14.08 1 6 1 72.1 0 2 3 2 0 1 10.50 0 2 3 73.6 0 3 3 3 0 1 6.98 1 1 1 67.5 0 4 2 1 0 1 4.40 0 2 3 65.8 0 5 2 2 0 1 21.40 0 3 3 63.2 0 6 3 1 0 0 5.10 0 1 3 65.4 0 You can mix single columns, ranges of columns, column names vs. numbers, and even change the order in which the columns are listed. Try this yourself, with the cytomegalovirus dataset. Copy the code chunk below and run it in your RStudio Console pane. Then edit it to select the ID, patient demographics, the prior treatment variables, and the dose variables. medicaldata::cytomegalovirus %&gt;% select(everything()) %&gt;% head() Show/Hide Solution medicaldata::cytomegalovirus %&gt;% select(ID, age:race, prior.radiation:prior.transplant, TNC.dose:TBI.dose) %&gt;% head() 8.7 Selecting Columns With Logical Operators You can select groups of columns with logical operators to combine selections. You can use c() to combine selections. An example: select(c(age:race, prior.radiation:prior.chemo)). the symbols &amp; and | to select the intersection or the union, respectively, of two sets of variables. An example: select(age:race &amp; prior.radiation:prior.chemo). the ! symbol to select the complement of a set of variables. An example: select(!c(age:race, prior.radiation:prior.chemo)). Try this yourself, with the esoph_ca dataset. Copy the code chunk below and run it in your RStudio Console pane. Then edit it to select all variables except the ncases and ncontrols, using the ! symbol. medicaldata::esoph_ca %&gt;% select(everything()) %&gt;% head() Show/Hide Solution medicaldata::esoph_ca %&gt;% select(!ncases:ncontrols) %&gt;% head() Now try editing the code chunk below to select all of the variables that are not related to dose or any kind of graft versus host disease (end in gvhd) in the cytomegalovirus dataset. Use the ! and the | symbols. medicaldata::cytomegalovirus %&gt;% select(everything()) %&gt;% head() Show/Hide Solution medicaldata::cytomegalovirus %&gt;% select(!c(TNC.dose:TBI.dose | agvhd:time.to.cgvhd)) %&gt;% head() 8.8 Further Challenges Try selecting variables on your own computer. Install R and Rstudio, as in Chapter 2. Then make sure you have the following packages installed, as in the Installing Packages chapter: tidyverse medicaldata Read in data from the medicaldata datasets with data(name) Then try some of the following challenges select in the cytomegalovirus dataset for select in the opt dataset for select in the covid_testing dataset for 8.9 Explore More about Filtering Some helpful resources include: The RYouWithMe series from RLadiesSyndey post on selecting here. The tidyverse guide to selecting variables, found here. Suzan Baert’s blog series on dplyr, part 2 about wrangling columns is found here. "],["using-mutate-to-make-new-variables-columns.html", "Chapter 9 Using Mutate to Make New Variables (Columns) 9.1 Calculating BMI 9.2 Recoding categorical or ordinal data 9.3 Calculating Glomerular Filtration Rate", " Chapter 9 Using Mutate to Make New Variables (Columns) Many datasets, especially if you were involved in the data collection, will have exactly the variables you need in exactly the right format and data type. But often we import data from the electronic medical record, a data warehouse, or the Centers for Disease Control, and the data may not be in quite the format we want. We also want to collect the most granular form of the data available, without any calculations or interpretations by either the participant, the study coordinator, or the investigator. For example, collecting the date of birth is more accurate than collecting the participant age in years (which is a rounded-off calculation). This allows us to accurately calculate the participant’s age at any particular point in time. The dataset below contains data on 4 participants, with baseline values and the dates of 2 subsequent visits. Copy this code block (with icon in top right of the code block) and paste it into your local RStudio instance to run it and create this temporary demonstration dataset on your own computer. dataset &lt;- tibble::tribble( ~studyid, ~dob, ~baseline_visit, ~visit_1, ~visit_2, ~wt_kg, ~ht_m, ~sex, ~race, ~ethnicity, ~creat, &#39;001&#39;, as.Date(&quot;1971-04-13&quot;), as.Date(&quot;2021-03-01&quot;), as.Date(&quot;2021-09-07&quot;), as.Date(&quot;2022-03-19&quot;), 64.2, 1.53, 1, 1, 0, 0.63, &#39;002&#39;, as.Date(&quot;1983-07-19&quot;), as.Date(&quot;2021-04-01&quot;), as.Date(&quot;2021-10-03&quot;), as.Date(&quot;2022-04-13&quot;), 56.3, 1.47, 2, 6, 1, 1.32, &#39;003&#39;, as.Date(&quot;1976-09-26&quot;), as.Date(&quot;2021-04-13&quot;), as.Date(&quot;2021-10-18&quot;), as.Date(&quot;2022-04-22&quot;), 84.7, 1.78, 1, 4, 0, 1.05, &#39;004&#39;, as.Date(&quot;1988-02-07&quot;), as.Date(&quot;2021-04-19&quot;), as.Date(&quot;2021-11-22&quot;), as.Date(&quot;2022-05-01&quot;), 99.2, 1.88, 2, 2, 0, 1.19) Below is an example of how to calculate the age at the baseline visit (dividing the interval days by 365.25 to get years), and then relocating this new value after the baseline visit to make it easier to find. Copy this code and run it yourself to see the result. dataset %&gt;% mutate(age_base_yrs = as.numeric( baseline_visit - dob)/365.25) %&gt;% relocate(age_base_yrs, .after = baseline_visit) Some takeaway points: - most mutate functions to produce new variables are fairly simple math - subtraction will convert dates to an interval of days - you can convert this interval to numeric to do more math (the conversion to years) - you have to assign a name to the new variable, and set it equal to your calculation - all the other variables remain in the dataset, you are just adding new ones - by default, these new variables (columns) are placed at the end (the far right) of your dataset - you can change their location to a more sensible or convenient location with the relocate() function. Arguments for this function include the variables that you want to relocate (the default is that they are inserted the front {or far left} of your dataset), and the .before= and .after= arguments, to help with specific column placement). - You can select the variables to relocate with the usual tidyselect dplyr helpers like starts_with(), where(is.numeric()), last_col(), matches(), etc. Try this yourself. Edit the code you copied above to do these calculations. Open the dataset in the Environment tab to get the correct variable names. Try these challenges: - Calculate the age at visit 2. Which participant is 45.6 years old at visit 2? Participant 001Participant 002Participant 003Participant 004 - Calculate the number of days between the baseline visit and visit 1. This gap is supposed to be 180-200 days. Which participant had a visit outside of the study window? Participant 001Participant 002Participant 003Participant 004 9.1 Calculating BMI Another common calculation is the calculation of body mass index. This requires dividing the weight in kilograms by the height in meters squared. Fortunately, our self-explanatory variable names reassure us that we have th right units for these. Run the code chunk below to see the raw data in the available small dataset. Now edit the code below to create a new variable named bmi with the mutate() function. dataset ## # A tibble: 4 × 11 ## studyid dob baseline_visit visit_1 visit_2 wt_kg ht_m sex ## &lt;chr&gt; &lt;date&gt; &lt;date&gt; &lt;date&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 001 1971-04-13 2021-03-01 2021-09-07 2022-03-19 64.2 1.53 1 ## 2 002 1983-07-19 2021-04-01 2021-10-03 2022-04-13 56.3 1.47 2 ## 3 003 1976-09-26 2021-04-13 2021-10-18 2022-04-22 84.7 1.78 1 ## 4 004 1988-02-07 2021-04-19 2021-11-22 2022-05-01 99.2 1.88 2 ## # ℹ 3 more variables: race &lt;dbl&gt;, ethnicity &lt;dbl&gt;, creat &lt;dbl&gt; Show/Hide the Solution Note that rounding to 2 places was added to make bmi look nicer, and knitr::kable() was used to make a scrollable HTML table. You can use the scroll bar to move to the right to see all of the columns. dataset %&gt;% mutate(bmi = round(wt_kg/ht_m^2, 2)) %&gt;% relocate(bmi, .before = wt_kg) %&gt;% knitr::kable() studyid dob baseline_visit visit_1 visit_2 bmi wt_kg ht_m sex race ethnicity creat 001 1971-04-13 2021-03-01 2021-09-07 2022-03-19 27.43 64.2 1.53 1 1 0 0.63 002 1983-07-19 2021-04-01 2021-10-03 2022-04-13 26.05 56.3 1.47 2 6 1 1.32 003 1976-09-26 2021-04-13 2021-10-18 2022-04-22 26.73 84.7 1.78 1 4 0 1.05 004 1988-02-07 2021-04-19 2021-11-22 2022-05-01 28.07 99.2 1.88 2 2 0 1.19 9.2 Recoding categorical or ordinal data Sex data and race data are often recorded as categorical data. A variety of surveys often have response scales that are ordinal, like a happiness scale from 0_never to 10_always. The categorical data responses like male / female for sex have no inherent order, while the ordinal scales clearly do. These responses are often entered/coded as numbers, which are can be confusing, especially if there are many variables in the codebook. It is better to make variables and values self-explaining. For example, if male was coded as 1 and female was coded as 2, it would be very easy to get these reversed, or interpreted differently in different parts of your analysis. It is better to recode these to link the coded value to the definition, like 1_male, and 2_female. Then there is no confusion about what each value means. You can still extract the numeric values, if needed for calculations, by using the parse_number() function to retrieve only the numeric value. This recoding can be done with the case_when() function. The code below takes a numeric sex variable and recodes it to a new sex_cat variable with 2 categories, 1_male, and 2_female. It identifies 2 distinct cases (sex ==1 and sex ==2), and recodes the values to the desired ones. dataset %&gt;% mutate(sex_cat = case_when(sex == 1 ~ &quot;1_male&quot;, sex == 2 ~ &quot;2_female&quot;)) ## # A tibble: 4 × 12 ## studyid dob baseline_visit visit_1 visit_2 wt_kg ht_m sex ## &lt;chr&gt; &lt;date&gt; &lt;date&gt; &lt;date&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 001 1971-04-13 2021-03-01 2021-09-07 2022-03-19 64.2 1.53 1 ## 2 002 1983-07-19 2021-04-01 2021-10-03 2022-04-13 56.3 1.47 2 ## 3 003 1976-09-26 2021-04-13 2021-10-18 2022-04-22 84.7 1.78 1 ## 4 004 1988-02-07 2021-04-19 2021-11-22 2022-05-01 99.2 1.88 2 ## # ℹ 4 more variables: race &lt;dbl&gt;, ethnicity &lt;dbl&gt;, creat &lt;dbl&gt;, sex_cat &lt;chr&gt; Note that it is very easy to get an error with the logical tests in case_when() if you forget to use TWO equals signs, which are needed to TEST for equality. You can set a variable equal to a value with one equals sign, but to perform a logical test you will need to use 2 equals signs. Try this yourself. Try this challenge: - Recode the NIH race category from numeric to helpful self-explanatory values. Copy the code block above to use as a starting point. Use: - 1_white - 2_black - 3_asian - 4_pacific_islander - 5_native_american - 6_more_than_one_race to recode these numeric values into self-explanatory values Show/Hide the Solution Note that flextable::flextable() was used to make a pretty HTML table. You can use the scroll bar to move to the right to see all of the columns. Both kable (via kableExtra) and flextable have lots of formatting options for fonts, size, colors, alignment, etc. dataset %&gt;% mutate(race = case_when(race == 1 ~ &quot;1_white&quot;, race == 2 ~ &quot;2_black&quot;, race == 3 ~ &quot;3_asian&quot;, race == 4 ~ &quot;4_pacific_islander&quot;, race == 5 ~ &quot;5_native_american&quot;, race == 6 ~ &quot;6_more_than_one_race&quot;)) %&gt;% flextable::flextable() .cl-98e1504c{}.cl-98dd1a9a{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-98deb18e{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-98deb198{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-98dec066{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-98dec067{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-98dec070{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-98dec071{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-98dec072{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-98dec07a{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}studyiddobbaseline_visitvisit_1visit_2wt_kght_msexraceethnicitycreat0011971-04-132021-03-012021-09-072022-03-1964.21.5311_white00.630021983-07-192021-04-012021-10-032022-04-1356.31.4726_more_than_one_race11.320031976-09-262021-04-132021-10-182022-04-2284.71.7814_pacific_islander01.050041988-02-072021-04-192021-11-222022-05-0199.21.8822_black01.19 9.3 Calculating Glomerular Filtration Rate A typical, but more complicated kind of mutation calculation is the calculation of GFR. This estimate of renal function is affected by sex, serum creatinine (sCr) level, and age, using the 2021 CKD-EPI Creatinine equations. These can be summarized as 2021 CKD-EPI Creatinine = 142 x (Scr/A)^B x 0.9938^age x (1.012 if female), where A and B are the following: Female Male Scr &lt;= 0.7 A = 0.7 B = -0.241 Scr &lt;= 0.9 A = 0.9 B = -0.302 Scr &gt; 0.7 A = 0.7 B = -1.2 Scr &gt; 0.9 A = 0.9 B = -1.2 which works out to 4 distinct equations. The four equations are listed here in R format to help you out. 2021 CKD-EPI Equations for GFR Case Female, low Creatinine Equation | ===============================================+ 142 * (creat/0.7)^-0.241 * 0.9938^age * 1.012 | Female, high Creatinine 142 * (creat/0.7)^-1.200 * 0.9938^age * 1.012 | Male, low Creatinine 142 * (creat/0.7)^-0.302 * 0.9938^age Male, high Creatinine 142 * (creat/0.7)^-1.200 * 0.9938^age | Try this yourself. Try this challenge in your local version of RStudio: Use mutate and case_when to calculate gfr for each of the four cases with each equation. Note that you have to calculate (baseline) age first, in order to use it as a variable in the gfr calculation. Relocate creat, sex, age, and gfr to a location right after the studyid. Show/Hide the Solution dataset %&gt;% mutate(age = as.numeric((baseline_visit - dob)/365.25)) %&gt;% mutate(gfr = case_when( sex == 2 &amp; creat &lt;= 0.7 ~ 142 * (creat/0.7)^-0.241 * 0.9938^age * 1.012, sex == 2 &amp; creat &gt; 0.7 ~ 142 * (creat/0.7)^-1.200 * 0.9938^age * 1.012, sex == 1 &amp; creat &lt;= 0.9 ~ 142 * (creat/0.7)^-0.302 * 0.9938^age, sex == 1 &amp; creat &gt; 0.9 ~ 142 * (creat/0.7)^-1.200 * 0.9938^age )) %&gt;% relocate(creat, sex, age, gfr, .after = studyid) ## # A tibble: 4 × 13 ## studyid creat sex age gfr dob baseline_visit visit_1 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; &lt;date&gt; &lt;date&gt; ## 1 001 0.63 1 49.9 107. 1971-04-13 2021-03-01 2021-09-07 ## 2 002 1.32 2 37.7 53.1 1983-07-19 2021-04-01 2021-10-03 ## 3 003 1.05 1 44.5 66.2 1976-09-26 2021-04-13 2021-10-18 ## 4 004 1.19 2 33.2 61.8 1988-02-07 2021-04-19 2021-11-22 ## # ℹ 5 more variables: visit_2 &lt;date&gt;, wt_kg &lt;dbl&gt;, ht_m &lt;dbl&gt;, race &lt;dbl&gt;, ## # ethnicity &lt;dbl&gt; "],["mutating-joins-to-combine-data-sources.html", "Chapter 10 Mutating Joins to Combine Data Sources 10.1 What are Joins? 10.2 What are Mutating Joins? 10.3 Let’s Start with Left Joins 10.4 Left Join in Action 10.5 Left Join in Practice 10.6 Quick Quiz 10.7 Problem variable names 10.8 Right Join in Action 10.9 Right Join in Practice 10.10 Inner Joins 10.11 Quick Quiz 10.12 Now Let’s take a Look at the result 10.13 Full Joins 10.14 Quick Quiz 10.15 Now Let’s take a Look at the result", " Chapter 10 Mutating Joins to Combine Data Sources 10.1 What are Joins? Joins (sometimes called merge operations) are used to join together different datasets. This can be really helpful for joining together data from different data sources, like different forms in REDCap (demographics, vitals, visit 1 data), or the results of a data query from your electronic medical record, or national or state-level data available from sources like the CDC or a state health department. By linking these data you can find new connections, and gain a new understanding of disease, social determinants of health, or geographic factors. 10.2 What are Mutating Joins? These are joins between a base dataset (x) and a new dataset (y) that add new variables to the base dataset, like a mutate() function in dplyr. Typically you would start with a dataset that includes one row for each observation, and often one row for each participant. There are four types of mutating joins: left join - all variables from the base dataset (x) are retained, and new variables from new dataset (y) that match the observations (rows) in dataset x on the key (unique id) variable are added. right join - all variables from the new dataset (y) are retained, and new variables from the base dataset (x) that match the observations (rows) in dataset y on the key (unique id) variable are added. inner join - includes all rows in both dataset (x) and dataset (y), requiring matching on the key (unique id) variable. full join - includes all rows in either dataset (x) or dataset (y), matching on the key (unique id) variable when matches are present, and filling in NAs in missing columns if no match is present. 10.3 Let’s Start with Left Joins To get started, let’s download two toy datasets - Copy and run the code chunk below to assign these to birthdays and hometowns. birthdays &lt;- read.csv(&quot;https://raw.githubusercontent.com/higgi13425/medicaldata/master/data-raw/join_data/birthdays.csv&quot;) %&gt;% select(-X) hometowns &lt;- read.csv(&quot;https://raw.githubusercontent.com/higgi13425/medicaldata/master/data-raw/join_data/hometowns.csv&quot;) %&gt;% select(-X) The left join is the most common mutating join, as it allows you to start with a base dataset and add matching variables from other sources. left join - all variables from the base dataset (x) are retained, and new variables from new dataset (y) that match the observations (rows) in dataset x on the key (unique id) variable are added. Let’s start with a simple left join with these two small and simple “toy” datasets about famous physicians. Start by copying and running a glimpse() function on each dataset from the code chunk below. glimpse(birthdays) ## Rows: 3 ## Columns: 2 ## $ name &lt;chr&gt; &quot;Rudolf Virchow&quot;, &quot;Virginia Apgar&quot;, &quot;William Osler&quot; ## $ dob &lt;chr&gt; &quot;10/13/1821&quot;, &quot;6/7/1909&quot;, &quot;7/12/1849&quot; glimpse(hometowns) ## Rows: 3 ## Columns: 2 ## $ name &lt;chr&gt; &quot;Rudolf Virchow&quot;, &quot;Virginia Apgar&quot;, &quot;Hippocrates&quot; ## $ hometown &lt;chr&gt; &quot;Berlin&quot;, &quot;Westfield, NJ&quot;, &quot;Kos&quot; We now have two small datasets, with 3 rows each and 2 variables each. Across the toy datasets, data are provided on 4 famous physicians, so that each dataset is missing one physician from the other dataset. The 3 main arguments of the left_join() function include x (base dataset, or left dataset) y (new dataset, or right dataset) by (variable to match, known as the key, or unique id - must be unique to each observation). The dplyr functions are often smart enough to figure the keyid variable out on their own. 10.4 Left Join in Action The animation below illustrates how a left_join works. The colored numbers represent the unique key variable, and the gray boxes represent the unique values from datasets x and y. Notice that observation 4 in dataset y, because it does not have a match in dataset x, does not end up in the final dataset. left join animation by Garrick Aden-Buie from the tidyexplain repo 10.5 Left Join in Practice Let’s see how it works. Run the code chunk below. The hometowns dataset is x, or the base/left dataset, and the birthdays dataset is the y, or new/right dataset. Notice that we don’t specify a variable for by. left_join(x = hometowns, y = birthdays) ## Joining with `by = join_by(name)` ## name hometown dob ## 1 Rudolf Virchow Berlin 10/13/1821 ## 2 Virginia Apgar Westfield, NJ 6/7/1909 ## 3 Hippocrates Kos &lt;NA&gt; This produces a new dataset with 3 columns - name, hometown, and date of birth. The left_join function figures out which is the key id variable to match datasets on its own. You could assign this dataset to a new object, and add more data from a 3rd, or even a 4th dataset, as long as each has a matching unique key variable. 10.6 Quick Quiz Which variable in the left_join above is the key unique variable present in both datasets that is used to join these two datasets? namehometowndob Why does Hippocrates have an NA for date of birth? Hippocrates does not appear in the hometown datasetHippocrates does not appear in the birthdays datasetHippocrates had a fear of candles Hippocrates always told everyone he was 29 This is great - left_join() figured out how to match up the observations on its own. But sometimes it is not obvious how to match up observations. To play it safe, you should specify the matching unique key id variable. In this case, the common variable to the two datasets is “name”. You specify this with the by variable in quotes, as in the below code chunk left_join(x = hometowns, y = birthdays, by = &quot;name&quot;) ## name hometown dob ## 1 Rudolf Virchow Berlin 10/13/1821 ## 2 Virginia Apgar Westfield, NJ 6/7/1909 ## 3 Hippocrates Kos &lt;NA&gt; This gets complicated when the intended matching variable does not quite match. A common “gotcha” when joining datasets is not having an exact match of the intended by variable. Common scenarios include: mismatched spelling or capitalization of the variable name mismatch in the variable data type: integers and numbers look the same, but if they are not the same data type, the join will fail. It is important to: glimpse() both datasets, and check the name of the intended by variable in both datasets. glimpse() both datasets, and check the data type of the intended by variable in both datasets. predict the number of rows and columns in the resulting dataset after the join - if it is way off, something is wrong (a really important reality check) 10.7 Problem variable names Sometimes your variable names will be just a bit off. Read in this new version of hometowns2 by copying and running the code below. hometowns2 &lt;- read.csv(&quot;https://raw.githubusercontent.com/higgi13425/medicaldata/master/data-raw/join_data/hometowns2.csv&quot;) %&gt;% select(-X) Now write your own left join of hometowns2 and birthdays using the code below as a starting point. Remember to glimpse( ) the new dataset first. left_join(x = hometowns2, y = birthdays, by = &quot;name&quot;) ## Error in `left_join()`: ## ! Join columns in `x` must be present in the data. ## ✖ Problem with `name`. 10.8 Right Join in Action The animation below illustrates how a right_join works. The colored numbers represent the unique key variable, and the gray boxes represent the unique values from datasets x and y. Notice that observation 3 in dataset x, because it does not have a match in dataset y, does not end up in the final dataset. In a right join, the y dataset is considered the base dataset, and the matching observations from the x dataset are added. This is not very different from a left_join, but occurs in a different order. right join animation by Garrick Aden-Buie from the tidyexplain repo 10.9 Right Join in Practice Let’s see how it works. Run the code chunk below. The hometowns dataset is x, or the base/left dataset, and the birthdays dataset is the y, or new/right dataset. Notice that we don’t specify a variable for by. right_join(x = hometowns, y = birthdays) ## Joining with `by = join_by(name)` ## name hometown dob ## 1 Rudolf Virchow Berlin 10/13/1821 ## 2 Virginia Apgar Westfield, NJ 6/7/1909 ## 3 William Osler &lt;NA&gt; 7/12/1849 This produces a new dataset with 3 columns - name, hometown, and date of birth. Notice that this result id different from the left_join result above. William Osler appears (without a hometown, as he was born in the wilds of Ontario), and Hippocrates does not. Which dataset is the base dataset affects the result of the join. The right_join function figures out which is the key id variable to match datasets on its own. You could assign this dataset to a new object, and add more data from a 3rd, or even a 4th dataset, as long as each has a matching unique key variable. Most people entirely use left_join(), rather than right_join(), for the sake of consistency. The main time you might want to use a right_join()() is when you have a base dataset, and you want to add some variables from a new dataset, but the new dataset needs some wrangling and selecting variables first. In this case, you can do your wrangling of the new dataset, then right_join() it to your base dataset. This will add the new variables to the base dataset. A simple example is shown below. We want to add the dataset hometowns2 to the dataset birthdays, but we first have to remove an extra variable (X), and fix the “Name” variable name. Then we can pipe the resulting dataset into the join. But if we pipe it into a left_join(), hometowns will by default become the base (x) dataset, as it comes first. If we want to keep birthdays as the base (x) dataset, we can use a right_join(). This will result in a table in which everyone has a known birthday, but not necessarily a known hometown. hometowns2 &lt;- read.csv(&quot;https://raw.githubusercontent.com/higgi13425/medicaldata/master/data-raw/join_data/hometowns2.csv&quot;) %&gt;% select(-X) %&gt;% purrr::set_names(c(&quot;name&quot;, &quot;hometown&quot;)) hometowns2 %&gt;% right_join(birthdays) ## Joining with `by = join_by(name)` ## name hometown dob ## 1 Rudolf Virchow Berlin 10/13/1821 ## 2 Virginia Apgar Westfield, NJ 6/7/1909 ## 3 William Osler &lt;NA&gt; 7/12/1849 10.10 Inner Joins The inner join only keeps observations for which there is a matching observation in both datasets. Think of the inner_join as the intersection of the two sets. Here is an animation of what this looks like inner join animation by Garrick Aden-Buie from the tidyexplain repo For birthdays and hometowns, what do you predict the result will be? Look at the datasets below (run the glimpse code) and take a guess. glimpse(birthdays) ## Rows: 3 ## Columns: 2 ## $ name &lt;chr&gt; &quot;Rudolf Virchow&quot;, &quot;Virginia Apgar&quot;, &quot;William Osler&quot; ## $ dob &lt;chr&gt; &quot;10/13/1821&quot;, &quot;6/7/1909&quot;, &quot;7/12/1849&quot; glimpse(hometowns) ## Rows: 3 ## Columns: 2 ## $ name &lt;chr&gt; &quot;Rudolf Virchow&quot;, &quot;Virginia Apgar&quot;, &quot;Hippocrates&quot; ## $ hometown &lt;chr&gt; &quot;Berlin&quot;, &quot;Westfield, NJ&quot;, &quot;Kos&quot; 10.11 Quick Quiz How many rows will result if you inner_join birthdays with hometowns? 4321 Which physicians will appear in this resulting table? Osler and HippocratesApgar, Virchow, and OslerApgar and VirchowVirchow and Hippocrates 10.12 Now Let’s take a Look at the result Click to Reveal inner_join(birthdays, hometowns) ## Joining with `by = join_by(name)` ## name dob hometown ## 1 Rudolf Virchow 10/13/1821 Berlin ## 2 Virginia Apgar 6/7/1909 Westfield, NJ The inner_join requires full matches, so only Virchow and Apgar, who appear in both datasets, appear in the inner_join. 10.13 Full Joins The full (aka outer) join keeps all observations for from both datasets, whether or not there is a match. Think of the full_join as the union of the two sets. Here is an animation of what this looks like full join animation by Garrick Aden-Buie from the tidyexplain repo For birthdays and hometowns, what do you predict the result will be? Look at the datasets below (run the glimpse code) and take a guess. glimpse(birthdays) ## Rows: 3 ## Columns: 2 ## $ name &lt;chr&gt; &quot;Rudolf Virchow&quot;, &quot;Virginia Apgar&quot;, &quot;William Osler&quot; ## $ dob &lt;chr&gt; &quot;10/13/1821&quot;, &quot;6/7/1909&quot;, &quot;7/12/1849&quot; glimpse(hometowns) ## Rows: 3 ## Columns: 2 ## $ name &lt;chr&gt; &quot;Rudolf Virchow&quot;, &quot;Virginia Apgar&quot;, &quot;Hippocrates&quot; ## $ hometown &lt;chr&gt; &quot;Berlin&quot;, &quot;Westfield, NJ&quot;, &quot;Kos&quot; 10.14 Quick Quiz How many rows will result if you full_join birthdays with hometowns? 4321 Which physicians will appear in this resulting table? Osler and HippocratesApgar, Osler, Hippocrates and VirchowApgar, Virchow, and OslerVirchow and Hippocrates 10.15 Now Let’s take a Look at the result Click to Reveal full_join(birthdays, hometowns) ## Joining with `by = join_by(name)` ## name dob hometown ## 1 Rudolf Virchow 10/13/1821 Berlin ## 2 Virginia Apgar 6/7/1909 Westfield, NJ ## 3 William Osler 7/12/1849 &lt;NA&gt; ## 4 Hippocrates &lt;NA&gt; Kos The full_join does not require matches, so all observations from both datasets, appear in the full_join result. "],["interpreting-error-messages.html", "Chapter 11 Interpreting Error Messages 11.1 The Common Errors Table 11.2 Examples of Common Errors and How to fix them 11.3 Errors Beyond This List 11.4 When Things Get Weird 11.5 References:", " Chapter 11 Interpreting Error Messages Especially when you are starting out, it can be very difficult to interpret error messages, because these can be quite jargon-y. Let’s start with a table of the most common error messages, and the likely cause in each case. Note that when reading an error message, there are two parts - the part before the colon, which identifies in which function the error occurred, and the part after the colon, which names the error. A typical error message is usually in the format: Error in Where the error occurred : what the error was here is an example Error in as_flextable(.) : object 'errors' not found On the left, you are being told that the error occurred when the as_flextable() function was called. This can be helpful if you have run a long pipeline of functions, as it helps you isolate the problem. On the right, you are being told what the error was. In this case, the function looked for the object errors in the working environment (see your Environment tab at the top right in RStudio), and could not find it. Note that sometimes syntax errors caused by missing components (a missing comma, a missing parenthesis, a missing pipe symbol %&gt;% , or a missing + sign in a ggplot pipe) will cause an error in the next function in the pipeline. Watch out for this, especially when the function where the error is found looks fine - often it occurs because there is a missing piece just before this function. Then we will walk through examples of how to create each error, and how to fix them, one by one. 11.1 The Common Errors Table Examine the error message from R, particularly the part that comes after the colon (:). The error messages listed in the left column will be what appears after the colon (:) Common Error Messages in R Error Message What it Means could not find function This usually means that you made a typographical error in the function name (including Capitalization - R is case-sensitive), or that the package you are intending to use (which contains the function) is not installed - with `install.packages(‘package_name’)` or the package is not loaded - with `library(package)` object ‘object-name’ not found This usually means that the function looked for an object (like a data frame or a vector) in your working environment (check your Environment pane) and could not find it. This commonly happens when you mistype the name of the object (double-check this, easy to fix), or you did not actually create or save this object to your working environment - confirm by checking your Environment tab at the top right in RStudio. filename does not exist in current working directory (‘path/to/working/directory’) This usually means one of three things: you mistyped the name of the file, or part of the path, you are not in the directory where the file is, or the file you thought you had saved does not exist (check your Files tab in the lower right pane in RStudio). error in if This usually means that you have an *if* statement that is trying to make a branch-point decision, but the logical statement that you wrote is not providing either a TRUE or a FALSE value. The most common reasons are typographical errors s in the logical statement, or an NA in one of the underlying values, which yields an NA from the logical statement. You may need to use a `na.rm = TRUE` option in your logical statement (the na.rm issue often comes up with means and medians). error in eval This usually occurs when you are trying to run a function on an object that does not exist in your environment. Check to make sure in your Environment pane, and consider that you may not have saved/assigned the object in a previous step. Alternatively, you may have a typographical error in the object name. Worth checking. cannot open This usually occurs when you are attempting to access or read a file that either does not exist, or is not in the folder that you thought it was. Check your working directory and find the file in your file structure. This can often be prevented by working in RStudio projects and using the here() function for paths to files. no applicable method This usually occurs when you are using a function that expects a particular data structure (vector, list, dataframe), but you have given it a different data structure as the input. Check the data structure of your object, and check the documentation for your function. For example, if you want to use a function that acts on vectors, this function will not work on a dataframe object. You may have to use the `pull(variable)`function to “pull” this variable out of the dataframe into a vector before using this function. subscript out of bounds you are trying to access an item in an environment object (like a vector, dataframe, or list) that does not exist, like the 9th item in a vector that is 7 items long, or the negative 2nd row of a dataframe. Check the length of the item, and the math that you used to count the item number (loops that go too long are often a culprit) replacement has [x] rows, data has [y] rows This usually occurs when you are trying to code for a new variable, or replace a variable in a dataframe. But somehow (missing values, NAs), what you are trying to add to the dataframe is not the same length (number of rows) as the rest of the existing dataframe. Use a length() function to check your building of this vector at each step, to figure out where your length went wrong. package not available for R version x.y.z This occurs when you are trying to install a package, and your R version is newly updated. The problem is that the package version available on CRAN has not caught up to your shiny new version of R. This can happen after an R update when the package developer is working on updating their package, but the new version has not made it onto CRAN yet. This is often fixable if you know where the developer stores their development code (usually on GitHub). For example, if the package is {medicaldata}, and the developer’s Github userid is higgi13425, then you can install the development version of this package with remotes::install_github('higgi13425/medicaldata'). This assumes that you have already installed and loaded the {remotes} package. non-numeric argument to a binary operator A binary operator, like + or *, is a mathematical operation that takes two values (operands) and produces another value. It gets grumpy when trying to do math on things that are not numbers. A typical input to produce this error would be 1 + 'one' - one operand is numeric, and the other 'one' is a character string - the non-numeric argument. object of type closure is not subsettable This occurs when you try to extract a subset of something - but it is actually a function, not an object. This most commonly occurs when you try to subset a particular object that does not exist, like df$patient_id or data$sbp, when you have not created the objects df or data. The reason you get this strange error message, rather than simply Error: object 'df' not found , is that df() and data() are defined functions in base R. It is good practice to avoid naming any objects data or df for this reason. It gets very confusing, and this is best avoided. 11.2 Examples of Common Errors and How to fix them 11.2.1 Missing Parenthesis This is a very common error. It is easy to lose track of how many sets of parentheses you have open in putting together a complicated function. Here is an example, where a closing parenthesis is missing from a mutate() function. prostate %&gt;% select(t_vol, p_vol, age, aa) %&gt;% mutate(ratio = t_vol/p_vol, older_aa = case_when(age &gt;65 &amp; aa == 1 ~ 1, TRUE ~0) %&gt;% filter(older_aa ==1) In this case, no output is produced, and the console does not return to the &gt; prompt. Instead, it offers a + prompt - in effect, asking you for something more. If you type in an extra closing parenthesis (after the filter function), it will give you an error. The error you get is: Error: Problem with `mutate()` input `older_aa`. x no applicable method for ‘filter_’ applied to an object of class “c(‘double’, ‘numeric’)” ℹ Input `older_aa` is ``%&gt;%`(…)`. R identifies a problem with the input “older_aa” to mutate - the parentheses are not closed. It then fails on the next function - filter, and gives you a strange error message - filter_ applied to… - because the input to the filter step (the next step after the error) was incoherent. This can be a bit confusing. But if you inspect the input older_aa, you will find the mis-matched parentheses. This is much easier to find with “rainbow parentheses” turned on in Tools/Global Options. When this option is on, you can be sure your parentheses are right when you end on red. Sometimes the very thin parentheses of some fonts can make it difficult to identify your red close parenthesis. The red vs. yellow parentheses may be easier to differentiate if you use a bold font for your code. You can change this with RStudio Tools/Global Options/Appearance. I am currently using FiraCode-Bold and the Crimson Editor theme in RStudio, which seems to help me. In this case, adding the missing parenthesis to the mutate step fixes it. Parentheses that end on red are all right. 11.2.2 An Extra Parenthesis What if you go the other way, with an extra parenthesis after some misguided copy-paste adventures? Let’s see what happens. prostate %&gt;% select(t_vol, p_vol, age, aa) %&gt;% mutate(ratio = t_vol/p_vol, older_aa = case_when(age &gt;65 &amp; aa == 1 ~ 1, TRUE ~0))) %&gt;% filter(older_aa ==1) In this code block, you will end up with two red closing parentheses, and when you click to the right of the final closing parenthesis, there will be no matching highlighted open parenthesis (note that the preceding closing parentheses both have matching highlighted open parentheses. Both of these are clues that this last one is an extra. The error you get from R is Error in filter(older_aa == 1) : object ‘older_aa’ not found The left side of the error message identifies the filter step as where the error occurs, and the right side of the error message states that the error is an object not found. The error occurs when R gets to the next function. It also tells you that older_aa was not successfully created - suggesting that the problem is in the step before the filter function. In this case, removing the extra parenthesis from the mutate step fixes it. 11.2.3 Missing pipe %&gt;% in a data wrangling pipeline This is a common error. It is easy to cut out one of your %&gt;% connectors when you are editing/debugging a data wrangling pipeline. Here is an example, where a %&gt;% is missing. Can you spot it? prostate %&gt;% select(t_vol, p_vol, age, aa) mutate(ratio = t_vol/p_vol, older_aa = case_when(age &gt;65 &amp; aa == 1 ~ 1, TRUE ~0)) %&gt;% filter(older_aa ==1) In this case, the error you get is: Error in mutate(ratio = t_vol/p_vol, older_aa = case_when(age &gt; 65 &amp; aa == : object ‘t_vol’ not found The left side of the error message identifies the mutate step as where the error occurs, and the right side of the error message states that the error is an object not found. This is a bit misleading, as the problem is not in the mutate step. But mutate is where the pipeline crashes, as it can not find the variable t_vol. You have to backtrack upwards line-by-line to find the error. Every line of a data wrangling pipeline should end in %&gt;%. Since this is such a common error, this should be one of your “usual suspects”. And the select line, just above the mutate line, is where the problem is. In this case, adding the missing %&gt;% to the end of the select step fixes your data wrangling pipeline. Use one function per line in a pipeline. Check every data wrangling pipeline to make sure each step (except the last) ends in a pipe %&gt;% 11.2.4 Missing + in a ggplot pipeline This is a common error. It is easy to cut out one of your + connectors when you are editing/debugging a ggplot. Here is an example, where a + is missing in the middle of a ggplot pipeline. prostate %&gt;% select(t_vol, p_vol, age, aa) %&gt;% ggplot(aes(x = factor(t_vol), y =p_vol)) geom_boxplot() + labs(x = &quot;tumor volume&quot;, y = &quot;prostate volume&quot;) + theme_minimal() In this case, you get a ggplot output, but without any boxplots. It is also missing your custom labels for the x and y axes, and the theme you wanted. Essentially, the code stops running after the initial ggplot() statement and the remaining lines of code are ignored. This can be pretty puzzling, as you do get a plot, but not what you intended. There is a partial plot in the Plots tab, but you get a somewhat helpful error in the Console. The error you get is: Error: Cannot add ggproto objects together. Did you forget to add this object to a ggplot object? R identifies a problem with the last 3 lines of code, starting with geom_boxplot() - it can not add these ggproto objects (the components of a ggplot) to the existing plot. It asks, “Did you forget to add?” which should be a clue that there is a missing + sign between lines of ggplot code. Since the theme and labels are the defaults, and there are no boxplots, suggest that these last 3 lines were not run at all, and that the missing plus sign should be found just before these lines of code. In this case, adding the missing + to the end of the ggplot step fixes your plot. Use one function per line in a pipeline. Check every ggplot pipeline to make sure each step (except the last) ends in a plus sign + 11.2.5 Pipe %&gt;% in Place of a + This is a common error. It is easy to start with your dataset, do some data wrangling steps with the pipe %&gt;% and keep piping out of habit, even after you start your ggplot. Unfortunately, once you start to ggplot, you have to use + as your code connector. Having a pipe instead will cause an error. Here is an example, where a %&gt;% is used instead of + in a ggplot pipeline. It usually happens at the beginning of the ggplot, when you are still in piping mode. prostate %&gt;% select(t_vol, p_vol, age, aa) %&gt;% ggplot(aes(x = factor(t_vol), y =p_vol)) %&gt;% geom_boxplot() + labs(x = &quot;tumor volume&quot;, y = &quot;prostate volume&quot;) + theme_minimal() In this case, you will not get a ggplot output, and you will get an error in the console. The error you get is: Error: `mapping` must be created by `aes()` Did you use %&gt;% instead of +? The error message identifies the aes() step as where the error occurs. R identifies a problem that causes the aes function to fail to create a mapping. The first line is not very helpful (other than identifying aes() as a problem), but in the next line, R asks, “Did you use %&gt;% instead of +?” which is very helpful. Once you know this, look at the line where aes() failed. This is where there is a pipe in place of a plus. In this case, replacing the %&gt;% with a + fixes your plot. 11.2.6 Missing Comma Within a Function() This is a common error. It is easy to start a series of arguments to a function, like multiple variables in a mutate step, and miss a comma between them. Here is an example, where a comma is missing in a series of mutate steps. Note that it is a good habit to put one mutate step on each line, with each line ending in a comma. This will help you find the missing comma if (no, when) you make this mistake. prostate %&gt;% select(t_vol, p_vol, age, aa) %&gt;% mutate(ratio = t_vol/p_vol, older_aa = case_when(age &gt;65 &amp; aa == 1 ~ 1, TRUE ~0) age_decade = floor(age / 10)) %&gt;% filter(older_aa ==1) In this case, you will not get a tibble output, and you will get an error in the console. The error you get is: Error in filter(older_aa == 1) : object ‘older_aa’ not found The left side of the error message identifies the filter step as where the error occurs, and the right side of the error message states that the error is an object not found. R identifies a problem that causes the filter function to fail, but this is actually a problem in the line prior. The variable older_aa was not created and is not available to filter. It should have been created in the mutate step, but this step is where the failure occurred. Because you formatted the mutate step with one mutate statement per line, it is easy to check each line for a comma - and the older_aa line is missing its comma. In this case, adding a comma at the end of the older_aa line (after “TRUE ~0)” fixes your data wrangling pipeline. 11.2.7 A Missing Object This is a common error. You may have created or modified a dataframe, but forgot to assign it to a new object name. Or maybe you did this assignment in a different session, but have not done it in your current session. Or maybe you made a typographical error in calling the object (“covvid” instead of “covid”). Either way, this object is not yet loaded into your computing environment (the Environment tab). In this example, we request data from the {medicaldata} package, but forget to assign it to an object. So it does not exist when we try to use it to start a pipeline. This does not work. medicaldata::covid_testing covid %&gt;% select(subject_id, age, result, ct_result, patient_class) %&gt;% mutate(high_titer = case_when(ct_result &lt; 18, TRUE ~ 0), age_decade = floor(age / 10)) %&gt;% filter(age &gt;50) In this case, you will not get a tibble output, and you will get an error in the console. The error you get is: Error in select(., subject_id, age, result, ct_result, patient_class) : object ‘covid’ not found The portion to the left of the comma identifies where the error occurs - in the select step. The portion to the right of the comma identifies the error. This one is easy. The object ‘covid’ was not found. You can check your Environment pane, and it will not be there. What the coder intended was to call medicaldata::covid_testing and assign it (with an arrow) to a new object named covid. But that assignment did not happen, and R is unable to guess what you meant. In this case, adding an assignment arrow -&gt; to the end of the medicaldata::covid_testing line and then covid completes the assignment, creates the covid object, and fixes your data wrangling pipeline. 11.2.8 One Equals Sign When you Need Two This is a very common error. The equals sign is commonly used in two ways in R. To assign a parameter or argument of a function, like x = p_vol, or ratio = p_vol/t_vol, or color = “blue”. In all of these assignment cases, you use one equals sign. To test a logical statement, like age == 60, or fam_hx == 1, or location == “Outpatient”. In all of these logical tests, you use two equals signs. It is very common to use one equals sign in a logical statement. This causes errors. Watch the last filter step below. prostate %&gt;% select(t_vol, p_vol, age, aa) %&gt;% mutate(ratio = t_vol/p_vol, older_aa = case_when(age &gt;65 &amp; aa == 1 ~ 1, TRUE ~0), age_decade = floor(age / 10)) %&gt;% filter(older_aa ==1) In this case, the error you receive is very helpful: Error: Problem with `filter()` input `..1`. x Input `..1` is named. ℹ This usually means that you’ve used `=` instead of `==`. ℹ Did you mean `older_aa == 1`? The problem is with the filter step. The error starts out very jargon-y. “input `..1`. x Input `..1` is named” - means the input to filter is actually named (an assignment). But then it gets a lot more helpful. It recognizes that you have made a common error, and suggests an appropriate fix. In this case, adding a 2nd equals sign in the filter step fixes your data wrangling pipeline. Testing for equality with == is a big problem with real numbers, rather than integers. Computers use algorithms to do math which are not quite exact, leading to small differences in decimals. The == equality test is very strict, so that something like sqrt(2)^2 == 2 is FALSE because of small differences far to the right of the decimal point, which can trip you up. You can see these if you run the modulo 2: sqrt(2)^2 %% 2, which gives you the remainder after you divide by 2, which is the very tiny 0.0000000000000004440892. In this situation, you should use the near() function, as near(sqrt(2)^2, 2) is TRUE. The near function has a built-in tolerance of 0.00000001490116, which will be able to handle any computer-generated small, stray decimals. You can set your own tolerance argument if needed. 11.2.9 Non-numeric argument to a binary operator This happens when you try to do math on things that are not numbers. It usually occurs when you have a variable(column) that looks like it is numeric (it contains numbers), but somewhere along the way it became a character string variable. This often occurs when data are being entered into a spreadsheet, and one value in the column has characters in it. This often happens when you have a column of systolic blood pressures, and one value is entered as “this was not done”, or “102, but taken standing up”. Having comments, even if only one character string in a column in Excel makes the whole column into the character string data type. This is not apparent until you try to do math with this variable, as in data %&gt;% mutate(mean_art_pressure = sbp/3 + 2/3* dbp) This will give you the error: Error in mutate(mean_art_pressure: non-numeric argument to binary operator To fix this, you will have to Determine which variable, sbp or dbp, is non-numeric (glimpse(data) will help). Review the values of the problem variable (possibly with table()) to find which is non-numeric. Fix these values manually in your code, and document with comments Which values are being fixed (e.g. sbp for subject 007, at visit 2) data$sbp[subject == 007 &amp; visit == 2] &lt;- 102 What the original value was, and what the new value will be Who made the change to the data Why the data change was made On what date the data change was made Never over-write your original data - keep a complete audit trail! 11.3 Errors Beyond This List This is where the internet comes in handy. Whatever errors you can create, someone has already run into. And they have asked for help on the internet, and most of the time, someone has helped them solve their error. You should copy your entire error message, and paste it into a web search. Google will often yield multiple similar examples, with various ways to solve the problem. In a future chapter, we will explore more effective ways to seek help, using a minimal reprex to describe your problem accurately to other people on sites like community.rstudio.com. Remember that the error may have occurred because of a problem in the previous line of code (missing parenthesis, comma, etc.), so don’t forget to check one line above. The Add-One-Line debugging strategy is another good strategy. Select the code for your pipeline from the beginning to 2 lines of code before the error. If that runs without errors, add one line to your selection, and run it. Keep adding lines to your selection and running until you hit the error. Then try to find the problem and fix it. 11.4 When Things Get Weird 11.4.1 Restart your R Session (Shift-Cmd-F10) If you are running code that has worked before, and it is not working now, it is possible that you have created something odd in your working Environment that is interfering with your code. Sometimes it is an old object from a previous session (it is always better to start from a clean slate). Completely restart your R session (click on Session/Restart R, or use the keyboard shortcut), make sure the Environment is clean, then run your code from start to finish to give it a new try. Sometimes a clean slate will make all the difference. 11.5 References: These are some helpful general references on troubleshooting in R, particularly focused on error messages encountered by beginners to R. Click on some of the links to check these out. https://bookdown.org/yih_huynh/Guide-to-R-Book/trouble.html https://medium.com/analytics-vidhya/common-errors-in-r-and-debugging-techniques-f11af3f1c7d3 https://rpubs.com/Altruimetavasi/Troubleshooting-in-R https://github.com/noamross/zero-dependency-problems/blob/master/misc/stack-overflow-common-r-errors.md https://www.r-bloggers.com/2016/06/common-r-programming-errors-faced-by-beginners/ https://www.r-bloggers.com/2015/03/the-most-common-r-error-messages/ https://rpubs.com/Altruimetavasi/Troubleshooting-in-R https://statisticsglobe.com/errors-warnings-r "],["the-building-blocks-of-r-data-types-data-structures-functions-and-packages.html", "Chapter 12 The Building Blocks of R: data types, data structures, functions, and packages 12.1 Data Types 12.2 Data Structures 12.3 Examining Data Types and Data Structures 12.4 Functions 12.5 Packages 12.6 The Building Blocks of R", " Chapter 12 The Building Blocks of R: data types, data structures, functions, and packages In this chapter, we will learn about some critical building blocks in R that can lead to a lot of frustration if you do not understand these building blocks and how they are used. Once you understand how these building blocks work, you will be able to avoid these frustrations and build some pretty amazing data analysis pipelines. 12.1 Data Types There are actually six data types in R, though we usually use only use 4 of these for data analysis. logical (TRUE or FALSE) integer (1L, 2L) - these take up less memory than a double. You specify a number as an integer (rather than a double) by adding a capital L after the number. double (aka real or decimal - 2.4, 4.7, pi). Double means that the value is stored in 64 bits (aka double precision) note that both integers and doubles have the class of numeric character (“myeloma” or “michigan”) complex ( 1+3i, 4-7i) - used under the hood for calculations raw (hexadecimal codes like B3 or FF) - used to communicate with devices like printers Note that there is not a true data type for categorical variables, like gender, or race, or ethnicity. These are encoded as factors, which behave mostly like a data type, but are technically a data class. For the purposes of dataframes, factors can be thought of as the 5th data type, but the result of typeof() on a factor variable will be “integer”, as that is how factors are stored, with text attributes for the level names. Note also that there is not a true data type for dates, or date:times, as these are stored as doubles in R. Their typeof() will be double, but their class() will be date or dttm. Storing these as doubles does make it easier to do math to calculate intervals of time. Note that you can test the type of an object in R with the typeof() function, which will return the data type. You can also test for a specific data type - is this the right kind of input, with the is.x functions, like is.character(), is.logical(), or is.numeric(). These will return the logical values TRUE or FALSE. This can be important, as many functions will report (or “throw”) an error when they receive the wrong kind of input data. When needed, you can also convert between data types, by manually coercing an object to a different data type with the as.x functions, like as.character(), as.logical(), as.integer(), or as.numeric() [as.double() ~~ as.numeric()]. Here are 4 examples of testing vectors with the typeof() function. Guess what the returned value will be before you run the code (click on the green arrow at the top right). # you can test vectors with typeof typeof(c(1.7, 5.3, 9.2)) [1] &quot;double&quot; typeof(c(&quot;hypertension&quot;, &quot;diabetes&quot;, &quot;atherosclerosis&quot;)) [1] &quot;character&quot; typeof(c(2L, 4L)) [1] &quot;integer&quot; typeof(c(TRUE, FALSE, TRUE)) [1] &quot;logical&quot; table(InsectSprays$spray) A B C D E F 12 12 12 12 12 12 typeof(InsectSprays$spray) [1] &quot;integer&quot; Here are 3 examples of coverting vectors from one type to another with as.x() functions. Guess what the returned value will be before you run the code (click on the green arrow at the top right). # you can convert vectors with as.x numeric &lt;- (c(1.7, 5.3, 9.2)) newvec1 &lt;- as.character(numeric) newvec1 [1] &quot;1.7&quot; &quot;5.3&quot; &quot;9.2&quot; typeof(newvec1) [1] &quot;character&quot; logical &lt;- c(TRUE, FALSE, TRUE) newvec2 &lt;- as.integer(logical) newvec2 [1] 1 0 1 typeof(newvec2) [1] &quot;integer&quot; character &lt;- c(&quot;2.4&quot;, &quot;5.3&quot;, &quot;7.2&quot;) newvec3 &lt;- as.numeric(character) newvec3 [1] 2.4 5.3 7.2 typeof(newvec3) [1] &quot;double&quot; 12.2 Data Structures Data structures are the nouns of programming in R. The data items of different types are organized into data structures. R has many data structures, and these include vector - the most common and basic data structure in R. Most functions in R operate on vectors. These vectorized functions act on every item in the vector, without you having to write a loop. Every item in a vector must be of the same data type. If the items added to a vector are of different data types, they will be silently and automatically coerced to a common data type. Sometimes this is helpful, but sometimes it can surprise you. &lt;Demo&gt; constructing vectors with concatenate, recycling of values, seq and seqalong, length (vs nchar). Use letters and LETTERS - two built in vectors in base R. Automatic coercion can be a common source of problems, especially for beginners. R tries to “helpfully” convert vectors from more specific types to more general types automatically and silently when you have mixed data types in a vector/variable column. Imagine you have a numeric vector of potassium values, like k &lt;- c(4.2, 3.9, 4.5, 4.3, 4.1) This is fine. k is a numeric class vector, with typeof(k) = double. But if the next value from the lab comes back as “sample lysed”, k &lt;- c(4.2, 3.9, 4.5, 4.3, 4.1. “sample lysed”), R will automatically and silently convert this vector to a more general class and type (“character”) The ordering of coercion (from more specific to more general) is: logical -&gt; integer -&gt; numeric -&gt; character -&gt; list Watch out for: data of the wrong type in your variable vectors, and silent changing of your data type - check your variable data types with glimpse() before you dive into data analysis. factors - factors are special vectors used for categorical data. These factors can be ordinal or nominal (unordered), and are important in lots of clinical data, and for modeling or plotting different categories. Factors are essentially integers with special labels (levels) attached. Factors can look like character vectors, but are actually stored as integers, which sometimes leads to unfortunate surprises. matrix - a matrix is a special case of a vector in R. A matrix must also have only a single data type, and has 2 dimensions. The matrix is filled with values by column as the default, and recycles values if needed. Matrices are often used for gene expression arrays and Omics applications to store lots of numeric results. Matrices are also often used “under the hood” for complex calculations, in the linear algebra used to fit many models. &lt;Demo matrix letters, nrow=2 vs nrow =6, dim(), matrix(letters, nrow=13), matrix(letters, nrow=2) list - a list is an all-purpose container for a variety of data types and vectors of any length. Lists are often heterogeneous in both data types and the length of vectors. Lists can even contain other lists. Lists are helpful when you have a related group of heterogeneous objects as results - vectors, dataframes, strings, etc., which can be bundled together in a list. One example of a list occurs in the starwars dataset, which has a row for each character. The column for which films they have appeared in is a list column. Each cell contains a character vectors of varying length, as each character has appeared in anywhere from 1 to 9 movies (as of 2021). starwars %&gt;% select(name, films) # A tibble: 87 × 2 name films &lt;chr&gt; &lt;list&gt; 1 Luke Skywalker &lt;chr [5]&gt; 2 C-3PO &lt;chr [6]&gt; 3 R2-D2 &lt;chr [7]&gt; 4 Darth Vader &lt;chr [4]&gt; 5 Leia Organa &lt;chr [5]&gt; 6 Owen Lars &lt;chr [3]&gt; 7 Beru Whitesun Lars &lt;chr [3]&gt; 8 R5-D4 &lt;chr [1]&gt; 9 Biggs Darklighter &lt;chr [1]&gt; 10 Obi-Wan Kenobi &lt;chr [6]&gt; # ℹ 77 more rows starwars$films %&gt;% head() [[1]] [1] &quot;A New Hope&quot; &quot;The Empire Strikes Back&quot; [3] &quot;Return of the Jedi&quot; &quot;Revenge of the Sith&quot; [5] &quot;The Force Awakens&quot; [[2]] [1] &quot;A New Hope&quot; &quot;The Empire Strikes Back&quot; [3] &quot;Return of the Jedi&quot; &quot;The Phantom Menace&quot; [5] &quot;Attack of the Clones&quot; &quot;Revenge of the Sith&quot; [[3]] [1] &quot;A New Hope&quot; &quot;The Empire Strikes Back&quot; [3] &quot;Return of the Jedi&quot; &quot;The Phantom Menace&quot; [5] &quot;Attack of the Clones&quot; &quot;Revenge of the Sith&quot; [7] &quot;The Force Awakens&quot; [[4]] [1] &quot;A New Hope&quot; &quot;The Empire Strikes Back&quot; [3] &quot;Return of the Jedi&quot; &quot;Revenge of the Sith&quot; [[5]] [1] &quot;A New Hope&quot; &quot;The Empire Strikes Back&quot; [3] &quot;Return of the Jedi&quot; &quot;Revenge of the Sith&quot; [5] &quot;The Force Awakens&quot; [[6]] [1] &quot;A New Hope&quot; &quot;Attack of the Clones&quot; &quot;Revenge of the Sith&quot; Lists can be a bit clunky to work with, as they nest more than a single value into a single cell. Sometimes this nested format can be helpful, and sometimes it is preferable to unnest() the data into a longer format. starwars %&gt;% select(name, films) # A tibble: 87 × 2 name films &lt;chr&gt; &lt;list&gt; 1 Luke Skywalker &lt;chr [5]&gt; 2 C-3PO &lt;chr [6]&gt; 3 R2-D2 &lt;chr [7]&gt; 4 Darth Vader &lt;chr [4]&gt; 5 Leia Organa &lt;chr [5]&gt; 6 Owen Lars &lt;chr [3]&gt; 7 Beru Whitesun Lars &lt;chr [3]&gt; 8 R5-D4 &lt;chr [1]&gt; 9 Biggs Darklighter &lt;chr [1]&gt; 10 Obi-Wan Kenobi &lt;chr [6]&gt; # ℹ 77 more rows # gives you a hidden list of films starwars %&gt;% select(name, films) %&gt;% unnest(cols = c(films)) # A tibble: 173 × 2 name films &lt;chr&gt; &lt;chr&gt; 1 Luke Skywalker A New Hope 2 Luke Skywalker The Empire Strikes Back 3 Luke Skywalker Return of the Jedi 4 Luke Skywalker Revenge of the Sith 5 Luke Skywalker The Force Awakens 6 C-3PO A New Hope 7 C-3PO The Empire Strikes Back 8 C-3PO Return of the Jedi 9 C-3PO The Phantom Menace 10 C-3PO Attack of the Clones # ℹ 163 more rows # unnest expands to multiple rows to show detail Lists can be useful for bundling togther related data of different types, like the results of a t-test. t_test_output &lt;- list( &quot;Welch Two Sample t-test&quot;, c(&quot;data: height by gender&quot;), data.frame(t = -1.5596, df = 37.315, p = 0.1273) ) t_test_output [[1]] [1] &quot;Welch Two Sample t-test&quot; [[2]] [1] &quot;data: height by gender&quot; [[3]] t df p 1 -1.5596 37.315 0.1273 data frame - a very important data structure in R, which corresponds to rectangular data in a spreadsheet. A data frame is a table of vectors (columns of variables) of the same length. If new vectors are added with a different length, an error will occur. Unlike a matrix, each vector (aka column, aka variable) in a dataframe can be a different data type. So you can combine character strings, integers, real numbers, logical values, and factors in a rectangular data frame in which each row is one observation, and the variables/columns/vectors are the values that are measured at that observation. A data frame can be thought of as a strict version of a list, in which each item in the list is an atomic vector (single data type) and must have the same length. You can even have list columns within a data frame. Note that if you run the typeof() function on a dataframe, it will report that it is a list. You can build a dataframe from a set of vectors (variables) by binding these together as columns/variables with the tibble() function. pat_id &lt;- c(1, 1, 2, 2, 3, 3) date &lt;- c(lubridate::ymd(&quot;2020-11-07&quot;, &quot;2020-12-03&quot;, &quot;2020-12-02&quot;, &quot;2020-12-15&quot;, &quot;2020-11-09&quot;, &quot;2020-12-02&quot;)) crp &lt;- c(5.1, 3.2, 7.6, 4.1, 4.3, 1.7) new_df &lt;- tibble(pat_id, date, crp) new_df # A tibble: 6 × 3 pat_id date crp &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; 1 1 2020-11-07 5.1 2 1 2020-12-03 3.2 3 2 2020-12-02 7.6 4 2 2020-12-15 4.1 5 3 2020-11-09 4.3 6 3 2020-12-02 1.7 tibble - a tibble is a modern upgrade to the data frame, with clear delineation of data types and printing that does not continuously spew out of your console. It also has the properties of a data frame underneath the additional features. You can convert a dataframe to a tibble with tibble(), or use tibble to build with vectors tibble(new_df) # A tibble: 6 × 3 pat_id date crp &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; 1 1 2020-11-07 5.1 2 1 2020-12-03 3.2 3 2 2020-12-02 7.6 4 2 2020-12-15 4.1 5 3 2020-11-09 4.3 6 3 2020-12-02 1.7 tibble(pat_id, date, crp) # A tibble: 6 × 3 pat_id date crp &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; 1 1 2020-11-07 5.1 2 1 2020-12-03 3.2 3 2 2020-12-02 7.6 4 2 2020-12-15 4.1 5 3 2020-11-09 4.3 6 3 2020-12-02 1.7 You can also build new row-wise tibbles with the tribble() function. tribble( ~pat_id, ~date, ~crp, 1, lubridate::ymd(&quot;2020-12-04&quot;), 5.1, 1, lubridate::ymd(&quot;2020-12-09&quot;), 3.7, 2, lubridate::ymd(&quot;2020-11-23&quot;), 3.6, 2, lubridate::ymd(&quot;2020-11-29&quot;), 1.9, 3, lubridate::ymd(&quot;2020-12-14&quot;), 1.9, 3, lubridate::ymd(&quot;2020-12-27&quot;), 0.6 ) # A tibble: 6 × 3 pat_id date crp &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; 1 1 2020-12-04 5.1 2 1 2020-12-09 3.7 3 2 2020-11-23 3.6 4 2 2020-11-29 1.9 5 3 2020-12-14 1.9 6 3 2020-12-27 0.6 R uses many other custom objects to contain things like a linear model, or the results of a t test. Many functions and packages build specific custom objects which are built upon these basic data structures. Similar to data types, functions in R are often designed to work on a specific data structure, and using the wrong data structure as input to a function will result in errors. It is important to be able to check your data structures as part of your initial DEV (Data Evaluation and Validation) process in order to avoid problems and prevent errors. 12.3 Examining Data Types and Data Structures There are a number of helpful base R functions to help you examine what the objects in your Environment actually are. This is an important step in avoiding errors, or in avoiding needing to diagnose them after the fact. assigning an object (not =) When you create a new object (dataframe, tibble, vector), it is transient. As soon as it prints to the Console, it is gone. If you want to refer back to it, or process it further later, you need to assign it to an object in your environment. When you do this, it will appear in your Environment pane in RStudio. To do this, you use an arrow from your code to the name of the new object. It is helpful to use concise names that are descriptive, in lower case with minimal punctuation (underscores and dashes are fine), no spaces, and that start with letters rather than numbers. It is important to avoid using R function names (like data or df or sum) as names for your objects. You can use either leftward arrows (Less than then dash key) &lt;- or rightward arrows -&gt; (dash key then greater than key) to assign data to an object. # example 1 tall &lt;- starwars %&gt;% filter(height &gt; 200) # example 2 starwars %&gt;% filter(height &lt; 70) -&gt; short Leftward arrows are thought of as sort of like the title of a recipe. In the first example above, you can read this as, “I am going to make a tibble of tall characters. I will start with the starwars dataset, then filter by height &gt;100 to get this tall tibble”. But most people don’t think or talk this way, and it is recommended to write “literate code” - which can be read naturally by humans and by computers. These data pipelines should read like sentences. Generally, we use the literate programming format in example 2 above for data wrangling, starting with a subject (starwars dataset), then one or more (automatically indented) verbs (functions) that wrangle the data, then end with the predicate (a new noun - the new resulting dataset). To do this requires the rightward arrow. To avoid hiding the resulting dataset in a thicket of code, remove the automatic indent and put this new object on the left margin. Once you have an object, you can use several functions to examine what you have, and to make sure that it is in the right format for future data wrangling or plotting functions. The str() function, denoting structure, is a good place to start interrogating data structures. Try this out. Run str(starwars) in your RStudio console. str(starwars) tibble [87 × 14] (S3: tbl_df/tbl/data.frame) $ name : chr [1:87] &quot;Luke Skywalker&quot; &quot;C-3PO&quot; &quot;R2-D2&quot; &quot;Darth Vader&quot; ... $ height : int [1:87] 172 167 96 202 150 178 165 97 183 182 ... $ mass : num [1:87] 77 75 32 136 49 120 75 32 84 77 ... $ hair_color: chr [1:87] &quot;blond&quot; NA NA &quot;none&quot; ... $ skin_color: chr [1:87] &quot;fair&quot; &quot;gold&quot; &quot;white, blue&quot; &quot;white&quot; ... $ eye_color : chr [1:87] &quot;blue&quot; &quot;yellow&quot; &quot;red&quot; &quot;yellow&quot; ... $ birth_year: num [1:87] 19 112 33 41.9 19 52 47 NA 24 57 ... $ sex : chr [1:87] &quot;male&quot; &quot;none&quot; &quot;none&quot; &quot;male&quot; ... $ gender : chr [1:87] &quot;masculine&quot; &quot;masculine&quot; &quot;masculine&quot; &quot;masculine&quot; ... $ homeworld : chr [1:87] &quot;Tatooine&quot; &quot;Tatooine&quot; &quot;Naboo&quot; &quot;Tatooine&quot; ... $ species : chr [1:87] &quot;Human&quot; &quot;Droid&quot; &quot;Droid&quot; &quot;Human&quot; ... $ films :List of 87 ..$ : chr [1:5] &quot;A New Hope&quot; &quot;The Empire Strikes Back&quot; &quot;Return of the Jedi&quot; &quot;Revenge of the Sith&quot; ... ..$ : chr [1:6] &quot;A New Hope&quot; &quot;The Empire Strikes Back&quot; &quot;Return of the Jedi&quot; &quot;The Phantom Menace&quot; ... ..$ : chr [1:7] &quot;A New Hope&quot; &quot;The Empire Strikes Back&quot; &quot;Return of the Jedi&quot; &quot;The Phantom Menace&quot; ... ..$ : chr [1:4] &quot;A New Hope&quot; &quot;The Empire Strikes Back&quot; &quot;Return of the Jedi&quot; &quot;Revenge of the Sith&quot; ..$ : chr [1:5] &quot;A New Hope&quot; &quot;The Empire Strikes Back&quot; &quot;Return of the Jedi&quot; &quot;Revenge of the Sith&quot; ... ..$ : chr [1:3] &quot;A New Hope&quot; &quot;Attack of the Clones&quot; &quot;Revenge of the Sith&quot; ..$ : chr [1:3] &quot;A New Hope&quot; &quot;Attack of the Clones&quot; &quot;Revenge of the Sith&quot; ..$ : chr &quot;A New Hope&quot; ..$ : chr &quot;A New Hope&quot; ..$ : chr [1:6] &quot;A New Hope&quot; &quot;The Empire Strikes Back&quot; &quot;Return of the Jedi&quot; &quot;The Phantom Menace&quot; ... ..$ : chr [1:3] &quot;The Phantom Menace&quot; &quot;Attack of the Clones&quot; &quot;Revenge of the Sith&quot; ..$ : chr [1:2] &quot;A New Hope&quot; &quot;Revenge of the Sith&quot; ..$ : chr [1:5] &quot;A New Hope&quot; &quot;The Empire Strikes Back&quot; &quot;Return of the Jedi&quot; &quot;Revenge of the Sith&quot; ... ..$ : chr [1:4] &quot;A New Hope&quot; &quot;The Empire Strikes Back&quot; &quot;Return of the Jedi&quot; &quot;The Force Awakens&quot; ..$ : chr &quot;A New Hope&quot; ..$ : chr [1:3] &quot;A New Hope&quot; &quot;Return of the Jedi&quot; &quot;The Phantom Menace&quot; ..$ : chr [1:3] &quot;A New Hope&quot; &quot;The Empire Strikes Back&quot; &quot;Return of the Jedi&quot; ..$ : chr &quot;A New Hope&quot; ..$ : chr [1:5] &quot;The Empire Strikes Back&quot; &quot;Return of the Jedi&quot; &quot;The Phantom Menace&quot; &quot;Attack of the Clones&quot; ... ..$ : chr [1:5] &quot;The Empire Strikes Back&quot; &quot;Return of the Jedi&quot; &quot;The Phantom Menace&quot; &quot;Attack of the Clones&quot; ... ..$ : chr [1:3] &quot;The Empire Strikes Back&quot; &quot;Return of the Jedi&quot; &quot;Attack of the Clones&quot; ..$ : chr &quot;The Empire Strikes Back&quot; ..$ : chr &quot;The Empire Strikes Back&quot; ..$ : chr [1:2] &quot;The Empire Strikes Back&quot; &quot;Return of the Jedi&quot; ..$ : chr &quot;The Empire Strikes Back&quot; ..$ : chr [1:2] &quot;Return of the Jedi&quot; &quot;The Force Awakens&quot; ..$ : chr &quot;Return of the Jedi&quot; ..$ : chr &quot;Return of the Jedi&quot; ..$ : chr &quot;Return of the Jedi&quot; ..$ : chr &quot;Return of the Jedi&quot; ..$ : chr &quot;The Phantom Menace&quot; ..$ : chr [1:3] &quot;The Phantom Menace&quot; &quot;Attack of the Clones&quot; &quot;Revenge of the Sith&quot; ..$ : chr &quot;The Phantom Menace&quot; ..$ : chr [1:3] &quot;The Phantom Menace&quot; &quot;Attack of the Clones&quot; &quot;Revenge of the Sith&quot; ..$ : chr [1:2] &quot;The Phantom Menace&quot; &quot;Attack of the Clones&quot; ..$ : chr &quot;The Phantom Menace&quot; ..$ : chr &quot;The Phantom Menace&quot; ..$ : chr &quot;The Phantom Menace&quot; ..$ : chr [1:2] &quot;The Phantom Menace&quot; &quot;Attack of the Clones&quot; ..$ : chr &quot;The Phantom Menace&quot; ..$ : chr &quot;The Phantom Menace&quot; ..$ : chr [1:2] &quot;The Phantom Menace&quot; &quot;Attack of the Clones&quot; ..$ : chr &quot;The Phantom Menace&quot; ..$ : chr &quot;Return of the Jedi&quot; ..$ : chr [1:3] &quot;The Phantom Menace&quot; &quot;Attack of the Clones&quot; &quot;Revenge of the Sith&quot; ..$ : chr &quot;The Phantom Menace&quot; ..$ : chr &quot;The Phantom Menace&quot; ..$ : chr &quot;The Phantom Menace&quot; ..$ : chr &quot;The Phantom Menace&quot; ..$ : chr [1:3] &quot;The Phantom Menace&quot; &quot;Attack of the Clones&quot; &quot;Revenge of the Sith&quot; ..$ : chr [1:3] &quot;The Phantom Menace&quot; &quot;Attack of the Clones&quot; &quot;Revenge of the Sith&quot; ..$ : chr [1:3] &quot;The Phantom Menace&quot; &quot;Attack of the Clones&quot; &quot;Revenge of the Sith&quot; ..$ : chr [1:2] &quot;The Phantom Menace&quot; &quot;Revenge of the Sith&quot; ..$ : chr [1:2] &quot;The Phantom Menace&quot; &quot;Revenge of the Sith&quot; ..$ : chr [1:2] &quot;The Phantom Menace&quot; &quot;Revenge of the Sith&quot; ..$ : chr &quot;The Phantom Menace&quot; ..$ : chr [1:3] &quot;The Phantom Menace&quot; &quot;Attack of the Clones&quot; &quot;Revenge of the Sith&quot; ..$ : chr [1:2] &quot;The Phantom Menace&quot; &quot;Attack of the Clones&quot; ..$ : chr &quot;Attack of the Clones&quot; ..$ : chr &quot;Attack of the Clones&quot; ..$ : chr &quot;Attack of the Clones&quot; ..$ : chr [1:2] &quot;Attack of the Clones&quot; &quot;Revenge of the Sith&quot; ..$ : chr [1:2] &quot;Attack of the Clones&quot; &quot;Revenge of the Sith&quot; ..$ : chr &quot;Attack of the Clones&quot; ..$ : chr &quot;Attack of the Clones&quot; ..$ : chr [1:2] &quot;Attack of the Clones&quot; &quot;Revenge of the Sith&quot; ..$ : chr [1:2] &quot;Attack of the Clones&quot; &quot;Revenge of the Sith&quot; ..$ : chr &quot;Attack of the Clones&quot; ..$ : chr &quot;Attack of the Clones&quot; ..$ : chr &quot;Attack of the Clones&quot; ..$ : chr &quot;Attack of the Clones&quot; ..$ : chr &quot;Attack of the Clones&quot; ..$ : chr &quot;Attack of the Clones&quot; ..$ : chr [1:2] &quot;Attack of the Clones&quot; &quot;Revenge of the Sith&quot; ..$ : chr &quot;Attack of the Clones&quot; ..$ : chr &quot;Attack of the Clones&quot; ..$ : chr [1:2] &quot;Attack of the Clones&quot; &quot;Revenge of the Sith&quot; ..$ : chr &quot;Revenge of the Sith&quot; ..$ : chr &quot;Revenge of the Sith&quot; ..$ : chr [1:2] &quot;A New Hope&quot; &quot;Revenge of the Sith&quot; ..$ : chr [1:2] &quot;Attack of the Clones&quot; &quot;Revenge of the Sith&quot; ..$ : chr &quot;Revenge of the Sith&quot; ..$ : chr &quot;The Force Awakens&quot; ..$ : chr &quot;The Force Awakens&quot; ..$ : chr &quot;The Force Awakens&quot; ..$ : chr &quot;The Force Awakens&quot; ..$ : chr &quot;The Force Awakens&quot; $ vehicles :List of 87 ..$ : chr [1:2] &quot;Snowspeeder&quot; &quot;Imperial Speeder Bike&quot; ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr &quot;Imperial Speeder Bike&quot; ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr &quot;Tribubble bongo&quot; ..$ : chr [1:2] &quot;Zephyr-G swoop bike&quot; &quot;XJ-6 airspeeder&quot; ..$ : chr(0) ..$ : chr &quot;AT-ST&quot; ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr &quot;Snowspeeder&quot; ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr &quot;Tribubble bongo&quot; ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr &quot;Sith speeder&quot; ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr &quot;Flitknot speeder&quot; ..$ : chr(0) ..$ : chr(0) ..$ : chr &quot;Koro-2 Exodrive airspeeder&quot; ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr &quot;Tsmeu-6 personal wheel bike&quot; ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) $ starships :List of 87 ..$ : chr [1:2] &quot;X-wing&quot; &quot;Imperial shuttle&quot; ..$ : chr(0) ..$ : chr(0) ..$ : chr &quot;TIE Advanced x1&quot; ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr &quot;X-wing&quot; ..$ : chr [1:5] &quot;Jedi starfighter&quot; &quot;Trade Federation cruiser&quot; &quot;Naboo star skiff&quot; &quot;Jedi Interceptor&quot; ... ..$ : chr [1:3] &quot;Naboo fighter&quot; &quot;Trade Federation cruiser&quot; &quot;Jedi Interceptor&quot; ..$ : chr(0) ..$ : chr [1:2] &quot;Millennium Falcon&quot; &quot;Imperial shuttle&quot; ..$ : chr [1:2] &quot;Millennium Falcon&quot; &quot;Imperial shuttle&quot; ..$ : chr(0) ..$ : chr(0) ..$ : chr &quot;X-wing&quot; ..$ : chr &quot;X-wing&quot; ..$ : chr(0) ..$ : chr(0) ..$ : chr &quot;Slave 1&quot; ..$ : chr(0) ..$ : chr(0) ..$ : chr &quot;Millennium Falcon&quot; ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr &quot;A-wing&quot; ..$ : chr(0) ..$ : chr &quot;Millennium Falcon&quot; ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr [1:3] &quot;Naboo fighter&quot; &quot;H-type Nubian yacht&quot; &quot;Naboo star skiff&quot; ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr &quot;Naboo Royal Starship&quot; ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr &quot;Scimitar&quot; ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr &quot;Jedi starfighter&quot; ..$ : chr(0) ..$ : chr &quot;Naboo fighter&quot; ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr &quot;Belbullab-22 starfighter&quot; ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr(0) ..$ : chr &quot;X-wing&quot; ..$ : chr(0) ..$ : chr(0) You can see from the output that this is a tibble, with 87 rows and 14 columns. It also meets the definitions of a table and a dataframe. Then the output shows each variable. The first 11 are either character or integer types. The last 3 (films, vehicles, starships) are all list-columns, and are more complicated. Note that glimpse(starwars) provides a prettier version of this output glimpse(starwars) Rows: 87 Columns: 14 $ name &lt;chr&gt; &quot;Luke Skywalker&quot;, &quot;C-3PO&quot;, &quot;R2-D2&quot;, &quot;Darth Vader&quot;, &quot;Leia Or… $ height &lt;int&gt; 172, 167, 96, 202, 150, 178, 165, 97, 183, 182, 188, 180, 2… $ mass &lt;dbl&gt; 77.0, 75.0, 32.0, 136.0, 49.0, 120.0, 75.0, 32.0, 84.0, 77.… $ hair_color &lt;chr&gt; &quot;blond&quot;, NA, NA, &quot;none&quot;, &quot;brown&quot;, &quot;brown, grey&quot;, &quot;brown&quot;, N… $ skin_color &lt;chr&gt; &quot;fair&quot;, &quot;gold&quot;, &quot;white, blue&quot;, &quot;white&quot;, &quot;light&quot;, &quot;light&quot;, &quot;… $ eye_color &lt;chr&gt; &quot;blue&quot;, &quot;yellow&quot;, &quot;red&quot;, &quot;yellow&quot;, &quot;brown&quot;, &quot;blue&quot;, &quot;blue&quot;,… $ birth_year &lt;dbl&gt; 19.0, 112.0, 33.0, 41.9, 19.0, 52.0, 47.0, NA, 24.0, 57.0, … $ sex &lt;chr&gt; &quot;male&quot;, &quot;none&quot;, &quot;none&quot;, &quot;male&quot;, &quot;female&quot;, &quot;male&quot;, &quot;female&quot;,… $ gender &lt;chr&gt; &quot;masculine&quot;, &quot;masculine&quot;, &quot;masculine&quot;, &quot;masculine&quot;, &quot;femini… $ homeworld &lt;chr&gt; &quot;Tatooine&quot;, &quot;Tatooine&quot;, &quot;Naboo&quot;, &quot;Tatooine&quot;, &quot;Alderaan&quot;, &quot;T… $ species &lt;chr&gt; &quot;Human&quot;, &quot;Droid&quot;, &quot;Droid&quot;, &quot;Human&quot;, &quot;Human&quot;, &quot;Human&quot;, &quot;Huma… $ films &lt;list&gt; &lt;&quot;A New Hope&quot;, &quot;The Empire Strikes Back&quot;, &quot;Return of the J… $ vehicles &lt;list&gt; &lt;&quot;Snowspeeder&quot;, &quot;Imperial Speeder Bike&quot;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &quot;Imp… $ starships &lt;list&gt; &lt;&quot;X-wing&quot;, &quot;Imperial shuttle&quot;&gt;, &lt;&gt;, &lt;&gt;, &quot;TIE Advanced x1&quot;,… If you want more detail about a given variable inside this dataframe, you can use typeof() or class(). typeof(starwars$mass) [1] &quot;double&quot; class(starwars$mass) [1] &quot;numeric&quot; For character variables, typeof() is the same as class(). But these are different for doubles and factors. Sometimes you want a quick look at all the variable names of a dataset. The functions names() or colnames() can quickly get you a vector of these names. names(starwars) [1] &quot;name&quot; &quot;height&quot; &quot;mass&quot; &quot;hair_color&quot; &quot;skin_color&quot; [6] &quot;eye_color&quot; &quot;birth_year&quot; &quot;sex&quot; &quot;gender&quot; &quot;homeworld&quot; [11] &quot;species&quot; &quot;films&quot; &quot;vehicles&quot; &quot;starships&quot; colnames(starwars) [1] &quot;name&quot; &quot;height&quot; &quot;mass&quot; &quot;hair_color&quot; &quot;skin_color&quot; [6] &quot;eye_color&quot; &quot;birth_year&quot; &quot;sex&quot; &quot;gender&quot; &quot;homeworld&quot; [11] &quot;species&quot; &quot;films&quot; &quot;vehicles&quot; &quot;starships&quot; If you want the dimensions of your dataset, you can use dim(). To just get the number of rows or columns, you can use nrow() or ncol(). When you have a numeric matrix, sometimes you have a ’bonus” column of rownames, which is a special column that specifies the observation, but does not have a normal column name. This keeps character strings out of the matrix, which can only have one data type. This is kind of a pain, especially if you need to access the information in the rownames column. When this is the case, the dplyr function rownames_to_column(matrix_name) is very helpful. The default name is rowname, but you can supply a better one. Run the example below in your Console pane. rownames_to_column(mtcars, var = &quot;make_model&quot;) make_model mpg cyl disp hp drat wt qsec vs am gear carb 1 Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 2 Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 3 Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 4 Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 5 Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 6 Valiant 18.1 6 225.0 105 2.76 3.460 20.22 1 0 3 1 7 Duster 360 14.3 8 360.0 245 3.21 3.570 15.84 0 0 3 4 8 Merc 240D 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 9 Merc 230 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 2 10 Merc 280 19.2 6 167.6 123 3.92 3.440 18.30 1 0 4 4 11 Merc 280C 17.8 6 167.6 123 3.92 3.440 18.90 1 0 4 4 12 Merc 450SE 16.4 8 275.8 180 3.07 4.070 17.40 0 0 3 3 13 Merc 450SL 17.3 8 275.8 180 3.07 3.730 17.60 0 0 3 3 14 Merc 450SLC 15.2 8 275.8 180 3.07 3.780 18.00 0 0 3 3 15 Cadillac Fleetwood 10.4 8 472.0 205 2.93 5.250 17.98 0 0 3 4 16 Lincoln Continental 10.4 8 460.0 215 3.00 5.424 17.82 0 0 3 4 17 Chrysler Imperial 14.7 8 440.0 230 3.23 5.345 17.42 0 0 3 4 18 Fiat 128 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 1 19 Honda Civic 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 20 Toyota Corolla 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 1 21 Toyota Corona 21.5 4 120.1 97 3.70 2.465 20.01 1 0 3 1 22 Dodge Challenger 15.5 8 318.0 150 2.76 3.520 16.87 0 0 3 2 23 AMC Javelin 15.2 8 304.0 150 3.15 3.435 17.30 0 0 3 2 24 Camaro Z28 13.3 8 350.0 245 3.73 3.840 15.41 0 0 3 4 25 Pontiac Firebird 19.2 8 400.0 175 3.08 3.845 17.05 0 0 3 2 26 Fiat X1-9 27.3 4 79.0 66 4.08 1.935 18.90 1 1 4 1 27 Porsche 914-2 26.0 4 120.3 91 4.43 2.140 16.70 0 1 5 2 28 Lotus Europa 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 29 Ford Pantera L 15.8 8 351.0 264 4.22 3.170 14.50 0 1 5 4 30 Ferrari Dino 19.7 6 145.0 175 3.62 2.770 15.50 0 1 5 6 31 Maserati Bora 15.0 8 301.0 335 3.54 3.570 14.60 0 1 5 8 32 Volvo 142E 21.4 4 121.0 109 4.11 2.780 18.60 1 1 4 2 12.4 Functions Functions are the verbs of programming in R. Functions act on existing data objects to rearrange them, change them, analyze them, plot them, or report them. Functions in R can do almost anything, and can work together in pipelines (aka chains) to do more complex and interesting things. Functions can call (activate) other functions, and you can build your own custom functions, which comes in handy when you want to do something similar multiple times, like summarizing data on 5 different variables. You could run a custom summary function on each variable (the argument to the function) each time, or use a programming function like map to run the function over a vector or list of the variables needed. You can see the inner workings of a function by just entering it into the RStudio console without parentheses. For example, for sd (standard deviation). sd function (x, na.rm = FALSE) sqrt(var(if (is.vector(x) || is.factor(x)) x else as.double(x), na.rm = na.rm)) &lt;bytecode: 0x120b4a4a0&gt; &lt;environment: namespace:stats&gt; You can see the inner workings of the sd function. This function takes the variance, then the square root of a vector, which is correct for producing a standard deviation. To run any function, you need to supply the parentheses, which normally contain the arguments (options) and identify the input data. Note that in a data pipe, the first argument is the incoming data, and does not need to be explicitly named in tidyverse functions. In older, non-tidyverse functions, data is often not the first argument, and needs to be named explicitly in a data pipeline, with the argument data = . telling the function to use the incoming data from the pipeline. To actually run any function, you need to include the parentheses at the end, even if you do not include any arguments. Two examples to try on your own are: Sys.Date() installed.packages() Give these a try in your Console pane. 12.5 Packages Packages make functions transportable and shareable. You can bundle a group of related functions into a package, and put it on Github, or even on CRAN, where other people can download it and use these functions for themselves. This can be helpful for miscellaneous functions that co-workers often use, or for a group of functions that work well together in a particular workflow. Packages can also contain data, which can be used for teaching examples, or as a way to share data. Packages can also contain tutorials related to the functions or the data in the package. Packages are like apps that you add to a phone to give it new functions. Packages enhance what you can do with R. When you start an R session in RStudio, your base R installation comes with 9 packages. You can see these listed by Clicking on Session/Restart R, then running print(.packages()) or search() in the Console pane. These packages include stats, graphics, grDevices, utils, datasets, devtools, usethis, methods, and base. You will also see the Global Environment and rstudio tools, and any autoloaded packages in this list. These are listed by their order on the search path. When you run (aka call) a function, R will search this path in order, starting with the Global Environment, then sequentially in the packages loaded, in order, for the function. This means that a function in a package loaded last (at the beginning of the search path) will mask a function with the same name in a package loaded earlier (like base, which is at the end of the search path). When you run the library() function to load a package, R will warn you about conflicts if you load a package with a function with the same name as a function in an already-loaded package. You can install more packages with the .install.packages() function, and see a pretty printed version of a list of all the installed packages with the library() function (with no arguments in the parentheses). You can get a matrix version (less pretty, but more accessible/manipulable) with the .installed.packages() function in the Console pane. You only have to install a package into your current library once. But to use a package in a current R session, you have to load it with the library(packagename) function. Let’s try this out on your own computer, within RStudio. First, within RStudio, go to the top menu bar and select Session/Restart R (Shift-Cmd-F10) to restart R and get a fresh, clean session. Then go to the Console pane and run the search() function. [Type in search() and press Return] You will see the search path, and all the currently loaded packages, in order. You can get a vector of just the loaded packages by going to the Console pane and running print(.packages()) Now load the tidyverse package by running the following in the Console pane: library(tidyverse) Note that there are 8 packages installed in addition to the {tidyverse} package (tidyverse is a meta-package, composed of multiple packages). Also note that there are two Conflicts reported. Two functions in the {dplyr} package, filter() and lag() have the same names as functions in the {stat} package. This means that when you run filter() or lag(), the default will be to run the {dplyr} versions, as these were installed last. These are earlier in the search path, and will mask the {stats} versions. You can still use the stats versions if you want to, by using the package prefix, with the format stats::filter() to make clear that you want this version, rather than dplyr::filter(). Now check what your search path looks like with search(). The nine packages from tidyverse (including tidyverse itself) should now be right after .GlobalEnv at the front of the search path, as they were installed last. If you now run print(.packages()) in the Console pane, you should now have 18 packages loaded. &lt;Demo - run library(tidyverse) - see the Conflicts warning about filter and lag.&gt;&lt;run search() again to see that tidyverse is a meta-package - with multiple new packages loaded in the search path). Packages are stored in libraries. You have a global library, and you can have project-specific libraries. You can see the file paths to your available libraries with the function .libPaths(). This will print (to the Console) the path to your package library for your specific major version of R. # You can check your own library path # Run this function in your Rstudio Console to find the current library on your computer .libPaths() [1] &quot;/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library&quot; 12.6 The Building Blocks of R Now you know about the 4 key building blocks of R, and how they work. Being able to check data types with typeof() and data structures with str() will help you avoid running functions on data that is not in the right format for a particular function. Dataframes and tibbles will be the key data structures which you will frequently manipulate with functions to wrangle, analyze, visualize, and report your medical research. "],["building-your-table-one-with-the-gtsummary-package.html", "Chapter 13 Building Your Table One with the {gtsummary} Package 13.1 Using tbl_summary() from the gtsummary package 13.2 Making a Basic table 13.3 Multiple Dimensions 13.4 New Challenges 13.5 Even More Help 13.6 Figuring out Column names 13.7 Even More Challenges 13.8 Adding Some Formatting 13.9 A Fancier Version for gt 13.10 A Fancier Version for Flextable", " Chapter 13 Building Your Table One with the {gtsummary} Package Table One is a standard table in most clinical studies, where the sample of the participants studied is described. This table is often used to provide the demographics and distributions of patient characteristics, to enable reviewers and readers to determine whether the study sample is representative of the population that they see in their clinical practice, and whether the results are generalizable to their patients. This is important because the vast majority of clinical trials are extreme examples of a convenience sample, as many potential participants will not meet the inclusion and exclusion criteria, and far fewer of the eligible people will be willing to consent and enroll. This means that the study sample is often not representative of the population of people with the particular disease state under study. In order to help the reader, we generally provide the mean and standard deviation of numeric variables like age and weight/BMI, and the counts and percentages of categorical variables like sex and disease location. If particular numeric variables are quite skewed, like hospital length of stay or medical costs, we will often use the median and interquartile range instead of the mean and standard deviation. In this chapter, we will use the {gtsummary} package to build a Table One. This package is a powerful tool for making tables in R, and is especially useful for clinical research, which it was designed for. It is built on top of the {gt} package, which is a modern and flexible package for building and formatting tables in R. The {gtsummary} package is designed to make it easy to make a Table One, and to customize it to your needs. You can use the tools from {gt} to format the table, or convert the table to another format like {flextable}, and use the formatting tools from that package if you prefer to format your table. 13.1 Using tbl_summary() from the gtsummary package The {gtsummary} package uses the tbl_summary() function to make a Table One. But you can do a lot with the options to customize this basic table. Let’s start with a clinical trial dataset, and use it to make a basic demographics table. Run the code below to see the data in two different ways. These data are from a simple hypothetical chemotherapy trial built into {gtsummary}. head(trial) # A tibble: 6 × 8 trt age marker stage grade response death ttdeath &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; 1 Drug A 23 0.16 T1 II 0 0 24 2 Drug B 9 1.11 T2 I 1 0 24 3 Drug A 31 0.277 T1 II 0 0 24 4 Drug A NA 2.07 T3 III 1 1 17.6 5 Drug A 51 2.77 T4 III 1 1 16.4 6 Drug B 39 0.613 T4 I 0 1 15.6 glimpse(trial) Rows: 200 Columns: 8 $ trt &lt;chr&gt; &quot;Drug A&quot;, &quot;Drug B&quot;, &quot;Drug A&quot;, &quot;Drug A&quot;, &quot;Drug A&quot;, &quot;Drug B&quot;, &quot;… $ age &lt;dbl&gt; 23, 9, 31, NA, 51, 39, 37, 32, 31, 34, 42, 63, 54, 21, 48, 71… $ marker &lt;dbl&gt; 0.160, 1.107, 0.277, 2.067, 2.767, 0.613, 0.354, 1.739, 0.144… $ stage &lt;fct&gt; T1, T2, T1, T3, T4, T4, T1, T1, T1, T3, T1, T3, T4, T4, T1, T… $ grade &lt;fct&gt; II, I, II, III, III, I, II, I, II, I, III, I, III, I, I, III,… $ response &lt;int&gt; 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0… $ death &lt;int&gt; 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0… $ ttdeath &lt;dbl&gt; 24.00, 24.00, 24.00, 17.64, 16.43, 15.64, 24.00, 18.43, 24.00… We can see from this output that patients at different cancer stages and grades are included in the trial, and that the treatment is either Drug A or Drug B. There are dichotomous variables for response and death and a continuous variable for time to death in months. You can load the {tidyverse}, {gt}, and {gtsummary} packages in your local RStudio session to get started. Run View(trial) to see the raw trial data in a spreadsheet-like format. Note the variable labels. 13.2 Making a Basic table You can use the tbl_summary function to get started with your first Table One. Copy and run the code below in your local RStudio session as a first step. Take a look at the HTML output in the Viewer tab on the lower right. Then add more variables to the include statement to get a more complete demographics table. Try adding cancer stage (stage) and grade. See how the function (automatically) handles categorical vs. continuous variables. Note that there are 11 missing age values. The function will by default include missing values in the table. library(gt) library(gtsummary) library(tidyverse, quietly = TRUE) trial %&gt;% tbl_summary(include = c(age, trt), statistic = list(all_categorical() ~ &quot;n = {n}&quot;), digits = all_continuous() ~ 0) #ubmowkgpyj table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #ubmowkgpyj thead, #ubmowkgpyj tbody, #ubmowkgpyj tfoot, #ubmowkgpyj tr, #ubmowkgpyj td, #ubmowkgpyj th { border-style: none; } #ubmowkgpyj p { margin: 0; padding: 0; } #ubmowkgpyj .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #ubmowkgpyj .gt_caption { padding-top: 4px; padding-bottom: 4px; } #ubmowkgpyj .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #ubmowkgpyj .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #ubmowkgpyj .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #ubmowkgpyj .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #ubmowkgpyj .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #ubmowkgpyj .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #ubmowkgpyj .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #ubmowkgpyj .gt_column_spanner_outer:first-child { padding-left: 0; } #ubmowkgpyj .gt_column_spanner_outer:last-child { padding-right: 0; } #ubmowkgpyj .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #ubmowkgpyj .gt_spanner_row { border-bottom-style: hidden; } #ubmowkgpyj .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #ubmowkgpyj .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #ubmowkgpyj .gt_from_md > :first-child { margin-top: 0; } #ubmowkgpyj .gt_from_md > :last-child { margin-bottom: 0; } #ubmowkgpyj .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #ubmowkgpyj .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #ubmowkgpyj .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #ubmowkgpyj .gt_row_group_first td { border-top-width: 2px; } #ubmowkgpyj .gt_row_group_first th { border-top-width: 2px; } #ubmowkgpyj .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #ubmowkgpyj .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #ubmowkgpyj .gt_first_summary_row.thick { border-top-width: 2px; } #ubmowkgpyj .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #ubmowkgpyj .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #ubmowkgpyj .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #ubmowkgpyj .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #ubmowkgpyj .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #ubmowkgpyj .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #ubmowkgpyj .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #ubmowkgpyj .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #ubmowkgpyj .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #ubmowkgpyj .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #ubmowkgpyj .gt_left { text-align: left; } #ubmowkgpyj .gt_center { text-align: center; } #ubmowkgpyj .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #ubmowkgpyj .gt_font_normal { font-weight: normal; } #ubmowkgpyj .gt_font_bold { font-weight: bold; } #ubmowkgpyj .gt_font_italic { font-style: italic; } #ubmowkgpyj .gt_super { font-size: 65%; } #ubmowkgpyj .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #ubmowkgpyj .gt_asterisk { font-size: 100%; vertical-align: 0; } #ubmowkgpyj .gt_indent_1 { text-indent: 5px; } #ubmowkgpyj .gt_indent_2 { text-indent: 10px; } #ubmowkgpyj .gt_indent_3 { text-indent: 15px; } #ubmowkgpyj .gt_indent_4 { text-indent: 20px; } #ubmowkgpyj .gt_indent_5 { text-indent: 25px; } #ubmowkgpyj .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #ubmowkgpyj div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } Characteristic N = 2001 Age 47 (38, 57)     Unknown 11 Chemotherapy Treatment     Drug A n = 98     Drug B n = 102 1 Median (Q1, Q3); n = n Note that we formatted the categorical variables to show the count of each level, with n = {n}, and we set the number of digits for continuous variables to 0. This is a good starting point for a Table One, but we can do much more with the tbl_summary function. 13.2.1 Challenges: Run help(\"tbl_summary\") in your local RStudio console. Read the help file, and figure out what each argument does in the function. Also take a look at the tutorial online. Click through this link to see the tutorial on the {gtsummary} packagetbl_summary()` function. How can you tell the function when a variable should be continuous vs categorical vs dichotomous? Set age to continuous. How do you control the number of digits in a mean or sd? Try setting age (or all_continous) to 2 digits. How do you set mean/sd vs median/IQR for a particular variable? (make age a mean/SD) Why does the treatment (when you add this variable) print out as Chemotherapy Treatment instead of trt? (check the View function) How can you change the label for a given variable? Try changing the T stage to Tumor Stage. How can you change the label for a given value (of a categorical variable)? Try changing the drug names to Axitinib (A) and Bleomycin (B). NOTE: this requires a mutate/case_when in the data pipeline BEFORE you call the tbl_summary function. Remove the n= from the categorical variables. Change the missing_text Unknown to “Missing” for the missing values in age. Take a few minutes to do these challenges (lean on the tutorial for help), then peek at the solution below. Solution trial %&gt;% mutate(trt = case_when(trt == &quot;Drug A&quot; ~ &quot;Axitinib&quot;, trt == &quot;Drug B&quot; ~ &quot;Bleomycin&quot;)) %&gt;% tbl_summary(include = c(age, trt, stage, grade), statistic = list(all_categorical() ~ &quot;{n}&quot;, all_continuous() ~ &quot;{mean} ({sd})&quot;), digits = all_continuous() ~ 2, label = list(trt ~ &quot;Chemotherapy Treatment&quot;, stage ~ &quot;Tumor Stage&quot;, grade ~ &quot;Tumor Grade&quot;), missing_text = &quot;Missing&quot;) #puczxvshcr table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #puczxvshcr thead, #puczxvshcr tbody, #puczxvshcr tfoot, #puczxvshcr tr, #puczxvshcr td, #puczxvshcr th { border-style: none; } #puczxvshcr p { margin: 0; padding: 0; } #puczxvshcr .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #puczxvshcr .gt_caption { padding-top: 4px; padding-bottom: 4px; } #puczxvshcr .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #puczxvshcr .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #puczxvshcr .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #puczxvshcr .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #puczxvshcr .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #puczxvshcr .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #puczxvshcr .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #puczxvshcr .gt_column_spanner_outer:first-child { padding-left: 0; } #puczxvshcr .gt_column_spanner_outer:last-child { padding-right: 0; } #puczxvshcr .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #puczxvshcr .gt_spanner_row { border-bottom-style: hidden; } #puczxvshcr .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #puczxvshcr .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #puczxvshcr .gt_from_md > :first-child { margin-top: 0; } #puczxvshcr .gt_from_md > :last-child { margin-bottom: 0; } #puczxvshcr .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #puczxvshcr .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #puczxvshcr .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #puczxvshcr .gt_row_group_first td { border-top-width: 2px; } #puczxvshcr .gt_row_group_first th { border-top-width: 2px; } #puczxvshcr .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #puczxvshcr .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #puczxvshcr .gt_first_summary_row.thick { border-top-width: 2px; } #puczxvshcr .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #puczxvshcr .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #puczxvshcr .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #puczxvshcr .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #puczxvshcr .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #puczxvshcr .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #puczxvshcr .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #puczxvshcr .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #puczxvshcr .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #puczxvshcr .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #puczxvshcr .gt_left { text-align: left; } #puczxvshcr .gt_center { text-align: center; } #puczxvshcr .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #puczxvshcr .gt_font_normal { font-weight: normal; } #puczxvshcr .gt_font_bold { font-weight: bold; } #puczxvshcr .gt_font_italic { font-style: italic; } #puczxvshcr .gt_super { font-size: 65%; } #puczxvshcr .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #puczxvshcr .gt_asterisk { font-size: 100%; vertical-align: 0; } #puczxvshcr .gt_indent_1 { text-indent: 5px; } #puczxvshcr .gt_indent_2 { text-indent: 10px; } #puczxvshcr .gt_indent_3 { text-indent: 15px; } #puczxvshcr .gt_indent_4 { text-indent: 20px; } #puczxvshcr .gt_indent_5 { text-indent: 25px; } #puczxvshcr .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #puczxvshcr div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } Characteristic N = 2001 Age 47.24 (14.31)     Missing 11 Chemotherapy Treatment     Axitinib 98     Bleomycin 102 Tumor Stage     T1 53     T2 54     T3 43     T4 50 Tumor Grade     I 68     II 68     III 64 1 Mean (SD); n 13.3 Multiple Dimensions Now for your next challenge - rather than just having one column, let’s help the reader compare the demographics of the two treatment arms with a by argument within tbl_summary(). Copy and edit the code below to produce separate columns for each treatment arm. Note that when you are using trt as the by variable for columns, it can not be included in the includeargument to make the rows, and it can not be in the list of labels to be modified. Note also that we added percentages (in parentheses) to the categorical levels. (how would you remove the parentheses and use a forward slash to separate the N from the percentage?) Copy and run the code below to see the result. trial %&gt;% mutate(trt = case_when(trt == &quot;Drug A&quot; ~ &quot;Axitinib&quot;, trt == &quot;Drug B&quot; ~ &quot;Bleomycin&quot;)) %&gt;% tbl_summary(by = trt, include = c(age, stage, grade), statistic = list(all_categorical() ~ &quot;{n} ({p}%)&quot;, all_continuous() ~ &quot;{mean} ({sd})&quot;), digits = all_continuous() ~ 2, label = list(stage ~ &quot;Tumor Stage&quot;, grade ~ &quot;Tumor Grade&quot;), missing_text = &quot;Missing&quot;) #dfvgtpyrin table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #dfvgtpyrin thead, #dfvgtpyrin tbody, #dfvgtpyrin tfoot, #dfvgtpyrin tr, #dfvgtpyrin td, #dfvgtpyrin th { border-style: none; } #dfvgtpyrin p { margin: 0; padding: 0; } #dfvgtpyrin .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #dfvgtpyrin .gt_caption { padding-top: 4px; padding-bottom: 4px; } #dfvgtpyrin .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #dfvgtpyrin .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #dfvgtpyrin .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #dfvgtpyrin .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #dfvgtpyrin .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #dfvgtpyrin .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #dfvgtpyrin .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #dfvgtpyrin .gt_column_spanner_outer:first-child { padding-left: 0; } #dfvgtpyrin .gt_column_spanner_outer:last-child { padding-right: 0; } #dfvgtpyrin .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #dfvgtpyrin .gt_spanner_row { border-bottom-style: hidden; } #dfvgtpyrin .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #dfvgtpyrin .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #dfvgtpyrin .gt_from_md > :first-child { margin-top: 0; } #dfvgtpyrin .gt_from_md > :last-child { margin-bottom: 0; } #dfvgtpyrin .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #dfvgtpyrin .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #dfvgtpyrin .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #dfvgtpyrin .gt_row_group_first td { border-top-width: 2px; } #dfvgtpyrin .gt_row_group_first th { border-top-width: 2px; } #dfvgtpyrin .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #dfvgtpyrin .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #dfvgtpyrin .gt_first_summary_row.thick { border-top-width: 2px; } #dfvgtpyrin .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #dfvgtpyrin .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #dfvgtpyrin .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #dfvgtpyrin .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #dfvgtpyrin .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #dfvgtpyrin .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #dfvgtpyrin .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #dfvgtpyrin .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #dfvgtpyrin .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #dfvgtpyrin .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #dfvgtpyrin .gt_left { text-align: left; } #dfvgtpyrin .gt_center { text-align: center; } #dfvgtpyrin .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #dfvgtpyrin .gt_font_normal { font-weight: normal; } #dfvgtpyrin .gt_font_bold { font-weight: bold; } #dfvgtpyrin .gt_font_italic { font-style: italic; } #dfvgtpyrin .gt_super { font-size: 65%; } #dfvgtpyrin .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #dfvgtpyrin .gt_asterisk { font-size: 100%; vertical-align: 0; } #dfvgtpyrin .gt_indent_1 { text-indent: 5px; } #dfvgtpyrin .gt_indent_2 { text-indent: 10px; } #dfvgtpyrin .gt_indent_3 { text-indent: 15px; } #dfvgtpyrin .gt_indent_4 { text-indent: 20px; } #dfvgtpyrin .gt_indent_5 { text-indent: 25px; } #dfvgtpyrin .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #dfvgtpyrin div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } Characteristic Axitinib N = 981 Bleomycin N = 1021 Age 47.01 (14.71) 47.45 (14.01)     Missing 7 4 Tumor Stage     T1 28 (29%) 25 (25%)     T2 25 (26%) 29 (28%)     T3 22 (22%) 21 (21%)     T4 23 (23%) 27 (26%) Tumor Grade     I 35 (36%) 33 (32%)     II 32 (33%) 36 (35%)     III 31 (32%) 33 (32%) 1 Mean (SD); n (%) 13.4 New Challenges Now for your next challenges (lean on the tbl_summary tutorial on the website): Change the label for grade to “Tumor Badness Scale” Change the label for stage to “Tumor Extent” Set all continuous variables to 3 digits Set a Spanning Header (using a modify function) over the Drug columns with the label of “Treatment Arm” (note that the names of the columns are actually “stat1” and “stat2”). What do the asterisks do? What happens if you remove them?) Make the labels bold (note that this is a new function, not an argument for tbl_summary()) Make the levels italicized Take a few minutes to do these challenges, then peek at the solution below. Solution trial %&gt;% mutate(trt = case_when(trt == &quot;Drug A&quot; ~ &quot;Axitinib&quot;, trt == &quot;Drug B&quot; ~ &quot;Bleomycin&quot;)) %&gt;% tbl_summary(by = trt, include = c(age, trt, stage, grade), statistic = list(all_categorical() ~ &quot;{n} ({p}%)&quot;, all_continuous() ~ &quot;{mean} ({sd})&quot;), digits = all_continuous() ~ 3, label = list(stage ~ &quot;Tumor Extent&quot;, grade ~ &quot;Tumor Badness Scale&quot;), missing_text = &quot;Missing&quot;) %&gt;% modify_spanning_header(all_stat_cols() ~ &quot;**Treatment Arm**&quot;) |&gt; italicize_levels() %&gt;% bold_labels() #bnthklenod table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #bnthklenod thead, #bnthklenod tbody, #bnthklenod tfoot, #bnthklenod tr, #bnthklenod td, #bnthklenod th { border-style: none; } #bnthklenod p { margin: 0; padding: 0; } #bnthklenod .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #bnthklenod .gt_caption { padding-top: 4px; padding-bottom: 4px; } #bnthklenod .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #bnthklenod .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #bnthklenod .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #bnthklenod .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #bnthklenod .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #bnthklenod .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #bnthklenod .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #bnthklenod .gt_column_spanner_outer:first-child { padding-left: 0; } #bnthklenod .gt_column_spanner_outer:last-child { padding-right: 0; } #bnthklenod .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #bnthklenod .gt_spanner_row { border-bottom-style: hidden; } #bnthklenod .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #bnthklenod .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #bnthklenod .gt_from_md > :first-child { margin-top: 0; } #bnthklenod .gt_from_md > :last-child { margin-bottom: 0; } #bnthklenod .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #bnthklenod .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #bnthklenod .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #bnthklenod .gt_row_group_first td { border-top-width: 2px; } #bnthklenod .gt_row_group_first th { border-top-width: 2px; } #bnthklenod .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #bnthklenod .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #bnthklenod .gt_first_summary_row.thick { border-top-width: 2px; } #bnthklenod .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #bnthklenod .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #bnthklenod .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #bnthklenod .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #bnthklenod .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #bnthklenod .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #bnthklenod .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #bnthklenod .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #bnthklenod .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #bnthklenod .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #bnthklenod .gt_left { text-align: left; } #bnthklenod .gt_center { text-align: center; } #bnthklenod .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #bnthklenod .gt_font_normal { font-weight: normal; } #bnthklenod .gt_font_bold { font-weight: bold; } #bnthklenod .gt_font_italic { font-style: italic; } #bnthklenod .gt_super { font-size: 65%; } #bnthklenod .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #bnthklenod .gt_asterisk { font-size: 100%; vertical-align: 0; } #bnthklenod .gt_indent_1 { text-indent: 5px; } #bnthklenod .gt_indent_2 { text-indent: 10px; } #bnthklenod .gt_indent_3 { text-indent: 15px; } #bnthklenod .gt_indent_4 { text-indent: 20px; } #bnthklenod .gt_indent_5 { text-indent: 25px; } #bnthklenod .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #bnthklenod div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } Characteristic Treatment Arm Axitinib N = 981 Bleomycin N = 1021 Age 47.011 (14.709) 47.449 (14.005)     Missing 7 4 Tumor Extent     T1 28 (29%) 25 (25%)     T2 25 (26%) 29 (28%)     T3 22 (22%) 21 (21%)     T4 23 (23%) 27 (26%) Tumor Badness Scale     I 35 (36%) 33 (32%)     II 32 (33%) 36 (35%)     III 31 (32%) 33 (32%) 1 Mean (SD); n (%) 13.5 Even More Help If the package author has set up vignettes, there are examples of how to use a function available as help files in R. You can run the function vignette(function) in the Console. Try vignette(\"gtsummary_definition\"). 13.6 Figuring out Column names Column names are made on the fly by tbl_summary when you use the by= argument or add_p() or add_n() in tbl_summary() so you can’t just refer to them by the name of the drug or trt variable (the displayed names are called Headers). You can use the show_header_names function to see the names of the columns of the table you just built. They are usually (from left to right) something like n, stat_1, stat_2, p.value, etc. But it helps to know the names of these if you want to build a spanning header. See the example below and its output to see how to use show_header_names. The column name labels (needed to manipulate tbese) are not the same as the displayed Headers. tbl &lt;- trial |&gt; tbl_summary(by = trt) |&gt; add_n() |&gt; add_p() tbl #wdbextjggu table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #wdbextjggu thead, #wdbextjggu tbody, #wdbextjggu tfoot, #wdbextjggu tr, #wdbextjggu td, #wdbextjggu th { border-style: none; } #wdbextjggu p { margin: 0; padding: 0; } #wdbextjggu .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #wdbextjggu .gt_caption { padding-top: 4px; padding-bottom: 4px; } #wdbextjggu .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #wdbextjggu .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #wdbextjggu .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #wdbextjggu .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #wdbextjggu .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #wdbextjggu .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #wdbextjggu .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #wdbextjggu .gt_column_spanner_outer:first-child { padding-left: 0; } #wdbextjggu .gt_column_spanner_outer:last-child { padding-right: 0; } #wdbextjggu .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #wdbextjggu .gt_spanner_row { border-bottom-style: hidden; } #wdbextjggu .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #wdbextjggu .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #wdbextjggu .gt_from_md > :first-child { margin-top: 0; } #wdbextjggu .gt_from_md > :last-child { margin-bottom: 0; } #wdbextjggu .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #wdbextjggu .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #wdbextjggu .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #wdbextjggu .gt_row_group_first td { border-top-width: 2px; } #wdbextjggu .gt_row_group_first th { border-top-width: 2px; } #wdbextjggu .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #wdbextjggu .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #wdbextjggu .gt_first_summary_row.thick { border-top-width: 2px; } #wdbextjggu .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #wdbextjggu .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #wdbextjggu .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #wdbextjggu .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #wdbextjggu .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #wdbextjggu .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #wdbextjggu .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #wdbextjggu .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #wdbextjggu .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #wdbextjggu .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #wdbextjggu .gt_left { text-align: left; } #wdbextjggu .gt_center { text-align: center; } #wdbextjggu .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #wdbextjggu .gt_font_normal { font-weight: normal; } #wdbextjggu .gt_font_bold { font-weight: bold; } #wdbextjggu .gt_font_italic { font-style: italic; } #wdbextjggu .gt_super { font-size: 65%; } #wdbextjggu .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #wdbextjggu .gt_asterisk { font-size: 100%; vertical-align: 0; } #wdbextjggu .gt_indent_1 { text-indent: 5px; } #wdbextjggu .gt_indent_2 { text-indent: 10px; } #wdbextjggu .gt_indent_3 { text-indent: 15px; } #wdbextjggu .gt_indent_4 { text-indent: 20px; } #wdbextjggu .gt_indent_5 { text-indent: 25px; } #wdbextjggu .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #wdbextjggu div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } Characteristic N Drug A N = 981 Drug B N = 1021 p-value2 Age 189 46 (37, 60) 48 (39, 56) 0.7     Unknown 7 4 Marker Level (ng/mL) 190 0.84 (0.23, 1.60) 0.52 (0.18, 1.21) 0.085     Unknown 6 4 T Stage 200 0.9     T1 28 (29%) 25 (25%)     T2 25 (26%) 29 (28%)     T3 22 (22%) 21 (21%)     T4 23 (23%) 27 (26%) Grade 200 0.9     I 35 (36%) 33 (32%)     II 32 (33%) 36 (35%)     III 31 (32%) 33 (32%) Tumor Response 193 28 (29%) 33 (34%) 0.5     Unknown 3 4 Patient Died 200 52 (53%) 60 (59%) 0.4 Months to Death/Censor 200 23.5 (17.4, 24.0) 21.2 (14.5, 24.0) 0.14 1 Median (Q1, Q3); n (%) 2 Wilcoxon rank sum test; Pearson’s Chi-squared test tbl |&gt; show_header_names() Column Name Header level* N* n* p* label &quot;**Characteristic**&quot; 200 &lt;int&gt; n &quot;**N**&quot; 200 &lt;int&gt; stat_1 &quot;**Drug A** \\nN = 98&quot; Drug A &lt;chr&gt; 200 &lt;int&gt; 98 &lt;int&gt; 0.490 &lt;dbl&gt; stat_2 &quot;**Drug B** \\nN = 102&quot; Drug B &lt;chr&gt; 200 &lt;int&gt; 102 &lt;int&gt; 0.510 &lt;dbl&gt; p.value &quot;**p-value**&quot; 200 &lt;int&gt; 13.7 Even More Challenges Start with this chunk of code: trial %&gt;% mutate(trt = case_when(trt == &quot;Drug A&quot; ~ &quot;Axitinib&quot;, trt == &quot;Drug B&quot; ~ &quot;Bleomycin&quot;)) %&gt;% tbl_summary(by = trt, include = c(age, trt, stage, grade), statistic = list(all_categorical() ~ &quot;{n} ({p}%)&quot;, all_continuous() ~ &quot;{mean} ({sd})&quot;), digits = all_continuous() ~ 3, label = list(stage ~ &quot;Tumor Extent&quot;, grade ~ &quot;Tumor Badness Scale&quot;), missing_text = &quot;Missing&quot;) %&gt;% modify_spanning_header(all_stat_cols() ~ &quot;**Treatment Arm**&quot;) |&gt; bold_labels() #rjzyfrtplm table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #rjzyfrtplm thead, #rjzyfrtplm tbody, #rjzyfrtplm tfoot, #rjzyfrtplm tr, #rjzyfrtplm td, #rjzyfrtplm th { border-style: none; } #rjzyfrtplm p { margin: 0; padding: 0; } #rjzyfrtplm .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #rjzyfrtplm .gt_caption { padding-top: 4px; padding-bottom: 4px; } #rjzyfrtplm .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #rjzyfrtplm .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #rjzyfrtplm .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #rjzyfrtplm .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #rjzyfrtplm .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #rjzyfrtplm .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #rjzyfrtplm .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #rjzyfrtplm .gt_column_spanner_outer:first-child { padding-left: 0; } #rjzyfrtplm .gt_column_spanner_outer:last-child { padding-right: 0; } #rjzyfrtplm .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #rjzyfrtplm .gt_spanner_row { border-bottom-style: hidden; } #rjzyfrtplm .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #rjzyfrtplm .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #rjzyfrtplm .gt_from_md > :first-child { margin-top: 0; } #rjzyfrtplm .gt_from_md > :last-child { margin-bottom: 0; } #rjzyfrtplm .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #rjzyfrtplm .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #rjzyfrtplm .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #rjzyfrtplm .gt_row_group_first td { border-top-width: 2px; } #rjzyfrtplm .gt_row_group_first th { border-top-width: 2px; } #rjzyfrtplm .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #rjzyfrtplm .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #rjzyfrtplm .gt_first_summary_row.thick { border-top-width: 2px; } #rjzyfrtplm .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #rjzyfrtplm .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #rjzyfrtplm .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #rjzyfrtplm .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #rjzyfrtplm .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #rjzyfrtplm .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #rjzyfrtplm .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #rjzyfrtplm .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #rjzyfrtplm .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #rjzyfrtplm .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #rjzyfrtplm .gt_left { text-align: left; } #rjzyfrtplm .gt_center { text-align: center; } #rjzyfrtplm .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #rjzyfrtplm .gt_font_normal { font-weight: normal; } #rjzyfrtplm .gt_font_bold { font-weight: bold; } #rjzyfrtplm .gt_font_italic { font-style: italic; } #rjzyfrtplm .gt_super { font-size: 65%; } #rjzyfrtplm .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #rjzyfrtplm .gt_asterisk { font-size: 100%; vertical-align: 0; } #rjzyfrtplm .gt_indent_1 { text-indent: 5px; } #rjzyfrtplm .gt_indent_2 { text-indent: 10px; } #rjzyfrtplm .gt_indent_3 { text-indent: 15px; } #rjzyfrtplm .gt_indent_4 { text-indent: 20px; } #rjzyfrtplm .gt_indent_5 { text-indent: 25px; } #rjzyfrtplm .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #rjzyfrtplm div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } Characteristic Treatment Arm Axitinib N = 981 Bleomycin N = 1021 Age 47.011 (14.709) 47.449 (14.005)     Missing 7 4 Tumor Extent     T1 28 (29%) 25 (25%)     T2 25 (26%) 29 (28%)     T3 22 (22%) 21 (21%)     T4 23 (23%) 27 (26%) Tumor Badness Scale     I 35 (36%) 33 (32%)     II 32 (33%) 36 (35%)     III 31 (32%) 33 (32%) 1 Mean (SD); n (%) Now for your next challenges: Add an overall column next to Drug A and Drug B Change the Characteristic column label to “Variable” (and make it bold) Add p values (though you really should not) Style p values to 3 digits Make the variable levels italicized Add an N column for each variable Take a few minutes to do these challenges, then peek at the solution below. Solution trial %&gt;% mutate(trt = case_when(trt == &quot;Drug A&quot; ~ &quot;Axitinib&quot;, trt == &quot;Drug B&quot; ~ &quot;Bleomycin&quot;)) %&gt;% tbl_summary(by = trt, include = c(age, trt, stage, grade), statistic = list(all_categorical() ~ &quot;{n} ({p}%)&quot;, all_continuous() ~ &quot;{mean} ({sd})&quot;), digits = all_continuous() ~ 3, label = list(stage ~ &quot;Tumor Extent&quot;, grade ~ &quot;Tumor Badness Scale&quot;), missing_text = &quot;Missing&quot;) %&gt;% modify_header(label = &quot;**Variable**&quot;) |&gt; add_overall() |&gt; add_n() |&gt; add_p(pvalue_fun = label_style_pvalue(digits = 3)) |&gt; modify_spanning_header(all_stat_cols() ~ &quot;**Treatment Arm**&quot;) |&gt; italicize_levels() %&gt;% bold_labels() #syzpjxlrvx table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #syzpjxlrvx thead, #syzpjxlrvx tbody, #syzpjxlrvx tfoot, #syzpjxlrvx tr, #syzpjxlrvx td, #syzpjxlrvx th { border-style: none; } #syzpjxlrvx p { margin: 0; padding: 0; } #syzpjxlrvx .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #syzpjxlrvx .gt_caption { padding-top: 4px; padding-bottom: 4px; } #syzpjxlrvx .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #syzpjxlrvx .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #syzpjxlrvx .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #syzpjxlrvx .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #syzpjxlrvx .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #syzpjxlrvx .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #syzpjxlrvx .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #syzpjxlrvx .gt_column_spanner_outer:first-child { padding-left: 0; } #syzpjxlrvx .gt_column_spanner_outer:last-child { padding-right: 0; } #syzpjxlrvx .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #syzpjxlrvx .gt_spanner_row { border-bottom-style: hidden; } #syzpjxlrvx .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #syzpjxlrvx .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #syzpjxlrvx .gt_from_md > :first-child { margin-top: 0; } #syzpjxlrvx .gt_from_md > :last-child { margin-bottom: 0; } #syzpjxlrvx .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #syzpjxlrvx .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #syzpjxlrvx .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #syzpjxlrvx .gt_row_group_first td { border-top-width: 2px; } #syzpjxlrvx .gt_row_group_first th { border-top-width: 2px; } #syzpjxlrvx .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #syzpjxlrvx .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #syzpjxlrvx .gt_first_summary_row.thick { border-top-width: 2px; } #syzpjxlrvx .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #syzpjxlrvx .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #syzpjxlrvx .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #syzpjxlrvx .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #syzpjxlrvx .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #syzpjxlrvx .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #syzpjxlrvx .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #syzpjxlrvx .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #syzpjxlrvx .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #syzpjxlrvx .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #syzpjxlrvx .gt_left { text-align: left; } #syzpjxlrvx .gt_center { text-align: center; } #syzpjxlrvx .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #syzpjxlrvx .gt_font_normal { font-weight: normal; } #syzpjxlrvx .gt_font_bold { font-weight: bold; } #syzpjxlrvx .gt_font_italic { font-style: italic; } #syzpjxlrvx .gt_super { font-size: 65%; } #syzpjxlrvx .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #syzpjxlrvx .gt_asterisk { font-size: 100%; vertical-align: 0; } #syzpjxlrvx .gt_indent_1 { text-indent: 5px; } #syzpjxlrvx .gt_indent_2 { text-indent: 10px; } #syzpjxlrvx .gt_indent_3 { text-indent: 15px; } #syzpjxlrvx .gt_indent_4 { text-indent: 20px; } #syzpjxlrvx .gt_indent_5 { text-indent: 25px; } #syzpjxlrvx .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #syzpjxlrvx div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } Variable N Treatment Arm p-value2 Overall N = 2001 Axitinib N = 981 Bleomycin N = 1021 Age 189 47.238 (14.312) 47.011 (14.709) 47.449 (14.005) 0.718     Missing 11 7 4 Tumor Extent 200 0.866     T1 53 (27%) 28 (29%) 25 (25%)     T2 54 (27%) 25 (26%) 29 (28%)     T3 43 (22%) 22 (22%) 21 (21%)     T4 50 (25%) 23 (23%) 27 (26%) Tumor Badness Scale 200 0.871     I 68 (34%) 35 (36%) 33 (32%)     II 68 (34%) 32 (33%) 36 (35%)     III 64 (32%) 31 (32%) 33 (32%) 1 Mean (SD); n (%) 2 Wilcoxon rank sum test; Pearson’s Chi-squared test 13.8 Adding Some Formatting The {gtsummary} package is designed to help you quickly make nice looking tables suitable for publication, but if you want complete control of formatting (font, color, etc), you want to use a table formatting package. The two big ones are {gt}, which is the underlying package for {gtsummary}, and {flextable} which can produce output for MS Word and Powerpoint as well as HTML. Check out the websites for each by googling for: gt and pkgdown flextable and pkgdown There are hundreds of functions in each package to help you organize and format tables. Often to a fairly obnoxious level. To get your tables from {gtsummary} ready for formatting, you need a conversion function. 13.8.1 Formatting with {gt} For gt tables, this is as_gt(). Once this is done, you can use any {gt) functions to format your table. Using the gt website for guidance, add some more formatting below. Try bolding, text colors, and cell colors. It may be helpful to search (Cmd-F) for tab_style() on the gt website. Take a few minutes to style your table to something elegant, or to something that looks like peak MySpace web page. trial %&gt;% select(trt, age, stage, grade) %&gt;% tbl_summary() %&gt;% as_gt() %&gt;% opt_table_font( font = list( google_font(name = &quot;Atkinson Hyperlegible Next&quot;) ) ) @import url(\"https://fonts.googleapis.com/css2?family=Atkinson+Hyperlegible+Next:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); #zmqzuavuer table { font-family: 'Atkinson Hyperlegible Next', system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #zmqzuavuer thead, #zmqzuavuer tbody, #zmqzuavuer tfoot, #zmqzuavuer tr, #zmqzuavuer td, #zmqzuavuer th { border-style: none; } #zmqzuavuer p { margin: 0; padding: 0; } #zmqzuavuer .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #zmqzuavuer .gt_caption { padding-top: 4px; padding-bottom: 4px; } #zmqzuavuer .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #zmqzuavuer .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #zmqzuavuer .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #zmqzuavuer .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #zmqzuavuer .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #zmqzuavuer .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #zmqzuavuer .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #zmqzuavuer .gt_column_spanner_outer:first-child { padding-left: 0; } #zmqzuavuer .gt_column_spanner_outer:last-child { padding-right: 0; } #zmqzuavuer .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #zmqzuavuer .gt_spanner_row { border-bottom-style: hidden; } #zmqzuavuer .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #zmqzuavuer .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #zmqzuavuer .gt_from_md > :first-child { margin-top: 0; } #zmqzuavuer .gt_from_md > :last-child { margin-bottom: 0; } #zmqzuavuer .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #zmqzuavuer .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #zmqzuavuer .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #zmqzuavuer .gt_row_group_first td { border-top-width: 2px; } #zmqzuavuer .gt_row_group_first th { border-top-width: 2px; } #zmqzuavuer .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #zmqzuavuer .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #zmqzuavuer .gt_first_summary_row.thick { border-top-width: 2px; } #zmqzuavuer .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #zmqzuavuer .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #zmqzuavuer .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #zmqzuavuer .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #zmqzuavuer .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #zmqzuavuer .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #zmqzuavuer .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #zmqzuavuer .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #zmqzuavuer .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #zmqzuavuer .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #zmqzuavuer .gt_left { text-align: left; } #zmqzuavuer .gt_center { text-align: center; } #zmqzuavuer .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #zmqzuavuer .gt_font_normal { font-weight: normal; } #zmqzuavuer .gt_font_bold { font-weight: bold; } #zmqzuavuer .gt_font_italic { font-style: italic; } #zmqzuavuer .gt_super { font-size: 65%; } #zmqzuavuer .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #zmqzuavuer .gt_asterisk { font-size: 100%; vertical-align: 0; } #zmqzuavuer .gt_indent_1 { text-indent: 5px; } #zmqzuavuer .gt_indent_2 { text-indent: 10px; } #zmqzuavuer .gt_indent_3 { text-indent: 15px; } #zmqzuavuer .gt_indent_4 { text-indent: 20px; } #zmqzuavuer .gt_indent_5 { text-indent: 25px; } #zmqzuavuer .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #zmqzuavuer div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } Characteristic N = 2001 Chemotherapy Treatment     Drug A 98 (49%)     Drug B 102 (51%) Age 47 (38, 57)     Unknown 11 T Stage     T1 53 (27%)     T2 54 (27%)     T3 43 (22%)     T4 50 (25%) Grade     I 68 (34%)     II 68 (34%)     III 64 (32%) 1 n (%); Median (Q1, Q3) 13.9 A Fancier Version for gt Here is a vertigo-inducing example of what you can do with the {gt} package. Self-control is important with table formatting. Take some time to explore the (thousands of) options in the {gt} package - you will likely be able to find most anything you could want in terms of table formatting, including conditional formatting, graphics and trendline plots (aka ‘sparklines’) in table cells. Take a look at the code below and try to decipher which functions produce which formatting in the resulting table. trial %&gt;% tbl_summary(by = trt, include = c(age, stage, grade)) %&gt;% as_gt() %&gt;% opt_table_font( font = list(google_font(name = &quot;Orbitron&quot;))) |&gt; tab_header(title = md(&quot;**Table 1: Tumor Characteristics by Treatment Arm**&quot;), subtitle = &quot;Trial was Conducted in TRON World&quot;) |&gt; tab_style(style = list( cell_text(weight = &quot;bold&quot;, color = &quot;white&quot;), cell_fill(color = &quot;blue&quot;), cell_text(size = 14)), locations = cells_body(rows = 1:2)) |&gt; tab_style(style = list( cell_text(weight = &quot;bold&quot;, color = &quot;white&quot;), cell_fill(color = &quot;red&quot;), cell_text(size = 14)), locations = cells_body(rows = 3:7)) |&gt; tab_style(style = list( cell_text(weight = &quot;bold&quot;, color = &quot;blue&quot;), cell_fill(color = &quot;pink&quot;), cell_text(size = 14)), locations = cells_body(rows = 8:11)) |&gt; tab_source_note( source_note = &quot;Source: TRON World&quot;) @import url(\"https://fonts.googleapis.com/css2?family=Orbitron:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\"); #wtekioloxy table { font-family: Orbitron, system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #wtekioloxy thead, #wtekioloxy tbody, #wtekioloxy tfoot, #wtekioloxy tr, #wtekioloxy td, #wtekioloxy th { border-style: none; } #wtekioloxy p { margin: 0; padding: 0; } #wtekioloxy .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #wtekioloxy .gt_caption { padding-top: 4px; padding-bottom: 4px; } #wtekioloxy .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #wtekioloxy .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #wtekioloxy .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #wtekioloxy .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #wtekioloxy .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #wtekioloxy .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #wtekioloxy .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #wtekioloxy .gt_column_spanner_outer:first-child { padding-left: 0; } #wtekioloxy .gt_column_spanner_outer:last-child { padding-right: 0; } #wtekioloxy .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #wtekioloxy .gt_spanner_row { border-bottom-style: hidden; } #wtekioloxy .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #wtekioloxy .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #wtekioloxy .gt_from_md > :first-child { margin-top: 0; } #wtekioloxy .gt_from_md > :last-child { margin-bottom: 0; } #wtekioloxy .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #wtekioloxy .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #wtekioloxy .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #wtekioloxy .gt_row_group_first td { border-top-width: 2px; } #wtekioloxy .gt_row_group_first th { border-top-width: 2px; } #wtekioloxy .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #wtekioloxy .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #wtekioloxy .gt_first_summary_row.thick { border-top-width: 2px; } #wtekioloxy .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #wtekioloxy .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #wtekioloxy .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #wtekioloxy .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #wtekioloxy .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #wtekioloxy .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #wtekioloxy .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #wtekioloxy .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #wtekioloxy .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #wtekioloxy .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #wtekioloxy .gt_left { text-align: left; } #wtekioloxy .gt_center { text-align: center; } #wtekioloxy .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #wtekioloxy .gt_font_normal { font-weight: normal; } #wtekioloxy .gt_font_bold { font-weight: bold; } #wtekioloxy .gt_font_italic { font-style: italic; } #wtekioloxy .gt_super { font-size: 65%; } #wtekioloxy .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #wtekioloxy .gt_asterisk { font-size: 100%; vertical-align: 0; } #wtekioloxy .gt_indent_1 { text-indent: 5px; } #wtekioloxy .gt_indent_2 { text-indent: 10px; } #wtekioloxy .gt_indent_3 { text-indent: 15px; } #wtekioloxy .gt_indent_4 { text-indent: 20px; } #wtekioloxy .gt_indent_5 { text-indent: 25px; } #wtekioloxy .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #wtekioloxy div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } Table 1: Tumor Characteristics by Treatment Arm Trial was Conducted in TRON World Characteristic Drug A N = 981 Drug B N = 1021 Age 46 (37, 60) 48 (39, 56)     Unknown 7 4 T Stage     T1 28 (29%) 25 (25%)     T2 25 (26%) 29 (28%)     T3 22 (22%) 21 (21%)     T4 23 (23%) 27 (26%) Grade     I 35 (36%) 33 (32%)     II 32 (33%) 36 (35%)     III 31 (32%) 33 (32%) Source: TRON World 1 Median (Q1, Q3); n (%) 13.9.1 The {flextable} package For gtsummary output, the conversion function is as_flex_table(). Then you can use any {flextable) functions to format. Using the flextable website, add some more formatting below. Try text and cell colors. It may be helpful to scroll down to the ‘Change Visual Properties’ header or to apply some of the default themes. Take some time to explore the (hundreds of) options in the {flextable} package - you will likely be able to find most anything you could reasonably want in terms of table formatting for publication. trial %&gt;% select(trt, age, stage, grade) %&gt;% tbl_summary() %&gt;% as_flex_table() %&gt;% font(fontname = &quot;Brush Script MT&quot;, part = &quot;header&quot;) %&gt;% fontsize(size = 18, part = &quot;header&quot;) .cl-9ecf2eb6{}.cl-9ecb719a{font-family:'Brush Script MT';font-size:18pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-9ecb71a4{font-family:'Brush Script MT';font-size:10.8pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;bottom:5.4pt;}.cl-9ecb71ae{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-9ecb71af{font-family:'Helvetica';font-size:6.6pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;bottom:3.3pt;}.cl-9eccc54a{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2pt;padding-top:2pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-9eccc54b{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2pt;padding-top:2pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-9eccc554{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-9eccc555{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-9eccc556{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:15pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-9eccc55e{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-9eccd378{width:2.026in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9eccd379{width:1.024in;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9eccd37a{width:2.026in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9eccd382{width:1.024in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9eccd383{width:2.026in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9eccd384{width:1.024in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9eccd38c{width:2.026in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9eccd38d{width:1.024in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9eccd38e{width:2.026in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9eccd396{width:1.024in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9eccd397{width:2.026in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9eccd398{width:1.024in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9eccd399{width:2.026in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9eccd3a0{width:1.024in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9eccd3a1{width:2.026in;background-color:transparent;vertical-align: top;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9eccd3aa{width:1.024in;background-color:transparent;vertical-align: top;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9eccd3ab{width:2.026in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9eccd3ac{width:1.024in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}CharacteristicN = 2001Chemotherapy TreatmentDrug A98 (49%)Drug B102 (51%)Age47 (38, 57)Unknown11T StageT153 (27%)T254 (27%)T343 (22%)T450 (25%)GradeI68 (34%)II68 (34%)III64 (32%)1n (%); Median (Q1, Q3) 13.10 A Fancier Version for Flextable Flextable enables you to use a variety of formatting options and to place the resulting tables into microsoft office documents like Word and Powerpoint using the package {officer}. The several packages (officer, officedown, flextable, mschart, rvg) used to make MS Office tables and plots by this group based in France is often referred to as the Officeverse. There is an entire book on how tuo use flextable. The Officeverse book can be found here Below is an example of some more complex formatting of a basic table one from this fake chemotherapy trial. While flextable can be used with the pipe operator, in this example we are adding conditional formatting and styling to the table in a more step-by-step manner updating the flextable (my_ft) object at each step. Conditional formatting (also available in {gt}) is helpful for highlighting interesting results for the reader myft &lt;- trial %&gt;% select(trt,age, grade, response) %&gt;% tbl_summary() %&gt;% gtsummary::as_flex_table() # builds table, converts to flextable big_b &lt;- fp_border_default(color = &quot;black&quot;, width = 2) # adds black border myft &lt;- italic(myft, j = 1) # makes first column italic # row numbers are referred to by i, columns by j myft &lt;- bg(myft, bg = &quot;#C90000&quot;, part = &quot;header&quot;) # red background for header myft &lt;- fontsize(myft, part = &quot;all&quot;, size = 14) #fontsize for all myft &lt;- color(myft, color = &quot;white&quot;, part = &quot;header&quot;) #white text header myft &lt;- border_outer(myft, big_b, part = &quot;header&quot;) # add border for header myft &lt;- border_outer(myft, big_b, part = &quot;body&quot;) # Add border for body myft &lt;- bold(myft, i = ~ label == &quot;Chemotherapy Treatment&quot;, j = 1, bold = TRUE) # change label for Rx myft &lt;- color(myft, i = ~ label == &quot;Drug A&quot;, # color drug label text by row color = &quot;blue&quot;) myft &lt;- color(myft, i = ~ label == &quot;Drug B&quot;, color = &quot;maroon&quot;) myft &lt;- bold(myft, i = ~ label == &quot;I&quot;| label == &quot;II&quot;, j = ~ stat_0, bold = TRUE) # highlight interesting results myft &lt;- color(myft, i = ~ label == &quot;I&quot;| label == &quot;II&quot;, j = ~ stat_0, color = &quot;red&quot;) myft &lt;- autofit(myft) #autoformat column height and width myft # print out the table in the viewer .cl-9f14c3fe{}.cl-9f11baa6{font-family:'Helvetica';font-size:14pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(255, 255, 255, 1.00);background-color:transparent;}.cl-9f11bab0{font-family:'Helvetica';font-size:8.4pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(255, 255, 255, 1.00);background-color:transparent;position: relative;bottom:4.2pt;}.cl-9f11baba{font-family:'Helvetica';font-size:14pt;font-weight:bold;font-style:italic;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-9f11babb{font-family:'Helvetica';font-size:14pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-9f11bac4{font-family:'Helvetica';font-size:14pt;font-weight:normal;font-style:italic;text-decoration:none;color:rgba(0, 0, 255, 1.00);background-color:transparent;}.cl-9f11bac5{font-family:'Helvetica';font-size:14pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 255, 1.00);background-color:transparent;}.cl-9f11bac6{font-family:'Helvetica';font-size:14pt;font-weight:normal;font-style:italic;text-decoration:none;color:rgba(176, 48, 96, 1.00);background-color:transparent;}.cl-9f11bace{font-family:'Helvetica';font-size:14pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(176, 48, 96, 1.00);background-color:transparent;}.cl-9f11bacf{font-family:'Helvetica';font-size:14pt;font-weight:normal;font-style:italic;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-9f11bad0{font-family:'Helvetica';font-size:14pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(255, 0, 0, 1.00);background-color:transparent;}.cl-9f11bad8{font-family:'Helvetica';font-size:8.4pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;bottom:4.2pt;}.cl-9f12f736{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2pt;padding-top:2pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-9f12f740{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2pt;padding-top:2pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-9f12f74a{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-9f12f74b{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-9f12f74c{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:15pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-9f12f74d{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-9f1303d4{width:2.641in;background-color:rgba(201, 0, 0, 1.00);vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 2pt solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f1303de{width:1.226in;background-color:rgba(201, 0, 0, 1.00);vertical-align: middle;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 2pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 2pt solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f1303e8{width:2.641in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 2pt solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f1303e9{width:1.226in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 2pt solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f1303ea{width:2.641in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 2pt solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f1303eb{width:1.226in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 2pt solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f1303f2{width:2.641in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 2pt solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f1303f3{width:1.226in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 2pt solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f1303f4{width:2.641in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 2pt solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f1303fc{width:1.226in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 2pt solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f1303fd{width:2.641in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 2pt solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f1303fe{width:1.226in;background-color:transparent;vertical-align: top;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 2pt solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f1303ff{width:2.641in;background-color:transparent;vertical-align: top;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 2pt solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f130400{width:1.226in;background-color:transparent;vertical-align: top;border-bottom: 2pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 2pt solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f130406{width:2.641in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9f130407{width:1.226in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}CharacteristicN = 2001Chemotherapy TreatmentDrug A98 (49%)Drug B102 (51%)Age47 (38, 57)Unknown11GradeI68 (34%)II68 (34%)III64 (32%)Tumor Response61 (32%)Unknown71n (%); Median (Q1, Q3) "],["tips-for-hashtag-debugging-your-pipes-and-ggplots.html", "Chapter 14 Tips for Hashtag Debugging your Pipes and GGPlots 14.1 Debugging 14.2 The Quick Screen 14.3 Systematic Hunting For Bugs in Pipes 14.4 Systematic Hunting For Bugs in Plots 14.5 Hashtag Debugging 14.6 Pipe 2 14.7 Plot 2 14.8 Plot3 14.9 Pipe 3", " Chapter 14 Tips for Hashtag Debugging your Pipes and GGPlots 14.1 Debugging While layering functions with piping in the tidyverse and the plus sign in ggplots is a great way to keep your code clear, your will invariably find some bugs in your code. This can be pretty frustrating, especially when you spend a lot of time staring at the code and it finally turns out to be something trivial, like a missing parenthesis, a pipe in place of a + (or the reverse), a missing aes() statement, or a mistyped function (fitler instead of filter). So how can you systematically approach debugging a pipe or plot, and find and fix your problem efficiently without spending tons of time? 14.2 The Quick Screen Start by checking for common errors - check for The Big 5. Click just to the right of each final parenthesis on each line. Does this result in highlighting the first parenthesis on that line of code? If not, you are probably missing a closing parenthesis. When piping, check that you have a proper pipe %&gt;% at the end of each line, except for the last line. When plotting, check that you have a plus sign + at the end of each line, except for the last line. Error message about a missing function - Error in function(arguments) : could not find function \"func\". Either you are calling a function from a library you have not loaded, or you mis-typed the function. If the library was not loaded, go back to the top and load the library that this function comes from. If you mis-typed the function (for example, /selcet), fix the typographical error. The error message will tell you which function seems to be missing. Error message about a missing object - Error: object 'xxxobj' not found. Make sure that you have typed the names of the dataframe and the variables correctly. Each of these is a data object. The error message will tell you which object seems to be missing. Your Turn: Search for The Big 5 in the pipe below (Hint - there are 5 Bugs to Be Found) You should end up with 4 columns of 10 rows, sorted by efficiency, when all of the bugs have been fixed. mtcars %&gt;% filter(cyl &gt;4) %&gt;% select(mpg, hp, displ) %&gt;% mutate(efficiency = hp/disp ) + filtre(efficiency &gt; 0.5) %&gt;% arrange(desc(efficiency) %&lt;% slice(1:10) ## Error in parse(text = input): &lt;text&gt;:8:0: unexpected end of input ## 6: arrange(desc(efficiency) %&lt;% ## 7: slice(1:10) ## ^ mtcars %&gt;% filter(cyl &gt;4) %&gt;% select(mpg, hp, displ) %&gt;% # watch for typos in object names mutate(efficiency = hp/disp ) + # watch for misplaced + vs %&gt;% filter(efficiency &gt; 0.5) %&gt;% # watch for typos arrange(desc(efficiency) %&lt;% # watch for mistyped pipes slice(1:10) ## Error in parse(text = input): &lt;text&gt;:8:0: unexpected end of input ## 6: arrange(desc(efficiency) %&lt;% # watch for mistyped pipes ## 7: slice(1:10) ## ^ mtcars %&gt;% filter(cyl &gt;4) %&gt;% select(mpg, hp, displ) %&gt;% mutate(efficiency = hp/disp ) %&gt;% filter(efficiency &gt; 0.5) %&gt;% arrange(desc(efficiency)) %&gt;% # watch for missing closing parentheses slice(1:10) ## Error in `select()`: ## ! Can&#39;t select columns that don&#39;t exist. ## ✖ Column `displ` doesn&#39;t exist. 14.3 Systematic Hunting For Bugs in Pipes What if it is not one of the Big 5 Pipe Bugs, and you need to hunt systematically? Let’s start by adding a pipe to the last line (slice(1:10)), and then a return() as a new line following slice(1:10), so that you now have an 8 line pipe. Note it will be blue - this is OK. It just shows that this is an important function. Adding return() just returns the result of the previous 7 lines, which does not seem like much, but it makes it a lot easier to use our debugging MVP, the hashtag. First, in debugging a pipe, you want to be able to quickly select and run lines repeatedly. You can do this with your mouse, but it is slow and sometimes inaccurate. You can do this faster with the keyboard. To run a whole pipe, just click anywhere in the pipe and press the key combination: Cmd-Shift-Return on the Mac Ctrl-Shift-Return on PC With this key combination, you don’t have to use your mouse to select lines to run. This will run the whole pipe or plot. Now you have to take control of exactly which lines of the pipe will run. You want to run a series of experiments to isolate the bug. Start by running the pipe from the top. Run just your first line (data) by putting a hashtag just before the first pipe %&gt;% and pressing Cmd-Shift-Return while still on that line. If that works, delete the hashtag and repeat the process on the 2nd line. You can stop running the pipe after only 2 lines by placing a hashtag just before the 2nd pipe. Then press your Cmd-Shift-Return key combo to run just the first 2 lines. If that works, try running the first 3 lines, by deleting the hashtag on line 2, and putting it just before the pipe on line 3 (Copy-Paste can help). Use this approach to run successively more lines of the pipe in the code chunk below. In which line of the pipe below do you hit the first error (bug)? iris %&gt;% filter(Sepal.Length &lt;5) %&gt;% select(Sepal.Length, Sepal.Width, Species) %&gt;% mutate(Sepal.Area = Sepal.Lngth * Sepal.Width) %&gt;% filter(Sepal.Area &gt;10) %&gt;% arrange(desc(Sepal.Area) %&gt;% slice(1:10) %&gt;% return() ## Error in parse(text = input): &lt;text&gt;:10:0: unexpected end of input ## 8: return() ## 9: ## ^ iris %&gt;% filter(Sepal.Length &lt;5) %&gt;% select(Sepal.Length, Sepal.Width, Species) %&gt;% mutate(Sepal.Area = Sepal.Lngth * Sepal.Width) %&gt;% # watch for typos filter(Sepal.Area &gt;10) %&gt;% arrange(desc(Sepal.Area) %&gt;% # watch for missing parentheses slice(1:10) %&gt;% return() ## Error in parse(text = input): &lt;text&gt;:10:0: unexpected end of input ## 8: return() ## 9: ## ^ Great. Now you know the bug is somewhere in lines 4-7. You can selectively turn off one line at a time by putting a hashtag at the beginning of the line. Use this approach to turn off line 5 (filter). Does this fix the pipe? If not, try lines 4,6,7 individually. Turning off which one gets rid of the error/changes the error? Changing the error means that you made it at least a little bit farther before a new error occurred. Now hunt in the ‘commented out/hashtagged’ line for an error you can fix. Once you think you have fixed it, try running the pipe up to and including that line (hashtag just before pipe in that line). Does that work? If yes, you have made progress. Keep going line by line until you find and fix the next bug, until you can get the whole pipe to run. 14.4 Systematic Hunting For Bugs in Plots The Big 5 Common Errors in Plots are slightly different. Click just to the right of each final parenthesis on each line. Does this result in highlighting the first parenthesis on that line of code? If not, you are probably missing a closing parenthesis. When plotting, check that you have a plus sign + at the end of each line, except for the last line. Missing aes() mapping. It is easy to get excited about your ggplot and declare variables in the ggplot statement, and forget about wrapping the mapping of x and y in an aesthetic function. Check to make sure that every time you map variables in your data to a plot component (x,y, color, shape, size, etc.) that this occurs inside an aes() call. Error message about a missing function - Error in function(arguments) : could not find function \"func\". Either you are calling a function from a library you have not loaded, or you mis-typed the function. If the library was not loaded, go back to the top and load the library that this function comes from. If you mis-typed the function (for example, /selcet), fix the typographical error. The error message will tell you which function seems to be missing. Error message about a missing object - Error: object 'xxxobj' not found. Make sure that you have typed the names of the dataframe and the variables correctly. Each of these is a data object. The error message will tell you which object seems to be missing. ## Your Turn to Debug a Plot Before hashtag-debugging the plot below, we will cap the plot code with an additional final line, by adding a + to the final line theme_minimal() and a new following line: NULL. This functions like return does for pipes - we can now use hashtags to turn off lines without causing errors because of missing pipes. Go ahead and add the + and NULL to the plot in the code chunk below. ## Error in theme_mnimal(): could not find function &quot;theme_mnimal&quot; Now use the same hashtag approach to run the lines of the plot code sequentially, adding one line at a time, with a hashtag placed just before the pipe, and using the Cmd-Shift-Return key combination. When you hit an error, use the hashtag at the beginning of each line that is a suspect in this Bug Hunt, and turn off one line at a time until you isolate the Bug. Then try to fix it, and run the whole plot chunk one line at a time. 14.5 Hashtag Debugging The elements of Hashtag Debugging of a code chunk are simply stated in 7 steps: Add a placeholder line to the end of the code chunk %&gt;% return() for data pipes + NULL for plots Insert a hashtag just before the line extender (%&gt;% for datapipes, + for plots) near the top of the code chunk Use Cmd-Shift-Return or Ctrl-Shift-Enter to run the code up to the hashtag. Keep running more lines by moving the hashtag down one line until you hit an error. Try to find and fix the error in that line. If needed, put a hashtag at the beginning of a line to turn off that line and run the rest of the pipe. If the error IS resolved (or changes), you have fixed the first error. Now run incrementally more lines (steps 2-4) until you have found a new error or completely fixed the pipe. Use your new skills. Figure out which Star Wars characters are overweight (by human standards) Try debugging the data pipe below. Work through each step in the process. 14.6 Pipe 2 starwars %&gt;% filter(height &lt;180) %&gt;% select(name, height, mass, gender homeworld, species) %&gt;% mtate(bmi = mass^2/height) %&gt;% filter(bmi&gt;=25) %&lt;% select(name, height, mass, bmi) %&gt;% arrange(dsc(bmi)) %&gt;% slice(1:15) ## Error in parse(text = input): &lt;text&gt;:3:37: unexpected symbol ## 2: filter(height &lt;180) %&gt;% ## 3: select(name, height, mass, gender homeworld ## ^ Good work! Now try debugging the problematic plotting code chunk below. There are multiple errors. Work through each step in the process. 14.7 Plot 2 murders %&gt;% ggplot(x = population/10^6, y = total, label = abb) + geom_abline(intercept = log10(r), lty=2, col=darkgrey) + geom_point(aes(color==region), size = 3) + geom_text_repel() + scale_x_log10() + scale_y_log10() + xlab(&quot;Populations in millions (log scale)&quot;) + ylab(&quot;Total number of murders (log scale)&quot;) ## Error: object &#39;darkgrey&#39; not found ggtitle(&quot;US Gun Murders in 2010&quot;) + scale_color_discrete(name=&quot;Region&quot;) ## NULL Here is another complex plot. Work through each step to completely debug this one. When it works, it will make a heatmap of measles cases in the US by month and year, with the introduction of the measles vaccine marked as an important event. 14.8 Plot3 us_contagious_diseases %&gt;% filter(!state%in%c(&quot;Hawaii&quot;,&quot;Alaska&quot;) &amp; disease == the_disease) %&gt;% mutate(rate = count / population * 10000 * 52 / weeks_reporting) %&gt;% mutate(state = reorder(state, rate) %&gt;% ggplot(aes(year state, fill = rate)) %&gt;% geom_tile(color = &quot;grey50&quot;) + scale_x_cntinuous(expand=c(0,0)) + scale_fill_gradientn(colors = brewer.pal(9, &quot;Reds&quot;), trans = &quot;sqrt&quot;) + geom_vline(xintercept=1963, col = &quot;blue&quot;) + theme_minimal() + theme(panel.grid = element_blank()) + ggttle(the_disease) + ylab(&quot;&quot;) + xlab(&quot;&quot;) ## Error in parse(text = input): &lt;text&gt;:5:19: unexpected symbol ## 4: mutate(state = reorder(state, rate) %&gt;% ## 5: ggplot(aes(year state ## ^ Now let’s try a final data pipe debugging. Use your skills to make this one work. 14.9 Pipe 3 gapminder %&gt;% filter(year == 1965) %&gt;% filter(!is.na(infant_mortality) %&gt;% mutate(adult_survival = life_expectancy/infant_mortality) %&gt;% select(country, adultsurvival, continent) %&gt;% group_by(continent) %&gt;% summarize(mean_adult_surv = mean(adult_survival), sd_adult_surv = stdev(adult_survival)) %&gt;% arrange(mean_adult_surv) ## Error in parse(text = input): &lt;text&gt;:11:0: unexpected end of input ## 9: arrange(mean_adult_surv) ## 10: ## ^ "],["finding-help-in-r.html", "Chapter 15 Finding Help in R 15.1 Programming in R 15.2 Starting with Help! 15.3 The Magic of Vignettes 15.4 Googling the Error Message 15.5 You Know What You Want to Do, but Don’t Know What Package or Function to Use 15.6 Seeking Advanced Help with a Minimal REPREX", " Chapter 15 Finding Help in R Because the path to something valuable is never easy. Learning R programming is hard, and at times will be frustrating. You will need help frequently. But the journey is a lot easier if you learn how to ask the R community for help when you are stuck. There is a very good chance that someone else has been stuck in the same place, and that there is good advice available. 15.1 Programming in R Saving programs and data in R is critical to producing reproducible medical research. But for most people, coding is not easy, comes with lots of syntax errors and cryptic error messages, and can be frustrating. One of the key skills in programming in R is finding help when you are stuck. In this chapter, we will explain several ways to find help in R, moving from the simple to the more complex. 15.2 Starting with Help! The simplest approach to getting help in R is to use the help() function. In the console, you can type help(“lm”) or help(“geom_boxplot”) or help(“filter”) to make the reference materials appear in the Help tab in the lower right quadrant of RStudio. Note that there may be more than one match - in which case it will show you a list. The search for help(“filter”) is a good example, as many packages have function that includes ‘filter’ in the name. In the code block below, use help(‘filter’) to find the details on the filter() function from the {dplyr} package. help() You can also get help by going directly to the Help tab, and entering a term in the search box (top right of the Help window, with a magnifying glass icon), and pressing return. Help will take you directly to the documentation of a package or a function, which includes Description Usage (generic function with argument defaults) Arguments - explanation of each argument Details provided by the package author Examples (which can sometimes be cryptic) This is useful if you are just trying to remember the arguments to a function and/or their defaults, but is often not terribly helpful for beginners trying to understand how to use a package or a particular function. Let’s explore the dplyr::filter documentation a bit. There are 3 arguments listed, though … is a bit cryptic. The first argument is the .data, which is often piped in. The … argument lets you insert a variety of logical statements to filter by, and the .preserve argument defaults to recalculating grouping structure after filtering (default value is FALSE). The Details section recommends filtering before grouping for better speed (because of that recalculation of grouping structure). There are details on how grouping and rownames are affected by filter, followed by a mention of 3 variants of filter, filter_all, filter_if, and filter_at, which allow you to work on selections of variables. This is followed by some examples of the use of filter. 15.3 The Magic of Vignettes While the function documentation that you can find with help() explains the nuts and bolts (and arguments) for a function, it does not tell you much about the intended use, or the structure of the data that you should use this function on. Wrangling data into the right structure is often critical to successfully using a function. This makes package vignettes very helpful. The browseVignettes(‘package_name’) function can help you find the available vignettes for a given package. Edit the code block below to browse vignettes for the tidyr package. Remember to use quotes. this will open a webpage list to read the vignette and see examples of the use of tidyr. browseVignettes() ## starting httpd help server ... done Another useful approach is to search on the web for vignettes. You can Google “flextable vignettes” fo find examples of how to use the flextable package. Jump to a web browser and try it out. You will see nice explanations, and examples of code that you can copy and paste back into RStudio and run - either in the Console (interactively), or in a script. Try out a few of the layout and formatting examples with flextable. Often when you are first using a package, the vignette is the best place to start to get oriented to the intended use of the package and its functions. Several newer packages have dedicated documentation websites make with the pkgdown package. You can search for these by Googling packagename and “tidyverse”” for packages in the tidyverse. Google the package website for the forcats package. Read the Home text, then check out the Reference page (tab) for each function. The Articles or “Get Started” tab often contains examples. A general strategy is to Google “ package in R”. Try googling a few others, like ggpubr RVerbalExpressions sf gtsummary arsenal 15.4 Googling the Error Message It is very common to get an obscure error message. These are intended to be helpful, but often are not. A few common error messages and their usual causes are: Error Message Common Causes “could not find function x” package not installed, or function misspelled “subscript out of bounds” trying to find the 15th item in a vector when there are only 12 “error in if” an if statement trying to deal with non-logical data or NAs. “cannot open” trying to read a file that can’t be found “object x not found” using an argument that needs quotes without the quotes. If there are no quotes, R assumes that you are looking for an object already defined in the Environment tab. An R error message cheat sheet can be found [here] (http://varianceexplained.org/courses/errors/) Over time, you will learn to recognize common errors. But until you do (and even after you do), a helpful way out of a frustrating error message is to copy the error message, and paste it into a Google search. Some one has had that error before and asked for help on the internet. You can learn from their experience, and see what solutions other folks have come up with. Run the code block below to generate an error, then google the error message and see if you can figure out how to fix it. ## Error in `geom_smooth()`: ## ! Problem while computing stat. ## ℹ Error occurred in the 1st layer. ## Caused by error in `compute_layer()`: ## ! `stat_smooth()` requires the following missing aesthetics: x and y. The problem is that the ggplot function does not include the aesthetics layer around x and y - aes(x, y) is required inside the ggplot() function to tell ggplot that the variables time and conc should be mapped to x and y. 15.5 You Know What You Want to Do, but Don’t Know What Package or Function to Use 15.5.1 CRAN Task Views There are two general approaches to this problem. If you know a general topic area, and are looking for packages, the CRAN Task Views can be really helpful in finding a package that does what you need. CRAN Task Views are lists of packages that do useful things in a certain topic area. Pick your task, and it will supply a useful list of likely packages, with a description of what the package does and a link to the documentation. Look for packages to help you block randomize patients into clinical trials on CRAN [here] (https://cran.r-project.org/web/views/). The ClinicalTrials link will take you to an extensive list of packages that help with a variety of needs for clinical trials. You will fairly quickly find the blockrand package is one that suits your needs, though there are a few other options available. 15.5.2 Google is Your Friend Try googling “How to do” task “in R”. Try “How do do block randomization in R”. Several options come up, including the blockrand package. Try another one - google “how to put significance bars in a ggplot in R”. Several options come up, including ggsignif and ggpubr. 15.6 Seeking Advanced Help with a Minimal REPREX There is a large R community, and many experienced people are willing to help you when you are stuck. However, it can be very difficult to accurately explain your problem to someone who is not at your computer. This problem has led to the concept of the minimal REProducible EXample (minimal REPREX), and the reprex package. The reprex package helps you post a useful example on websites like the RStudio Community or Stack Overflow to ask for help. A minimal reproducible example includes: 1. All of the libraries needed 2. a small (‘toy’) dataset, with no extra columns (just the ones needed), and a limited number of rows (often 5-6). 3. Your code, which is not quite working, or producing a surprising result 4. A clear explanation of the result you are trying to get with your code (sometimes this is a jpeg of a graph, or a table of what you want the data to look like after processing). There is a nice explanation of how to reprex for beginners here. More resources and details can be found in the RStudio Community FAQ here Before we start making a reprex of our own, let’s look at a few examples on RStudio Community. https://community.rstudio.com/t/could-not-plot-geometric-point/42558 https://community.rstudio.com/t/how-to-subset-a-data-frame-by-a-rowvalue/43514/8 https://community.rstudio.com/t/pivot-wider-tidyselect-and-col-how-to-exclude-variables/41191 https://community.rstudio.com/t/new-to-r-would-like-to-find-a-way-to-find-the-mean-of-each-states/39161 Now you have a feel for what a reprex looks like, and how folks ask and answer questions on RStudio Community. So let’s imagine that you are trying to plot data on blood pressure for men and women, and you want to color the points differently for men and women. But you don’t know how. Let’s start with the 4 steps to a reprex. In a new script you need to: include all libraries needed. In this case, library(tidyverse) covers any data wrangling and ggplot2 Include your data. This should be a minimal or ‘toy’ dataset. Be SURE you are not including any fields that are Protected Health Information (PHI) or identifiers. You can do this one of several ways: use a built-in dataset (https://www.rdocumentation.org/packages/datasets/versions/3.6.1) and select() a few key variables and filter() down to a reasonable number of rows (or use head() to get 6 rows), or take your own data and select only the columns needed and use filter() or head() for a minimal number of rows. Make sure not to use any Protected Health Information (PHI).Then use dput() to add the data to the reprex and assign it to an object medicaldata::blood_storage %&gt;% select(Recurrence, PVol, TVol, AA, FamHx) %&gt;% head() -&gt; small_blood dput(small_blood) ## structure(list(Recurrence = c(1, 1, 0, 0, 0, 0), PVol = c(54, ## 43.2, 102.7, 46, 60, 45.9), TVol = c(3, 3, 1, 1, 2, 2), AA = c(0, ## 0, 0, 0, 0, 0), FamHx = c(0, 0, 0, 0, 0, 0)), row.names = c(NA, ## 6L), class = &quot;data.frame&quot;) # output of data will show up in the console # copy this and assign it to an object to start your reprex. # as below dataset &lt;- structure(list(Recurrence = c(1, 1, 0, 0, 0, 0), PVol = c(54, 43.2, 102.7, 46, 60, 45.9), TVol = c(3, 3, 1, 1, 2, 2), AA = c(0, 0, 0, 0, 0, 0), FamHx = c(0, 0, 0, 0, 0, 0)), row.names = c(NA, 6L), class = &quot;data.frame&quot;) build a toy dataset from scratch with tibble:tribble(). Each ~tilde_var gives you a variable name, each separated by commas, and each value is separated by a comma. And, remember not to put a comma after the last value (a common mistake). dataset &lt;- tibble::tribble( ~pat_id, ~sbp, ~dbp, ~hr, 001, 147, 92, 84, 002, 158, 99, 88, 003, 137, 84, 67, 004, 129, 92, 73 ) Use the datapasta package to copy in some data from a website or spreadsheet Install the package, copy a (small) amount of data. Use the add-in to paste your data, usually as a data frame or a tribble (you can choose either). Remember to assign it to an object like dataset. 15.6.0.1 Built in datasets In the code chunk below, examine the built-in dataset, infert. Then select only education, age, and parity. Then use head() to get only 6 rows. Assign this to data and print it out glimpse(datasets::infert) ## Rows: 248 ## Columns: 8 ## $ education &lt;fct&gt; 0-5yrs, 0-5yrs, 0-5yrs, 0-5yrs, 6-11yrs, 6-11yrs, 6-11y… ## $ age &lt;dbl&gt; 26, 42, 39, 34, 35, 36, 23, 32, 21, 28, 29, 37, 31, 29,… ## $ parity &lt;dbl&gt; 6, 1, 6, 4, 3, 4, 1, 2, 1, 2, 2, 4, 1, 3, 2, 2, 5, 1, 3… ## $ induced &lt;dbl&gt; 1, 1, 2, 2, 1, 2, 0, 0, 0, 0, 1, 2, 1, 2, 1, 2, 2, 0, 2… ## $ case &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1… ## $ spontaneous &lt;dbl&gt; 2, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1… ## $ stratum &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, … ## $ pooled.stratum &lt;dbl&gt; 3, 1, 4, 2, 32, 36, 6, 22, 5, 19, 20, 37, 9, 29, 21, 18… glimpse(datasets::infert) ## Rows: 248 ## Columns: 8 ## $ education &lt;fct&gt; 0-5yrs, 0-5yrs, 0-5yrs, 0-5yrs, 6-11yrs, 6-11yrs, 6-11y… ## $ age &lt;dbl&gt; 26, 42, 39, 34, 35, 36, 23, 32, 21, 28, 29, 37, 31, 29,… ## $ parity &lt;dbl&gt; 6, 1, 6, 4, 3, 4, 1, 2, 1, 2, 2, 4, 1, 3, 2, 2, 5, 1, 3… ## $ induced &lt;dbl&gt; 1, 1, 2, 2, 1, 2, 0, 0, 0, 0, 1, 2, 1, 2, 1, 2, 2, 0, 2… ## $ case &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1… ## $ spontaneous &lt;dbl&gt; 2, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1… ## $ stratum &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, … ## $ pooled.stratum &lt;dbl&gt; 3, 1, 4, 2, 32, 36, 6, 22, 5, 19, 20, 37, 9, 29, 21, 18… data &lt;- infert %&gt;% select(education, age, parity) %&gt;% head() data ## education age parity ## 1 0-5yrs 26 6 ## 2 0-5yrs 42 1 ## 3 0-5yrs 39 6 ## 4 0-5yrs 34 4 ## 5 6-11yrs 35 3 ## 6 6-11yrs 36 4 15.6.0.2 Filtering your dataframe object In the code chunk below, examine the local dataset, emerg_dept, which has counts of ED arrivals, how many breached the UK 4 hour guarantee, and how many got admitted. Then select() only org_code, attendances, breaches, and admissions. Then arrange() to have the top attendances at the top, use top_n(10) to get only the top 10 rows. Assign this to data and print it out emerg_dept ## # A tibble: 50 × 6 ## period org_code type attendances breaches admissions ## &lt;date&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2018-07-01 RRK 1 32209 6499 11332 ## 2 2018-07-01 R1H 1 28357 6294 7986 ## 3 2018-07-01 RW6 1 23887 4641 6282 ## 4 2018-07-01 R0A 1 22012 4669 6818 ## 5 2018-07-01 RDU 1 21043 1941 6519 ## 6 2018-07-01 RAL 1 20481 2529 4530 ## 7 2018-07-01 RF4 1 19303 4606 5004 ## 8 2018-07-01 RWE 1 18890 4861 4522 ## 9 2018-07-01 RXF 1 18828 2731 3981 ## 10 2018-07-01 RQM 1 18560 1064 4130 ## # ℹ 40 more rows emerg_dept %&gt;% select(org_code, attendances:admissions) %&gt;% arrange(desc(attendances)) %&gt;% top_n(10) -&gt; data ## Selecting by admissions data ## # A tibble: 10 × 4 ## org_code attendances breaches admissions ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 RRK 32209 6499 11332 ## 2 R1H 28357 6294 7986 ## 3 RW6 23887 4641 6282 ## 4 R0A 22012 4669 6818 ## 5 RDU 21043 1941 6519 ## 6 RF4 19303 4606 5004 ## 7 RR8 17889 3507 5345 ## 8 RTG 17591 2757 5302 ## 9 RJE 16622 3758 5855 ## 10 R1K 11922 3038 6098 15.6.0.3 Toy datasets Run the code below to build a toy dataset with patient_id, sbp, dbp. Then edit the code to add 4 values for heart rate and 4 values for respiratory rate df &lt;- data.frame( patient_id = 1:4, sbp = c(151, 137, 129, 144), dbp = c(92, 85, 79, 66) ) df ## patient_id sbp dbp ## 1 1 151 92 ## 2 2 137 85 ## 3 3 129 79 ## 4 4 144 66 15.6.0.4 Fun with Datapasta Example datapasta is a package for pasting data. It is super-helpful when you just want to quickly get a bit of data from a website or a spreadsheet. install the package {datapasta}, if you don’t have it already run library(datapasta) Go to the website, https://en.wikipedia.org/wiki/Health_insurance_coverage_in_the_United_States, and find the large table named, “Percent uninsured (all persons) by state, 1999–2014”. Carefully copy the table without the title line. Then use the Addins dropdown to “Paste as Tribble” into your code file. Assign the resulting tibble to an object named ins_data. You will get funny names for the columns. Change these with names(ins_data), and assign state and 1999:2014 to the names. names(ins_data) &lt;- c('state', c(1999:2014)) Then filter to get rid of DC and United States. You should end up with 50 rows. Show/Hide Solution ins_data &lt;- tibble::tribble( ~V1, ~V2, ~V3, ~V4, ~V5, ~V6, ~V7, ~V8, ~V9, ~V10, ~V11, ~V12, ~V13, ~V14, ~V15, ~V16, ~V17, &quot;Division&quot;, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, &quot;Alabama&quot;, 12, 12.5, 12.4, 12.2, 12.5, 12, 14, 15.1, 11.7, 11.5, 16.4, 15.5, 13, 14.8, 13.6, 12.1, &quot;Alaska&quot;, 18.3, 17.4, 14.8, 18, 17.5, 15.3, 16.9, 16.4, 17.6, 19.6, 17.2, 18.1, 18.2, 19, 18.5, 17.2, &quot;Arizona&quot;, 19.4, 16.4, 16.7, 16.4, 16.4, 16.2, 19.1, 20.8, 17.8, 19.1, 18.9, 19.1, 17.3, 18, 17.1, 13.6, &quot;Arkansas&quot;, 13.9, 14.1, 16.4, 16.5, 17.2, 15.9, 17.2, 18.6, 15.7, 17.6, 19, 18.5, 17.5, 18.4, 16, 11.8, &quot;California&quot;, 19, 17.5, 18, 16.5, 17.3, 17.5, 18, 17.8, 17.5, 18.1, 19.3, 19.4, 19.7, 17.9, 17.2, 12.4, &quot;Colorado&quot;, 14.1, 12.9, 14.6, 14.5, 15.3, 15.2, 16.2, 16.5, 16, 15.4, 14.5, 12.9, 15.7, 13.7, 14.1, 10.3, &quot;Connecticut&quot;, 7.3, 8.9, 8.2, 8.6, 9.4, 10.3, 10.1, 8.7, 8.6, 9.4, 11.1, 11.2, 8.6, 8.1, 9.4, 6.9, &quot;Delaware&quot;, 9.7, 8.5, 8.5, 9.2, 9.6, 13.1, 11.6, 11.9, 10.6, 10.7, 13, 11.3, 10, 10.8, 9.1, 7.8, &quot;District of Columbia&quot;, 14, 12.8, 12.3, 13, 12.7, 12, 12.4, 10.9, 9.3, 9.4, 12.4, 12.8, 8.4, 7.9, 6.7, 5.3, &quot;Florida&quot;, 17.4, 16.2, 16.9, 15.6, 17, 18.3, 19.5, 20.3, 19.8, 19.4, 21.7, 20.7, 19.8, 21.5, 20, 16.6, &quot;Georgia&quot;, 14.2, 13.9, 14.7, 14.6, 15.2, 15.7, 17.9, 17.3, 17.2, 17.1, 20.5, 19.5, 19.2, 19.2, 18.8, 15.8, &quot;Hawaii&quot;, 9.2, 7.9, 8.2, 8.8, 8.6, 8.5, 8.1, 7.9, 6.9, 7.3, 7.4, 7.7, 7.8, 7.7, 6.7, 5.3, &quot;Idaho&quot;, 18.2, 15.4, 15.7, 16.9, 17.7, 14.5, 14.4, 15.1, 13.6, 15.4, 15.1, 19.1, 16.9, 15.9, 16.2, 13.6, &quot;Illinois&quot;, 11.9, 12, 11.8, 12.4, 13.8, 12.5, 13.2, 13.5, 13, 12.2, 14.2, 14.8, 14.7, 13.6, 12.7, 9.7, &quot;Indiana&quot;, 8.9, 10.1, 10.1, 11.5, 12.2, 12.4, 13.1, 11.3, 11, 11.3, 13.7, 13.4, 12, 13.4, 14, 11.9, &quot;Iowa&quot;, 7.8, 8.1, 6.8, 9, 10.4, 8.8, 8.1, 9.9, 8.8, 9, 10.8, 12.2, 10, 10.1, 8.1, 6.2, &quot;Kansas&quot;, 11.2, 9.6, 9.8, 9.4, 10.1, 10.6, 10, 12.1, 12.4, 11.8, 12.8, 12.6, 13.5, 12.6, 12.3, 10.2, &quot;Kentucky&quot;, 12.9, 12.7, 11.6, 12.7, 13.7, 13.9, 11.7, 15.2, 13.4, 15.7, 15.9, 14.8, 14.4, 15.7, 14.3, 8.5, &quot;Louisiana&quot;, 20.9, 16.8, 17.8, 17.2, 19, 17, 16.9, 21.1, 18, 19.5, 14.5, 19.8, 20.8, 18.3, 16.6, 8.5, &quot;Maine&quot;, 9.2, 10.4, 10.2, 10.4, 9.6, 9.3, 9.8, 8.9, 8.5, 10.2, 10, 9.3, 10, 9.5, 11.2, 10.1, &quot;Maryland&quot;, 10, 9, 11, 11.7, 12.2, 11.9, 13.1, 13.2, 12.7, 11.4, 13.3, 12.8, 13.8, 12.4, 10.2, 7.9, &quot;Massachusetts&quot;, 7.8, 7.1, 6.9, 9.5, 10.1, 9.8, 8.6, 9.6, 4.9, 5, 4.3, 5.5, 3.4, 4.1, 3.7, 3.3, &quot;Michigan&quot;, 9, 7.8, 9, 9.8, 9.3, 10.2, 9.5, 10.1, 10.8, 11.5, 13, 13, 12.5, 10.9, 11, 8.5, &quot;Minnesota&quot;, 6.6, 8, 6.9, 7.9, 8.7, 8.3, 7.6, 8.9, 8, 8.2, 8, 9.7, 9.2, 8.3, 8.2, 5.9, &quot;Mississippi&quot;, 15.7, 13.2, 17, 16.2, 17.5, 16.9, 16.5, 20.3, 18.4, 17.7, 17.3, 21, 16.2, 15.3, 17.1, 14.5, &quot;Missouri&quot;, 6.6, 8.6, 9.7, 10.8, 9.9, 11, 11.4, 13.1, 12.2, 12.4, 14.6, 13.9, 14.9, 13.3, 13, 11.7, &quot;Montana&quot;, 17.3, 16.1, 13.8, 14.3, 18.9, 17.5, 15.5, 16.9, 15, 15.7, 15.1, 18.2, 18.3, 18.1, 16.5, 14.2, &quot;Nebraska&quot;, 9, 7.9, 7.9, 9.3, 10.1, 10.3, 9.8, 12, 13, 11.1, 11.1, 13.2, 12.3, 13.3, 11.3, 9.7, &quot;Nevada&quot;, 18.3, 15.7, 14.5, 18.4, 17.6, 18.2, 16.5, 18.6, 16.9, 18.1, 20.6, 21.4, 22.6, 23.5, 20.7, 15.2, &quot;New Hampshire&quot;, 7.7, 7.9, 9.7, 8.8, 9.3, 8.7, 9.1, 10.8, 9.9, 10.1, 9.8, 10.1, 12.5, 12, 10.7, 9.2, &quot;New Jersey&quot;, 11.1, 10.2, 11.6, 12, 12.8, 12.6, 13.7, 14.8, 14.6, 13.2, 14.5, 15.6, 15.4, 14, 13.2, 10.9, &quot;New Mexico&quot;, 24, 23, 19.6, 20, 21.3, 19.3, 20.2, 22.7, 21.8, 22.8, 20.9, 21.4, 19.6, 21.9, 18.6, 14.5, &quot;New York&quot;, 14.4, 14.5, 13.9, 14, 14.3, 11.8, 12.1, 13.4, 12.3, 13.4, 14.1, 15.1, 12.2, 11.3, 10.7, 8.7, &quot;North Carolina&quot;, 12.5, 12.1, 13.3, 15.9, 16.7, 14.2, 14.5, 17.4, 16.2, 15.1, 17.8, 17.1, 16.3, 17.2, 15.6, 13.1, &quot;North Dakota&quot;, 10.2, 9.8, 8, 9.7, 10.3, 10, 10.8, 11.8, 9.5, 11.6, 10.3, 13.4, 9.1, 11.5, 10.4, 7.9, &quot;Ohio&quot;, 9.9, 9.8, 9.9, 10.4, 11.1, 10.3, 11, 9.6, 11.1, 11.2, 13.8, 13.6, 13.7, 12.3, 11, 8.4, &quot;Oklahoma&quot;, 15.4, 17.4, 17.2, 16.7, 19.1, 18.7, 17.7, 18.8, 17.6, 13.8, 17.9, 17.3, 16.9, 17.2, 17.7, 15.4, &quot;Oregon&quot;, 14.2, 11.6, 12.7, 14.3, 16, 15.4, 15.3, 17.5, 16.2, 15.9, 17.3, 16, 13.8, 15.4, 14.7, 9.7, &quot;Pennsylvania&quot;, 7.8, 7.6, 8.4, 10.2, 10, 10.1, 9.3, 9.4, 9.1, 9.6, 10.9, 10.9, 10.8, 12, 9.7, 8.5, &quot;Rhode Island&quot;, 5.9, 6.9, 7.7, 8.1, 10.4, 10, 10.7, 8.1, 10.5, 11, 12, 11.5, 12, 12.3, 11.6, 7.4, &quot;South Carolina&quot;, 14.8, 10.7, 11.1, 11.1, 13.1, 14.9, 16.3, 15.3, 15.9, 15.5, 16.8, 20.5, 19, 14.3, 15.8, 13.6, &quot;South Dakota&quot;, 10.1, 10.8, 8.3, 10.8, 10.6, 11, 11.5, 11.5, 9.9, 12.2, 13.1, 13.1, 13, 14.4, 11.3, 9.8, &quot;Tennessee&quot;, 9.3, 10.7, 10.1, 9.8, 12.2, 12.4, 13.4, 13.2, 14, 14.5, 15, 14.6, 13.3, 13.9, 13.9, 12, &quot;Texas&quot;, 21.1, 22, 22.4, 24.5, 23.6, 23.6, 22.9, 23.9, 24.7, 24.5, 25.5, 24.6, 23.8, 24.6, 22.1, 19.1, &quot;United States&quot;, 13.6, 13.1, 13.5, 13.9, 14.6, 14.3, 14.6, 15.2, 14.7, 14.9, 16.1, 16.3, 15.7, 15.4, 14.5, 11.7, &quot;Utah&quot;, 11.9, 10.8, 13.8, 12.1, 11.5, 12.8, 15.5, 16.7, 12.2, 12, 14.1, 13.8, 14.6, 14.4, 14, 12.5, &quot;Vermont&quot;, 10.1, 7.4, 8.8, 8.9, 8.4, 9.8, 11.2, 9.8, 10.1, 9.3, 9.4, 9.3, 8.6, 7, 7.2, 5, &quot;Virginia&quot;, 11.3, 9.6, 9.8, 11.8, 11.5, 13, 12.3, 12.5, 14.2, 11.8, 12.6, 14, 13.4, 12.5, 12.3, 10.9, &quot;Washington&quot;, 12.2, 13.1, 13.3, 12.3, 14.8, 12.5, 12.5, 11.5, 11, 12, 12.6, 13.9, 14.5, 13.6, 14, 9.2, &quot;West Virginia&quot;, 14.9, 13.4, 12.9, 13.8, 16.8, 15.7, 16.5, 13.3, 13.7, 14.5, 13.7, 13.4, 14.9, 14.6, 14, 8.6, &quot;Wisconsin&quot;, 9.7, 7.1, 7.3, 8.6, 9.8, 10.3, 8.8, 8, 8, 9.2, 8.9, 9.4, 10.4, 9.7, 9.1, 7.3, &quot;Wyoming&quot;, 14.5, 14.7, 14.1, 14.8, 14.8, 12.3, 14.4, 14.2, 13.2, 13.3, 15.4, 17.2, 17.8, 15.4, 13.4, 12 ) names(ins_data) &lt;- c(&quot;state&quot;, c(1999:2014)) ins_data %&gt;% slice(2:45) %&gt;% bind_rows(slice(ins_data, 47:53)) %&gt;% filter(state != &quot;District of Columbia&quot;) %&gt;% filter(state != &quot;United States&quot;) -&gt; ins_data include your minimal code - just enough to reproduce the problem, and no more. Now you need to - run this minimal code in a new script window to make sure it reproduces the problem and gets the same error. - consider adding an illustration of what you want or expect to output to look like - Install the reprex package #install.packages(&#39;reprex&#39;) Select all of the code in your new script window, including libraries, data, and code copy this with Ctrl-C (Windows) or Cmd-C (Mac) go to the Console, type in “reprex()” and enter your REPREX will be generated and will show up in your Viewer tab. This is now also on your Clipboard. Go to RStudio Community and start a new topic. Type in an introduction to your problem, state clearly what you are trying to do, and where you are stuck. Paste in the reprex. Thank people in advance for their help. Post this topic. Wait for helpful answers. You can also email a reprex to a friend, so that they can give it a try. Try making your own reprex, and emailing it to a friend. See if they can find/solve the problem. "],["the-basics-of-base-r.html", "Chapter 16 The Basics of Base R 16.1 Dimensions of Data Rectangles 16.2 Naming columns 16.3 Concatenation 16.4 Sequences 16.5 Constants 16.6 Fancier Sequences 16.7 Mathematical functions 16.8 Handling missing data (NAs) 16.9 Cutting Continuous data into Levels", " Chapter 16 The Basics of Base R While there are many great features of the tidyverse, one should not throw out the base R with the bathwater. The functions and packages of base R are stable and slow to change (unlike the dynamic packages and functions of the tidyverse), and many are helpful and important building blocks for using R. Some of the functions in base R tend to fail silently, and have unhelpful error messages, but they are embedded in a lot of R scripts. When you search for help with R on websites like RStudio Community and Stack Overflow, you will often find base R code, and you will need to know how to interpret it. There are many really basic and important functions in base R that are worth knowing about. Once you have a handle on these basic functions, you can say Obscure base R / video game meme meme details 16.1 Dimensions of Data Rectangles Whether you have a data.frame, a tibble, or a matrix, it can be helpful to know the dimensions of what you have. You can get at these dimensions with dim() nrow() ncol() You may want to know how many rows to loop over, or how many columns need names, but you will frequently need to access these numbers. The dim() function returns two numbers - the rows first, then the columns. Let’s try this on the licorice dataset from the {medicaldata} package. dim(licorice) ## [1] 235 19 This is great, as long as you know that the first number is the number of rows, and the 2nd number is the number of columns (standard notation is R x C, so rows first, columns second). But if you want to get the number of rows out, and store it in a variable, you need to use the brackets [n] notation. Brackets allow you to pull out the nth item in a vector or a list. Let’s pull out the first item (the number of rows), and the second item (the number of columns) separately. We will store these in the 2 variables rows and columns, then print them out. rows &lt;- dim(licorice)[1] rows ## [1] 235 columns &lt;- dim(licorice)[2] columns ## [1] 19 You can also do this more directly with the nrow() and ncol() functions. rows &lt;- nrow(licorice) rows ## [1] 235 columns &lt;- ncol(licorice) columns ## [1] 19 A similar approach can give you the length of a vector with the length() function. Here we will check the length of the treat vector in the licorice tibble. length(licorice$treat) ## [1] 235 The length() function works a bit differently on dataframes or tibbles - it returns the number of variables/columns. This can be surprising if you don’t expect it, and you are expecting the number of rows. length(licorice) ## [1] 19 16.2 Naming columns Sometimes you want to take a quick look at the names of all of you columns in a dataframe. The names() function is a quick solution. names(licorice) ## [1] &quot;preOp_gender&quot; &quot;preOp_asa&quot; &quot;preOp_calcBMI&quot; ## [4] &quot;preOp_age&quot; &quot;preOp_mallampati&quot; &quot;preOp_smoking&quot; ## [7] &quot;preOp_pain&quot; &quot;treat&quot; &quot;intraOp_surgerySize&quot; ## [10] &quot;extubation_cough&quot; &quot;pacu30min_cough&quot; &quot;pacu30min_throatPain&quot; ## [13] &quot;pacu30min_swallowPain&quot; &quot;pacu90min_cough&quot; &quot;pacu90min_throatPain&quot; ## [16] &quot;postOp4hour_cough&quot; &quot;postOp4hour_throatPain&quot; &quot;pod1am_cough&quot; ## [19] &quot;pod1am_throatPain&quot; You can also use names() to re-set the names if you want to change a bunch of column names, by assigning a vector of names (of the same length). names(licorice) &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;, &quot;F&quot;, &quot;G&quot;, &quot;H&quot;, &quot;I&quot;, &quot;J&quot;, &quot;K&quot;, &quot;L&quot;, &quot;M&quot;, &quot;N&quot;, &quot;O&quot;, &quot;P&quot;, &quot;Q&quot;, &quot;R&quot;, &quot;S&quot;) licorice[1:10, ] ## A B C D E F G H I J K L M N O P Q R S ## 1 0 3 32.98 67 2 1 0 1 2 0 0 0 0 0 0 0 0 0 0 ## 2 0 2 23.66 76 2 2 0 1 1 0 0 0 0 0 0 0 0 0 0 ## 3 0 2 26.83 58 2 1 0 1 2 0 0 0 0 0 0 0 0 0 0 ## 4 0 2 28.39 59 2 1 0 1 3 0 0 0 0 0 0 0 0 0 0 ## 5 0 1 30.45 73 1 2 0 1 2 0 0 0 0 0 0 0 0 0 0 ## 6 0 2 35.49 61 3 1 0 1 3 0 0 0 0 0 0 0 0 0 0 ## 7 0 3 25.50 66 1 1 0 1 3 0 0 0 0 0 0 0 0 0 0 ## 8 0 2 31.10 61 2 1 0 1 1 0 0 0 0 0 0 0 0 0 0 ## 9 0 3 21.22 83 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 ## 10 0 3 27.16 69 2 3 0 1 2 0 0 0 0 0 0 0 0 0 0 Note that you can use the set_names() function in the {purrr} package to conveniently change variable/column names within a data pipeline, and the rename() function in the dplyr package to change particular variable/column names. licorice %&gt;% purrr::set_names(1:19) %&gt;% dplyr::rename(&quot;purple&quot; = 2) %&gt;% # note rename(new_name = old_name) tibble() ## # A tibble: 235 × 19 ## `1` purple `3` `4` `5` `6` `7` `8` `9` `10` `11` `12` ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 3 33.0 67 2 1 0 1 2 0 0 0 ## 2 0 2 23.7 76 2 2 0 1 1 0 0 0 ## 3 0 2 26.8 58 2 1 0 1 2 0 0 0 ## 4 0 2 28.4 59 2 1 0 1 3 0 0 0 ## 5 0 1 30.4 73 1 2 0 1 2 0 0 0 ## 6 0 2 35.5 61 3 1 0 1 3 0 0 0 ## 7 0 3 25.5 66 1 1 0 1 3 0 0 0 ## 8 0 2 31.1 61 2 1 0 1 1 0 0 0 ## 9 0 3 21.2 83 1 1 0 1 1 0 0 0 ## 10 0 3 27.2 69 2 3 0 1 2 0 0 0 ## # ℹ 225 more rows ## # ℹ 7 more variables: `13` &lt;dbl&gt;, `14` &lt;dbl&gt;, `15` &lt;dbl&gt;, `16` &lt;dbl&gt;, ## # `17` &lt;dbl&gt;, `18` &lt;dbl&gt;, `19` &lt;dbl&gt; licorice[1:10, ] ## A B C D E F G H I J K L M N O P Q R S ## 1 0 3 32.98 67 2 1 0 1 2 0 0 0 0 0 0 0 0 0 0 ## 2 0 2 23.66 76 2 2 0 1 1 0 0 0 0 0 0 0 0 0 0 ## 3 0 2 26.83 58 2 1 0 1 2 0 0 0 0 0 0 0 0 0 0 ## 4 0 2 28.39 59 2 1 0 1 3 0 0 0 0 0 0 0 0 0 0 ## 5 0 1 30.45 73 1 2 0 1 2 0 0 0 0 0 0 0 0 0 0 ## 6 0 2 35.49 61 3 1 0 1 3 0 0 0 0 0 0 0 0 0 0 ## 7 0 3 25.50 66 1 1 0 1 3 0 0 0 0 0 0 0 0 0 0 ## 8 0 2 31.10 61 2 1 0 1 1 0 0 0 0 0 0 0 0 0 0 ## 9 0 3 21.22 83 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 ## 10 0 3 27.16 69 2 3 0 1 2 0 0 0 0 0 0 0 0 0 0 Note also that we used the bracket notation above to print just the first 10 rows of the renamed version of the licorice dataframe. This was done with brackets that define which [rows, columns] we want to use (in this case for printing). By using the sequence 1:10, we choose the first 10 rows. By putting nothing after the comma, we select all columns. You might be wondering why the column names reverted to alphabetical letters after we used set_names to change them to numbers. This is because we did set the names, and printed the result out to the console, but did not assign the result back to the licorice object with an assignment arrow, so it is transient, rather than a lasting change to the licorice object. This is a common pitfall for beginners. We can use also use brackets to choose exactly which rows and columns we want. licorice[4:7, c(2,5,10)] ## B E J ## 4 2 2 0 ## 5 1 1 0 ## 6 2 3 0 ## 7 3 1 0 Here we have selected 4 particular rows with a sequence (4:7), and 3 particular columns (by concatenating these into a vector with the c() function). 16.3 Concatenation One of the simplest, but most common early functions in R is c(). The c() function concatenates items together into a vector. This can be helpful for building a vector of items to iterate over, or to build a vector which will become a variable in a dataframe, or even a vector of options for a function. You simply write the items, separated by commas, in order inside the parentheses of c(). Remember that strings need to be enclosed in matching quotes. fib_numbers &lt;- c(1, 1, 2, 3, 5, 8, 13, 21, 34) fruit_vec &lt;- c(&quot;apple&quot;, &quot;banana&quot;, &quot;coconut&quot;, &quot;dragonfruit&quot;, &quot;elderberry&quot;) fib_numbers ## [1] 1 1 2 3 5 8 13 21 34 fruit_vec ## [1] &quot;apple&quot; &quot;banana&quot; &quot;coconut&quot; &quot;dragonfruit&quot; &quot;elderberry&quot; 16.4 Sequences There are times when you want to create a sequence of numbers (i.e. 1 to 10, or 1 to 100), without manually concatenating a vector. The easiest way to do this is with the colon (:). You can assign 1:12 to an object, or 77:83, if you prefer. 1:12 ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 77:83 ## [1] 77 78 79 80 81 82 83 16.5 Constants Note that base R has some handy constants that may help in making vectors - LETTERS (vector of letters (string) from A to Z) - letters (vector of letters (string) from a to z) - month.abb (vector of 3 letter (English) month abbreviations from Jan to Dec) - month.name (vector of 3 letter (English) month abbreviations from January to December) - pi (the irrational number for relating diameter to circumference) You can select subsets of these with the bracket notation, i.e letters[1:13]. You can also format number for printing as strings with sprintf() (for print formatting) to include the desired number of decimals. LETTERS[7:12] ## [1] &quot;G&quot; &quot;H&quot; &quot;I&quot; &quot;J&quot; &quot;K&quot; &quot;L&quot; letters[5:10] ## [1] &quot;e&quot; &quot;f&quot; &quot;g&quot; &quot;h&quot; &quot;i&quot; &quot;j&quot; month.abb[10:12] ## [1] &quot;Oct&quot; &quot;Nov&quot; &quot;Dec&quot; pi %&gt;% sprintf(fmt = &quot;%1.5f&quot;, .) ## [1] &quot;3.14159&quot; 16.6 Fancier Sequences You can make more complex sequences with the seq() function. The main arguments (parameters) of seq() are from (default =1) to (default =1) by (default = (to-from)/length) length You will generally need at least 3 of these to describe a sequence, or seq() will use the default by value of 1. Note that if the by increment does not match the to argument, the sequence will stop at the last number before the to number. seq_len(n) is a shortcut that gives you a sequence from 1 to n, while seq_along(vector) is a shortcut that gives you a sequence from 1 to the length of a the vector. See the examples below # leaving out &quot;length&quot; seq(from = 2, to = 18, by = 2) ## [1] 2 4 6 8 10 12 14 16 18 # leaving out argument names seq(3, 18, length=6) ## [1] 3 6 9 12 15 18 # &#39;length&#39; and &#39;to&#39; do not match seq(from = 24, to = 4, by = -6) ## [1] 24 18 12 6 # leaving out &quot;to&quot; seq(from = 5, by = 5, length = 6) ## [1] 5 10 15 20 25 30 # leaving out &quot;by&quot; seq(from = 16, to = 128, length = 8) ## [1] 16 32 48 64 80 96 112 128 seq(from = 51, by = -3, length = 17) ## [1] 51 48 45 42 39 36 33 30 27 24 21 18 15 12 9 6 3 # using the seq_len() shortcut with n seq_len(14) ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # using the seq_along() shortcut with a vector seq_along(7:23) ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 seq_along(licorice$C) ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ## [19] 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 ## [37] 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 ## [55] 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 ## [73] 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 ## [91] 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 ## [109] 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 ## [127] 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 ## [145] 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 ## [163] 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 ## [181] 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 ## [199] 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 ## [217] 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 ## [235] 235 16.7 Mathematical functions R has many mathematical functions, which can be used in a variety of calculations. These can be run on a vector, or on a variable in a dataframe. These include (and there are many more): mean median var sd min max range rank sum Examples are shown below mean(1:20) ## [1] 10.5 median(licorice$C) ## [1] 25.91 var(licorice$C) ## [1] 18.24933 sd(licorice$C) ## [1] 4.271923 min(licorice$C) ## [1] 15.6 max(licorice$C) ## [1] 36.33 range(licorice$C)[2] # selects 2nd value in range (max) ## [1] 36.33 rank(licorice$C)[1] # ranks first 10 values ## [1] 225 sum(licorice$C) # sum of values ## [1] 6013.99 16.8 Handling missing data (NAs) R designates missing values as the symbol NA (not available). NAs propagate through calculations, so that if you have a vector with at least one NA, and you try to calculate the mean, it will return NA. mean(licorice$J) ## [1] NA You can handle this within many functions (including mean, median, sd, and var) with the argument na.rm = TRUE. The default for these is na.rm = FALSE, so that if you are trying to do an operation on missing data, R will tell you. na.rm is an argument in a number of mathematical functions, in which na comes first, followed by the verb rm (remove). Testing whether a value or values are missing (NA) is in the reverse order. You use the is.na() function, in which the verb comes first, and then followed by NA. You might reasonably think that you can just use a normal equality test for NA values, like licorice$J == NA ## [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA ## [26] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA ## [51] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA ## [76] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA ## [101] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA ## [126] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA ## [151] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA ## [176] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA ## [201] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA ## [226] NA NA NA NA NA NA NA NA NA NA but, because NAs propagate, you get just NAs, rather than TRUE or FALSE. You can use is.na() for this. licorice$J %&gt;% is.na() ## [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [73] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [85] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [97] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [109] FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [121] FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [133] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [145] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [157] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [169] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [181] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [193] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [205] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [217] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [229] FALSE FALSE FALSE FALSE FALSE FALSE FALSE There are a few TRUEs in there (value is NA), but they can be hard to count. The sum() function can help, when combined with is.na(). The which() function can help you figure out which values are missing. The anyNA() function can tell you if there are any missing values in a vector (or a variable/column in a dataframe). licorice$J %&gt;% is.na() %&gt;% sum() ## [1] 2 licorice$J %&gt;% is.na() %&gt;% which() ## [1] 113 123 licorice$C %&gt;% anyNA() ## [1] FALSE licorice$J %&gt;% anyNA() ## [1] TRUE There are two missing values, in rows 113 and 123. The na.omit() function can remove all of the rows(cases, observations) from a dataframe that have at least one missing value in any column. This can be helpful for modeling, in which cases with missing data can cause problems. It is helpful to keep track of the number of rows before and after na.omit(), to know how many cases/observations/rows you are discarding. nrow(licorice) ## [1] 235 licorice %&gt;% na.omit() %&gt;% # modeling would happen here if not too many cases discarded nrow() ## [1] 233 Note that this can also be done in the tidyverse with drop_na() in the {tidyr} package. You can include a particular column or columns as an argument in drop_na() to only drop observations if there are missing values in these particular columns. licorice %&gt;% drop_na(H:J) %&gt;% nrow() ## [1] 233 The code above takes the licorice dataset, looks for NA values in rows of (only) columns H through J, and drops 2 rows based on missing data, reducing the number of rows from 235 to 233. 16.9 Cutting Continuous data into Levels While there are good arguments for why not to do this (dichotomania, loss of granularity in data), it is common to cut continuous data into levels, like (mild, moderate, severe), or (normal weight, overweight, obese). This can, when there are already established standard levels, make the data easier to interpret. The cut() function in base R makes this easy to do. C_factor3 &lt;- cut(licorice$C, breaks = 3) table(C_factor3) ## C_factor3 ## (15.6,22.5] (22.5,29.4] (29.4,36.4] ## 59 130 46 str(C_factor3) ## Factor w/ 3 levels &quot;(15.6,22.5]&quot;,..: 3 2 2 2 3 3 2 3 1 2 ... This creates a new variable (C_factor), which is a factor with 3 levels. The levels are stored as 1, 2, 3, and range from 15.6-22.5 for 1, above 22.5-29.4 for 2, and above 29.4 to 36.4 for 3. The interval notation uses the square bracket for including the listed number, and parentheses for starting just after the listed number. It is a good practice to develop a standard way of naming these created variables, which are related to the original variable, are factors, and have a certain number of levels. One helpful shorthand is to take the original variable name, and to add the suffix “_f4” for a factor with 4 levels. A dichotomized variable would be ”varname_f2” "],["updating-r-rstudio-and-your-packages.html", "Chapter 17 Updating R, RStudio, and Your Packages 17.1 Installing Packages 17.2 Loading Packages with Library 17.3 Updating R 17.4 Updating RStudio 17.5 Updating Your Packages", " Chapter 17 Updating R, RStudio, and Your Packages 17.1 Installing Packages The most important way to update R is to add packages. Each package adds new functions and/or data to R, enabling you to do much more in the R and RStudio environment. When you open R, or start a new session, you have only the base version of R available, and it is pretty spartan. You can see how many packages you have available to you by starting RStudio and going to the menu Session/New Session, or Session/Restart R. Each of these will give you a clean workspace to start in. Once you have started a new session, or restarted R, run the following code: print(.packages()) You will find that you only have 9 packages available, including base, utils, methods, stats, graphics, grDevices, datasets, devtools, and usethis. This is what is called “base R” and is essentially the bare minimum needed to use R. In order to use more of the power of R and RStudio, you will need to install packages (a one-time task), and load them (in each session) before use with a library(package_name) function. If you Google a bit for ways to do things in R, you will find many packages that can be helpful. The most strictly validated packages are hosted on CRAN - a mirrored server. There are now over 20,000 packages on CRAN to do various specialized things in R. These were all useful for someone, so they have shared them on CRAN. To install packages from CRAN, you use the function: install.packages(\"package_name\") Notice that the package_name has to be in quotes. These can be single or double quotes. The package_name and install.packages() are case_sensitive like all objects and functions in R, so that something like Install.Packages will not work. Once the package is installed, you keep that in your R library associated with your current major version of R. You will need to update &amp; reinstall packages each time you update a major version of R. R versions are designated with R version #.#.# A change in the third number indicates a patch level change. A change in the first number (from R 3.6.2 to 4.0.0) is a major version change, while a change in the middle number (4.0.2 to 4.1.0) is a minor version change. Any major or minor version upgrade will require re-installation of your add-on packages into a version-specific package library. Let’s practice installing a package. Run the code below to install the remotes() package. install.packages(&quot;remotes&quot;) 17.1.1 Installing Packages from Github Some packages are still in development. These are often in repositories on GitHub, rather than on the CRAN servers. To install these packages, you need to know path to the repository. You can install the development version of the medicaldata package from Github (the stable version is on CRAN). Run the code below to install this package (this assumes that you already have the remotes package installed). remotes::install_github(&quot;higgi13425/medicaldata&quot;) In contrast to install.packages, the library() function can work with quotes around the package_name, but they are not required. This is because these packages are already installed in your R library, and are known quantities. In general, known objects in your R Environment pane (dataframes, vectors) do not require quotes, and novel things like new packages (or variables hidden inside of a data frame) do require quotes or a $ - though the tidyverse packages work around this quote issue for variables inside of a data frame. If you re-run print(.packages) at this point, you will not have any more packages. This is because you have installed new packages, but not loaded them with library(). Notice that you were able to use the {remotes} package function, install_github() above, without loading the package with library(remotes), because you explicitly called the function with its package name, as in remotes::install_github(). Try installing a few more packages, like “janitor”, or “gtsummary”. These should now show up with installed.packages(). Then use library() to load these packages, and see that the output of print(.packages) has changed. 17.1.2 Problems with Installing Packages 17.1.2.1 R Version Issues Sometimes you may run into a problem installing a package which was developed for a previous version of R. Especially if you have recently upgraded your R version recently, the CRAN version of a package may be a bit behind. This can often be fixed by googling for “github” and “package_name”. This will usually lead you to the github repository for that package, which will have a pathname of “github_username/package_name”. Once you know this, you can use devtools::install_github('github_username/package_name') to install the newest version of the package, which will usually be compatible with the latest version of R. 17.1.2.2 Installing from Source vs Binaries When you install or update a package that is in rapid development, you may get this message: There are binary versions available but the source versions are later: binary source needs_compilation tidyr 1.1.4 1.2.0 TRUE This means that the latest version (in this case, 1.2.0), is available, but it has to be compiled and built from source code, which is a bit slower. It is faster to install from binary files, which tend to be available on CRAN (built by the CRAN volunteer maintainer team) a little bit later. When the binary version of a package is not yet available, you will be asked to decide - you can install the source code version (installs slower, but you get the very latest version), or the binary version (installs fast, but a version behind). Most of the time, unless you have a very slow internet connection, you want to install from the source version. The compilation part is what slows the installation. Usually, you want to answer Yes to the question Do you want to install from sources the packages which need compilation? (Yes/no/cancel) Why do some packages need to be compiled from source (~ 25%) and others (~75%) don’t? Usually it is because the ones that need to be compiled include another language (like C or C++, rather than pure R) which needs to be compiled. These additional languages are usually used to improve processing speed of the resulting functions. 17.1.2.3 Dependencies Some packages are dependent on specific versions of other packages, and will ask you to update the other packages during installation. As a general rule, you should say ‘yes’ to all packages. If you are worried about over-writing an existing package in a way that would break your code in a different project, then that project needs its own project-specific library, which you can create with the {renv} package. 17.1.2.4 Extra-R Dependencies Sometimes packages require (depend upon) software that is not part of the R ecosystem. These will generally give you messages during the install process asking you to install this helper software. Common helper software packages include things like gtk+, freetype, and proj. Sometimes you will need to go to websites, or use software like Homebrew (on the Mac) to install these extra helper pieces of software. If you have never used Homebrew, here is a basic guide to get you started. The Homebrew page is here. You can search on the Homebrew page and usually find the packages you need. They can be installed (via your Terminal Application (in Utilties) with something like brew install packagename. A bit of googling with the error message as the search term will usually help you find the specific package name. Once the external-to-R package is installed, you can go back and install the R package that depends on the external software package. 17.1.2.5 Package Installation Failed Sometimes you will get a message like: Warning in install.packages : installation of package \"ragg\" had non-zero exit status This means that the package installation failed. Sometimes it is because there is a problem with the package, but more often there is a missing dependency. Often you can figure this out by scrolling upward. You will often find messages telling you that fatal error: 'ft2build.h' file not found Suggesting that you need a file named ‘ft2build.h’. You will likely need to web search for this error to find out how to fix it, usually by downloading and installing a piece of software that the problematic package needs in order to run. Another example - configure: error: Install libtiff-dev or equivalent first (or set PKG_MODULE if non-standard) ERROR: configuration failed for package 'tiff' You are missing a piece of software external to R called libtiff-dev. The error message is fairly helpful. 17.2 Loading Packages with Library Run the code chunk below to load both {tidyverse} and {medicaldata}. Note that the {tidyverse} package is actually a meta-package that contains 8 packages, and each one has its own version number. library(tidyverse) library(medicaldata) Notice that loading tidyverse led to some conflict messages. The dplyr::filter function masks the stats::filter() function. These two packages, {dplyr} and {stats}, both have a function named filter(). The more recently loaded package is assumed to be the default, so if you call a filter() command, R will use dplyr::filter(). If you want to call the stats::filter() command, you have to explicitly use the package::function() format. If you are not sure which package you loaded last, it can be wise to use the explicit format when calling functions in R. The other masked function is lag(). The function dplyr::lag() is masking stats::lag(), as {dplyr} was loaded after {stats}. Most of the time this is not a big difference, but every once in a while a conflict between package functions can get very confusing. When in doubt, use the explicit format, in which you call package::function() to make clear what you mean, as in dplyr::lag() vs. stats::lag(). Note that it is good practice to load all of your packages needed for an R script or an Rmarkdown (.Rmd) document at the beginning of the script or .Rmd. This allows someone else using your script or Rmd to check whether they have the needed packages installed, and install them if needed. In an Rmarkdown document, this is done in a special setup code chunk near the top of the document. If some of these packages are not on CRAN, it is good practice to add a comment (a statement after a hashtag) on how to install this package. For example, in a setup chunk that loads {tidyverse} and {medicaldata}, it is a good idea to add a comment on how to install {medicaldata}, which is not yet on CRAN. See the example below library(tidyverse) library(medicaldata) # the {medicaldata} package can be installed with remotes::install_github(&#39;higgi13425/medicaldata&#39;) 17.2.0.1 Explicitly Managing Function Conflicts You can also manage conflicts between identically-named functions from different packages in R with the {conflicted} package, which identifies conflicts when you have called a function without explicitly naming the package that it is from. You load library(conflicted) and it will watch out for conflicts and send an error when you call a function in an ambiguous way. If you don’t want to always explicitly specify between dplyr::filter, base::filter and rstatix::filter, you can set your default version of a function right after you load your libraries, with conflicted::conflict_prefer(\"filter\", \"dplyr\"), which tells R that you want to use the dplyr version of filter by default, and that you will specify if you want to use base::filter or rstatix::filter. 17.3 Updating R Every once in a while, you will want to update your version of R. Usually this occurs with a major version upgrade, when something important changes. You may not rush into this, as it means re-installing all of your packages, but eventually it is worth it to be up to date. In order to update R, you have to find your installed version of R and run it on its own, outside of RStudio. This is easy if you have an R desktop shortcut, but not too hard if you hunt around a bit in your Applications folder. Double click the R icon to start up R. It will open the R Console and a menu. Click on the R menu at top left, and select Check for R Updates. If you are up to date, the R Console will report “Your version of R is up to date”. If not, this process will provide windows and buttons to click to upgrade to the latest version of R. When done, quit R and start RStudio to make sure the update has carried over. You should see the new version number when RStudio starts. 17.4 Updating RStudio To update RStudio, just run RStudio, and go to the Help menu in the top menu bar (not the Help tab in the lower right quadrant). In the Help menu, select Check for Updates. It will tell you if you are using the latest version of RStudio, or will direct you to the website to download the latest version. 17.5 Updating Your Packages To update your packages, you go to the Tools menu in RStudio, and select Check for package updates. You will usually get a list of the packages that have been updated since you installed them. Generally, select Update All, and allow one restart of your R session. RStudio may ask you if you want to restart more than once, but always say no after the first session restart. You may be asked about installing some packages from source, and you should generally select Yes. In general, your Console pane will be a bit chatty as it documents all the steps in package installation, but should generally end with something like: “The downloaded source packages are in ‘/private/var/folders/93/s18zkv2d4f556fxbjvb8yglc0000gp/T/RtmpHnsvlh/downloaded_packages’” and return to your &gt; prompt. If you then re-check for Package Updates, you will get the message that all of your packages are up to date. This process is a bit different after a major version upgrade of R, which we will cover in a later chapter. You have to retreive a list of all your packages, decide which to keep, and then install these fresh in the new version of R (and its new, major-version-specific package library). "],["major-r-updates-where-are-my-packages.html", "Chapter 18 Major R Updates (Where Are My Packages?) 18.1 When to Upgrade R 18.2 Preparing for a Minor or Major R Upgrade 18.3 STEP 6: Rebuilding All of your Packages in One (Automated) Step 18.4 Checking the new library path 18.5 Now Check your list of Packages 18.6 Updating Packages", " Chapter 18 Major R Updates (Where Are My Packages?) Versions of R have numbers attached, like R.4.1.2. The first number is the major version (4). The second number is the minor version (1). The third number is the patch level (2). When you upgrade R from one patch level to the next, from 4.1.1 to 4.1.2, the changes are very minor, and backward-compatible. However, when you upgrade from one minor version (the middle number) to the next, from 4.0.2 to 4.1.0, you will find that most of your carefully installed and much-beloved packages are gone. All of the add-on packages you know and love, from {tidyverse} to {rstatix}, did not come along for the upgrade. Note that these are not actually gone, but in a library specific to the previous minor version (4.1), and that you are expected to have a new library for 4.2. The reason for this is that packages are built/updated for minor versions, and if you just tried to use the 4.1 version with R 4.2, you could have some mysterious errors. This likely only applies to 1-3% of packages with each minor update, but it is super-annoying to try to track down which package is misbehaving and needs to be rebuilt for the new version. So it is generally not recommended to just copy your packages from the old library (4.1) to the new (4.2) library, but to rebuild them. Be Mindful Do not just upgrade R to a new minor (or major) version in the middle of a project. This will take a bit of work and time, maybe 10 minutes if you have a lot of packages installed, as this will require re-installing packages to a new library folder. It is possible, though unlikely, that parts of your project may break with a new version of R. The R Consortium tries to avoid breaking changes, especially for recent majpr versions of R. 18.1 When to Upgrade R As a general rule, patch upgrades are very minor, but fix problems that have been found with the previous version. You can upgrade to a new patch version at any time, and it is recommended to do so. Upgrading to a new minor or major version is a bit more involved. You usually want to wait a week or two after an upgrede for all of the assorted package binaries to catch up and be customized for the new version. You may also want to wait for the first patched version (e.g., 4.5.1, rather than 4.5.0) to come out, to make sure your work is not exposed to the initial bugs of a new version. There usually aren’t many, and they usually aren’t major, but it is a conservative approach to wait for the *.*.1 version. On the other hand, sometimes the new features of the new version are so compelling that you don’t want to wait. 18.2 Preparing for a Minor or Major R Upgrade You want to check the version number of the current R version at r-project.org. It may have been a while since you upgraded. Let’s also check your current installed R version, with R.Version() in the Console. If you are not in the middle of a major project, it may be a good time to upgrade. There are several new features (like the native pipe, installing packages in parallel) being added to base R that are worth the upgrade. Before you jump into upgrading R versions and packages, make sure that any important projects are protected. Make sure that your important ongoing projects use the {renv} package to preserve their Environment, and that you have taken a recent snapshot with renv::snapshot() You can also manage more than one R version on your local computer with the {rig} package, so that you can stick with R 4.2.3 until you finish that particular project, while working in R 4.5.1 in all of your new projects. Take a moment to identify the location of your current package library, with .libPaths(). This should look something like: [1] \"/Library/Frameworks/R.framework/Versions/4.1/Resources/library\" Note that this package library is specific to the most recent major and minor version of R. If you upgrade from 4.0.x to 4.1.x, you will have a new library path to a new 4.1/Resources/library folder, and will need to re-install packages in this folder. Take a moment to explore this file path with Finder on the Mac or Windows File Explorer in Windows. Go to /Library/Frameworks/R.framework/Versions/ to see all the past versions of R that you have installed. You will see a folder for each minor version of R you have installed, and inside each of these folders is a Resources folder, and inside of that is a library folder. This is where all of your packages are stored. Take a moment to save this file path in a text file or a word document, as you will need to know where your most recent library is located when you upgrade R. This will be helpful if you choose to use the updater package to help you with the upgrade process. 18.2.1 Before you upgrade R You can copy over some packages from the previous version’s library folder, but these were built under the prior version of R, and some of these won’t work with the new minor version of R. It is better (and now pretty fast) to rebuild these packages from scratch, and you can do this in one of two ways: After the R upgrade, just install packages as you need them (which is not a bad way to clean out packages you are not actually using), but a lot of people prefer to re-install all of their packages in an organized way, rather than just-in-time when they want to use them. It can be a bit annoying for the first week or two after an upgrade to frequently have to stop and reinstall packages, but you get through it. Re-install all of your packages in bulk right after thee R upgrade. This is a lot faster, and requires you to only stop your work once. 18.2.2 STEP 1: Clean up old, unused packages If you are planning a bulk re-install (#2), you should first take a look at the current packages in RStudio. Click on the Help tab, then the Home icon, then under Reference in the Home window, select Packages. This will show you a list of your currently installed packages in your current library. Take 10 (or more,if you have many packages) minutes to inspect this list, and find packages that you used once and probably won’t use again. This is a good way to do a bit of spring cleaning, and not just blindly re-install every package you tried once and never used again. You can always install more packages later as you need them. As an example, I used the R package {blueycolors} for one specific project (it provides ggplot2 palettes for colors from the Bluey cartoon) and I don’t need it anymore. I can just remove it from my library with remove.packages(\"blueycolors\") and then install it again if I need it in the future. But if I find a bunch of packages like this that I want to remove, I can copy the package names from the help window and paste them into a vector in the Console to remove them all at once. I will create a starter vector named pkg_remove_vec with: (copy this code chunk and run it in your local RStudio session) pkg_remove_vec &lt;- Hmisc::Cs(c()) Then I can copy the package names from the Help window, and insert commas between them into the center of the parentheses, like this: pkg_remove_vec &lt;- c(Hmisc::Cs(billboarder, blueycolors, ggplot2movies)) Note that this requires that the {Hmisc} package is installed, so you may need to install {Hmisc} first. The Cs function from Hmisc will take comma-separated values and apply quotes around each item, turning this into a proper vector without you having to type out each quotation mark. You now have a vector, pkg_remove_vec in your Environment. 18.2.3 STEP 2: Build a dataframe of your currently installed packages. You can build a dataframe of your currently installed packages with the code chunk below: (copy and run this in your local instance of RStudio) pkg_current &lt;- installed.packages() |&gt; as.data.frame() |&gt; dplyr::select(Package, Version) |&gt; tibble::remove_rownames() You can now see this dataframe in your Environment tab, with the number of packages (obs.) listed. You can inspoect this dataframe by clicking on the name pkg_current, and then scroll through the list to see if there are any other packages you want to remove. 18.2.4 STEP 3: Removing unwanted Packages from the dataframe You can remove unwanted packages from the dataframe with the code below. This will remove any packages in the pkg_remove_vec vector from the pkg_current dataframe. pkg_current &lt;- pkg_current |&gt; dplyr::filter(!Package %in% pkg_remove_vec) The data frame pkg_current now contains only the packages you want to keep. You will be able to use this dataframe to re-install all of your packages in bulk. 18.2.5 STEP 4: Upgrading R to the new Version Go to r-project.org and download the new version of R. Install the new version of R. restart R and RStudio - confirm that the new version is running with R.Version(). 18.2.6 STEP 5: Upgrading the RStudio Version While you are at it, check in the RStudio menu Help/Check for Updates to see if there is a new version of RStudio. Upgrade this if needed. The new version of RStudio will have updates to make it work better with the new version of R. Restart RStudio. You should now have the new version of R (check R.Version()) and the new version of RStudio (check Help/Check for Updates in RStudio). Check your library path again with .libPaths(). You should see a new library path for the new version of R. Explore this with Finder or Windows File Explorer. You should find a folder for your new version, with a Resources folder, and inside that a library folder. This is where a base set of packages will be installed. But you will be missing packages like tidyverse, ggplot2, and dplyr (and lots of others) that you had in your old version of R. 18.3 STEP 6: Rebuilding All of your Packages in One (Automated) Step There are two options for doing this: You can use the install.packages() function to install all of your packages in one step with the dataframe we built earlier. You can use the pkg_current dataframe you created above to do this. You can run the code below to install all of your packages in one step: (copy this and run it in your local RStudio session) install.packages( pkg_current$Package, dependencies = TRUE, repos = c(CRAN = &quot;https://cran.rstudio.com/&quot;), type = &quot;source&quot; ) One of the benefits of R version 4.5.0 and higher is that it will install packages in parallel, which is much faster than the previous parallel approach. From ~ 40 min for 700+ packages to 1 minute. Scroll through the output and check for any errors, or packages that did not install. Dig into the error messages (if any) one by one. If you have problems addressing the errors, check the troubleshooting guide at Chapter 12.1.2, Problems with Installing Packages. There is a slick package called {updater} which can handle the grunt work for you. It can be found at https://www.danieldsjoberg.com/updater/ There are 3 steps: Copy and save the path to your current R system library before you upgrade R. Run .libPaths() in the Console to get the path to your current library. Copy this path to a text file or Notes/Notepad on your computer. Upgrade R to the new version. Go to r-project.org and download the new version of R. Install the new version of R. restart R and RStudio - confirm that the new version is running with R.Version(). While you are at it, check in the RStudio menu Help/Check for Updates to see if there is a new version of RStudio. Upgrade this if needed Install your packages to the new library. Install the {updater} package with install.packages(\"updater\"). Run updater::install_pkgs(lib.loc = c(\"&lt;location(s) saved in Step 1&gt;\")) in the Console. Note that this is the point where you copy the saved library path from Step 1 into the parentheses (with quotes) into the Console. Note that you will want to update the version number in the path to your new version. This will end up looking something like updater::install_pkgs(lib.loc = c(\"/Library/Frameworks/R.framework/Versions/4.7/Resources/library\")). 18.4 Checking the new library path When all of the installation is complete, you can check your work. You can check the new library path with .libPaths(). This should now point to the new library folder for the new version of R. If you have multiple library paths, the first one is the one that will be used for installing packages. It should look something like /Library/Frameworks/R.framework/Versions/5.1-arm64/Resources/library\" 18.5 Now Check your list of Packages You should also review the Console text for errors or problems. You may find you need software packages external to R, or that you have tried to install some packages that are not on CRAN. Many packages that are not on CRAN are ones that you may have previously installed from Github or BioConductor. Note these by making a list of packages left to be installed, and install those from GitHub with remotes::install_github(\"username/packagename). As one example, you can install the development version of the {medicaldata} package from github with remotes::install_github(\"higgi13425/medicaldata\"). Note that the stable version is available on the CRAN repository. You may have similar issues with packages installed from BioConductor, which requires you to use BiocManager::install(\"packagename\"). Once you have completely installed your packages, check your work by running installed.packages() again. You should see a full list of your packages, and you are updated and ready to go! 18.6 Updating Packages If all of your current important projects are protected with an {renv} snapshot, this is probably a good time to update your tools (packages). Especially in the first month after a major R update, a lot of R packages are updated to optimize functions in the new version of R. You can do this easily within RStudio with the menu commands Tools/Check for Package Updates. Select All, and let the updates begin. You will usually want to compile the newest version from source code, rather than a recent version from binaries. It may take 2-3 weeks after an R update to have all the packages available in binaries, so you may need to compile from source code if you upgrade R right after a new version is released. If you have problems with updating packages, check the troubleshooting guide at Chapter 12.1.2, Problems with Installing Packages. "],["intermediate-steps-toward-reproducibility.html", "Chapter 19 Intermediate Steps Toward Reproducibility 19.1 Level 3 Reproducibility 19.2 Code Review with a Coding Partner 19.3 Sharing code on GitHub", " Chapter 19 Intermediate Steps Toward Reproducibility Now that you have become familiar with storing your code in saved Rmarkdown documents or RScripts, let’s continue on our journey to Research Reproducibility. Levels of Reproducibility In this chapter, you will learn how to: - Use RStudio Projects - Organize multiple files and folders in a project - Use the {here} package to avoid file paths that are specific to your computer - Do code review with a coding partner - Share code on Github - Sharing deidentified data on websites like figshare and Open Science Foundation - Building project-specific libraries with {renv} and snapshots to maintain your package environment. 19.1 Level 3 Reproducibility At this point, you may have a very long Rmarkdown document, or several documents with code, for a particular data project. There are challenges to organizing your files, your data, and your outputs. RStudio Projects help greatly in organizing your work. These Projects organize a coherent research project into a single folder in your storage/file system, anchored by a unique *.Rproj file in the folder. To get started, you may want to create a particular folder for R projects on your computer. I typically put an Rcode folder inside the Documents folder, and store RStudio Projects inside of the Rcode folder. Take a moment to create your Rcode folder, if you don’t have one already. It is best not to store RStudio Projects inside of other Projects. RStudio looks for the name.Rproj file to identify a project, and it gets confused if these are nested. Avoid having a name.Rproj file in either your Documents folder or your Rcode folder, to avoid problems. Now that you have an Rcode folder, let’s set it as the default location for your files and Projects in R. In RStudio, select (Tools/Global Options). Click on the General Tab on the left. Setting Default File Location Under R Sessions, enter the Default directory as ~/Documents/Rcode, or use the Browse button to browse to this folder and select it. 19.1.1 Creating a New Project in RStudio Open a new RStudio Session (Session/New Session), and start a new project, by selecting (File/New Project). You will be presented with a box of 3 options. Most of the time you will select New Directory. If you have already started on a research project, with data and code files in a particular folder that is not yet an RStudio project, you can select Existing Directory, and browse to the correct folder, and make it an official RStudio project. If you or a collaborator have already shared a project on GitHub, you can select Version Control, select Git, enter the repository URL, and clone this project to your computer. After you select New Directory, you will be asked to select New Project (rather than R package, Shiny App, website, book, etc.), then give the project (and its directory) a short name. It is generally a good idea to check both of the boxes to (1) Create a git repository, and (2) Use renv with this project. Creating a New Project Then click the Create Project button. This creates a new folder on your computer, named new-project, within your Rcode folder. This currently only contains a file named new-project.Rproj and a folder named .Rproj.user which handles files for you. Check your Rcode folder to find the new folder. You can copy or move your data files for this project to this folder. If you have started your coding for this project, move your code files to this project folder as well. Now you need to begin to organize your Project Folder. There are a lot of opinions and workflow templates for this, but most include folders for: data_raw - untouched raw data files data_processed (numbered in order if several iterations) R (for scripts, functions) metadata - plans/aims, TODO lists, descriptions of datafiles code - analysis files (Rmarkdown, numbered in order) output - output tables, figures, manuscript and a README.Rmd file to orient someone new to the project - what are the goals, where are data found, where are the analysis scripts, and how to run the code in order to reproduce the analysis. 19.1.1.1 Naming and Numbering Files In general, it is helpful to name code files with a short useful title that describes their function, along with a leading number, so that the order of running the code files is clear, like 01-import-clean_redcap_data.Rmd 02-import-clean_data-warehouse_data.Rmd 03-merge_redcap_data-warehouse_data.Rmd These will be easily sorted and organized in your new-project/code/ folder, as the leading numbers help organize these (keeping the leading 0 on the front of 0 through 9 helps sorting a lot when you have more than 10 files). It is also helpful to number and name your data files clearly. These should usually correspond to the code files that created them. At the end of a code step, you can save/write your resulting data file to an *.rda file or a *.csv file, to be loaded at the start of the next code file. These might look like the following in the new-project/processed-data/ folder. 01-cleaned_redcap_data.csv 02-cleaned_data-warehouse_data.csv 03-merged_redcap_data-warehouse_data.csv Note that we are using ‘chunked’ naming, so that the files have a consistent naming pattern with chunks in the same order, and distinct chunks are separated by underscores, while informative chunks composed of more than one word are separated by dashes. It is surprisingly important to be thoughtful about your chunked naming scheme early on, as it can help you in many ways in organizing, sorting, and manipulating files later. 19.1.2 File paths and the {here} package One of the great frustrations in sharing an RStudio project with a collaborator is that it is common to refer to files with absolute file paths which are specific to your computer. Unfortunately, the files will inevitably not be in the same place on your collaborator’s computer, and all of the path references to load or write/save files will not work. This frustration has led reasonable people to threaten computer arson, and to propose better approaches. Computer Arson In order to have a set of file paths that work on any computer that has a copy of your Project, you need to use the {here} package. Go ahead and install it now and load it library(here) if you don’t have it already. # install.packages(&quot;here&quot;) library(here) here() ## [1] &quot;/Users/peterhiggins/Documents/RCode/rmrwr-book&quot; Then run the here() function in your Console pane. It will return the path to your current Project. It essentially figures out where your project directory is, and provides this as a home base. This can be used to reference other folders in your project in a relative way. For example, to list the files in your data-raw folder (aka directory, or dir), you can use the {fs} package and the here() function, as in: fs::dir_ls(here(&quot;data-raw&quot;)) The here() function supplies the file path details up to your RStudio Project folder, and then you can add any subfolder or filename details within the parentheses. Similarly, you can write your cleaned and merged data file to the data-processed folder with write_csv(here(&quot;data-processed/03-merged_redcap_data-warehouse_data.csv&quot;)) Which will write the csv file to the data-processed folder within your Project. Now when you share the Project with a collaborator, the file paths for reading and writing files will now all work. Move a data file and a code file into your Project Folder. Create folders like data-raw, data-processed, metadata, code. You can do this by ‘hand’ with your computer’s operating system, or with the fs package, using fs::create_dir(\"name\") Use fs:dir_ls(here()) to list the files in the top level of your project Move the files into the appropriate folders re-run fs:dir_ls(here()) to see the change in the listing Now run fs:dir_ls(here(\"foldername\")) to see the contents of each of the folders (by name) that you created. 19.2 Code Review with a Coding Partner Checking code is a largely thankless job, but it is extremely important to prevent errors. It also encourages you to document your thinking and your code more thoroughly if you know someone else will be reviewing and checking it. If they can’t understand what you are doing, they can’t adequately review your code. It is important to find someone, often at a parallel position in their career, who is doing data coding for their research, so that you can become code review partners. Each of you can help the other become a better, clearer coder, and each of you can be more confident that your code does not contain mistakes. It can be very helpful to do this in several stages, to prevent problems later, rather than trying to review an entire project’s code in one go. after data import, cleaning, relabeling and merging After initial analysis After all figures, tables, manuscript ready 19.2.1 Checklist for Code Review This is a general and fairly comprehensive guidance. Use the items you (and the code creator) wish to focus on. Review a small, manageable chunk of code at a time. This takes a lot of focus, and often a lot of solving mysteries (poorly documented code). Make sure you understand the goal of the code, and/or the hypothesis being tested Is the README clear enough on where the data are, where the code is located, and what to run in what order? Is the code itself, with comments &amp; text, readable and understandable? Does it stand on its own without a lot of over-the-shoulder explanations? Is it structured in a project with {here} and {renv} to have consistent file paths and package versions? Are there libraries loaded that are not needed? Are all libraries loaded at the top of the code script? Think about file names and variable names - are they clear and helpful? Could they be better? Do the variable names include units, when appropriate, like sbp_mmHg, ast_iu-mL, cr_mg-L, to make clear what is being measured without a codebook? Are the values (for categorical and ordinal scales) self-explanatory? (e.g “0_No” and “1_Yes” are superior to 0/1, or “1_Asian”, “2_Black”, or “1_placebo”, “2_amazingmab”, rather than having to backtrack to a codebook? Has data been checked for missing data, outliers, time trends, correlations? Are things that should be correlated actually correlated? (Data Exploration and Validation (DEV?)) Does the data contain any PHI that needs to be de-identified? Can it be scrubbed? Does all the code run in a new, clean session on a different computer? Use {tidylog} to track data cleaning/processing steps. Are there a lot more rows/columns disappearing than expected? Check and validate data cleaning steps - was the result what was intended? Check and validate merges - was the result what was intended? Check and validate recoding of variables - mutate steps, case_when steps, intervention arms, outcome definitions - as the result what was intended? Keep notes, make recommendations for improvement If things are unclear, suggest how to make them clear Are there repeated steps that could be made into functions? Are there functions repeated multiple times that could be done once with purrr::map? Are there scientific threats to the validity of the research? Is there possible bias? mis-measurement? Potential confounders not present in the dataset? is this the best dataset to answer this question? Any general recommendations or suggestions of tools, packages, or functions that could be used to make this (or future) code projects better? Sign off on this code chunk - add a signoff comment at the end # I, NAME, have reviewed this code for errors and clarity on DATE and APPROVE this code. 19.3 Sharing code on GitHub "],["building-table-one-for-a-clinical-study.html", "Chapter 20 Building Table One for a Clinical Study 20.1 Packages Needed for this Chapter: 20.2 Pathway for this Chapter 20.3 Baseline Characteristics 20.4 Building Your Table 1 20.5 Try this with a new dataset 20.6 Making Modifications to the trial table 20.7 More Modifications to the trial table 20.8 Taking Control of the Stats", " Chapter 20 Building Table One for a Clinical Study In most clinical research, whether in an epidemiologic study or in a clinical trial, it is important to present a summary of the baseline characteristics of the study sample. This is often referred to as a “Table 1” or “Table One”. You generally want to provide enough information about your study sample so that a reader can determine whether your study sample is similar to the population or the specific patient they are interested in. The reader should be able to determine if the study is generalizable to their popuation or their patient of interest. There are a number of R packates that can help you build a Table 1. These include the appropriately named {tableone} package, the {arsenal} package, and the {compareGroups} package. But since 2020, the {gtsummary} package has become the most popular package for this purpose. This is in part because it is focused on clinical applications, and because it builds on the robust table infrastructure provided by the {gt} package, which is a modern approach to building tables in R. In this chapter, we will focus on building a Table 1 using data from the {medicaldata} package, the {gtsummary} package, and the {arsenal} package. The {gtsummary} package is also generally useful for producing other tables and tables of regression results. 20.1 Packages Needed for this Chapter: {gt} {gtsummary} {arsenal} {medicaldata} {tidyverse} 20.2 Pathway for this Chapter Let’s start by looking at the mockstudy data from the {arsenal} package. This is a mock study of treatment of cholangiocarcinoma with 3 different chemotherapy regimens. We will generate the dimensions, then glimpse the data. dim(mockstudy) ## [1] 1499 14 glimpse(mockstudy) ## Rows: 1,499 ## Columns: 14 ## $ case &lt;int&gt; 110754, 99706, 105271, 105001, 112263, 86205, 99508, 90158… ## $ age &lt;int&gt; 67, 74, 50, 71, 69, 56, 50, 57, 51, 63, 61, 59, 61, 59, 60… ## $ arm &lt;chr&gt; &quot;F: FOLFOX&quot;, &quot;A: IFL&quot;, &quot;A: IFL&quot;, &quot;G: IROX&quot;, &quot;F: FOLFOX&quot;, &quot;… ## $ sex &lt;fct&gt; Male, Female, Female, Female, Female, Male, Male, Male, Fe… ## $ race &lt;chr&gt; &quot;Caucasian&quot;, &quot;Caucasian&quot;, &quot;Caucasian&quot;, &quot;Caucasian&quot;, NA, &quot;C… ## $ fu.time &lt;int&gt; 922, 270, 175, 128, 233, 120, 369, 421, 387, 363, 168, 106… ## $ fu.stat &lt;int&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2… ## $ ps &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0… ## $ hgb &lt;dbl&gt; 11.5, 10.7, 11.1, 12.6, 13.0, 10.2, 13.3, 12.1, 13.8, 12.1… ## $ bmi &lt;dbl&gt; 25.09861, 19.49786, NA, 29.42922, 26.35352, 19.03673, 24.5… ## $ alk.phos &lt;int&gt; 160, 290, 700, 771, 350, 569, 162, 152, 231, 492, 740, 239… ## $ ast &lt;int&gt; 35, 52, 100, 68, 35, 27, 16, 12, 25, 18, 45, 16, 50, 80, 1… ## $ mdquality.s &lt;int&gt; NA, 1, 1, 1, NA, 1, 1, 1, 1, 1, NA, NA, 1, 0, 1, 1, 0, NA,… ## $ age.ord &lt;ord&gt; 60-69, 70-79, 40-49, 70-79, 60-69, 50-59, 40-49, 50-59, 50… 20.3 Baseline Characteristics For a Table One, you do not want outcomes like fu.time (followup time), but you do want particpant characteristics that were present at the start of the study. We also don’t need trivial information like case numbers or patient IDs. Let’s select for these with dplyr::select. mockstudy_baseline &lt;- mockstudy %&gt;% select(-fu.time, -fu.stat, -ps, -case, -mdquality.s, -age.ord) 20.4 Building Your Table 1 The main function for building a Table 1 with gtsummary is tbl_summary(). We can pipe the selected data into this function to get a first (ungrouped) version of the table. mockstudy_baseline |&gt; tbl_summary() #xkmepwliul table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #xkmepwliul thead, #xkmepwliul tbody, #xkmepwliul tfoot, #xkmepwliul tr, #xkmepwliul td, #xkmepwliul th { border-style: none; } #xkmepwliul p { margin: 0; padding: 0; } #xkmepwliul .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #xkmepwliul .gt_caption { padding-top: 4px; padding-bottom: 4px; } #xkmepwliul .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #xkmepwliul .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #xkmepwliul .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #xkmepwliul .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #xkmepwliul .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #xkmepwliul .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #xkmepwliul .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #xkmepwliul .gt_column_spanner_outer:first-child { padding-left: 0; } #xkmepwliul .gt_column_spanner_outer:last-child { padding-right: 0; } #xkmepwliul .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #xkmepwliul .gt_spanner_row { border-bottom-style: hidden; } #xkmepwliul .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #xkmepwliul .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #xkmepwliul .gt_from_md > :first-child { margin-top: 0; } #xkmepwliul .gt_from_md > :last-child { margin-bottom: 0; } #xkmepwliul .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #xkmepwliul .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #xkmepwliul .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #xkmepwliul .gt_row_group_first td { border-top-width: 2px; } #xkmepwliul .gt_row_group_first th { border-top-width: 2px; } #xkmepwliul .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #xkmepwliul .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #xkmepwliul .gt_first_summary_row.thick { border-top-width: 2px; } #xkmepwliul .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #xkmepwliul .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #xkmepwliul .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #xkmepwliul .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #xkmepwliul .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #xkmepwliul .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #xkmepwliul .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #xkmepwliul .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #xkmepwliul .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #xkmepwliul .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #xkmepwliul .gt_left { text-align: left; } #xkmepwliul .gt_center { text-align: center; } #xkmepwliul .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #xkmepwliul .gt_font_normal { font-weight: normal; } #xkmepwliul .gt_font_bold { font-weight: bold; } #xkmepwliul .gt_font_italic { font-style: italic; } #xkmepwliul .gt_super { font-size: 65%; } #xkmepwliul .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #xkmepwliul .gt_asterisk { font-size: 100%; vertical-align: 0; } #xkmepwliul .gt_indent_1 { text-indent: 5px; } #xkmepwliul .gt_indent_2 { text-indent: 10px; } #xkmepwliul .gt_indent_3 { text-indent: 15px; } #xkmepwliul .gt_indent_4 { text-indent: 20px; } #xkmepwliul .gt_indent_5 { text-indent: 25px; } #xkmepwliul .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #xkmepwliul div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } Characteristic N = 1,4991 Age in Years 61 (52, 68) Treatment Arm     A: IFL 428 (29%)     F: FOLFOX 691 (46%)     G: IROX 380 (25%) sex     Male 916 (61%)     Female 583 (39%) Race     African-Am 115 (7.7%)     Asian 18 (1.2%)     Caucasian 1,288 (86%)     Hawaii/Pacific 5 (0.3%)     Hispanic 54 (3.6%)     Native-Am/Alaska 5 (0.3%)     Other 7 (0.5%)     Unknown 7 hgb 12.30 (11.10, 13.50)     Unknown 266 Body Mass Index (kg/m^2) 26.3 (23.5, 30.2)     Unknown 33 alk.phos 123 (86, 207)     Unknown 266 ast 27 (20, 41)     Unknown 266 1 Median (Q1, Q3); n (%) 20.4.1 Updating Variable Labels This very quickly gives you a pretty version of a Table 1 that is publication-ready. However, you might not like the variable names that were easy to use in analysis. You might want longer or clearer versions for the table for publication. You can use the tbl_summary() function to rename variables. You can use the label argument to rename variables. Let’s rename the variables Sex and Race in the table to make them more publication-ready. mockstudy_baseline |&gt; tbl_summary(label = list( sex ~ &quot;Sex at Birth&quot;, race ~ &quot;Race Identified by Participant&quot;)) #qdpjaaxwip table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #qdpjaaxwip thead, #qdpjaaxwip tbody, #qdpjaaxwip tfoot, #qdpjaaxwip tr, #qdpjaaxwip td, #qdpjaaxwip th { border-style: none; } #qdpjaaxwip p { margin: 0; padding: 0; } #qdpjaaxwip .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #qdpjaaxwip .gt_caption { padding-top: 4px; padding-bottom: 4px; } #qdpjaaxwip .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #qdpjaaxwip .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #qdpjaaxwip .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #qdpjaaxwip .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qdpjaaxwip .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #qdpjaaxwip .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #qdpjaaxwip .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #qdpjaaxwip .gt_column_spanner_outer:first-child { padding-left: 0; } #qdpjaaxwip .gt_column_spanner_outer:last-child { padding-right: 0; } #qdpjaaxwip .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #qdpjaaxwip .gt_spanner_row { border-bottom-style: hidden; } #qdpjaaxwip .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #qdpjaaxwip .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #qdpjaaxwip .gt_from_md > :first-child { margin-top: 0; } #qdpjaaxwip .gt_from_md > :last-child { margin-bottom: 0; } #qdpjaaxwip .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #qdpjaaxwip .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #qdpjaaxwip .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #qdpjaaxwip .gt_row_group_first td { border-top-width: 2px; } #qdpjaaxwip .gt_row_group_first th { border-top-width: 2px; } #qdpjaaxwip .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #qdpjaaxwip .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #qdpjaaxwip .gt_first_summary_row.thick { border-top-width: 2px; } #qdpjaaxwip .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qdpjaaxwip .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #qdpjaaxwip .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #qdpjaaxwip .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #qdpjaaxwip .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #qdpjaaxwip .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qdpjaaxwip .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #qdpjaaxwip .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #qdpjaaxwip .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #qdpjaaxwip .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #qdpjaaxwip .gt_left { text-align: left; } #qdpjaaxwip .gt_center { text-align: center; } #qdpjaaxwip .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #qdpjaaxwip .gt_font_normal { font-weight: normal; } #qdpjaaxwip .gt_font_bold { font-weight: bold; } #qdpjaaxwip .gt_font_italic { font-style: italic; } #qdpjaaxwip .gt_super { font-size: 65%; } #qdpjaaxwip .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #qdpjaaxwip .gt_asterisk { font-size: 100%; vertical-align: 0; } #qdpjaaxwip .gt_indent_1 { text-indent: 5px; } #qdpjaaxwip .gt_indent_2 { text-indent: 10px; } #qdpjaaxwip .gt_indent_3 { text-indent: 15px; } #qdpjaaxwip .gt_indent_4 { text-indent: 20px; } #qdpjaaxwip .gt_indent_5 { text-indent: 25px; } #qdpjaaxwip .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #qdpjaaxwip div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } Characteristic N = 1,4991 Age in Years 61 (52, 68) Treatment Arm     A: IFL 428 (29%)     F: FOLFOX 691 (46%)     G: IROX 380 (25%) Sex at Birth     Male 916 (61%)     Female 583 (39%) Race Identified by Participant     African-Am 115 (7.7%)     Asian 18 (1.2%)     Caucasian 1,288 (86%)     Hawaii/Pacific 5 (0.3%)     Hispanic 54 (3.6%)     Native-Am/Alaska 5 (0.3%)     Other 7 (0.5%)     Unknown 7 hgb 12.30 (11.10, 13.50)     Unknown 266 Body Mass Index (kg/m^2) 26.3 (23.5, 30.2)     Unknown 33 alk.phos 123 (86, 207)     Unknown 266 ast 27 (20, 41)     Unknown 266 1 Median (Q1, Q3); n (%) 20.4.2 Updating Variable Values The value for Race of “African-Am” is shorthand, but not great for publication. Let’s fix this to “African-American” by using a mutate() function to change the value ofrace to “African-American” when it is “African-Am”. We will do this before we pipe the data into tbl_summary(). mockstudy_baseline |&gt; mutate(race = case_when(race == &quot;African-Am&quot; ~ &quot;African-American&quot;, .default = race)) |&gt; tbl_summary(label = list( sex ~ &quot;Sex at Birth&quot;, race ~ &quot;Race Identified by Participant&quot;)) #olaezasgyj table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #olaezasgyj thead, #olaezasgyj tbody, #olaezasgyj tfoot, #olaezasgyj tr, #olaezasgyj td, #olaezasgyj th { border-style: none; } #olaezasgyj p { margin: 0; padding: 0; } #olaezasgyj .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #olaezasgyj .gt_caption { padding-top: 4px; padding-bottom: 4px; } #olaezasgyj .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #olaezasgyj .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #olaezasgyj .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #olaezasgyj .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #olaezasgyj .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #olaezasgyj .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #olaezasgyj .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #olaezasgyj .gt_column_spanner_outer:first-child { padding-left: 0; } #olaezasgyj .gt_column_spanner_outer:last-child { padding-right: 0; } #olaezasgyj .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #olaezasgyj .gt_spanner_row { border-bottom-style: hidden; } #olaezasgyj .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #olaezasgyj .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #olaezasgyj .gt_from_md > :first-child { margin-top: 0; } #olaezasgyj .gt_from_md > :last-child { margin-bottom: 0; } #olaezasgyj .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #olaezasgyj .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #olaezasgyj .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #olaezasgyj .gt_row_group_first td { border-top-width: 2px; } #olaezasgyj .gt_row_group_first th { border-top-width: 2px; } #olaezasgyj .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #olaezasgyj .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #olaezasgyj .gt_first_summary_row.thick { border-top-width: 2px; } #olaezasgyj .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #olaezasgyj .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #olaezasgyj .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #olaezasgyj .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #olaezasgyj .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #olaezasgyj .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #olaezasgyj .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #olaezasgyj .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #olaezasgyj .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #olaezasgyj .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #olaezasgyj .gt_left { text-align: left; } #olaezasgyj .gt_center { text-align: center; } #olaezasgyj .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #olaezasgyj .gt_font_normal { font-weight: normal; } #olaezasgyj .gt_font_bold { font-weight: bold; } #olaezasgyj .gt_font_italic { font-style: italic; } #olaezasgyj .gt_super { font-size: 65%; } #olaezasgyj .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #olaezasgyj .gt_asterisk { font-size: 100%; vertical-align: 0; } #olaezasgyj .gt_indent_1 { text-indent: 5px; } #olaezasgyj .gt_indent_2 { text-indent: 10px; } #olaezasgyj .gt_indent_3 { text-indent: 15px; } #olaezasgyj .gt_indent_4 { text-indent: 20px; } #olaezasgyj .gt_indent_5 { text-indent: 25px; } #olaezasgyj .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #olaezasgyj div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } Characteristic N = 1,4991 Age in Years 61 (52, 68) Treatment Arm     A: IFL 428 (29%)     F: FOLFOX 691 (46%)     G: IROX 380 (25%) Sex at Birth     Male 916 (61%)     Female 583 (39%) Race Identified by Participant     African-American 115 (7.7%)     Asian 18 (1.2%)     Caucasian 1,288 (86%)     Hawaii/Pacific 5 (0.3%)     Hispanic 54 (3.6%)     Native-Am/Alaska 5 (0.3%)     Other 7 (0.5%)     Unknown 7 hgb 12.30 (11.10, 13.50)     Unknown 266 Body Mass Index (kg/m^2) 26.3 (23.5, 30.2)     Unknown 33 alk.phos 123 (86, 207)     Unknown 266 ast 27 (20, 41)     Unknown 266 1 Median (Q1, Q3); n (%) 20.4.3 Table 1 separated by Treatment Arm Let’s make a Table 1 that is now separated into distinct columns by Treatment Arm, allowing readers to compare the two groups and get a sense of whether the randomization was balanced. As we are making many comparisons on each characteristic of the participants, it is NOT appropriate to list p values for each comparison. We will use the tbl_summary(by = arm) argument to separate the table by treatment arm. We will also add_overall() and add_n() as these are commonly used. mockstudy_baseline |&gt; mutate(race = case_when(race == &quot;African-Am&quot; ~ &quot;African-American&quot;, .default = race)) |&gt; tbl_summary(label = list( sex ~ &quot;Sex at Birth&quot;, race ~ &quot;Race Identified by Participant&quot;), by = arm) |&gt; add_overall() |&gt; add_n() #kjyhsmuzpi table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #kjyhsmuzpi thead, #kjyhsmuzpi tbody, #kjyhsmuzpi tfoot, #kjyhsmuzpi tr, #kjyhsmuzpi td, #kjyhsmuzpi th { border-style: none; } #kjyhsmuzpi p { margin: 0; padding: 0; } #kjyhsmuzpi .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #kjyhsmuzpi .gt_caption { padding-top: 4px; padding-bottom: 4px; } #kjyhsmuzpi .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #kjyhsmuzpi .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #kjyhsmuzpi .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #kjyhsmuzpi .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #kjyhsmuzpi .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #kjyhsmuzpi .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #kjyhsmuzpi .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #kjyhsmuzpi .gt_column_spanner_outer:first-child { padding-left: 0; } #kjyhsmuzpi .gt_column_spanner_outer:last-child { padding-right: 0; } #kjyhsmuzpi .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #kjyhsmuzpi .gt_spanner_row { border-bottom-style: hidden; } #kjyhsmuzpi .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #kjyhsmuzpi .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #kjyhsmuzpi .gt_from_md > :first-child { margin-top: 0; } #kjyhsmuzpi .gt_from_md > :last-child { margin-bottom: 0; } #kjyhsmuzpi .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #kjyhsmuzpi .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #kjyhsmuzpi .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #kjyhsmuzpi .gt_row_group_first td { border-top-width: 2px; } #kjyhsmuzpi .gt_row_group_first th { border-top-width: 2px; } #kjyhsmuzpi .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #kjyhsmuzpi .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #kjyhsmuzpi .gt_first_summary_row.thick { border-top-width: 2px; } #kjyhsmuzpi .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #kjyhsmuzpi .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #kjyhsmuzpi .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #kjyhsmuzpi .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #kjyhsmuzpi .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #kjyhsmuzpi .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #kjyhsmuzpi .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #kjyhsmuzpi .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #kjyhsmuzpi .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #kjyhsmuzpi .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #kjyhsmuzpi .gt_left { text-align: left; } #kjyhsmuzpi .gt_center { text-align: center; } #kjyhsmuzpi .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #kjyhsmuzpi .gt_font_normal { font-weight: normal; } #kjyhsmuzpi .gt_font_bold { font-weight: bold; } #kjyhsmuzpi .gt_font_italic { font-style: italic; } #kjyhsmuzpi .gt_super { font-size: 65%; } #kjyhsmuzpi .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #kjyhsmuzpi .gt_asterisk { font-size: 100%; vertical-align: 0; } #kjyhsmuzpi .gt_indent_1 { text-indent: 5px; } #kjyhsmuzpi .gt_indent_2 { text-indent: 10px; } #kjyhsmuzpi .gt_indent_3 { text-indent: 15px; } #kjyhsmuzpi .gt_indent_4 { text-indent: 20px; } #kjyhsmuzpi .gt_indent_5 { text-indent: 25px; } #kjyhsmuzpi .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #kjyhsmuzpi div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } Characteristic N Overall N = 1,4991 A: IFL N = 4281 F: FOLFOX N = 6911 G: IROX N = 3801 Age in Years 1,499 61 (52, 68) 61 (53, 68) 61 (52, 69) 61 (52, 68) Sex at Birth 1,499     Male 916 (61%) 277 (65%) 411 (59%) 228 (60%)     Female 583 (39%) 151 (35%) 280 (41%) 152 (40%) Race Identified by Participant 1,492     African-American 115 (7.7%) 39 (9.1%) 49 (7.2%) 27 (7.1%)     Asian 18 (1.2%) 1 (0.2%) 14 (2.0%) 3 (0.8%)     Caucasian 1,288 (86%) 371 (87%) 586 (86%) 331 (87%)     Hawaii/Pacific 5 (0.3%) 1 (0.2%) 3 (0.4%) 1 (0.3%)     Hispanic 54 (3.6%) 12 (2.8%) 28 (4.1%) 14 (3.7%)     Native-Am/Alaska 5 (0.3%) 2 (0.5%) 1 (0.1%) 2 (0.5%)     Other 7 (0.5%) 2 (0.5%) 4 (0.6%) 1 (0.3%)     Unknown 7 0 6 1 hgb 1,233 12.30 (11.10, 13.50) 12.10 (11.00, 13.50) 12.20 (11.10, 13.60) 12.40 (11.15, 13.65)     Unknown 266 69 141 56 Body Mass Index (kg/m^2) 1,466 26.3 (23.5, 30.2) 26.2 (23.6, 30.6) 26.5 (23.7, 30.1) 26.0 (23.2, 29.6)     Unknown 33 9 20 4 alk.phos 1,233 123 (86, 207) 133 (89, 219) 116 (85, 195) 122 (88, 212)     Unknown 266 69 141 56 ast 1,233 27 (20, 41) 29 (21, 42) 26 (19, 40) 27 (20, 41)     Unknown 266 69 141 56 1 Median (Q1, Q3); n (%) 20.4.4 Styling our Table 1 Let’s redefine the Unknown values as Missing (within the tbl_summary function), and bold the labels. mockstudy_baseline |&gt; mutate(race = case_when(race == &quot;African-Am&quot; ~ &quot;African-American&quot;, .default = race)) |&gt; tbl_summary(label = list( sex ~ &quot;Sex at Birth&quot;, race ~ &quot;Race Identified by Participant&quot;), by = arm, missing_text = &quot;Missing&quot;) |&gt; add_overall() |&gt; add_n() |&gt; bold_labels() #fotueasdzl table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #fotueasdzl thead, #fotueasdzl tbody, #fotueasdzl tfoot, #fotueasdzl tr, #fotueasdzl td, #fotueasdzl th { border-style: none; } #fotueasdzl p { margin: 0; padding: 0; } #fotueasdzl .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #fotueasdzl .gt_caption { padding-top: 4px; padding-bottom: 4px; } #fotueasdzl .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #fotueasdzl .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #fotueasdzl .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #fotueasdzl .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #fotueasdzl .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #fotueasdzl .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #fotueasdzl .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #fotueasdzl .gt_column_spanner_outer:first-child { padding-left: 0; } #fotueasdzl .gt_column_spanner_outer:last-child { padding-right: 0; } #fotueasdzl .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #fotueasdzl .gt_spanner_row { border-bottom-style: hidden; } #fotueasdzl .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #fotueasdzl .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #fotueasdzl .gt_from_md > :first-child { margin-top: 0; } #fotueasdzl .gt_from_md > :last-child { margin-bottom: 0; } #fotueasdzl .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #fotueasdzl .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #fotueasdzl .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #fotueasdzl .gt_row_group_first td { border-top-width: 2px; } #fotueasdzl .gt_row_group_first th { border-top-width: 2px; } #fotueasdzl .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #fotueasdzl .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #fotueasdzl .gt_first_summary_row.thick { border-top-width: 2px; } #fotueasdzl .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #fotueasdzl .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #fotueasdzl .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #fotueasdzl .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #fotueasdzl .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #fotueasdzl .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #fotueasdzl .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #fotueasdzl .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #fotueasdzl .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #fotueasdzl .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #fotueasdzl .gt_left { text-align: left; } #fotueasdzl .gt_center { text-align: center; } #fotueasdzl .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #fotueasdzl .gt_font_normal { font-weight: normal; } #fotueasdzl .gt_font_bold { font-weight: bold; } #fotueasdzl .gt_font_italic { font-style: italic; } #fotueasdzl .gt_super { font-size: 65%; } #fotueasdzl .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #fotueasdzl .gt_asterisk { font-size: 100%; vertical-align: 0; } #fotueasdzl .gt_indent_1 { text-indent: 5px; } #fotueasdzl .gt_indent_2 { text-indent: 10px; } #fotueasdzl .gt_indent_3 { text-indent: 15px; } #fotueasdzl .gt_indent_4 { text-indent: 20px; } #fotueasdzl .gt_indent_5 { text-indent: 25px; } #fotueasdzl .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #fotueasdzl div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } Characteristic N Overall N = 1,4991 A: IFL N = 4281 F: FOLFOX N = 6911 G: IROX N = 3801 Age in Years 1,499 61 (52, 68) 61 (53, 68) 61 (52, 69) 61 (52, 68) Sex at Birth 1,499     Male 916 (61%) 277 (65%) 411 (59%) 228 (60%)     Female 583 (39%) 151 (35%) 280 (41%) 152 (40%) Race Identified by Participant 1,492     African-American 115 (7.7%) 39 (9.1%) 49 (7.2%) 27 (7.1%)     Asian 18 (1.2%) 1 (0.2%) 14 (2.0%) 3 (0.8%)     Caucasian 1,288 (86%) 371 (87%) 586 (86%) 331 (87%)     Hawaii/Pacific 5 (0.3%) 1 (0.2%) 3 (0.4%) 1 (0.3%)     Hispanic 54 (3.6%) 12 (2.8%) 28 (4.1%) 14 (3.7%)     Native-Am/Alaska 5 (0.3%) 2 (0.5%) 1 (0.1%) 2 (0.5%)     Other 7 (0.5%) 2 (0.5%) 4 (0.6%) 1 (0.3%)     Missing 7 0 6 1 hgb 1,233 12.30 (11.10, 13.50) 12.10 (11.00, 13.50) 12.20 (11.10, 13.60) 12.40 (11.15, 13.65)     Missing 266 69 141 56 Body Mass Index (kg/m^2) 1,466 26.3 (23.5, 30.2) 26.2 (23.6, 30.6) 26.5 (23.7, 30.1) 26.0 (23.2, 29.6)     Missing 33 9 20 4 alk.phos 1,233 123 (86, 207) 133 (89, 219) 116 (85, 195) 122 (88, 212)     Missing 266 69 141 56 ast 1,233 27 (20, 41) 29 (21, 42) 26 (19, 40) 27 (20, 41)     Missing 266 69 141 56 1 Median (Q1, Q3); n (%) 20.4.5 Adding A Column Spanner You can add column spanners to your table to group variables together. In this case, it would make sense to identify and group the three treatment arms with a column spanner. tbl &lt;- mockstudy_baseline |&gt; mutate(race = case_when(race == &quot;African-Am&quot; ~ &quot;African-American&quot;, .default = race)) |&gt; tbl_summary(label = list( sex ~ &quot;Sex at Birth&quot;, race ~ &quot;Race Identified by Participant&quot;), by = arm, missing_text = &quot;Missing&quot;) |&gt; add_overall() |&gt; add_n() |&gt; bold_labels() |&gt; modify_spanning_header(c(&quot;stat_1&quot;, &quot;stat_2&quot;, &quot;stat_3&quot;) ~ &quot;**Treatment Received**&quot;) tbl #gxzzjnxmya table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #gxzzjnxmya thead, #gxzzjnxmya tbody, #gxzzjnxmya tfoot, #gxzzjnxmya tr, #gxzzjnxmya td, #gxzzjnxmya th { border-style: none; } #gxzzjnxmya p { margin: 0; padding: 0; } #gxzzjnxmya .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #gxzzjnxmya .gt_caption { padding-top: 4px; padding-bottom: 4px; } #gxzzjnxmya .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #gxzzjnxmya .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #gxzzjnxmya .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #gxzzjnxmya .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #gxzzjnxmya .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #gxzzjnxmya .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #gxzzjnxmya .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #gxzzjnxmya .gt_column_spanner_outer:first-child { padding-left: 0; } #gxzzjnxmya .gt_column_spanner_outer:last-child { padding-right: 0; } #gxzzjnxmya .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #gxzzjnxmya .gt_spanner_row { border-bottom-style: hidden; } #gxzzjnxmya .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #gxzzjnxmya .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #gxzzjnxmya .gt_from_md > :first-child { margin-top: 0; } #gxzzjnxmya .gt_from_md > :last-child { margin-bottom: 0; } #gxzzjnxmya .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #gxzzjnxmya .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #gxzzjnxmya .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #gxzzjnxmya .gt_row_group_first td { border-top-width: 2px; } #gxzzjnxmya .gt_row_group_first th { border-top-width: 2px; } #gxzzjnxmya .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #gxzzjnxmya .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #gxzzjnxmya .gt_first_summary_row.thick { border-top-width: 2px; } #gxzzjnxmya .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #gxzzjnxmya .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #gxzzjnxmya .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #gxzzjnxmya .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #gxzzjnxmya .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #gxzzjnxmya .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #gxzzjnxmya .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #gxzzjnxmya .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #gxzzjnxmya .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #gxzzjnxmya .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #gxzzjnxmya .gt_left { text-align: left; } #gxzzjnxmya .gt_center { text-align: center; } #gxzzjnxmya .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #gxzzjnxmya .gt_font_normal { font-weight: normal; } #gxzzjnxmya .gt_font_bold { font-weight: bold; } #gxzzjnxmya .gt_font_italic { font-style: italic; } #gxzzjnxmya .gt_super { font-size: 65%; } #gxzzjnxmya .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #gxzzjnxmya .gt_asterisk { font-size: 100%; vertical-align: 0; } #gxzzjnxmya .gt_indent_1 { text-indent: 5px; } #gxzzjnxmya .gt_indent_2 { text-indent: 10px; } #gxzzjnxmya .gt_indent_3 { text-indent: 15px; } #gxzzjnxmya .gt_indent_4 { text-indent: 20px; } #gxzzjnxmya .gt_indent_5 { text-indent: 25px; } #gxzzjnxmya .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #gxzzjnxmya div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } Characteristic N Overall N = 1,4991 Treatment Received A: IFL N = 4281 F: FOLFOX N = 6911 G: IROX N = 3801 Age in Years 1,499 61 (52, 68) 61 (53, 68) 61 (52, 69) 61 (52, 68) Sex at Birth 1,499     Male 916 (61%) 277 (65%) 411 (59%) 228 (60%)     Female 583 (39%) 151 (35%) 280 (41%) 152 (40%) Race Identified by Participant 1,492     African-American 115 (7.7%) 39 (9.1%) 49 (7.2%) 27 (7.1%)     Asian 18 (1.2%) 1 (0.2%) 14 (2.0%) 3 (0.8%)     Caucasian 1,288 (86%) 371 (87%) 586 (86%) 331 (87%)     Hawaii/Pacific 5 (0.3%) 1 (0.2%) 3 (0.4%) 1 (0.3%)     Hispanic 54 (3.6%) 12 (2.8%) 28 (4.1%) 14 (3.7%)     Native-Am/Alaska 5 (0.3%) 2 (0.5%) 1 (0.1%) 2 (0.5%)     Other 7 (0.5%) 2 (0.5%) 4 (0.6%) 1 (0.3%)     Missing 7 0 6 1 hgb 1,233 12.30 (11.10, 13.50) 12.10 (11.00, 13.50) 12.20 (11.10, 13.60) 12.40 (11.15, 13.65)     Missing 266 69 141 56 Body Mass Index (kg/m^2) 1,466 26.3 (23.5, 30.2) 26.2 (23.6, 30.6) 26.5 (23.7, 30.1) 26.0 (23.2, 29.6)     Missing 33 9 20 4 alk.phos 1,233 123 (86, 207) 133 (89, 219) 116 (85, 195) 122 (88, 212)     Missing 266 69 141 56 ast 1,233 27 (20, 41) 29 (21, 42) 26 (19, 40) 27 (20, 41)     Missing 266 69 141 56 1 Median (Q1, Q3); n (%) Note that the standard column names for columns in tbl_summary() are label n stat_0 stat_1 stat_2 stat_3, etc. Note that you can confirm these with show_header_names() and you can change these with modify_header() to take control of the line breaks with and bolding with **. Let’s take a look: show_header_names(tbl) ## Column Name Header level* N* n* p* ## label &quot;**Characteristic**&quot; 1,499 &lt;int&gt; ## n &quot;**N**&quot; ## stat_0 &quot;**Overall** \\nN = 1,499&quot; Overall &lt;chr&gt; 1,499 &lt;int&gt; 1,499 &lt;int&gt; 1.00 &lt;dbl&gt; ## stat_1 &quot;**A: IFL** \\nN = 428&quot; A: IFL &lt;chr&gt; 1,499 &lt;int&gt; 428 &lt;int&gt; 0.286 &lt;dbl&gt; ## stat_2 &quot;**F: FOLFOX** \\nN = 691&quot; F: FOLFOX &lt;chr&gt; 1,499 &lt;int&gt; 691 &lt;int&gt; 0.461 &lt;dbl&gt; ## stat_3 &quot;**G: IROX** \\nN = 380&quot; G: IROX &lt;chr&gt; 1,499 &lt;int&gt; 380 &lt;int&gt; 0.254 &lt;dbl&gt; ## * These values may be dynamically placed into headers (and other locations). ## ℹ Review the `modify_header()` (`?gtsummary::modify_header()`) help for ## examples. tbl |&gt; modify_header((update = list( stat_0 ~ &quot;**Overall**&lt;br&gt;N = 1,499&quot;, stat_1 ~ &quot;**A: IFL**&lt;br&gt;N = 428&quot;, stat_2 ~ &quot;**F: FOLFOX**&lt;br&gt;N = 691&quot;, stat_3 ~ &quot;**G: IROX**&lt;br&gt;N = 380&quot;) )) ## Warning: The `update` argument of `modify_header()` is deprecated as of gtsummary 2.0.0. ## ℹ Use `modify_header(...)` input instead. Dynamic dots allow for syntax like ## `modify_header(!!!list(...))`. ## ℹ The deprecated feature was likely used in the gtsummary package. ## Please report the issue at &lt;https://github.com/ddsjoberg/gtsummary/issues&gt;. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. #nlbtrtazkv table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #nlbtrtazkv thead, #nlbtrtazkv tbody, #nlbtrtazkv tfoot, #nlbtrtazkv tr, #nlbtrtazkv td, #nlbtrtazkv th { border-style: none; } #nlbtrtazkv p { margin: 0; padding: 0; } #nlbtrtazkv .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #nlbtrtazkv .gt_caption { padding-top: 4px; padding-bottom: 4px; } #nlbtrtazkv .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #nlbtrtazkv .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #nlbtrtazkv .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #nlbtrtazkv .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #nlbtrtazkv .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #nlbtrtazkv .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #nlbtrtazkv .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #nlbtrtazkv .gt_column_spanner_outer:first-child { padding-left: 0; } #nlbtrtazkv .gt_column_spanner_outer:last-child { padding-right: 0; } #nlbtrtazkv .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #nlbtrtazkv .gt_spanner_row { border-bottom-style: hidden; } #nlbtrtazkv .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #nlbtrtazkv .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #nlbtrtazkv .gt_from_md > :first-child { margin-top: 0; } #nlbtrtazkv .gt_from_md > :last-child { margin-bottom: 0; } #nlbtrtazkv .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #nlbtrtazkv .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #nlbtrtazkv .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #nlbtrtazkv .gt_row_group_first td { border-top-width: 2px; } #nlbtrtazkv .gt_row_group_first th { border-top-width: 2px; } #nlbtrtazkv .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #nlbtrtazkv .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #nlbtrtazkv .gt_first_summary_row.thick { border-top-width: 2px; } #nlbtrtazkv .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #nlbtrtazkv .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #nlbtrtazkv .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #nlbtrtazkv .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #nlbtrtazkv .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #nlbtrtazkv .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #nlbtrtazkv .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #nlbtrtazkv .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #nlbtrtazkv .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #nlbtrtazkv .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #nlbtrtazkv .gt_left { text-align: left; } #nlbtrtazkv .gt_center { text-align: center; } #nlbtrtazkv .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #nlbtrtazkv .gt_font_normal { font-weight: normal; } #nlbtrtazkv .gt_font_bold { font-weight: bold; } #nlbtrtazkv .gt_font_italic { font-style: italic; } #nlbtrtazkv .gt_super { font-size: 65%; } #nlbtrtazkv .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #nlbtrtazkv .gt_asterisk { font-size: 100%; vertical-align: 0; } #nlbtrtazkv .gt_indent_1 { text-indent: 5px; } #nlbtrtazkv .gt_indent_2 { text-indent: 10px; } #nlbtrtazkv .gt_indent_3 { text-indent: 15px; } #nlbtrtazkv .gt_indent_4 { text-indent: 20px; } #nlbtrtazkv .gt_indent_5 { text-indent: 25px; } #nlbtrtazkv .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #nlbtrtazkv div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } Characteristic N OverallN = 1,4991 Treatment Received A: IFLN = 4281 F: FOLFOXN = 6911 G: IROXN = 3801 Age in Years 1,499 61 (52, 68) 61 (53, 68) 61 (52, 69) 61 (52, 68) Sex at Birth 1,499     Male 916 (61%) 277 (65%) 411 (59%) 228 (60%)     Female 583 (39%) 151 (35%) 280 (41%) 152 (40%) Race Identified by Participant 1,492     African-American 115 (7.7%) 39 (9.1%) 49 (7.2%) 27 (7.1%)     Asian 18 (1.2%) 1 (0.2%) 14 (2.0%) 3 (0.8%)     Caucasian 1,288 (86%) 371 (87%) 586 (86%) 331 (87%)     Hawaii/Pacific 5 (0.3%) 1 (0.2%) 3 (0.4%) 1 (0.3%)     Hispanic 54 (3.6%) 12 (2.8%) 28 (4.1%) 14 (3.7%)     Native-Am/Alaska 5 (0.3%) 2 (0.5%) 1 (0.1%) 2 (0.5%)     Other 7 (0.5%) 2 (0.5%) 4 (0.6%) 1 (0.3%)     Missing 7 0 6 1 hgb 1,233 12.30 (11.10, 13.50) 12.10 (11.00, 13.50) 12.20 (11.10, 13.60) 12.40 (11.15, 13.65)     Missing 266 69 141 56 Body Mass Index (kg/m^2) 1,466 26.3 (23.5, 30.2) 26.2 (23.6, 30.6) 26.5 (23.7, 30.1) 26.0 (23.2, 29.6)     Missing 33 9 20 4 alk.phos 1,233 123 (86, 207) 133 (89, 219) 116 (85, 195) 122 (88, 212)     Missing 266 69 141 56 ast 1,233 27 (20, 41) 29 (21, 42) 26 (19, 40) 27 (20, 41)     Missing 266 69 141 56 1 Median (Q1, Q3); n (%) 20.4.6 Further Styling our Table 1 You can use {gtsummary} functions to modify header names, footnotes, captions, the number of digits in numbers, and the stats used. See the tutorial article here for more information. The pdf cheatsheet is also downloadable at the same website under Articles/cheat sheet, and is very helpful. You can convert this table to a gt table with as_gt() and further style it, using all of the table styling functions available in the {gt} package. Lots of details on how to style {gt} tables can be found in the {gt} package documentation. 20.4.7 Your Turn In the last code block, we saved the table as the object tbl. Take this tbl object and fix up the labels for hgb, alk.phos, and ast to be more publication-ready. add a caption to the table that says “Baseline Characteristics of Participants in the Mock Study by Treatment Arm” add a footnote to the table that says “Note: Missing values are indicated as ‘Missing’ in the table.” improve the value labels for ‘Hawaii/Pacific’, and ‘Native-Am/Alaska’ to be “Native Hawaiian or other Pacific Islander” and “American Indian or Alaska Native” respectively. change the number of digits in the table to 2. change the stats to show the mean and standard deviation for continuous variables, and the count and percent for categorical variables. convert the table to a gt table and style it with the gt package. Add some color. The code block below starts with tbl, unmodified. Add a pipe and start fixing it up, with the goals above. Refer to the {gtsummary} and {gt} documentation for help. Click on the links below as needed. gtsummary: tbl_summary() gt: gt() tbl #fxbwzzkdvp table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #fxbwzzkdvp thead, #fxbwzzkdvp tbody, #fxbwzzkdvp tfoot, #fxbwzzkdvp tr, #fxbwzzkdvp td, #fxbwzzkdvp th { border-style: none; } #fxbwzzkdvp p { margin: 0; padding: 0; } #fxbwzzkdvp .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #fxbwzzkdvp .gt_caption { padding-top: 4px; padding-bottom: 4px; } #fxbwzzkdvp .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #fxbwzzkdvp .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #fxbwzzkdvp .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #fxbwzzkdvp .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #fxbwzzkdvp .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #fxbwzzkdvp .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #fxbwzzkdvp .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #fxbwzzkdvp .gt_column_spanner_outer:first-child { padding-left: 0; } #fxbwzzkdvp .gt_column_spanner_outer:last-child { padding-right: 0; } #fxbwzzkdvp .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #fxbwzzkdvp .gt_spanner_row { border-bottom-style: hidden; } #fxbwzzkdvp .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #fxbwzzkdvp .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #fxbwzzkdvp .gt_from_md > :first-child { margin-top: 0; } #fxbwzzkdvp .gt_from_md > :last-child { margin-bottom: 0; } #fxbwzzkdvp .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #fxbwzzkdvp .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #fxbwzzkdvp .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #fxbwzzkdvp .gt_row_group_first td { border-top-width: 2px; } #fxbwzzkdvp .gt_row_group_first th { border-top-width: 2px; } #fxbwzzkdvp .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #fxbwzzkdvp .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #fxbwzzkdvp .gt_first_summary_row.thick { border-top-width: 2px; } #fxbwzzkdvp .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #fxbwzzkdvp .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #fxbwzzkdvp .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #fxbwzzkdvp .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #fxbwzzkdvp .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #fxbwzzkdvp .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #fxbwzzkdvp .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #fxbwzzkdvp .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #fxbwzzkdvp .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #fxbwzzkdvp .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #fxbwzzkdvp .gt_left { text-align: left; } #fxbwzzkdvp .gt_center { text-align: center; } #fxbwzzkdvp .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #fxbwzzkdvp .gt_font_normal { font-weight: normal; } #fxbwzzkdvp .gt_font_bold { font-weight: bold; } #fxbwzzkdvp .gt_font_italic { font-style: italic; } #fxbwzzkdvp .gt_super { font-size: 65%; } #fxbwzzkdvp .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #fxbwzzkdvp .gt_asterisk { font-size: 100%; vertical-align: 0; } #fxbwzzkdvp .gt_indent_1 { text-indent: 5px; } #fxbwzzkdvp .gt_indent_2 { text-indent: 10px; } #fxbwzzkdvp .gt_indent_3 { text-indent: 15px; } #fxbwzzkdvp .gt_indent_4 { text-indent: 20px; } #fxbwzzkdvp .gt_indent_5 { text-indent: 25px; } #fxbwzzkdvp .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #fxbwzzkdvp div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } Characteristic N Overall N = 1,4991 Treatment Received A: IFL N = 4281 F: FOLFOX N = 6911 G: IROX N = 3801 Age in Years 1,499 61 (52, 68) 61 (53, 68) 61 (52, 69) 61 (52, 68) Sex at Birth 1,499     Male 916 (61%) 277 (65%) 411 (59%) 228 (60%)     Female 583 (39%) 151 (35%) 280 (41%) 152 (40%) Race Identified by Participant 1,492     African-American 115 (7.7%) 39 (9.1%) 49 (7.2%) 27 (7.1%)     Asian 18 (1.2%) 1 (0.2%) 14 (2.0%) 3 (0.8%)     Caucasian 1,288 (86%) 371 (87%) 586 (86%) 331 (87%)     Hawaii/Pacific 5 (0.3%) 1 (0.2%) 3 (0.4%) 1 (0.3%)     Hispanic 54 (3.6%) 12 (2.8%) 28 (4.1%) 14 (3.7%)     Native-Am/Alaska 5 (0.3%) 2 (0.5%) 1 (0.1%) 2 (0.5%)     Other 7 (0.5%) 2 (0.5%) 4 (0.6%) 1 (0.3%)     Missing 7 0 6 1 hgb 1,233 12.30 (11.10, 13.50) 12.10 (11.00, 13.50) 12.20 (11.10, 13.60) 12.40 (11.15, 13.65)     Missing 266 69 141 56 Body Mass Index (kg/m^2) 1,466 26.3 (23.5, 30.2) 26.2 (23.6, 30.6) 26.5 (23.7, 30.1) 26.0 (23.2, 29.6)     Missing 33 9 20 4 alk.phos 1,233 123 (86, 207) 133 (89, 219) 116 (85, 195) 122 (88, 212)     Missing 266 69 141 56 ast 1,233 27 (20, 41) 29 (21, 42) 26 (19, 40) 27 (20, 41)     Missing 266 69 141 56 1 Median (Q1, Q3); n (%) 20.5 Try this with a new dataset Now we will use the trial dataset from the {gtsummary} package to create a Table 1. The trial dataset is a simulated dataset of a clinical trial with 200 observations and 6 variables. Run the code block below. Which are baseline variables for Table 1, and which are outcome variables? Use your R skills to: select the baseline variables create a Table 1, divided by treatment (trt), and set the missing_text to “Missing”. trial ## # A tibble: 200 × 8 ## trt age marker stage grade response death ttdeath ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Drug A 23 0.16 T1 II 0 0 24 ## 2 Drug B 9 1.11 T2 I 1 0 24 ## 3 Drug A 31 0.277 T1 II 0 0 24 ## 4 Drug A NA 2.07 T3 III 1 1 17.6 ## 5 Drug A 51 2.77 T4 III 1 1 16.4 ## 6 Drug B 39 0.613 T4 I 0 1 15.6 ## 7 Drug A 37 0.354 T1 II 0 0 24 ## 8 Drug A 32 1.74 T1 I 0 1 18.4 ## 9 Drug A 31 0.144 T1 II 0 0 24 ## 10 Drug B 34 0.205 T3 I 0 1 10.5 ## # ℹ 190 more rows Show code Solution trial |&gt; select(age, marker, stage, grade, trt) |&gt; tbl_summary(by = trt, missing_text = &quot;Missing&quot;) #kwmsvordpx table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #kwmsvordpx thead, #kwmsvordpx tbody, #kwmsvordpx tfoot, #kwmsvordpx tr, #kwmsvordpx td, #kwmsvordpx th { border-style: none; } #kwmsvordpx p { margin: 0; padding: 0; } #kwmsvordpx .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #kwmsvordpx .gt_caption { padding-top: 4px; padding-bottom: 4px; } #kwmsvordpx .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #kwmsvordpx .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #kwmsvordpx .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #kwmsvordpx .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #kwmsvordpx .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #kwmsvordpx .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #kwmsvordpx .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #kwmsvordpx .gt_column_spanner_outer:first-child { padding-left: 0; } #kwmsvordpx .gt_column_spanner_outer:last-child { padding-right: 0; } #kwmsvordpx .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #kwmsvordpx .gt_spanner_row { border-bottom-style: hidden; } #kwmsvordpx .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #kwmsvordpx .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #kwmsvordpx .gt_from_md > :first-child { margin-top: 0; } #kwmsvordpx .gt_from_md > :last-child { margin-bottom: 0; } #kwmsvordpx .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #kwmsvordpx .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #kwmsvordpx .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #kwmsvordpx .gt_row_group_first td { border-top-width: 2px; } #kwmsvordpx .gt_row_group_first th { border-top-width: 2px; } #kwmsvordpx .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #kwmsvordpx .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #kwmsvordpx .gt_first_summary_row.thick { border-top-width: 2px; } #kwmsvordpx .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #kwmsvordpx .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #kwmsvordpx .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #kwmsvordpx .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #kwmsvordpx .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #kwmsvordpx .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #kwmsvordpx .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #kwmsvordpx .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #kwmsvordpx .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #kwmsvordpx .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #kwmsvordpx .gt_left { text-align: left; } #kwmsvordpx .gt_center { text-align: center; } #kwmsvordpx .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #kwmsvordpx .gt_font_normal { font-weight: normal; } #kwmsvordpx .gt_font_bold { font-weight: bold; } #kwmsvordpx .gt_font_italic { font-style: italic; } #kwmsvordpx .gt_super { font-size: 65%; } #kwmsvordpx .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #kwmsvordpx .gt_asterisk { font-size: 100%; vertical-align: 0; } #kwmsvordpx .gt_indent_1 { text-indent: 5px; } #kwmsvordpx .gt_indent_2 { text-indent: 10px; } #kwmsvordpx .gt_indent_3 { text-indent: 15px; } #kwmsvordpx .gt_indent_4 { text-indent: 20px; } #kwmsvordpx .gt_indent_5 { text-indent: 25px; } #kwmsvordpx .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #kwmsvordpx div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } Characteristic Drug A N = 981 Drug B N = 1021 Age 46 (37, 60) 48 (39, 56)     Missing 7 4 Marker Level (ng/mL) 0.84 (0.23, 1.60) 0.52 (0.18, 1.21)     Missing 6 4 T Stage     T1 28 (29%) 25 (25%)     T2 25 (26%) 29 (28%)     T3 22 (22%) 21 (21%)     T4 23 (23%) 27 (26%) Grade     I 35 (36%) 33 (32%)     II 32 (33%) 36 (35%)     III 31 (32%) 33 (32%) 1 Median (Q1, Q3); n (%) 20.6 Making Modifications to the trial table Let’s do some basics, like adding a column for N, adding the overall column, and bolding the labels. Show code Solution trial |&gt; select(age, marker, stage, grade, trt) |&gt; tbl_summary(by = trt, missing_text = &quot;Missing&quot;) |&gt; add_n() |&gt; add_overall() |&gt; bold_labels() #vnnebskezu table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #vnnebskezu thead, #vnnebskezu tbody, #vnnebskezu tfoot, #vnnebskezu tr, #vnnebskezu td, #vnnebskezu th { border-style: none; } #vnnebskezu p { margin: 0; padding: 0; } #vnnebskezu .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #vnnebskezu .gt_caption { padding-top: 4px; padding-bottom: 4px; } #vnnebskezu .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #vnnebskezu .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #vnnebskezu .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #vnnebskezu .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #vnnebskezu .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #vnnebskezu .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #vnnebskezu .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #vnnebskezu .gt_column_spanner_outer:first-child { padding-left: 0; } #vnnebskezu .gt_column_spanner_outer:last-child { padding-right: 0; } #vnnebskezu .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #vnnebskezu .gt_spanner_row { border-bottom-style: hidden; } #vnnebskezu .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #vnnebskezu .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #vnnebskezu .gt_from_md > :first-child { margin-top: 0; } #vnnebskezu .gt_from_md > :last-child { margin-bottom: 0; } #vnnebskezu .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #vnnebskezu .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #vnnebskezu .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #vnnebskezu .gt_row_group_first td { border-top-width: 2px; } #vnnebskezu .gt_row_group_first th { border-top-width: 2px; } #vnnebskezu .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #vnnebskezu .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #vnnebskezu .gt_first_summary_row.thick { border-top-width: 2px; } #vnnebskezu .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #vnnebskezu .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #vnnebskezu .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #vnnebskezu .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #vnnebskezu .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #vnnebskezu .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #vnnebskezu .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #vnnebskezu .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #vnnebskezu .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #vnnebskezu .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #vnnebskezu .gt_left { text-align: left; } #vnnebskezu .gt_center { text-align: center; } #vnnebskezu .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #vnnebskezu .gt_font_normal { font-weight: normal; } #vnnebskezu .gt_font_bold { font-weight: bold; } #vnnebskezu .gt_font_italic { font-style: italic; } #vnnebskezu .gt_super { font-size: 65%; } #vnnebskezu .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #vnnebskezu .gt_asterisk { font-size: 100%; vertical-align: 0; } #vnnebskezu .gt_indent_1 { text-indent: 5px; } #vnnebskezu .gt_indent_2 { text-indent: 10px; } #vnnebskezu .gt_indent_3 { text-indent: 15px; } #vnnebskezu .gt_indent_4 { text-indent: 20px; } #vnnebskezu .gt_indent_5 { text-indent: 25px; } #vnnebskezu .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #vnnebskezu div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } Characteristic N Overall N = 2001 Drug A N = 981 Drug B N = 1021 Age 189 47 (38, 57) 46 (37, 60) 48 (39, 56)     Missing 11 7 4 Marker Level (ng/mL) 190 0.64 (0.22, 1.41) 0.84 (0.23, 1.60) 0.52 (0.18, 1.21)     Missing 10 6 4 T Stage 200     T1 53 (27%) 28 (29%) 25 (25%)     T2 54 (27%) 25 (26%) 29 (28%)     T3 43 (22%) 22 (22%) 21 (21%)     T4 50 (25%) 23 (23%) 27 (26%) Grade 200     I 68 (34%) 35 (36%) 33 (32%)     II 68 (34%) 32 (33%) 36 (35%)     III 64 (32%) 31 (32%) 33 (32%) 1 Median (Q1, Q3); n (%) 20.7 More Modifications to the trial table Let’s change the Headers to make them have line breaks (and no commas), change the label Characteristic to ’Participant Characteristic, and add a column spanner for the treatment arms. Use flanking double asterisks**` to bold the headers as needed. Show code Solution trial |&gt; select(age, marker, stage, grade, trt) |&gt; tbl_summary(by = trt, missing_text = &quot;Missing&quot;) |&gt; add_n() |&gt; add_overall() |&gt; bold_labels() |&gt; modify_header(update = list( label ~ &quot;**Participant&lt;br&gt;Characteristic**&quot;, stat_0 ~ &quot;**Overall**&lt;br&gt;N = 200&quot;, stat_1 ~ &quot;**Drug A**&lt;br&gt;N = 98&quot;, stat_2 ~ &quot;**Drug B**&lt;br&gt;N = 102&quot; )) |&gt; modify_spanning_header(c(&quot;stat_1&quot;, &quot;stat_2&quot;) ~ &quot;**Treatment Arm**&quot;) #laiotgbhpg table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #laiotgbhpg thead, #laiotgbhpg tbody, #laiotgbhpg tfoot, #laiotgbhpg tr, #laiotgbhpg td, #laiotgbhpg th { border-style: none; } #laiotgbhpg p { margin: 0; padding: 0; } #laiotgbhpg .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #laiotgbhpg .gt_caption { padding-top: 4px; padding-bottom: 4px; } #laiotgbhpg .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #laiotgbhpg .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #laiotgbhpg .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #laiotgbhpg .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #laiotgbhpg .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #laiotgbhpg .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #laiotgbhpg .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #laiotgbhpg .gt_column_spanner_outer:first-child { padding-left: 0; } #laiotgbhpg .gt_column_spanner_outer:last-child { padding-right: 0; } #laiotgbhpg .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #laiotgbhpg .gt_spanner_row { border-bottom-style: hidden; } #laiotgbhpg .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #laiotgbhpg .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #laiotgbhpg .gt_from_md > :first-child { margin-top: 0; } #laiotgbhpg .gt_from_md > :last-child { margin-bottom: 0; } #laiotgbhpg .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #laiotgbhpg .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #laiotgbhpg .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #laiotgbhpg .gt_row_group_first td { border-top-width: 2px; } #laiotgbhpg .gt_row_group_first th { border-top-width: 2px; } #laiotgbhpg .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #laiotgbhpg .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #laiotgbhpg .gt_first_summary_row.thick { border-top-width: 2px; } #laiotgbhpg .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #laiotgbhpg .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #laiotgbhpg .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #laiotgbhpg .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #laiotgbhpg .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #laiotgbhpg .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #laiotgbhpg .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #laiotgbhpg .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #laiotgbhpg .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #laiotgbhpg .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #laiotgbhpg .gt_left { text-align: left; } #laiotgbhpg .gt_center { text-align: center; } #laiotgbhpg .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #laiotgbhpg .gt_font_normal { font-weight: normal; } #laiotgbhpg .gt_font_bold { font-weight: bold; } #laiotgbhpg .gt_font_italic { font-style: italic; } #laiotgbhpg .gt_super { font-size: 65%; } #laiotgbhpg .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #laiotgbhpg .gt_asterisk { font-size: 100%; vertical-align: 0; } #laiotgbhpg .gt_indent_1 { text-indent: 5px; } #laiotgbhpg .gt_indent_2 { text-indent: 10px; } #laiotgbhpg .gt_indent_3 { text-indent: 15px; } #laiotgbhpg .gt_indent_4 { text-indent: 20px; } #laiotgbhpg .gt_indent_5 { text-indent: 25px; } #laiotgbhpg .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #laiotgbhpg div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } ParticipantCharacteristic N OverallN = 2001 Treatment Arm Drug AN = 981 Drug BN = 1021 Age 189 47 (38, 57) 46 (37, 60) 48 (39, 56)     Missing 11 7 4 Marker Level (ng/mL) 190 0.64 (0.22, 1.41) 0.84 (0.23, 1.60) 0.52 (0.18, 1.21)     Missing 10 6 4 T Stage 200     T1 53 (27%) 28 (29%) 25 (25%)     T2 54 (27%) 25 (26%) 29 (28%)     T3 43 (22%) 22 (22%) 21 (21%)     T4 50 (25%) 23 (23%) 27 (26%) Grade 200     I 68 (34%) 35 (36%) 33 (32%)     II 68 (34%) 32 (33%) 36 (35%)     III 64 (32%) 31 (32%) 33 (32%) 1 Median (Q1, Q3); n (%) 20.8 Taking Control of the Stats You can take control of what statistics are shown. Let’s see an example where you require mean and SD for all continuous variables in the table, set digits to 2, and show fractions and percentages for all categorical values. These changes are made within the tbl_summary() function. Note how the footnote changes to keep up. trial |&gt; select(age, marker, stage, grade, trt) |&gt; tbl_summary(by = trt, missing_text = &quot;Missing&quot;, statistic = list( all_continuous() ~ &quot;{mean} ({sd})&quot;, all_categorical() ~ &quot;{n} / {N} ({p}%)&quot; ), digits = all_continuous() ~ 2, label = grade ~ &quot;Tumor Grade&quot;,) |&gt; add_n() |&gt; add_overall() |&gt; bold_labels() |&gt; modify_header(update = list( label ~ &quot;**Participant&lt;br&gt;Characteristic**&quot;, stat_0 ~ &quot;**Overall**&lt;br&gt;N = 200&quot;, stat_1 ~ &quot;**Drug A**&lt;br&gt;N = 98&quot;, stat_2 ~ &quot;**Drug B**&lt;br&gt;N = 102&quot; )) |&gt; modify_spanning_header(c(&quot;stat_1&quot;, &quot;stat_2&quot;) ~ &quot;**Treatment Arm**&quot;) #kixiwcyycr table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #kixiwcyycr thead, #kixiwcyycr tbody, #kixiwcyycr tfoot, #kixiwcyycr tr, #kixiwcyycr td, #kixiwcyycr th { border-style: none; } #kixiwcyycr p { margin: 0; padding: 0; } #kixiwcyycr .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #kixiwcyycr .gt_caption { padding-top: 4px; padding-bottom: 4px; } #kixiwcyycr .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #kixiwcyycr .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #kixiwcyycr .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #kixiwcyycr .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #kixiwcyycr .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #kixiwcyycr .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #kixiwcyycr .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #kixiwcyycr .gt_column_spanner_outer:first-child { padding-left: 0; } #kixiwcyycr .gt_column_spanner_outer:last-child { padding-right: 0; } #kixiwcyycr .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #kixiwcyycr .gt_spanner_row { border-bottom-style: hidden; } #kixiwcyycr .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #kixiwcyycr .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #kixiwcyycr .gt_from_md > :first-child { margin-top: 0; } #kixiwcyycr .gt_from_md > :last-child { margin-bottom: 0; } #kixiwcyycr .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #kixiwcyycr .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #kixiwcyycr .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #kixiwcyycr .gt_row_group_first td { border-top-width: 2px; } #kixiwcyycr .gt_row_group_first th { border-top-width: 2px; } #kixiwcyycr .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #kixiwcyycr .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #kixiwcyycr .gt_first_summary_row.thick { border-top-width: 2px; } #kixiwcyycr .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #kixiwcyycr .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #kixiwcyycr .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #kixiwcyycr .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #kixiwcyycr .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #kixiwcyycr .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #kixiwcyycr .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #kixiwcyycr .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #kixiwcyycr .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #kixiwcyycr .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #kixiwcyycr .gt_left { text-align: left; } #kixiwcyycr .gt_center { text-align: center; } #kixiwcyycr .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #kixiwcyycr .gt_font_normal { font-weight: normal; } #kixiwcyycr .gt_font_bold { font-weight: bold; } #kixiwcyycr .gt_font_italic { font-style: italic; } #kixiwcyycr .gt_super { font-size: 65%; } #kixiwcyycr .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #kixiwcyycr .gt_asterisk { font-size: 100%; vertical-align: 0; } #kixiwcyycr .gt_indent_1 { text-indent: 5px; } #kixiwcyycr .gt_indent_2 { text-indent: 10px; } #kixiwcyycr .gt_indent_3 { text-indent: 15px; } #kixiwcyycr .gt_indent_4 { text-indent: 20px; } #kixiwcyycr .gt_indent_5 { text-indent: 25px; } #kixiwcyycr .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #kixiwcyycr div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } ParticipantCharacteristic N OverallN = 2001 Treatment Arm Drug AN = 981 Drug BN = 1021 Age 189 47.24 (14.31) 47.01 (14.71) 47.45 (14.01)     Missing 11 7 4 Marker Level (ng/mL) 190 0.92 (0.86) 1.02 (0.89) 0.82 (0.83)     Missing 10 6 4 T Stage 200     T1 53 / 200 (27%) 28 / 98 (29%) 25 / 102 (25%)     T2 54 / 200 (27%) 25 / 98 (26%) 29 / 102 (28%)     T3 43 / 200 (22%) 22 / 98 (22%) 21 / 102 (21%)     T4 50 / 200 (25%) 23 / 98 (23%) 27 / 102 (26%) Tumor Grade 200     I 68 / 200 (34%) 35 / 98 (36%) 33 / 102 (32%)     II 68 / 200 (34%) 32 / 98 (33%) 36 / 102 (35%)     III 64 / 200 (32%) 31 / 98 (32%) 33 / 102 (32%) 1 Mean (SD); n / N (%) 20.8.1 Your Turn The original streptomycin for tuberculosis trial never had a Table 1, because it was published in 1955, when these did not exist. Let’s make one now. Gender and the baseline_x variables in the strep_tb dataset will be the baseline variables. The arm variable will be the treatment variable. Use the strep_tb dataset from the {medicaldata} package to create a Table 1. You will need to run data(strep_tb) to load the dataset. Then pipe the strep_tb dataset into a select function, then into the tbl_summary() function. Improve the table from the baseline generic version. Add details and styling that you think would be helpful to the reader, and make it publication-ready. Consider cleaning up some of the value labels with mutate statements. Show code Solution strep_tb |&gt; select(gender, starts_with(&quot;baseline&quot;), arm) |&gt; tbl_summary(by = arm, missing_text = &quot;Missing&quot;, label = list( gender ~ &quot;Gender&quot;, baseline_condition ~ &quot;Baseline Condition&quot;, baseline_temp ~ &quot;Baseline Temperature&quot;, baseline_esr ~ &quot;Baseline ESR&quot;, baseline_cavitation ~ &quot;Baseline Cavitation&quot; )) |&gt; add_n() |&gt; add_overall() |&gt; bold_labels() |&gt; modify_header(update = list( label ~ &quot;**Participant&lt;br&gt;Characteristic**&quot;, stat_0 ~ &quot;**Overall**&lt;br&gt;N = 107&quot;, stat_1 ~ &quot;**Control**&lt;br&gt;N = 52&quot;, stat_2 ~ &quot;**Streptomycin**&lt;br&gt;N = 55&quot; )) |&gt; modify_spanning_header(c(&quot;stat_1&quot;, &quot;stat_2&quot;) ~ &quot;**Treatment Arm**&quot;) #lxbrasflla table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #lxbrasflla thead, #lxbrasflla tbody, #lxbrasflla tfoot, #lxbrasflla tr, #lxbrasflla td, #lxbrasflla th { border-style: none; } #lxbrasflla p { margin: 0; padding: 0; } #lxbrasflla .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #lxbrasflla .gt_caption { padding-top: 4px; padding-bottom: 4px; } #lxbrasflla .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #lxbrasflla .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #lxbrasflla .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #lxbrasflla .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #lxbrasflla .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #lxbrasflla .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #lxbrasflla .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #lxbrasflla .gt_column_spanner_outer:first-child { padding-left: 0; } #lxbrasflla .gt_column_spanner_outer:last-child { padding-right: 0; } #lxbrasflla .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #lxbrasflla .gt_spanner_row { border-bottom-style: hidden; } #lxbrasflla .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #lxbrasflla .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #lxbrasflla .gt_from_md > :first-child { margin-top: 0; } #lxbrasflla .gt_from_md > :last-child { margin-bottom: 0; } #lxbrasflla .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #lxbrasflla .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #lxbrasflla .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #lxbrasflla .gt_row_group_first td { border-top-width: 2px; } #lxbrasflla .gt_row_group_first th { border-top-width: 2px; } #lxbrasflla .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #lxbrasflla .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #lxbrasflla .gt_first_summary_row.thick { border-top-width: 2px; } #lxbrasflla .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #lxbrasflla .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #lxbrasflla .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #lxbrasflla .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #lxbrasflla .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #lxbrasflla .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #lxbrasflla .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #lxbrasflla .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #lxbrasflla .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #lxbrasflla .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #lxbrasflla .gt_left { text-align: left; } #lxbrasflla .gt_center { text-align: center; } #lxbrasflla .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #lxbrasflla .gt_font_normal { font-weight: normal; } #lxbrasflla .gt_font_bold { font-weight: bold; } #lxbrasflla .gt_font_italic { font-style: italic; } #lxbrasflla .gt_super { font-size: 65%; } #lxbrasflla .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #lxbrasflla .gt_asterisk { font-size: 100%; vertical-align: 0; } #lxbrasflla .gt_indent_1 { text-indent: 5px; } #lxbrasflla .gt_indent_2 { text-indent: 10px; } #lxbrasflla .gt_indent_3 { text-indent: 15px; } #lxbrasflla .gt_indent_4 { text-indent: 20px; } #lxbrasflla .gt_indent_5 { text-indent: 25px; } #lxbrasflla .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #lxbrasflla div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } ParticipantCharacteristic N OverallN = 1071 Treatment Arm ControlN = 521 StreptomycinN = 551 Gender 107     F 59 (55%) 28 (54%) 31 (56%)     M 48 (45%) 24 (46%) 24 (44%) Baseline Condition 107     1_Good 16 (15%) 8 (15%) 8 (15%)     2_Fair 37 (35%) 20 (38%) 17 (31%)     3_Poor 54 (50%) 24 (46%) 30 (55%) Baseline Temperature 107     1_&lt;=98.9F/37.2C 7 (6.5%) 4 (7.7%) 3 (5.5%)     2_99-99.9F/37.3-37.7C 24 (22%) 12 (23%) 12 (22%)     2_99-99.9F/37.3-37.7C/37.3-37.7C 1 (0.9%) 0 (0%) 1 (1.8%)     3_100-100.9F/37.8-38.2C 31 (29%) 17 (33%) 14 (25%)     3_100-100.9F/37.8-38.2C/37.8-38.2C 1 (0.9%) 0 (0%) 1 (1.8%)     4_&gt;=101F/38.3C 43 (40%) 19 (37%) 24 (44%) Baseline ESR 106     2_11-20 5 (4.7%) 2 (3.9%) 3 (5.5%)     3_21-50 36 (34%) 20 (39%) 16 (29%)     4_51+ 65 (61%) 29 (57%) 36 (65%)     Missing 1 1 0 Baseline Cavitation 107 62 (58%) 30 (58%) 32 (58%) 1 n (%) "],["comparing-two-measures-of-centrality.html", "Chapter 21 Comparing Two Measures of Centrality", " Chapter 21 Comparing Two Measures of Centrality A common question in medical research is whether one group had a better outcome than another group. These outcomes can be measured with dichotomous outcomes like death or hospitalization, but continuous outcomes like systolic blood pressure, endoscopic score, or ejection fraction are more commonly available, and provide more statistical power, and usually require a smaller sample size. There is a tendency in clinical research to focus on dichotomous outcomes, even to the point of converting continuous measures to dichotomous ones (aka “dichotomania”, see Frank Harrell comments here), for fear of detecting and acting upon a small change in a continuous outcome that is not clinically meaningful. While this can be a concern, especially in very large, over-powered studies, it can be addressed by aiming for a continuous difference that is at least as large as one that many clinicians agree (a priori) is clinically important (the MCID, or Minimum Clinically Important Difference). The most common comparison of two groups with a continuous outcome is to look at the means or medians, and determine whether the available evidence suggests that these are equal (the null hypothesis). This can be done for means with Student’s t-test. Let’s start by looking at the cytomegalovirus data set. This includes data on 64 patients who received bone marrow stem cell transplant, and looks at their time to activation of CMV (cytomegalovirus). In the code chunk below, we group the data by donor cmv status (donor.cmv), and look at the mean time to CMV activation (time.to.cmv variable). Run the code (using the green arrow at the top right of the code chunk below) to see the difference in time to CMV activation in months between groups. Try out some other grouping variables in the group_by statement, in place of donor.cmv. Consider variables like race, sex, and recipient.cmv. Edit the code and run it again with the green arrow at the top right. # insert libraries in each chunk as if independent library(tidyverse) library(medicaldata) cytomegalovirus %&gt;% group_by(sex) %&gt;% summarize(mean_time2cmv = mean(time.to.cmv)) -&gt; summ summ ## # A tibble: 2 × 2 ## sex mean_time2cmv ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0 13.7 ## 2 1 12.7 That seems like a big difference for donor.cmv, between 13.7303333 months and 12.7441176 months. And it makes theoretical sense that having a CMV positive donor is more likely to be associated with early activation of CMV in the recipient. But is it a significant difference, one that would be very unlikely to happen by chance? That depends on things like the number of people in each group, and the standard deviation in each group. That is the kind of question you can answer with a t-test, or for particularly skewed data like hospital length of stay or medical charges, a Wilcoxon test. 21.0.1 Applying the t test The t-test is a simple test that compares the means of two groups, and tells you how likely it is that the difference you see is due to random chance. The t-test assumes that the data is normally distributed, and that the variances are equal. If the data is not normally distributed, or the variances are not equal, you can use a non-parametric test like the Wilcoxon test. cytomegalovirus |&gt; rstatix::t_test(time.to.cmv ~ cgvhd, detailed = TRUE) ## # A tibble: 1 × 15 ## estimate estimate1 estimate2 .y. group1 group2 n1 n2 statistic p ## * &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -13.8 7.18 21.0 time… 0 1 36 28 -2.99 0.00493 ## # ℹ 5 more variables: df &lt;dbl&gt;, conf.low &lt;dbl&gt;, conf.high &lt;dbl&gt;, method &lt;chr&gt;, ## # alternative &lt;chr&gt; "],["simple-example-of-a-t-test.html", "Chapter 22 Simple example of a t-test 22.1 Common Problem 22.2 One Sample T test 22.3 Insert flipbook for ttest here 22.4 Fine, but what about 2 groups? 22.5 3 Assumptions of Student’s t test 22.6 Getting results out of t.test 22.7 Reporting the results from t.test using inline code", " Chapter 22 Simple example of a t-test mtcars %&gt;% filter(cyl ==4 | cyl ==6) %&gt;% mutate(cyl_f = as.factor(cyl)) %&gt;% t.test(mpg ~ cyl_f, data = .) Welch Two Sample t-test data: mpg by cyl_f t = 4.7191, df = 12.956, p-value = 0.0004048 alternative hypothesis: true difference in means between group 4 and group 6 is not equal to 0 95 percent confidence interval: 3.751376 10.090182 sample estimates: mean in group 4 mean in group 6 26.66364 19.74286 22.1 Common Problem Comparing two groups Mean or median vs. expected Two arms of study - independent Pre and post / spouse and partner / left vs right arm – paired groups Are the means significantly different? Or the medians (if not normally distributed)? 22.1.1 How Skewed is Too Skewed? Formal test of normality = Shapiro-Wilk test Use base data set called ToothGrowth library(tidyverse) library(medicaldata) data &lt;- cytomegalovirus head(data) ## ID age sex race diagnosis diagnosis.type ## 1 1 61 1 0 acute myeloid leukemia 1 ## 2 2 62 1 1 non-Hodgkin lymphoma 0 ## 3 3 63 0 1 non-Hodgkin lymphoma 0 ## 4 4 33 0 1 Hodgkin lymphoma 0 ## 5 5 54 0 1 acute lymphoblastic leukemia 0 ## 6 6 55 1 1 myelofibrosis 1 ## time.to.transplant prior.radiation prior.chemo prior.transplant recipient.cmv ## 1 5.16 0 2 0 1 ## 2 79.05 1 3 0 0 ## 3 35.58 0 4 0 1 ## 4 33.02 1 4 0 1 ## 5 11.40 0 5 0 1 ## 6 2.43 0 0 0 1 ## donor.cmv donor.sex TNC.dose CD34.dose CD3.dose CD8.dose TBI.dose C1/C2 aKIRs ## 1 0 0 18.31 2.29 3.21 0.95 200 0 1 ## 2 0 1 4.26 2.04 NA NA 200 1 5 ## 3 1 0 8.09 6.97 2.19 0.59 200 0 3 ## 4 0 1 21.02 6.09 4.87 2.32 200 0 2 ## 5 1 0 14.70 2.36 6.55 2.40 400 0 6 ## 6 1 1 4.29 6.91 2.53 0.86 200 0 2 ## cmv time.to.cmv agvhd time.to.agvhd cgvhd time.to.cgvhd ## 1 1 3.91 1 3.55 0 6.28 ## 2 0 65.12 0 65.12 0 65.12 ## 3 0 3.75 0 3.75 0 3.75 ## 4 0 48.49 1 28.55 1 10.45 ## 5 0 4.37 1 2.79 0 4.37 ## 6 1 4.53 1 3.88 0 6.87 22.1.2 Visualize the Distribution of data variables in ggplot Use geom_histogram or geom_density (pick one or the other) look at the distribution of CD3.dose or time.to.cmv Bonus points: facet by sex or race or donor.cmv Your turn to try it library(tidyverse) library(medicaldata) data %&gt;% ggplot(mapping = aes(time.to.cmv)) + geom_density() + facet_wrap(~sex) + theme_linedraw() library(tidyverse) library(medicaldata) data %&gt;% ggplot(mapping = aes(time.to.cmv)) + geom_histogram() + facet_wrap(~race) 22.1.3 Visualize the Distribution of data$len in ggplot The OJ group is left skewed May be problematic for using means formally test with Shapiro-Wilk library(tidyverse) library(medicaldata) data$time.to.cmv %&gt;% shapiro.test() ## ## Shapiro-Wilk normality test ## ## data: . ## W = 0.68261, p-value = 1.762e-10 22.1.4 Results of Shapiro-Wilk p-value = 0.1091 p not &lt; 0.05 Acceptably close to normal OK to compare means rather than medians can use t test rather than wilcoxon test if p is &lt; 0.05, use wilcoxon test also known as Mann-Whitney test a rank-based (non-parametric) test 22.1.5 Try it yourself use df &lt;- msleep library(tidyverse) library(medicaldata) df &lt;- msleep head(df$sleep_total) ## [1] 12.1 17.0 14.4 14.9 4.0 14.4 test the normality of total sleep hours in mammals 22.1.6 Mammal sleep hours library(tidyverse) library(medicaldata) shapiro.test(df$sleep_total) ## ## Shapiro-Wilk normality test ## ## data: df$sleep_total ## W = 0.97973, p-value = 0.2143 meets criteria - acceptable to consider normally distributed now consider - is the mean roughly 8 hours of sleep per day? 22.2 One Sample T test univariate test Ho: mean is 8 hours Ha: mean is not 8 hours can use t test because shapiro.test is NS 22.2.1 How to do One Sample T test library(tidyverse) library(medicaldata) t.test(df$sleep_total, alternative = &quot;two.sided&quot;, mu = 8) Try it out, see if you can interpret results 22.2.2 Interpreting the One Sample T test ## ## One Sample t-test ## ## data: df$sleep_total ## t = 4.9822, df = 82, p-value = 3.437e-06 ## alternative hypothesis: true mean is not equal to 8 ## 95 percent confidence interval: ## 9.461972 11.405497 ## sample estimates: ## mean of x ## 10.43373 p is highly significant can reject the null, accept alternative sample mean 10.43, CI 9.46-11.41 22.2.3 What are the arguments of the t.test function? x = vector of continuous numerical data y= NULL - optional 2nd vector of continuous numerical data alternative = c(“two.sided”, “less”, “greater”), mu = 0 paired = FALSE var.equal = FALSE conf.level = 0.95 documentation 22.3 Insert flipbook for ttest here Below is a flipbook. It illustrates a bit of how to do a t-test. click on it and you can use the arrow keys to proceed forward and back through the slides, as you add lines of code and more results occur. Let’s start with a flipbook slide show. When the title slide appears, you can step through each line of the code to see what it does. The right/left and/or up/down arrows will let you move forward and backward in the code. You can use the arrow keys to go through it one step at a time (forward or backward, depending on which arrow key you use), to see what each line of code actually does. Give it a try below. See if you can figure out what each line of code is doing. 22.3.1 Flipbook Time! This is t-testing in action. 22.4 Fine, but what about 2 groups? consider df$vore library(tidyverse) library(medicaldata) prostate &lt;- medicaldata::blood_storage tabyl(prostate$AA) ## prostate$AA n percent ## 0 261 0.8259494 ## 1 55 0.1740506 hypothesis - herbivores need more time to get food, sleep less than carnivores how to test this? normal, so can use t test for 2 groups 22.4.1 Setting up 2 group t test formula interface: outcome ~ groupvar library(tidyverse) library(medicaldata) df %&gt;% filter(vore %in% c(&quot;herbi&quot;, &quot;carni&quot;)) %&gt;% t.test(formula = sleep_total ~ vore, data = .) Try it yourself What do the results mean? 22.4.2 Results of the 2 group t test ## ## Welch Two Sample t-test ## ## data: sleep_total by vore ## t = 0.63232, df = 39.31, p-value = 0.5308 ## alternative hypothesis: true difference in means between group carni and group herbi is not equal to 0 ## 95 percent confidence interval: ## -1.911365 3.650509 ## sample estimates: ## mean in group carni mean in group herbi ## 10.378947 9.509375 22.4.3 Interpreting the 2 group t test Welch t-test (not Student) Welch does NOT assume equal variances in each group p value NS accept null hypothesis Ho: means of groups roughly equal Ha: means are different 95% CI crosses 0 Carnivores sleep a little more, but not a lot 22.4.4 2 group t test with wide data You want to compare column A with column B (data are not tidy) Do mammals spend more time awake than asleep? library(tidyverse) library(medicaldata) t.test(x = df$sleep_total, y = df$awake, data = msleep) 22.4.5 Results of 2 group t test with wide data library(tidyverse) library(medicaldata) t.test(x = df$sleep_total, y = df$awake, data = msleep) ## ## Welch Two Sample t-test ## ## data: df$sleep_total and df$awake ## t = -4.5353, df = 164, p-value = 1.106e-05 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -4.498066 -1.769404 ## sample estimates: ## mean of x mean of y ## 10.43373 13.56747 22.5 3 Assumptions of Student’s t test Sample is normally distributed (test with Shapiro) Variances are homogeneous (homoskedasticity) (test with Levene) Observations are independent not paired like left vs. right colon not paired like spouse and partner not paired like measurements pre and post Rx 22.5.1 Testing Assumptions of Student’s t test Normality - test with Shapiro If not normal, Wilcoxon &gt; t test Equal Variances - test with Levene If not equal, Welch t &gt; Student’s t Observations are independent Think about data collection are some observations correlated with some others? If correlated, use paired t test 22.6 Getting results out of t.test Use the tidy function from the broom package Do carnivores have bigger brains than insectivores? library(tidyverse) library(medicaldata) library(broom) df %&gt;% filter(vore %in% c(&quot;carni&quot;, &quot;insecti&quot;)) %&gt;% t.test(formula = brainwt ~ vore, data = .) %&gt;% tidy() -&gt; result result 22.6.1 Getting results out of t.test ## # A tibble: 1 × 10 ## estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.0577 0.0793 0.0216 1.20 0.253 12 -0.0471 0.163 ## # ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt; 22.7 Reporting the results from t.test using inline code use backticks before and after, start with r i.e. My result is [backtick]r code here[backtick]. The mean brain weight for carnivores was 0.0792556 The mean brain weight for herbivores was 0.02155 The difference was 0.0577056 The t statistic for this Two Sample t-test was 1.1995501 The p value was 0.2534631 The confidence interval was from -0.05 to 0.16 22.7.1 For Next Time Skewness and Kurtosis Review Normality When to use Wilcoxon Levene test for equal variances When to use Welch t vs. Student’s t Paired t and Wilcoxon tests "],["sample-size-calculations-with-pwr.html", "Chapter 23 Sample Size Calculations with {pwr} 23.1 Sample Size for a Continuous Endpoint (t-test) 23.2 One Sample t-test for Lowering Creatinine 23.3 Paired t-tests (before vs after, or truly paired) 23.4 2 Sample t tests with Unequal Study Arm Sizes 23.5 Testing Multiple Options and Plotting Results 23.6 Your Turn 23.7 Sample Sizes for Proportions 23.8 Sample size for two proportions, equal n 23.9 Sample size for two proportions, unequal arms 23.10 Your Turn 23.11 add chi square 23.12 add correlation test 23.13 add anova 23.14 add linear model 23.15 add note on guessing effect sizes - cohen small, medium, large 23.16 Explore More", " Chapter 23 Sample Size Calculations with {pwr} When designing clinical studies, it is often important to calculate a reasonable estimate of the needed sample size. This is critical for planning, as you may find out very quickly that a reasonable study budget and timeline will be futile. Grant funding agencies will be very interested in whether you have a good rationale for your proposed sample size and timeline, so that they can avoid wasting their money. Fortunately, the {pwr} package helps with many of the needed calculations. Let’s first install this package from CRAN, and load it with a library() function. Remember that you can copy each code chunk to the clipboard, then paste it into your RStudio console (or a script) to edit and run it. Just hover your mouse pointer over the top right corner of each code chunk until a copy icon appears, then click on it to copy the code. install.packages(&#39;pwr&#39;) library(pwr) The {pwr} package has a number of functions for calculating sample size and power. Functions in the {pwr} package Test Sample Size Function one-sample, two-sample, and paired t-tests pwr.t.test() two-sample t-tests (unequal sample sizes) pwr.t2n.test() two-sample proportion test (unequal sample sizes) pwr.2p2n.test() one-sample proportion test pwr.p.test() two-sample proportion test pwr.2p.test() two-sample proportion test (unequal sample sizes) pwr.2p2n.test() one-way balanced ANOVA pwr.anova.test() correlation test pwr.r.test() chi-squared test (goodness of fit and association) pwr.chisq.test() test for the general linear model pwr.f2.test() Now that you have {pwr} up and running, we can start with a simple example. 23.1 Sample Size for a Continuous Endpoint (t-test) Let’s propose a study of a new drug to reduce hemoglobin A1c in type 2 diabetes over a 1 year study period. You estimate that your recruited participants will have a mean baseline A1c of 9.0, which will be unchanged by your placebo, but reduced (on average) to 7.0 by the study drug. You need to calculate an effect size (aka Cohen’s d) in order to estimate your sample size. This effect size is equal to the difference between the means at the endpoint, divided by the pooled standard deviation. Many clinicians can estimate the means and the difference, but the pooled standard deviation is not very intutitive. Sometimes you have an estimate from pilot data (though these tend to have wide confidence intervals, as pilot studies are small). In other circumstances, you can estimate a standard deviation for Hgb A1c from values from a large data warehouse. When you don’t have either of these, it can be helpful to start by estimating the range of values. This is something that is intutitive, and experienced clinicians can do fairly easily. Just get a few clinicians in a room, and ask them for the highest and lowest values of HgbA1c that they have ever seen. You will quickly find a minimum and maximum that you can estimate as the range (in this case, let’s say 5.0 and 17.0 for min and max of Hgb A1c). This range divided by 4 is a reasonable rough estimate of the standard deviation. Remember that a normally distributed continuous value will have a 95% confidence interval that is plus or minus 1.96 standard deviations from the sample mean. Round this up to 2 for the full range, and you can see why we divide the range by 4 to get an estimate of the standard deviation. In our case, the difference is 2 and the range/4 (estimate of SD) is 3. So our effect size (Cohen’s d) is 0.66. Plug in 0.66 for d in the code chunk below, and run this code chunk to get an estimate of the n in each arm of a 2 armed study with a two sample t-test of the primary endpoint. pwr::pwr.t.test(n = NULL, sig.level = 0.05, type = &quot;two.sample&quot;, alternative = &quot;two.sided&quot;, power = 0.80, d = __) We come up with 37.02 participants in each group to provide 80% power to detect a difference of 2 in HgbA1c, assuming a standard deviation of 3, using a two-sided alpha of 0.05. To conduct this study, assuming a 20% dropout rate in each arm, would require 37+8 subjects per arm, or 90 overall. At an enrollment rate of 10 per month, it will require 9 months to enroll all the participants, and 21 months (9 + 12 month intervention) to complete the data collection. It is a very common mistake to look at the result for n, and assume that this is your total sample size needed. The n provided by {pwr} is the number per arm. You need to multiply this n by the number of arms (or in a paired analysis, by the number of pairs) to get your total n. Another common mistake is to assume no dropout of participants. It is important to have a reasonable estimate (10-20% for short studies, 30-50% for long or demanding studies) and inflate your intended sample size by this amount. It is even better if you know from similar studies what the actual dropout rate was, and use this as an estimate (if there are similar previous studies). As a general rule, it is better to be conservative, and estimate a larger sample size, than to end up with p = 0.07. Once you define your test type (the options are “two.sample”, “one.sample”, and “paired”), and the alternative (“two.sided”, “greater”, or “less”), four variables remain in a sample size and power calculation. These are the remaining four arguments of the pwr.t.test() function. These are: n the significance level (sig.level) the power the effect size (Cohen’s d) If you know any three of these, you can calculate the fourth. In order to do this, you set the one of these four arguments that you want to calculate equal to NULL, and specify the other 3. Imagine that we only have enough funds to run this study on 50 participants. What would our power be to detect a difference of 2 in Hgb A1c? You can set the power to NULL, and the n to 25 (remember that n is per arm), and run the chunk below. pwr::pwr.t.test(n = __, # note that n is per arm sig.level = 0.05, type = &quot;two.sample&quot;, alternative = &quot;two.sided&quot;, power = __, d = 0.66) We end up with 62.8% power, assuming no participant dropout (which is an extremely unlikely assumption). You can do the same thing, changing the NULL, to calculate an effect size or a significance level, if you have any need to. In most cases, you are calculating a sample size, then realizing that you might not have that much money/resources. Then many calculate the power you would obtain given the resources you actually have. Let’s show a few more examples. 23.2 One Sample t-test for Lowering Creatinine Eddie Enema, holistic healer, has proposed an unblinded pilot study of thrice-daily 2 liter enemas with “Eddie’s Dialysis Cleanser,” a proprietary mix of vitamins and minerals, which he believes will lower the serum creatinine of patients on the kidney transplant waiting list by more than 1.0 g/dL in 24 hours. The creatinine SD in this group of patients is 2. The null hypothesis is &lt; 1.0 g/dL. The alternative hypothesis is &gt;= 1.0 g/dL. Cohen’s d is 1.0 (the proposed change, or delta)/2 (the SD) = 0.5. How many participants would Eddie Enema have to recruit to have 80% power to test this one-sample, one-sided hypothesis, with an alpha of 0.05? Check each of the argument values and run the chunk below to find out. pwr::pwr.t.test(n = NULL, # note that n is per arm sig.level = 0.05, type = &quot;one.sample&quot;, alternative = &quot;greater&quot;, power = 0.8, d = 0.5) Fast Eddie would need to recruit slightly more than 26 participants (you always have to round up to get whole human participants) to have 80% power, assuming no dropout between the first and third enema, or before the blood draw 24 hours after baseline. Note that since this is an unblinded, one-sample study, The n in the results is multiplied by the number of arms (there is only 1 arm) to give you a sample size of 27. A note about alpha and beta alpha is described as the type I error, or the probability of declaring significant a difference that is not truly significant. We often use a two-sided alpha, which cuts the region of significance in half, and distributes it to both tails of the distribution, allowing for both significant positive and negative differences. Alpha is commonly set at 0.05, which works out to 0.025 on each tail of the distribution with a two-tailed alpha. beta is the power, or (1- the risk of type II error). Type II error is the probability of missing a significant result and declaring it nonsignificant after hypothesis testing. Power is often set at 80%, or 0.8, but can be 90%, 95%, or 99%, depending on how important it is not to miss a significant result, and how much money and time you have to spend (both of which tend to increase N and power). There is often an important tradeoff between type I and type II error. Things that decrease type II error (increase power) like spending more time and money for a larger N, will increase your risk of type I error. Conversely, reducing your risk of type I error will generally increase your risk of type II error. You may be in situations in which you have to decide which type of error is more important to avoid for your clinical situation to maximize benefit and minimize harms for patients. 23.3 Paired t-tests (before vs after, or truly paired) As you can see from the above example, you can use a before-after design to measure differences from baseline, and essentially convert a two-sample paired design (each participant’s baseline measurement is paired with their post-intervention measurement) to a single sample design based on the difference between the before and after values. The before-after (or baseline-postintervention) design is probably the most common paired design, but occasionally we have truly paired designs, like when we test an ointment for psoriasis on one arm, and use a placebo or sham ointment on the other arm. When this is possible, through bilateral symmetry (this also works for eyedrops in eyes, or dental treatments), it is much more efficient (in the recruiting sense) than recruiting separate groups for the treatment and control arms. To see the difference between two-sample and paired designs, run the code chunk below, for a two-sample study with a Cohen’s d of 0.8 and 80% power. Then change the type to “paired”, and see the effect on sample size. pwr::pwr.t.test(n = NULL, # note that n is per arm sig.level = 0.05, type = &quot;two.sample&quot;, alternative = &quot;two.sided&quot;, power = 0.8, d = 0.8) Note that this changes the needed sample size from 52 subjects (26 per arm) to 15 subjects (as there is only one participant needed each paired application of 2 study treatments, and n in this case indicates the number of pairs), though it would be wise to randomize patients to having the treatment on the right vs. left arm (to maintain the blind). This is a large gain in recruiting efficiency. Use paired designs whenever you can. 23.4 2 Sample t tests with Unequal Study Arm Sizes Occasionally investigators want unbalanced arms, as they feel that patients are more likely to participate if they have a greater chance of receiving the study drug than the placebo. It is fairly common to use 2:1 or 3:1 ratios. Larger ratios, like 4:1 or 5:1, are thought to risk increasing the placebo response rate, as participants assume that they are on the active drug. This is somewhat less efficient in recruiting terms, but it may improve the recruiting rate enough to compensate for the loss in efficiency. This requires a slightly different function, the pwr.t2n.test() function. Let’s look at an example below. Instead of n, we have n1 and n2, and we have to specify one of these, and leave the other as NULL. Or we can try a variety of ratios of n1 and n2, leaving the power set to NULL, and test numbers to produce the desired power. We are proposing a study in which the expected reduction in systolic blood pressure is 10 mm Hg, with a standard deviation of 20 mm Hg. We choose an n1 of 40, and a power of 80%, then let the function determine n2. pwr::pwr.t2n.test(n1 = 40, n2 = NULL, sig.level = 0.05, alternative = &quot;two.sided&quot;, power = 0.8, d = 0.5) In this case, n2 works out to slightly over 153 in the drug arm, or nearly 4:1. Calculating effect size, or Cohen’s d. You can calculate the d value yourself. Or, you can make your life easier to let the {pwr} package do this for you. You can leave the calculation of the delta/SD to the program, by setting d = (20-10)/20, and the program will calculate the d of 0.5 for you. We can also round up the ratio to 4:1 (160:40) and determine the resulting power. pwr::pwr.t2n.test(n1 = c(40), n2 = c(160), sig.level = 0.05, alternative = &quot;two.sided&quot;, power = NULL, d = 0.5) This provides a power of 80.3%. 23.5 Testing Multiple Options and Plotting Results It can be helpful to compare multiple scenarios, varying the n or the estimated effect size, to examine trade-offs and potential scenarios when planning a trial. You can test multiple particular scenarios by listing the variables in a concatenated vector, as shown below for n1 and n2. pwr::pwr.t2n.test(n1 = c(40, 60, 80), n2 = c(80, 120, 160), sig.level = 0.05, alternative = &quot;two.sided&quot;, power = NULL, d = 0.5) This provides 3 distinct scenarios, with 3 pairs of n1/n2 values, and the calculated power for each scenario. You can also examine many scenarios, with the sequence function, seq(). For the sequence function, three arguments are needed: from, the number the sequence starts from to, the number the sequence ends at (inclusive) by, the number to increment by Note that the length of the sequences produced by seq() must match (or be a multiple of the other) if you are sequencing multiple arguments, so that there is a number for each scenario. If the lengths of the sequences are multiples of each other (8 and 4 in the example below), the shorter sequence (n2) will be silently “recycled” (used again in the same order) to produce a vector of matching length (8). pwr::pwr.t2n.test(n1 = seq(from = 40, to = 75, by = 5), n2 = seq(60, 120, 20), sig.level = 0.05, alternative = &quot;two.sided&quot;, power = NULL, d = 0.5) Sometimes it is helpful to look at multiple scenarios and plot the results. You can do this by leaving n = NULL, and plotting the results, as seen below. The null value will be varied across a reasonable range, and the results plotted, with an optimal value identified. The plot function will use ggplot2 if this package is loaded, or base R plotting if ggplot2 is not available. As you can see below, you can modify the ggplot2 plot of the results with standard ggplot2 functions. results &lt;- pwr::pwr.t2n.test(n1 = c(40), n2 = NULL, sig.level = 0.05, alternative = &quot;two.sided&quot;, power = 0.80, d = 0.5) plot(results) + ggplot2::theme_minimal(base_size = 14) + labs(title = &#39;Optimizing Sample Size for my 2-Sided t test&#39;, subtitle = &quot;Always Round up for Whole Participants, N = 194&quot;) Note that the results object is a list, and you can access individual pieces with the dollar sign operator, so that `results$n1` equals 40, and `results$n2` equals 153. You can examine the components of the results object in the Environment pane in RStudio. You can use these in inline R expressions in an Rmarkdown document to write up your results. Remember that each inline R expression is wrapped in backwards apostrophes, like `r code` (using the character to the left of the 1 key on the standard US keyboard), and starts with an r to let the computer know that the incoming code is written in R. This helps you write up a sentence like the below for a grant application: Using an estimated effect size of 0.5, with a two-sided alpha of 0.05, we calculated that for 40 participants in group 1, 153.0968718 participants would be needed in group 2 to produce a power of 0.8. When you knit an Rmarkdown file with these inline R expressions, each will be automatically converted to the result number and appear as standard text. 23.6 Your Turn Try calculating the sample size or power needed in the continuous outcome scenarios below. See if you can plot the results as directed by editing the code chunks. 23.6.1 Scenario 1: FEV1 in COPD You want to increase the FEV1 (forced expiratory volume in 1 second) of patients with COPD (chronic obstructive pulmonary disease) by 10% of predicted from baseline using weekly inhaled stem cells vs. placebo. Unfortunately, the standard deviation of FEV1 measurements is 20%. You want to have 80% power to detect this difference, with a 2-sided alpha of 0.05, with equal n in each of the two arms. Fill in the blanks in the code chunk below to calculate the sample size needed (n x number of arms). Remember that the effect size (Cohen’s d) = change in endpoint (delta)/SD of the endpoint. pwr::pwr.t.test(n = __, # note that n is per arm sig.level = __, type = &quot;__&quot;, alternative = &quot;__&quot;, power = __, d = __) You should get 128 participants (assuming no dropout) from 64 per arm. Cohen’s d is 10/20 = 0.5. It can be tricky to keep the type of “two.sample” and the alternative of “two.sided” straight. But you can do this! 23.6.2 Scenario 2: BNP in CHF You want to decrease the BNP (brain natriuretic protein) of patients with CHF (congestive heart failure) by 300 pg/mL from baseline with a new oral intropic agent vs. placebo. BNP levels go up during worsening of heart failure, and a variety of effective treatments lower BNP, which can function as surrogate marker in clinical trials. The standard deviation of BNP measurements is estimated at 350 pg/mL. You want to have 80% power to detect this difference, with a 2-sided alpha of 0.05, with equal n in each of the two arms. Also consider an alternative scenario with a change in BNP of only 150 pg/mL. Remember that the effect size (Cohen’s d) = change in endpoint (delta)/SD of the endpoint. Fill in the blanks in the code chunk below (2 scenarios) to calculate the sample size needed (n x number of arms) for both alternatives. pwr::pwr.t.test(n = __, # note that n is per arm sig.level = __, type = &quot;two.__&quot;, alternative = &quot;two.__&quot;, power = __, d = __/__) pwr::pwr.t.test(n = __, # note that n is per arm sig.level = __, type = &quot;two.__&quot;, alternative = &quot;two.__&quot;, power = __, d = __/__) You should get 46 participants (assuming no dropout) from 23 per arm x 2 arms, or 174 participants (87x2) with the alternative effect size. The effect size (Cohen’s d) is 300/350 = 0.86 in the original, and 150/350 (0.43) in the alternative effect. Note that you can let R calculate the Cohen’s d - just type in 300/350 and 150/350, and R will use these as values of d. 23.6.3 Scenario 3: Barthel Index in Stroke You want to increase the Barthel Activities of Daily Living Index of patients with stroke by 25 points from baseline with an intensive in-home PT and OPT intervention vs. usual care (which usually increases BADLI by only 5 points). You roughly estimate the standard deviation of Barthel index measurements as 38. You want to have 80% power to detect this difference, with a 2-sided alpha of 0.05, with equal n in each of the two arms. You want to consider multiple possible options for n, and plot these for a nice figure in your grant application. Fill in the blanks in the code chunk below to calculate and plot the sample size needed (n x number of arms). results &lt;- pwr::pwr.t.test(n = __, # note that n is per arm sig.level = __, type = &quot;two.__&quot;, alternative = &quot;two.sided&quot;, power = __, d = __ ) plot(results) You should get an optimal sample size of 116 participants (assuming no dropout) from 58 per arm x 2 arms, with a nice plot to show this in your grant proposal. The effect size (Cohen’s d) is (25-5)/38 = 0.526. 23.7 Sample Sizes for Proportions Let’s assume that patients discharged from your hospital after a myocardial infarction have historically received a prescription for aspirin 80% of the time. A nursing quality improvement project on the cardiac floor has tried to increase this rate to 95%. How many patients do you need to track after the QI intervention to determine if the proportion has truly increased? the null hypothesis is that the proportion is 0.8 the alternative hypothesis is that the proportion is 0.95. For this, we need the pwr.p.test() function for one proportion. We will also use a built-in function of {pwr}, the ES.h() function, to help us calculate the effect size. This function takes our two hypothesized proportions and calculates an effect size with an arcsine transformation. pwr.p.test(h = ES.h(p1 = 0.95, p2 = 0.80), n = NULL, sig.level = 0.05, power = 0.80, alternative = &quot;greater&quot;) ## ## proportion power calculation for binomial distribution (arcsine transformation) ## ## h = 0.4762684 ## n = 27.25616 ## sig.level = 0.05 ## power = 0.8 ## alternative = greater We need to evaluate at least the next 28 patients discharged with MIs to have 80% power to test this one-sided hypothesis. A note about test sided-ness and publication. Frequently in common use, you may only be focused on an increase or decrease in a proportion or a continuous outcome, and a one-sided test seems reasonable. This is fine for internal use or local quality improvement work. However, for FDA approval of a drug, for grant applications, or for journal publications, the standard is to always use two-sided tests, being open to the possibility of both improvement or worsening of the outcome you are studying. This is important to know before you submit a grant application, a manuscript for publication, or a dossier for FDA approval of a drug or device. 23.8 Sample size for two proportions, equal n For this, we need the pwr.2p.test() function for two proportions. You want to calculate the sample size for a study of a cardiac plexus parasympathetic nerve stimulator for pulmonary hypertension. You expect the baseline one year mortality to be 15% in high-risk patients, and expect to reduce this to 5% with this intervention. You will compare a sham (turned off) stimulator to an active stimulator in a 2 arm study. Use a 2-sided alpha of 0.05 and a power of 80%. Copy and edit the code chunk below to determine the sample size (n, rounded up) per arm, and the overall sample size (2n) fo the study. pwr.p.test(h = ES.h(p1 = __, p2 = __), n = __, sig.level = __, power = __, alternative = &quot;__&quot;) We need to enroll at least 67 per arm, or 134 overall. Dichotomous endpoints are generally regarded as having greater clinical significance than continuous endpoints, but often require more power and sample size (and more money and time). Most investigators are short on money and time, and prefer continuous outcome endpoints. 23.9 Sample size for two proportions, unequal arms For this, we need the pwr.2p2n.test() function for two proportions with unequal sample sizes. Imagine you want to enroll class IV CHF patients in a device trial in which they will be randomized 3:1 to a device (vs sham) that restores their serum sodium to 140 mmol/L and their albumin to 40 mg/dL each night. You expect to reduce 1 year mortality from 80% to 65% with this device. You want to know what your power will be if you enroll 300 in the device arm and 100 in the sham arm. pwr.2p2n.test(h = ES.h(p1 = __, p2 = __), n1 = __, n2 = __, sig.level = __, power = __, alternative = &quot;two.sided&quot;) This (300:100) enrollment will have 84.6% power to detect a change from 15% to 5% mortality, with a two-sided alpha of 0.05. 23.10 Your Turn Try calculating the sample size or power needed in the proportional outcome scenarios below. See if you can plot the results as directed by editing the code chunks. 23.10.1 Scenario 1: Mortality on Renal Dialysis You want to decrease the mortality of patients on renal dialysis, which averages 20% per year in your local dialysis center. You will randomize patients to a bundle of statin, aspirin, beta blocker, and weekly erythropoietin vs. usual care, and hope to reduce annual mortality to 10%. You want to have 80% power to detect this difference, with a 2-sided alpha of 0.05, with equal n in each of the two arms. Fill in the blanks in the code chunk below to calculate the sample size needed (n x number of arms). pwr.p.test(h = ES.h(p1 = __, p2 = __), n = __, sig.level = .05, power = __, alternative = &quot;two.__&quot;) You always round up first (to whole participants per arm), then multiply by the number of arms. You will need a minimum of 98 per arm, for a total of 196 participants needed to complete the trial. 23.10.2 Scenario 2: Intestinal anastomosis in Crohn’s disease You want to decrease 1-year endoscopic recurrence rate in Crohn’s disease from 90% to 70%. A local surgeon claims that his new “slipknot anastomosis” technique will accomplish this, by reducing colonic backwash and thereby, reducing endoscopic recurrence. You want to have 80% power to detect this difference, with a 2-sided alpha of 0.05, with equal n in each of the two arms. Also consider an alternative, more conservative scenario with a endoscopic recurrence rate of 80% with the new method. Fill in the blanks in the code chunk below to calculate the sample size needed (n x number of arms) for both alternatives. pwr.p.test(h = c(ES.h(p1 = 0.9, p2 = __)), n = NULL, sig.level = .05, power = __, alternative = &quot;two.sided&quot;) pwr.p.test(h = c(ES.h(p1 = __, p2 = __)), n = __, sig.level = __, power = .80, alternative = __) With the originally claimed recurrence proportion of 70%, you will need 30 participants per arm, or 60 for the whole study. The more conservative estimate will require 98 subjects per arm, or 196 for the whole study. 23.10.3 Scenario 3: Metformin in Donuts Your local endocrinologist has identified consumption of glazed donuts as a major risk factor for development of type 2 diabetes in your region. She proposes to randomize participants to glazed donuts spiked with metformin vs usual donuts, expecting to reduce the 1 year proportion of prediabetics with a HgbA1c &gt; 7.0 from 25% to 10%. You want to have 80% power to detect this difference, with a 2-sided alpha of 0.05, with 2 times as many participants in the metformin donut arm. You want to consider multiple possible sample sizes (n = 25, 50, 75) for the control glazed donuts, with 2n (double the sample size in each scenario) for the metformin donuts group. Fill in the blanks in the code chunk below to calculate the resulting power for each of the three sample size scenarios. pwr.2p2n.test(h = ES.h(p1 = __, p2 = __), n1 = seq(from = __, to = __, by = 25), n2 = seq(from = __, to = __, by = 50), sig.level = __, power = NULL, alternative = &quot;two.sided&quot;) You should get a power of 37.7% for the smallest n, 64.5% for n1=50/n2=100, and 81.4% for the largest n scenario. 23.11 add chi square 23.12 add correlation test 23.13 add anova 23.14 add linear model 23.15 add note on guessing effect sizes - cohen small, medium, large 23.16 Explore More You can explore other examples here in the official {pwr} vignette. Power calculations for more complex endpoints and study designs can be found in R packages listed in the Clinical Trials CRAN Task View here. Consider the packages {samplesize}, {TrialSize}, {clusterpower}, {CRTsize}, {cosa}, {PowerTOST}, {PowerUpR}, and which may be relevant for your particular analysis. Two other helpful references are books: Cohen, J. (1988). Statistical Power Analysis for the Behavioral Sciences (2nd ed.). LEA. Ryan, T.P. (2013) Sample Size Determination and Power. Wiley. "],["randomization-for-clinical-trials-with-r.html", "Chapter 24 Randomization for Clinical Trials with R 24.1 Printing these on Cards 24.2 Now, try this yourself 24.3 Now Freestyle", " Chapter 24 Randomization for Clinical Trials with R There are a number of packages for doing key functions for clinical trials in R. You can find many of these on the CRAN Task View for Clinical Trials, at https://cran.r-project.org/web/views/ClinicalTrials.html. This is a curated list of packages that anyone might find useful in designing, monitoring, or analyzing clinical trials, and is often a good place to start in looking for packages that might be relevant for clinical trials. If you use Ctrl-F to search the web page for “rand”, several packages address randomization, including blockrand randomizeR pwr experiment clusterPower CRTSize cosa PowerupR Several of these are specifically for more complex designs, including cluster and multilevel randomization (clusterPower, cosa, CRTSize). For today, we will focus on the straightforward randomization packages including {blockrand} and {randomizer}. The {blockrand} package creates randomizations for clinical trials with can include stratified enrollment and permuted block randomization, and can produce a PDF file of randomization cards. Let’s start with an example in {blockrand}. Details on the package can be found at https://cran.r-project.org/web/packages/blockrand/blockrand.pdf or by running help(blockrand) in your Console. You want to randomize 180 inpatients with severe ulcerative colitis to one of 3 arms: corticosteroids alone (control), corticosteroids + tofacitinib, or corticosteroids + upadacitinib. You want to stratify the participants by (1) prior biologic failure and (2) Albumin level above or below 3.0. To be prepared for dropouts and imbalanced enrollment, you want to have a randomization list with at least 60 assignments available for each arm and stratum. To avoid a recognizable pattern in the randomization, you want to have a permuted block design with blocks of sizes 3, 6, and 9. Below, you will see how to do this for the biologic failure - low albumin stratum. bfla &lt;- blockrand(n = 60, num.levels = 3, # three treatments levels = c(&quot;CS&quot;, &quot;CS/Tofa&quot;, &quot;CS/Upa&quot;), # arm names stratum = &quot;Bfail.LowAlb&quot;, # stratum name id.prefix = &quot;BfLA&quot;, # stratum abbrev block.sizes = c(1,2,3), # times arms = 3,6,9 block.prefix = &quot;BfLA&quot;) # stratum abbrev bfla ## id stratum block.id block.size treatment ## 1 BfLA01 Bfail.LowAlb BfLA01 6 CS/Tofa ## 2 BfLA02 Bfail.LowAlb BfLA01 6 CS/Tofa ## 3 BfLA03 Bfail.LowAlb BfLA01 6 CS ## 4 BfLA04 Bfail.LowAlb BfLA01 6 CS/Upa ## 5 BfLA05 Bfail.LowAlb BfLA01 6 CS ## 6 BfLA06 Bfail.LowAlb BfLA01 6 CS/Upa ## 7 BfLA07 Bfail.LowAlb BfLA02 9 CS/Tofa ## 8 BfLA08 Bfail.LowAlb BfLA02 9 CS ## 9 BfLA09 Bfail.LowAlb BfLA02 9 CS/Tofa ## 10 BfLA10 Bfail.LowAlb BfLA02 9 CS/Upa ## 11 BfLA11 Bfail.LowAlb BfLA02 9 CS/Upa ## 12 BfLA12 Bfail.LowAlb BfLA02 9 CS/Tofa ## 13 BfLA13 Bfail.LowAlb BfLA02 9 CS/Upa ## 14 BfLA14 Bfail.LowAlb BfLA02 9 CS ## 15 BfLA15 Bfail.LowAlb BfLA02 9 CS ## 16 BfLA16 Bfail.LowAlb BfLA03 9 CS/Upa ## 17 BfLA17 Bfail.LowAlb BfLA03 9 CS/Upa ## 18 BfLA18 Bfail.LowAlb BfLA03 9 CS/Tofa ## 19 BfLA19 Bfail.LowAlb BfLA03 9 CS/Tofa ## 20 BfLA20 Bfail.LowAlb BfLA03 9 CS ## 21 BfLA21 Bfail.LowAlb BfLA03 9 CS/Upa ## 22 BfLA22 Bfail.LowAlb BfLA03 9 CS ## 23 BfLA23 Bfail.LowAlb BfLA03 9 CS ## 24 BfLA24 Bfail.LowAlb BfLA03 9 CS/Tofa ## 25 BfLA25 Bfail.LowAlb BfLA04 3 CS/Tofa ## 26 BfLA26 Bfail.LowAlb BfLA04 3 CS/Upa ## 27 BfLA27 Bfail.LowAlb BfLA04 3 CS ## 28 BfLA28 Bfail.LowAlb BfLA05 3 CS/Tofa ## 29 BfLA29 Bfail.LowAlb BfLA05 3 CS ## 30 BfLA30 Bfail.LowAlb BfLA05 3 CS/Upa ## 31 BfLA31 Bfail.LowAlb BfLA06 9 CS/Tofa ## 32 BfLA32 Bfail.LowAlb BfLA06 9 CS/Upa ## 33 BfLA33 Bfail.LowAlb BfLA06 9 CS/Tofa ## 34 BfLA34 Bfail.LowAlb BfLA06 9 CS ## 35 BfLA35 Bfail.LowAlb BfLA06 9 CS/Upa ## 36 BfLA36 Bfail.LowAlb BfLA06 9 CS/Upa ## 37 BfLA37 Bfail.LowAlb BfLA06 9 CS/Tofa ## 38 BfLA38 Bfail.LowAlb BfLA06 9 CS ## 39 BfLA39 Bfail.LowAlb BfLA06 9 CS ## 40 BfLA40 Bfail.LowAlb BfLA07 6 CS/Tofa ## 41 BfLA41 Bfail.LowAlb BfLA07 6 CS/Upa ## 42 BfLA42 Bfail.LowAlb BfLA07 6 CS ## 43 BfLA43 Bfail.LowAlb BfLA07 6 CS/Upa ## 44 BfLA44 Bfail.LowAlb BfLA07 6 CS/Tofa ## 45 BfLA45 Bfail.LowAlb BfLA07 6 CS ## 46 BfLA46 Bfail.LowAlb BfLA08 3 CS/Tofa ## 47 BfLA47 Bfail.LowAlb BfLA08 3 CS/Upa ## 48 BfLA48 Bfail.LowAlb BfLA08 3 CS ## 49 BfLA49 Bfail.LowAlb BfLA09 9 CS ## 50 BfLA50 Bfail.LowAlb BfLA09 9 CS/Upa ## 51 BfLA51 Bfail.LowAlb BfLA09 9 CS ## 52 BfLA52 Bfail.LowAlb BfLA09 9 CS/Upa ## 53 BfLA53 Bfail.LowAlb BfLA09 9 CS/Upa ## 54 BfLA54 Bfail.LowAlb BfLA09 9 CS/Tofa ## 55 BfLA55 Bfail.LowAlb BfLA09 9 CS/Tofa ## 56 BfLA56 Bfail.LowAlb BfLA09 9 CS/Tofa ## 57 BfLA57 Bfail.LowAlb BfLA09 9 CS ## 58 BfLA58 Bfail.LowAlb BfLA10 6 CS ## 59 BfLA59 Bfail.LowAlb BfLA10 6 CS/Upa ## 60 BfLA60 Bfail.LowAlb BfLA10 6 CS/Upa ## 61 BfLA61 Bfail.LowAlb BfLA10 6 CS/Tofa ## 62 BfLA62 Bfail.LowAlb BfLA10 6 CS/Tofa ## 63 BfLA63 Bfail.LowAlb BfLA10 6 CS You can see the id for each participant, their stratum, the block.id for their permuted block, the block.size, and their assigned treatment. You can imagine this as a randomization list, or as assignments that you could print out on cards and seal in security envelopes for the time of randomization. Of course, this is only one of our four strata. We should do the same for the 3 other strata. bfha &lt;- blockrand(n = 60, num.levels = 3, # three treatments levels = c(&quot;CS&quot;, &quot;CS/Tofa&quot;, &quot;CS/Upa&quot;), # arm names stratum = &quot;Bfail.HiAlb&quot;, # stratum name id.prefix = &quot;BfHA&quot;, # stratum abbrev block.sizes = c(1,2,3), # times arms = 3,6,9 block.prefix = &quot;BfHA&quot;) # stratum abbrev bfha ## id stratum block.id block.size treatment ## 1 BfHA01 Bfail.HiAlb BfHA01 6 CS/Tofa ## 2 BfHA02 Bfail.HiAlb BfHA01 6 CS/Tofa ## 3 BfHA03 Bfail.HiAlb BfHA01 6 CS ## 4 BfHA04 Bfail.HiAlb BfHA01 6 CS/Upa ## 5 BfHA05 Bfail.HiAlb BfHA01 6 CS/Upa ## 6 BfHA06 Bfail.HiAlb BfHA01 6 CS ## 7 BfHA07 Bfail.HiAlb BfHA02 3 CS/Tofa ## 8 BfHA08 Bfail.HiAlb BfHA02 3 CS ## 9 BfHA09 Bfail.HiAlb BfHA02 3 CS/Upa ## 10 BfHA10 Bfail.HiAlb BfHA03 9 CS/Tofa ## 11 BfHA11 Bfail.HiAlb BfHA03 9 CS ## 12 BfHA12 Bfail.HiAlb BfHA03 9 CS/Upa ## 13 BfHA13 Bfail.HiAlb BfHA03 9 CS/Tofa ## 14 BfHA14 Bfail.HiAlb BfHA03 9 CS/Upa ## 15 BfHA15 Bfail.HiAlb BfHA03 9 CS/Tofa ## 16 BfHA16 Bfail.HiAlb BfHA03 9 CS/Upa ## 17 BfHA17 Bfail.HiAlb BfHA03 9 CS ## 18 BfHA18 Bfail.HiAlb BfHA03 9 CS ## 19 BfHA19 Bfail.HiAlb BfHA04 9 CS ## 20 BfHA20 Bfail.HiAlb BfHA04 9 CS/Tofa ## 21 BfHA21 Bfail.HiAlb BfHA04 9 CS/Tofa ## 22 BfHA22 Bfail.HiAlb BfHA04 9 CS/Upa ## 23 BfHA23 Bfail.HiAlb BfHA04 9 CS/Upa ## 24 BfHA24 Bfail.HiAlb BfHA04 9 CS/Tofa ## 25 BfHA25 Bfail.HiAlb BfHA04 9 CS ## 26 BfHA26 Bfail.HiAlb BfHA04 9 CS/Upa ## 27 BfHA27 Bfail.HiAlb BfHA04 9 CS ## 28 BfHA28 Bfail.HiAlb BfHA05 3 CS/Upa ## 29 BfHA29 Bfail.HiAlb BfHA05 3 CS/Tofa ## 30 BfHA30 Bfail.HiAlb BfHA05 3 CS ## 31 BfHA31 Bfail.HiAlb BfHA06 6 CS ## 32 BfHA32 Bfail.HiAlb BfHA06 6 CS/Upa ## 33 BfHA33 Bfail.HiAlb BfHA06 6 CS ## 34 BfHA34 Bfail.HiAlb BfHA06 6 CS/Tofa ## 35 BfHA35 Bfail.HiAlb BfHA06 6 CS/Upa ## 36 BfHA36 Bfail.HiAlb BfHA06 6 CS/Tofa ## 37 BfHA37 Bfail.HiAlb BfHA07 6 CS ## 38 BfHA38 Bfail.HiAlb BfHA07 6 CS/Upa ## 39 BfHA39 Bfail.HiAlb BfHA07 6 CS/Upa ## 40 BfHA40 Bfail.HiAlb BfHA07 6 CS/Tofa ## 41 BfHA41 Bfail.HiAlb BfHA07 6 CS ## 42 BfHA42 Bfail.HiAlb BfHA07 6 CS/Tofa ## 43 BfHA43 Bfail.HiAlb BfHA08 9 CS/Upa ## 44 BfHA44 Bfail.HiAlb BfHA08 9 CS/Tofa ## 45 BfHA45 Bfail.HiAlb BfHA08 9 CS ## 46 BfHA46 Bfail.HiAlb BfHA08 9 CS ## 47 BfHA47 Bfail.HiAlb BfHA08 9 CS/Upa ## 48 BfHA48 Bfail.HiAlb BfHA08 9 CS ## 49 BfHA49 Bfail.HiAlb BfHA08 9 CS/Tofa ## 50 BfHA50 Bfail.HiAlb BfHA08 9 CS/Upa ## 51 BfHA51 Bfail.HiAlb BfHA08 9 CS/Tofa ## 52 BfHA52 Bfail.HiAlb BfHA09 6 CS/Tofa ## 53 BfHA53 Bfail.HiAlb BfHA09 6 CS ## 54 BfHA54 Bfail.HiAlb BfHA09 6 CS ## 55 BfHA55 Bfail.HiAlb BfHA09 6 CS/Tofa ## 56 BfHA56 Bfail.HiAlb BfHA09 6 CS/Upa ## 57 BfHA57 Bfail.HiAlb BfHA09 6 CS/Upa ## 58 BfHA58 Bfail.HiAlb BfHA10 9 CS/Upa ## 59 BfHA59 Bfail.HiAlb BfHA10 9 CS/Tofa ## 60 BfHA60 Bfail.HiAlb BfHA10 9 CS/Upa ## 61 BfHA61 Bfail.HiAlb BfHA10 9 CS/Upa ## 62 BfHA62 Bfail.HiAlb BfHA10 9 CS/Tofa ## 63 BfHA63 Bfail.HiAlb BfHA10 9 CS ## 64 BfHA64 Bfail.HiAlb BfHA10 9 CS ## 65 BfHA65 Bfail.HiAlb BfHA10 9 CS ## 66 BfHA66 Bfail.HiAlb BfHA10 9 CS/Tofa bnha &lt;- blockrand(n = 60, num.levels = 3, levels = c(&quot;CS&quot;, &quot;CS/Tofa&quot;, &quot;CS/Upa&quot;), stratum = &quot;Bnaive.HiAlb&quot;, id.prefix = &quot;BnHA&quot;, block.sizes = c(1,2,3, 4), block.prefix = &quot;BnHA&quot;) bnha ## id stratum block.id block.size treatment ## 1 BnHA01 Bnaive.HiAlb BnHA1 12 CS ## 2 BnHA02 Bnaive.HiAlb BnHA1 12 CS ## 3 BnHA03 Bnaive.HiAlb BnHA1 12 CS/Tofa ## 4 BnHA04 Bnaive.HiAlb BnHA1 12 CS/Tofa ## 5 BnHA05 Bnaive.HiAlb BnHA1 12 CS/Tofa ## 6 BnHA06 Bnaive.HiAlb BnHA1 12 CS/Upa ## 7 BnHA07 Bnaive.HiAlb BnHA1 12 CS/Upa ## 8 BnHA08 Bnaive.HiAlb BnHA1 12 CS/Upa ## 9 BnHA09 Bnaive.HiAlb BnHA1 12 CS ## 10 BnHA10 Bnaive.HiAlb BnHA1 12 CS ## 11 BnHA11 Bnaive.HiAlb BnHA1 12 CS/Upa ## 12 BnHA12 Bnaive.HiAlb BnHA1 12 CS/Tofa ## 13 BnHA13 Bnaive.HiAlb BnHA2 3 CS/Tofa ## 14 BnHA14 Bnaive.HiAlb BnHA2 3 CS/Upa ## 15 BnHA15 Bnaive.HiAlb BnHA2 3 CS ## 16 BnHA16 Bnaive.HiAlb BnHA3 6 CS/Tofa ## 17 BnHA17 Bnaive.HiAlb BnHA3 6 CS ## 18 BnHA18 Bnaive.HiAlb BnHA3 6 CS/Upa ## 19 BnHA19 Bnaive.HiAlb BnHA3 6 CS/Upa ## 20 BnHA20 Bnaive.HiAlb BnHA3 6 CS ## 21 BnHA21 Bnaive.HiAlb BnHA3 6 CS/Tofa ## 22 BnHA22 Bnaive.HiAlb BnHA4 3 CS/Tofa ## 23 BnHA23 Bnaive.HiAlb BnHA4 3 CS/Upa ## 24 BnHA24 Bnaive.HiAlb BnHA4 3 CS ## 25 BnHA25 Bnaive.HiAlb BnHA5 12 CS/Tofa ## 26 BnHA26 Bnaive.HiAlb BnHA5 12 CS ## 27 BnHA27 Bnaive.HiAlb BnHA5 12 CS/Tofa ## 28 BnHA28 Bnaive.HiAlb BnHA5 12 CS ## 29 BnHA29 Bnaive.HiAlb BnHA5 12 CS/Upa ## 30 BnHA30 Bnaive.HiAlb BnHA5 12 CS/Upa ## 31 BnHA31 Bnaive.HiAlb BnHA5 12 CS/Tofa ## 32 BnHA32 Bnaive.HiAlb BnHA5 12 CS ## 33 BnHA33 Bnaive.HiAlb BnHA5 12 CS/Tofa ## 34 BnHA34 Bnaive.HiAlb BnHA5 12 CS/Upa ## 35 BnHA35 Bnaive.HiAlb BnHA5 12 CS ## 36 BnHA36 Bnaive.HiAlb BnHA5 12 CS/Upa ## 37 BnHA37 Bnaive.HiAlb BnHA6 6 CS/Upa ## 38 BnHA38 Bnaive.HiAlb BnHA6 6 CS/Tofa ## 39 BnHA39 Bnaive.HiAlb BnHA6 6 CS ## 40 BnHA40 Bnaive.HiAlb BnHA6 6 CS/Upa ## 41 BnHA41 Bnaive.HiAlb BnHA6 6 CS/Tofa ## 42 BnHA42 Bnaive.HiAlb BnHA6 6 CS ## 43 BnHA43 Bnaive.HiAlb BnHA7 12 CS/Tofa ## 44 BnHA44 Bnaive.HiAlb BnHA7 12 CS/Upa ## 45 BnHA45 Bnaive.HiAlb BnHA7 12 CS ## 46 BnHA46 Bnaive.HiAlb BnHA7 12 CS/Tofa ## 47 BnHA47 Bnaive.HiAlb BnHA7 12 CS ## 48 BnHA48 Bnaive.HiAlb BnHA7 12 CS ## 49 BnHA49 Bnaive.HiAlb BnHA7 12 CS/Tofa ## 50 BnHA50 Bnaive.HiAlb BnHA7 12 CS ## 51 BnHA51 Bnaive.HiAlb BnHA7 12 CS/Upa ## 52 BnHA52 Bnaive.HiAlb BnHA7 12 CS/Upa ## 53 BnHA53 Bnaive.HiAlb BnHA7 12 CS/Upa ## 54 BnHA54 Bnaive.HiAlb BnHA7 12 CS/Tofa ## 55 BnHA55 Bnaive.HiAlb BnHA8 9 CS/Tofa ## 56 BnHA56 Bnaive.HiAlb BnHA8 9 CS/Tofa ## 57 BnHA57 Bnaive.HiAlb BnHA8 9 CS ## 58 BnHA58 Bnaive.HiAlb BnHA8 9 CS/Upa ## 59 BnHA59 Bnaive.HiAlb BnHA8 9 CS ## 60 BnHA60 Bnaive.HiAlb BnHA8 9 CS ## 61 BnHA61 Bnaive.HiAlb BnHA8 9 CS/Upa ## 62 BnHA62 Bnaive.HiAlb BnHA8 9 CS/Tofa ## 63 BnHA63 Bnaive.HiAlb BnHA8 9 CS/Upa bnla &lt;- blockrand(n = 60, num.levels = 3, levels = c(&quot;CS&quot;, &quot;CS/Tofa&quot;, &quot;CS/Upa&quot;), stratum = &quot;Bnaive.LoAlb&quot;, id.prefix = &quot;BnLA&quot;, block.sizes = c(1,2,3), block.prefix = &quot;BnLA&quot;) bnla ## id stratum block.id block.size treatment ## 1 BnLA01 Bnaive.LoAlb BnLA01 6 CS/Tofa ## 2 BnLA02 Bnaive.LoAlb BnLA01 6 CS/Tofa ## 3 BnLA03 Bnaive.LoAlb BnLA01 6 CS/Upa ## 4 BnLA04 Bnaive.LoAlb BnLA01 6 CS ## 5 BnLA05 Bnaive.LoAlb BnLA01 6 CS/Upa ## 6 BnLA06 Bnaive.LoAlb BnLA01 6 CS ## 7 BnLA07 Bnaive.LoAlb BnLA02 9 CS/Tofa ## 8 BnLA08 Bnaive.LoAlb BnLA02 9 CS/Upa ## 9 BnLA09 Bnaive.LoAlb BnLA02 9 CS/Tofa ## 10 BnLA10 Bnaive.LoAlb BnLA02 9 CS ## 11 BnLA11 Bnaive.LoAlb BnLA02 9 CS/Tofa ## 12 BnLA12 Bnaive.LoAlb BnLA02 9 CS ## 13 BnLA13 Bnaive.LoAlb BnLA02 9 CS/Upa ## 14 BnLA14 Bnaive.LoAlb BnLA02 9 CS/Upa ## 15 BnLA15 Bnaive.LoAlb BnLA02 9 CS ## 16 BnLA16 Bnaive.LoAlb BnLA03 6 CS/Tofa ## 17 BnLA17 Bnaive.LoAlb BnLA03 6 CS ## 18 BnLA18 Bnaive.LoAlb BnLA03 6 CS ## 19 BnLA19 Bnaive.LoAlb BnLA03 6 CS/Upa ## 20 BnLA20 Bnaive.LoAlb BnLA03 6 CS/Upa ## 21 BnLA21 Bnaive.LoAlb BnLA03 6 CS/Tofa ## 22 BnLA22 Bnaive.LoAlb BnLA04 3 CS ## 23 BnLA23 Bnaive.LoAlb BnLA04 3 CS/Upa ## 24 BnLA24 Bnaive.LoAlb BnLA04 3 CS/Tofa ## 25 BnLA25 Bnaive.LoAlb BnLA05 6 CS/Upa ## 26 BnLA26 Bnaive.LoAlb BnLA05 6 CS ## 27 BnLA27 Bnaive.LoAlb BnLA05 6 CS/Tofa ## 28 BnLA28 Bnaive.LoAlb BnLA05 6 CS/Upa ## 29 BnLA29 Bnaive.LoAlb BnLA05 6 CS/Tofa ## 30 BnLA30 Bnaive.LoAlb BnLA05 6 CS ## 31 BnLA31 Bnaive.LoAlb BnLA06 3 CS ## 32 BnLA32 Bnaive.LoAlb BnLA06 3 CS/Tofa ## 33 BnLA33 Bnaive.LoAlb BnLA06 3 CS/Upa ## 34 BnLA34 Bnaive.LoAlb BnLA07 3 CS ## 35 BnLA35 Bnaive.LoAlb BnLA07 3 CS/Tofa ## 36 BnLA36 Bnaive.LoAlb BnLA07 3 CS/Upa ## 37 BnLA37 Bnaive.LoAlb BnLA08 3 CS/Upa ## 38 BnLA38 Bnaive.LoAlb BnLA08 3 CS/Tofa ## 39 BnLA39 Bnaive.LoAlb BnLA08 3 CS ## 40 BnLA40 Bnaive.LoAlb BnLA09 9 CS/Tofa ## 41 BnLA41 Bnaive.LoAlb BnLA09 9 CS/Tofa ## 42 BnLA42 Bnaive.LoAlb BnLA09 9 CS/Upa ## 43 BnLA43 Bnaive.LoAlb BnLA09 9 CS ## 44 BnLA44 Bnaive.LoAlb BnLA09 9 CS/Tofa ## 45 BnLA45 Bnaive.LoAlb BnLA09 9 CS/Upa ## 46 BnLA46 Bnaive.LoAlb BnLA09 9 CS/Upa ## 47 BnLA47 Bnaive.LoAlb BnLA09 9 CS ## 48 BnLA48 Bnaive.LoAlb BnLA09 9 CS ## 49 BnLA49 Bnaive.LoAlb BnLA10 6 CS/Tofa ## 50 BnLA50 Bnaive.LoAlb BnLA10 6 CS ## 51 BnLA51 Bnaive.LoAlb BnLA10 6 CS/Upa ## 52 BnLA52 Bnaive.LoAlb BnLA10 6 CS/Upa ## 53 BnLA53 Bnaive.LoAlb BnLA10 6 CS ## 54 BnLA54 Bnaive.LoAlb BnLA10 6 CS/Tofa ## 55 BnLA55 Bnaive.LoAlb BnLA11 9 CS/Upa ## 56 BnLA56 Bnaive.LoAlb BnLA11 9 CS/Upa ## 57 BnLA57 Bnaive.LoAlb BnLA11 9 CS/Tofa ## 58 BnLA58 Bnaive.LoAlb BnLA11 9 CS/Upa ## 59 BnLA59 Bnaive.LoAlb BnLA11 9 CS/Tofa ## 60 BnLA60 Bnaive.LoAlb BnLA11 9 CS ## 61 BnLA61 Bnaive.LoAlb BnLA11 9 CS/Tofa ## 62 BnLA62 Bnaive.LoAlb BnLA11 9 CS ## 63 BnLA63 Bnaive.LoAlb BnLA11 9 CS 24.1 Printing these on Cards Ideally, you will print out each randomization on a card, and seal it in a security envelope, with the outside of the envelope labeled with the id. You can do this with the plotblockrand() function. This function creates a pdf file of randomization cards for printing. These are designed so that the middle text will show in a standard letter sized envelope with a window, and the top text (the assignment) can be folded over to increase security (against anyone trying to peek through the security envelope to guess the assignment). uc_study &lt;- bind_rows(bfha, bfla, bnha, bnla) # bind together the four strata into one dataframe blockrand::plotblockrand(uc_study, # input dataframe file = &quot;uc_study.pdf&quot;, # output pdf # top hidden text with assignment top=list(text=c(&#39;My Study&#39;,&#39;Patient: %ID%&#39;,&#39;Treatment: %TREAT%&#39;), col=c(&#39;black&#39;,&#39;black&#39;,&#39;red&#39;),font=c(1,1,4)), # middle text to show through window of # 10 envelope middle=list(text=c(&quot;My Study&quot;,&quot;Stratum: %STRAT%&quot;,&quot;Patient: %ID%&quot;), col=c(&#39;black&#39;,&#39;blue&#39;,&#39;orange&#39;),font=c(1,2,3)), # bottom text- any instructions to study coordinator bottom=&quot;Call 123-4567 to report patient entry&quot;, cut.marks=TRUE) # add cut marks - 4 per page Open up the file uc_study.pdf in your Files tab to see the output pdf file, with assorted fonts and colors. Just for fun, change (and then re-run) the text “My Study” to something more interesting change “Patient” to “Participant” change “Treatment” to “Arm” or “Assignment” change some of the colors to standard R colors change some of the fonts (within 1-4) Sometimes with equal blocks, and clear treatment effects or side effects, nurses or study coordinators can guess the randomization pattern. If you want to get fancy, and make it even harder to guess treatment assignments, you can add one of the unequal blocks options, to make it hard to find patterns in treatment or in side effects. Set uneq.beg = TRUE for an unequal block in the beginning, or uneq.mid = TRUE for an unequal block in the middle. 24.2 Now, try this yourself You want to randomize 80 outpatients with Crohn’s disease to one of 8 arms, as part of a 2^3 factorial design to increase patient activation. These arms involve using (A,B, C) or not using (a,b,c) 3 intervention components. The 8 arms then become: abc abC aBc aBC Abc AbC ABc ABC Then we want to stratify the participants by baseline PAM score (a measure of patient activation) with levels of low, medium, and high PAM. To be prepared for dropouts and imbalanced enrollment, you want to have a randomization list with at least 32 assignments available for each arm and stratum. To avoid a recognizable pattern in the randomization, you want to have a permuted block design with blocks of sizes 8 and 16. You can hover over top right corner of the code chunk below, and a copy icon will appear - click this to copy the code to your clipboard. You can then paste it into your local version of RStudio, edit it, and run it. In the code block below, fill in the blanks to complete the code to make a dataframe for the low_pam stratum. low_pam &lt;- blockrand(n = __, num.levels = __, #eight treatments levels = c(&quot;abc&quot;, &quot;abC&quot;, &quot;aBc&quot;, &quot;aBC&quot;, &quot;Abc&quot;, &quot;AbC&quot;, &quot;ABc&quot;, &quot;ABC&quot;), # arm names stratum = &quot;__&quot;, # stratum name id.prefix = &quot;lp&quot;, # stratum abbrev block.sizes = c(1,2,3), # times arms block.prefix = &quot;LP&quot;) # stratum abbrev low_pam Now that you have one stratum sorted, edit the code block below to create the med_pam and high_pam strata. med_pam &lt;- blockrand(n = __, num.levels = __, #eight treatments levels = c(&quot;abc&quot;, &quot;abC&quot;, &quot;aBc&quot;, &quot;aBC&quot;, &quot;Abc&quot;, &quot;AbC&quot;, &quot;ABc&quot;, &quot;ABC&quot;), # arm names stratum = &quot;__&quot;, # stratum name id.prefix = &quot;__&quot;, # stratum abbrev block.sizes = c(__), # times arms block.prefix = &quot;__&quot;) # stratum abbrev med_pam high_pam &lt;- blockrand(n = __, num.levels = __, #eight treatments levels = c(&quot;abc&quot;, &quot;abC&quot;, &quot;aBc&quot;, &quot;aBC&quot;, &quot;Abc&quot;, &quot;AbC&quot;, &quot;ABc&quot;, &quot;ABC&quot;), # arm names stratum = &quot;__&quot;, # stratum name id.prefix = &quot;__&quot;, # stratum abbrev block.sizes = c(__), # times arms block.prefix = &quot;__&quot;) # stratum abbrev high_pam Great! Now try to bind these 3 strata into one dataframe print these as cards to a pdf file Edit the code chunk below to produce the pdf file cd_study &lt;- bind_rows(__,__,__) # bind together the 3 strata into one dataframe blockrand::plotblockrand(__, # input dataframe file = &quot;cd_study.pdf&quot;, # output pdf # top hidden text with assignment top=list(text=c(&#39;CD Study&#39;,&#39;Patient: %ID%&#39;,&#39;Treatment: %__%&#39;), col=c(&#39;orange&#39;,&#39;blue&#39;,&#39;red&#39;),font=c(1,1,4)), # middle text to show through window of # 10 envelope middle=list(text=c(&quot;CD Study&quot;,&quot;Stratum: %STRAT%&quot;,&quot;Patient: %__%&quot;), col=c(&#39;black&#39;,&#39;red&#39;,&#39;cadetblue&#39;),font=c(1,2,3)), # bottom text- any instructions to study coordinator bottom=&quot;Call 123-4567 to report patient entry&quot;, cut.marks=TRUE) # add cut marks - 4 per page 24.3 Now Freestyle Your turn. Create randomization tables and a pdf file of cards for a study of 2 microbiome interventions to reduce the formation of colon adenomas. your 3 study arms will be - placebo, Streptococcus thermophilus, and S.thermo plus lactose (a preferred sugar for S.t, making this arm a synbiotic, while arm 2 is a probiotic) - aka 3 arms called: pbo, probiotic, synbiotic. Your stratifications will be by prior polyps being MSI_hi or MSI_lo (for microsatellite instability mutations) BMI above or below 35. BMI_hi, BMI_low block sizes of 4,8,12,16 160 per arm Edit the code block below for the first stratum mhbh &lt;- blockrand(n = __, # treatment arms num.levels = __, # of treatments levels = c(&quot;placebo&quot;, &quot;probiotic&quot;, &quot;synbiotic&quot;), # arm names stratum = &quot;__,__&quot;, # stratum name id.prefix = &quot;mhbh&quot;, # stratum abbrev block.sizes = c(__,__,__,__), # times arms block.prefix = &quot;__&quot;) # stratum abbrev mhbh Edit the code block below for the remaining strata mhbl &lt;- blockrand(n = __, # treatment arms num.levels = 3, # of treatments levels = c(&quot;placebo&quot;, &quot;probiotic&quot;, &quot;__&quot;), # arm names stratum = &quot;msi_hi.bmi_lo&quot;, # stratum name id.prefix = &quot;__&quot;, # stratum abbrev block.sizes = c(1,2,__,__), # times arms block.prefix = &quot;MHBL&quot;) # stratum abbrev mhbl mlbl &lt;- blockrand(n = 160, # treatment arms num.levels = __, # of treatments levels = c(&quot;placebo&quot;, &quot;__&quot;, &quot;synbiotic&quot;), # arm names stratum = &quot;__&quot;, # stratum name id.prefix = &quot;mlbl&quot;, # stratum abbrev block.sizes = c(__,__,3,4), # times arms block.prefix = &quot;MLBL&quot;) # stratum abbrev mlbl mlbh &lt;- blockrand(n = __, # treatment arms num.levels = 3, # of treatments levels = c(&quot;__&quot;, &quot;probiotic&quot;, &quot;synbiotic&quot;), # arm names stratum = &quot;msi_lo.bmi_hi&quot;, # stratum name id.prefix = &quot;__&quot;, # stratum abbrev block.sizes = c(1,2,3,4), # times arms block.prefix = &quot;MLBH&quot;) # stratum abbrev mlbh Edit the code block below to bind the strata together and print the cards adenoma_study &lt;- bind_rows(mlbl, mlbh, mhbh, mhbl) # bind together the strata into one dataframe blockrand::plotblockrand(__, # input dataframe file = &quot;adenoma_cards.pdf&quot;, # output pdf # top hidden text with assignment top=list(text=c(&#39;Adenoma Study&#39;,&#39;Patient: %__%&#39;,&#39;Treatment: %TREAT%&#39;), col=c(&#39;orange&#39;,&#39;blue&#39;,&#39;red&#39;),font=c(1,1,4)), # middle text to show through window of # 10 envelope middle=list(text=c(&quot;Adenoma Study&quot;,&quot;Stratum: %__%&quot;,&quot;Patient: %ID%&quot;), col=c(&#39;black&#39;,&#39;red&#39;,&#39;cadetblue&#39;),font=c(1,2,3)), # bottom text- any instructions to study coordinator bottom=&quot;Call 123-4567 to report patient entry. \\nInstruct participant to avoid antibiotics and stop aspirin&quot;, cut.marks=TRUE) # add cut marks - 4 per page "],["univariate-ggplots-to-visualize-distributions.html", "Chapter 25 Univariate ggplots to Visualize Distributions 25.1 Histograms 25.2 Density Plots 25.3 Comparing Distributions Across Categories 25.4 Boxplots 25.5 Violin Plots 25.6 Ridgeline Plots", " Chapter 25 Univariate ggplots to Visualize Distributions When you first encounter a new dataset, it is often helpful to start with Data Exploration and Validation (DEV) . Note that DEV is different from EDA (Exploratory Data Analysis), which involves rummaging through your data (often with plots) and generating new hypotheses, performing multiple tests, and essentially data mining. DEV has specific goals, which include identifying variables with problematic values (NA, outliers), unexpected distributions (sometimes bimodal), and less-than-helpful variable names or data types. In this chapter, we will look at investigating single continuous variables, looking for outliers, multi-modal distributions, and making comparisons across categories. 25.1 Histograms One of the most helpful ways to get started is to explore your continuous variables with the humble histogram or dotplot. These geoms in ggplot2 allow you to see a distribution of a single variable, and are a good way to get started with ggplot. Let’s start by looking at the distribution of the number of colon polyps found in participants in a clinical trial. You just need to map a variable (in this case, number12m) to the x aesthetic, and you are good to go. medicaldata::polyps %&gt;% ggplot() + aes(x = number12m) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## Warning: Removed 2 rows containing non-finite outside the scale range ## (`stat_bin()`). This gives us a very basic histogram, with some participants with zero polyps, but many with much larger numbers. We also learn that geom_histogram is a bit grumpy, and complains that we have not picked a binwidth (or a number of bins). Since the distribution goes out to 60+ polyps, let’s pick a binwidth of 5 (or about 13 bins). polyps %&gt;% ggplot() + aes(x = number12m) + geom_histogram(binwidth = 5) ## Warning: Removed 2 rows containing non-finite outside the scale range ## (`stat_bin()`). Even with 13 bins, most bins contain only one or two participants. It would be more helpful to visualize each participant as a single dot, which you can do with a dotplot (geom_dotplot). medicaldata::polyps %&gt;% ggplot() + aes(x = number12m, fill = treatment) + geom_dotplot(binwidth = 1) + scale_y_continuous(NULL, breaks = NULL) + # Make this ratio = (tallest column * binwidth * 1.5) coord_fixed(ratio = 6) + labs(title = &quot;Distribution of Participants binned by number of Polyps&quot;, subtitle = &quot;Colored by Treatment&quot;) + theme(legend.position = &quot;top&quot;) ## Warning: Removed 2 rows containing missing values or values outside the scale range ## (`stat_bindot()`). One of the nice things about geom_dotplot() is that it represents each participant as a dot, which is closer to reality than columns which look like they are portraying values, rather than counts. The y-axis is less helpful. It is showing the proportion of the total sample, which is sort of helpful, but this leaves a lot of empty space with no data most of the time. 25.1.1 Comparisons of Distributions with Histograms When you have a continuous variable that could vary across several categories of a categorical variable, you may want to compare the distributions across the categories. You can compare a small number of categories with histograms, usually 5 categories or less is manageable. There are several ways to make this kind of comparison. You can set the fill aesthetic to the categorical variable. In this case, we will use the treatment variable. This is OK, as you can see the sulindac-treated patients are shifted to the left, but it is not great, as the counts are stacked, and this can make comparisons hard. Note that color = outline of bars color, as opposed to fill. medicaldata::polyps %&gt;% ggplot() + aes(x = number12m, fill = treatment) + geom_histogram(bins=15, color = &quot;purple&quot;) ## Warning: Removed 2 rows containing non-finite outside the scale range ## (`stat_bin()`). A mirror histogram can work well for 2 categories. You filter the data by value within the geom, and set the y value to ..density.. for one category value, and to negative -..density.. for the other category value, as seen below. The ..density.. variable is a value ggplot calculates in the background with a stat function. medicaldata::polyps %&gt;% ggplot(aes(x = number12m)) + geom_histogram(fill = &quot;red&quot;, aes(y = ..density..), data = . %&gt;% filter(treatment == &#39;placebo&#39;), bins = 15) + geom_label(aes(x = 55, y = 0.03, label = &quot;Placebo&quot;), color = &quot;red&quot;) + geom_histogram(fill = &quot;#404080&quot;, aes(y = -..density..), data = . %&gt;% filter(treatment == &#39;sulindac&#39;), bins = 15) + geom_label(aes(x = 20, y = -0.03, label = &quot;Sulindac&quot;), color = &quot;#404080&quot;) ## Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0. ## ℹ Please use `after_stat(density)` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. ## Warning in geom_label(aes(x = 55, y = 0.03, label = &quot;Placebo&quot;), color = &quot;red&quot;): All aesthetics have length 1, but the data has 22 rows. ## ℹ Please consider using `annotate()` or provide this layer with data containing ## a single row. ## Warning in geom_label(aes(x = 20, y = -0.03, label = &quot;Sulindac&quot;), color = &quot;#404080&quot;): All aesthetics have length 1, but the data has 22 rows. ## ℹ Please consider using `annotate()` or provide this layer with data containing ## a single row. ## Warning: Removed 2 rows containing non-finite outside the scale range ## (`stat_bin()`). You can do small multiples with facet_wrap medicaldata::polyps %&gt;% ggplot() + aes(x = number12m, fill = treatment) + geom_histogram(bins =15) + facet_grid(. ~ treatment) ## Warning: Removed 2 rows containing non-finite outside the scale range ## (`stat_bin()`). Note for facet_wrap and facet_grid, the formula notation or the arguments is y \\~ x, so that by putting treatment after the tilde, the treatments are compared on the x axis, or side by side. If you put the treatment categorical value in the first (y) position, they would be shown as top and bottom. medicaldata::polyps %&gt;% ggplot() + aes(x = number12m, fill = treatment) + geom_histogram(bins =15) + facet_grid(treatment ~ .) ## Warning: Removed 2 rows containing non-finite outside the scale range ## (`stat_bin()`). While the viewer can generally make the comparisons with 2 categories, it can get more complicated with increasing numbers of categories. 25.1.2 Histograms and Categories You can also look at distributions of different categories, by color: mockstudy %&gt;% ggplot() + aes(x = age, color = sex, fill = sex) + geom_histogram(alpha=0.3, position=&quot;identity&quot;) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Or with vertical facets: mockstudy %&gt;% ggplot() + aes(x = fu.time, color = sex) + geom_histogram(fill=&quot;white&quot;, alpha=0.5, position=&quot;identity&quot;)+ facet_grid(sex ~ .) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. or horizontal facets: mockstudy %&gt;% ggplot() + aes(x = age, color = sex) + geom_histogram(fill=&quot;white&quot;, alpha=0.5, position=&quot;identity&quot;)+ facet_grid(. ~ sex) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 25.2 Density Plots Density Plots are essentially smoothed versions of histograms. Density plots are helpful to show the distribution of a numeric variable. The defaults for smoothing are quite reasonable. The only required aesthetic (like histogram) is an x variable. Optional aesthetics include alpha - setting the transparency, from 0 (invisible) to 1 (the default). Used when there are a lot of overlapping points, usually in the range from 0.05-0.5. group - for grouping into separate curves by a categorical variable. color - color of the distribution line, like color = “orchid”. When this is set to a categorical variable, geom_density will group by this variable and assign different colors to the groups. If you want to control the color assignments, you can use a palette with scale_color_brewer() or scale_color_manual (with the manual option you can set your own values or palette). Some options can be found here. fill color. You can use a single color, or set this to a categorical variable and use scale_fill_brewer or scale_fill_manual. You can also use scale_fill_viridis. size (line thickness) - the default is 1. linetype (6 types 1-6). You can also use the names of these 6 standard line types in quotes which are “solid”, “dashed”, “dotted”, “dotdash”, “longdash”, or “twodash”. You can even define a cutsom line type, providing the lengths of (up to 8) consecutive on-off segments. The string “3313” specifies a line with 3 units on, 3 units off, 1 unit on, 3 units off (dash-dot). The standard dotted and dashed line types (types 2-6) correspond to “44”, “13”. “1343”, “73” and “2262”. mockstudy %&gt;% ggplot() + aes(x = age) + geom_density() + geom_density(fill=&quot;orchid&quot;, size = 2, position=&quot;identity&quot;, alpha = 0.4, linetype = &quot;dashed&quot;)+ facet_grid(. ~ sex) + hrbrthemes::theme_ipsum() ## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. ## ℹ Please use `linewidth` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. 25.2.1 Comparisons with Density plots You can compare a small number of categories with density plots, usually 5 or less. https://www.r-graph-gallery.com/density-plot You can set color and fill to the same variable. But you may have a lot of overlap. It may help to make these semi-transparent. It can be problematic if there is a lot of overlap and multiple categories, as they can hide each other A mirror density chart can work well for 2 categories. You can do small multiples with facet_wrap You can even do a stacked density chart. This is not great, as after the first layer, the baseline changes, and it ban be hard to compare. Can work for large differences between categories, but not good for small differences. 25.3 Comparing Distributions Across Categories Several geoms are designed for comparisons of distributions across multiple categories, and are more useful for this than histograms or density plots, particularly when the number of categories is large. These include Boxplots Ridgeline plots Violin plots All of these can be combined with plotting of individual data points to give both a summary of the distribution and visualization of the actual data. This can be important, especially when the number data points varies across categories, or of the number of data points are quite low in one part of the distribution. 25.4 Boxplots Boxplots are quick summaries of a distribution. They quickly give you a median line, and 25th and 75th percentiles (the ends of the box). The upper whisker is found at the last observation less than or equal to the 75th percentile plus 1.5* the IQR (interquartile range, or 75th-25th percentile). The lower whisker is found at the last observation less than or equal to the 25th percentile minus 1.5* the IQR. Points beyond the whiskers are considered “outliers”. Boxplots can be useful to compare distributions of a continuous variable across several categories. However, boxplots have several weakesses. Boxplots assume that your data are unimodal, and hide the distribution of your data points, which can be problematic if they are truly bimodal or trimodal (or even more local modes! (as in a Likert scale). Boxplots can also hide the number of observations, which may be quite different between categories. When this is an issue, it can be helpful to add data points, with geoms like jitter, beeswarm, or sina, or in ridgeline/raincloud plots. If there are a lot of overlapping points, you may need to set the geom_point alpha argument to a low value (0.05-0.5), rather than the default transparency of one. It can help the viewer of box plots to arrange your categories by order of their median, to make the interpretation easier. If your categories have a natural order (like months of the year), you will generally be better off keeping this natural order than ordering by median. 25.5 Violin Plots https://www.r-graph-gallery.com/violin_and_boxplot_ggplot2.html Violin Plots are essentially distribution plots that are symmetrical around their baseline. They are better than boxplots in that they don’t hide the distribution of your data points, and they don’t assume that the data are unimodal. You can see multiple local clusters if they are present in your data. A bimodal distribution will give you a shape that is reminiscent of a violin body. Violin plots can be helpful for comparing the distribution of a continuous variable across many categories. Violin plots can hide the number of observations, which may be quite different between categories. When this is an issue, it can be helpful to add points, with geoms like jitter, beeswarm, or sina, or in ridgeline/raincloud plots. If there are a lot of overlapping points, you may need to set the geom_point alpha argument to a low value (0.05-0.5), rather than the default transparency of one. Violin plots are helpful when you are comparing many groups. 25.6 Ridgeline Plots https://www.r-graph-gallery.com/ridgeline-plot Ridgeline plots are a nice way to show the distribution of a continuous variable, and compare distributions across several categories. Ridgeline plots are great for showing off striking differences between categories. Because they can have some overlap, they are not best for small or subtle differences. Note that you can add the N in each category to the category label when the number in each category varies. cmv %&gt;% ggplot(aes(x = time.to.transplant, y = diagnosis)) + geom_density_ridges(scale = 0.9) ## Picking joint bandwidth of 8.96 ## Warning: Removed 1 row containing non-finite outside the scale range ## (`stat_density_ridges()`). 25.6.1 Including Plots You can also embed plots, for example: cmv %&gt;% ggplot(aes(x = time.to.agvhd, y = diagnosis, fill= stat(x))) + geom_density_ridges_gradient(scale = 0.9) + scale_fill_viridis_c(name = &quot;Days&quot;, option = &quot;A&quot;) + labs(title = &quot;Time to AGvHD in Days&quot;) ## Warning: `stat(x)` was deprecated in ggplot2 3.4.0. ## ℹ Please use `after_stat(x)` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. ## Picking joint bandwidth of 8.13 25.6.2 Including Points You can also add data points, for example: cmv %&gt;% ggplot(aes(x = time.to.cmv, y = diagnosis, fill= stat(x))) + geom_density_ridges_gradient(scale = 0.5, jittered_points = TRUE, position = &quot;raincloud&quot;, alpha = 0.5) + scale_fill_viridis_c(name = &quot;Days&quot;, option = &quot;B&quot;) + labs(title = &quot;Time to CMV in Days&quot;) + theme_ridges() ## Picking joint bandwidth of 8.96 25.6.3 Including Points You can also add data points, for example: cmv %&gt;% ggplot(aes(x = CD8.dose, y = diagnosis, fill= stat(x))) + geom_density_ridges_gradient(scale = 0.9) + scale_fill_viridis_c(name = &quot;Days&quot;, option = &quot;C&quot;) + labs(title = &quot;CD8 Dose&quot;) + theme_ridges() ## Picking joint bandwidth of 0.249 25.6.4 Including Points You can also add data points, for example: cmv %&gt;% ggplot(aes(x = CD3.dose, y = diagnosis, fill= stat(x))) + geom_density_ridges_gradient(scale = 0.7, jittered_points = TRUE, position = &quot;raincloud&quot;) + scale_fill_viridis_c(name = &quot;Days&quot;, option = &quot;D&quot;) + labs(title = &quot;CD3 Dose&quot;) + theme_ridges() ## Picking joint bandwidth of 0.761 25.6.5 Including Points You can also add data points, for example: cmv %&gt;% ggplot(aes(x = TNC.dose, y = diagnosis, fill= stat(x))) + geom_density_ridges_gradient(scale = 2, jittered_points = TRUE, position = &quot;points_sina&quot;, alpha = 0.7) + scale_fill_viridis_c(name = &quot;Days&quot;, option = &quot;E&quot;) + labs(title = &quot;TNC Dose&quot;) + theme_ridges() ## Picking joint bandwidth of 2.19 "],["bivariate-ggplot2-scatterplots-to-visualize-relationships-between-variables.html", "Chapter 26 Bivariate ggplot2 Scatterplots to Visualize Relationships Between Variables 26.1 Packages used in this Chapter 26.2 Data Exploration and Validation (DEV) 26.3 Scatterplots 26.4 Mapping More Variables 26.5 Inheritance and Layering in ggplot2 26.6 Aesthetic mapping Micro-Quiz! 26.7 Controlling Point Shape, Size, and Color Manually", " Chapter 26 Bivariate ggplot2 Scatterplots to Visualize Relationships Between Variables 26.1 Packages used in this Chapter Use library(packagename) to load these packages, and install.packages(\"packagename\") to install these if they are not already installed. {tidyverse} {medicaldata} {ggpubr} 26.2 Data Exploration and Validation (DEV) When you first encounter a new dataset, it is often helpful to start with Data Exploration and Validation (DEV) . Note that DEV is different from EDA (Exploratory Data Analysis), which involves rummaging through your data (often with plots) and generating new hypotheses, performing multiple tests, and essentially data mining. DEV has specific goals, which include identifying variables with problematic values (NA, outliers), unexpected distributions (sometimes bimodal), and less-than-helpful variable names or data types. In this chapter, we will look at investigating pairs of continuous variables, looking for relationships and correlations. We will also add some new skills to help you customize your scatter plots, and to learn to think conceptually about building up ggplots in layers. 26.3 Scatterplots One of the most helpful ways to get started in exploring relationships between continuous variables is to explore pairs of continuous variables with a scatterplot. These are accomplished with geom_point() in ggplot2. A scatterplot allows you to see the relationship between two continuous variables, and is a good way to get started with ggplot. Let’s start by looking at the realtionship between the number of colon polyps found in participants in a clinical trial and their age. We start by building up layers data layer - tell R which dataset to use ggplot command - start a ggplot aesthetic mapping layer (ask R to map variables) geom layer (how to draw the datapoints) In this example, we will map the participant age to x, and the baseline number of polyps to y, and use geom_point as the geom. medicaldata::polyps %&gt;% ggplot() + aes(x = age, y = baseline) + geom_point() Copy this code to your RStudio console, and run it to get this plot. This gives us a very basic scatterplot, with a y-axis range between 7 and 318 polyps (that would have been a looooong colonoscopy if you tried to remove all 318 polyps). Not a dramatic correlation, though you could imagine a downward slope with age if you fitted a linear regression line. Though this is likely pulled way up at age 18 by the participant with many polyps. Now try changing the code to map y to the number of polyps at 3 months (number3m). The code example below adds a linear regression line with method = \"lm\". lm stands for linear model. Add a smoothing line to your code in the Console. Try method = \"loess\" for a different look, rather than forcing a linear relationship. polyps %&gt;% ggplot() + aes(x = age, y = baseline) + geom_point() + geom_smooth(method = &#39;loess&#39;) ## `geom_smooth()` using formula = &#39;y ~ x&#39; Does it matter whether you map x or y first, in the aes() function? Try swapping these to find out. 26.3.1 Micro-quiz! (correct answers will be green!) X must always be mapped before Y in ggplot2 aes() functions TRUEFALSE The medicaldata::polyps line of code represents the geomdataaesthetic layer of the ggplot. The aes() function is the aesthetic layer, which pipesgluesmaps data variables to visual properties (aesthetics) of the plot. 26.4 Mapping More Variables You can add more information to a plot by mapping additional variables, which can help you make comparisons. You can map the treatment variable (sulindac or placebo) to the color aesthetic for the points. You just add color = varname to map a new variable named (varname) to the color. Try this by modifying the code below. Remember to put a comma between mappings, and to put your aesthetic mapping inside the aes() function. Then run the code chunk to generate a plot. polyps %&gt;% ggplot() + aes(x = age, y = number3m) + geom_point(color = &#39;blue&#39;) + geom_smooth(method = &#39;lm&#39;) ## `geom_smooth()` using formula = &#39;y ~ x&#39; If this did not work, put , color = treatment after y = number3m inside the aes() parentheses. This should produce a plot with 2 colors of points, for placebo and sulindac, and 2 smoothed lines, one for each treatment. While the confidence intervals overlap, this does suggest that participants receiving sulindac might have fewer polyps. Try this for the 12 month polyp count, using y = number12m. This should look even more impressive. You can map the treatment variable to other aesthetics (visual properties) of the plot. Try this out with a few options: mapping treatment to shape (and color!) mapping number3m to size, and/or alpha NOTE that alpha is a term for the degree of opacity of a visual object, with zero = transparent. NOTE that a variable can be mapped to more than one visual property. BUT if you try to map more than one variable to a single visual property within the aes() function, the subsequent mappings will be ignored. The 1st mapping (within one aes) wins. polyps %&gt;% ggplot() + aes(x = age, y = number3m) + geom_point() If you try to map a variable to a visual property outside of the aes() function, it will be treated as a constant, not a variable, which can lead to strange results. Try moving color = treatment to a spot inside of the geom_point() function parentheses. Or even better, try color = 'blue' to within geom_point(). What happens? 26.5 Inheritance and Layering in ggplot2 Adding layers to a ggplot allows you to increase the complexity and customize a plot, building it up, layer by layer. This layered structure allows you to map a visual property (aesthetic) once, in the ggplot layer, or in the aes() layer. All subsequent layers inherit these visual properties, unless you specify differently. So your geom_point() layer inherits the mappings from the aesthetic layer. But if you want to, you can over-write the inherited properties, by stating a different aes() mapping. See the example below - the color mapping in geom_point over-writes the color mapping in the aesthetic layer, because it is in a later layer. In this case, the last layer wins. polyps %&gt;% ggplot() + aes(x = age, y = number3m, color = treatment) + geom_point(aes(color = age)) You can choose to do this deliberately. In the case below, this is done to make a single regression line that is purple, rather than the default black color. Because the color in geom_smooth() is set to a constant, you only get one (overall) regression line. Also notice that the color of the points is a bit dimmer than the previous plot. This is because the geom_smooth gray confidence interval from the linear regression is covering most of the points. Test this out by moving the geom_point() layer to the line after geom_smooth(). This should bring these points to the front. Whatever layer is last in the code is plotted on top. You can also ‘lighten up’ the confidence interval by setting the alpha for geom_smooth() to 0.1 (on a 0 to 1 opacity scale) polyps %&gt;% ggplot() + aes(x = age, y = number3m, color = treatment) + geom_point() + geom_smooth(method = &#39;lm&#39;, color = &#39;purple&#39;) 26.6 Aesthetic mapping Micro-Quiz! (correct answers will be green!) Which one of the following is NOT a visual property that you can map a variable to in a scatterplot fillcolorshapealphadatasize All mapping of variables to visual properties must be within the parentheses of the ggplotgeom_pointcoloraesscale function. You should assign visual properties to constant values, like color = \"blue\" or size = 2 within ggplot() or the geom_point() function, but outside of an aes() function TRUEFALSE. 26.7 Controlling Point Shape, Size, and Color Manually There are 25 point shapes available in R, which can be seen here, with the help of the show_point_shapes() function from {ggpubr}: ggpubr::show_point_shapes() Notice that the shapes 21-25 have an outline color, and can be filled with a different color, while shapes 1-20 only have a single color option. By default, ggplot2 selects shapes and colors for you automatically (in order, 1-25, for shapes, and in the order of the default color palette for colors), so that you don’t have to worry about specifying these. But if you want to take the wheel, you can have more control of the shape, size, and color of your scatterplot points with scale functions. Let’s try this with a scatterplot using the cmv dataset. We will look at the relationship between the CD34 cell dose at the time of bone marrow transplant, and the time to development of CMV. For our base plot, we will map donor cmv status to color. Since the donor.cmv variable is stored as a double it is continuous, but we actually want this as a dichtomous 0/1 variable, so we will recode this ‘on the fly’ in the aesthetic mapping as factor(donor.cmv) instead of just donor.cmv. You can remove factor() from the code below to how this helps. cmv %&gt;% ggplot() + aes(y = CD34.dose, x = time.to.cmv, color = factor(donor.cmv)) + geom_point() + geom_smooth(method = &#39;lm&#39;) These data show an interaction between cmv.donor status and the CD34.dose. In folks who receive a CMV+ donor BMT, higher doses of CD34 cells are associated with a delay in the onset of CMV, but this is not the case with CMV negative BMT donors. 26.7.1 Manual Shapes To control the point shapes, let’s replace the geom_smooth line with scale_shape_manual() and set the values to 22 and 25. We also have to set an aesthetic mapping for shape. Let’s map this to the donor.sex variable. cmv %&gt;% ggplot() + aes(y = CD34.dose, x = time.to.cmv, color = factor(donor.cmv), shape = factor(donor.sex)) + geom_point() + scale_shape_manual(values = c(22, 25)) Again, because donor.sex is stored as a numeric variable, we have to make it into a dichotomous factor on the fly in order to map this variable to shapes. Note that when you use the fillable shapes (21-25), you can also map a fill aesthetic to different color properties, separate from the color outline of the shape. You can also see that encoding donor.sex as 0 or 1 is not terribly helpful. It is often helpful to store data in #_label format, like 0_male, 1_female, to keep the encoding clear. You can extract the numeric portion with parse_number() if you want to do math on the variable later. If you have a lot of categories (like the 13 diagnosis categories in the cmv dataset), it can be easier to let ggplot handle the shapes, rather than having to specify 13 shapes. 26.7.2 Manual Sizes Let’s manually control the sizes of points - use the same approach, with scale_size_manual(). We want to emphasize the points with donor.cmv = 1, to see how this relates to the outcome variable, cmv, which is mapped to color. Run the scatter plot below as an example, then edit the code to map size to factor(donor.cmv). Then add a line of code for scale_size_manual(), and set the values to 1 and 4. cmv %&gt;% ggplot() + aes(y = age, x = time.to.transplant, size = CD8.dose, color = factor(cmv)) + geom_point() 26.7.3 Manual Color Let’s manually control the colors - use the same approach, with scale_color_manual(). Run the scatter plot below as an example, then edit the code to map color to factor(donor.cmv). Then add a line of code for scale_color_manual(), and set the values to “green” and “red”. cmv %&gt;% ggplot() + aes(y = age, x = time.to.transplant, color = diagnosis) + geom_point() "],["extensions-to-ggplot.html", "Chapter 27 Extensions to ggplot 27.1 Goals for this Chapter 27.2 Packages Needed for this chapter 27.3 A Flipbook of Where We Are Going With ggplot Extensions 27.4 A Waffle Plot 27.5 An Alluvial Plot 27.6 Lollipop Plots 27.7 Dumbbell Plots 27.8 Spaghetti Plots with Summary Smoothed Lines for Change Over Time 27.9 Swimmer Plots 27.10 Adding Significance Comparisons with {ggsignif}", " Chapter 27 Extensions to ggplot The {ggplot2} package is made to be extensible - so that other people can write packages that add new (often niche) geoms for specific purposes. This chapter is a short tour of some of the neat extensions people have written, and when and where they can be useful. Some of these are distinct packages, and others are just cool ways to use ggplot. Please check out the links to the individual packages to learn more, as we will frequently just scratch the surface of what is available. 27.1 Goals for this Chapter learn how and why to use waffle plots learn how and when to use alluvial plots learn how and when to use lollipop plots learn how and when to use dumbbell plots learn how and when to use spaghetti plots learn how and when to use swimmer plots 27.2 Packages Needed for this chapter You will need {tidyverse}, {medicaldata}, {waffle}, {ggalluvial}, {ggalt}, {ggrepel}, {ggforce}, {ggalt}, {ggtext}. {ggsignif}, {ggbump}, {survminer}, {ggcorrplot}, {plotROC}, {directlabels}, {geomtextpath}, {ggheatmap}, {ggQC}, {ggupset}, {plotly}, and {gganimate}. # install.packages(&#39;tidyverse&#39;) # install.packages(&#39;medicaldata&#39;) library(tidyverse) library(medicaldata) library(ggrepel) library(ggforce) library(ggalt) library(ggtext) library(ggsignif) library(ggbump) library(survminer) library(ggmosaic) library(ggcorrplot) library(plotROC) library(directlabels) library(geomtextpath) library(ggheatmap) library(ggQC) library(ggupset) library(ComplexUpset) library(plotly) library(gganimate) 27.3 A Flipbook of Where We Are Going With ggplot Extensions See the flipbook below, which contains some examples of what you can do with ggplot extensions. You can use the the icons in the bottom bar to expand to full screen or share this flipbook. If you are in full screen mode, you can use the Home button to go the the first slide and the End button to go to the last slide, and the Escape key to get out of full screen mode. 27.3.1 MAKE FLIPBOOK 27.4 A Waffle Plot Why is this better than a bar plot or a dotplot? In order to represent counts, or individual participants in a trial, a bar plot is a bit deceiving. It appears to be a continuous variable. But each participant in a clinical trial is a discrete individual. A bar plot can be helpful for very large numbers, but for manageable numbers it is a bit of a misrepresentation. A dotplot, with geom_dotplot, would seem like a good option, but it only displays proportions, not counts. In order to show outcomes for distinct individual participants, a waffle plot comes in handy. These have become quite popular in data journalism to represent counts. Let’s start with a waffle plot of library(waffle) indo_rct &lt;- medicaldata::indo_rct scaler &lt;- 1 indo_data &lt;- indo_rct %&gt;% group_by(outcome, rx) %&gt;% count() %&gt;% mutate(n = n/scaler) indo_data %&gt;% #mutate(site = case_when(site == &quot;1_UM&quot; ~ &quot;Michigan&quot;, site == &quot;2_IU&quot; ~ &quot;Indiana&quot;, site == &quot;3_UK&quot; ~ &quot;Kentucky&quot;, site == &quot;4_Case&quot; ~ &quot;Case&quot;)) %&gt;% mutate(rx = str_sub(rx, 3L, 10L)) %&gt;% ggplot(aes(fill = outcome, values = n)) + geom_waffle(color = &quot;white&quot;, size=0.25, n_rows = 10, na.rm = TRUE, flip = TRUE, radius = unit(0.7, units = &quot;mm&quot;)) + facet_wrap(~rx, nrow = 1, strip.position = &quot;bottom&quot;) + scale_x_discrete() + scale_y_continuous(breaks = seq(10, 40, 10), labels = function(x) format(x * 10*scaler, scientific = F), expand = c(0,0)) + scale_fill_manual(values = c(&quot;#1a85ff&quot;, &quot;#d41159&quot; )) + coord_equal() + labs( title = &quot;Post-ERCP Outcomes by Treatment: &lt;br&gt;&lt;span style = &#39;color:#d41159;&#39;&gt;Pancreatitis&lt;/span&gt;, or &lt;span style = &#39;color:#1a85ff;&#39;&gt;No Event&lt;/span&gt;, &lt;br&gt;in the Rectal Indomethacin Trial&quot;, subtitle = sprintf(&quot;One square = %s Outcome, Each Row = 10 Outcomes&quot;, scaler), x = &quot;&quot;, y = &quot;&quot;, caption = &quot;Data: NEJM 2012; 366:1414-1422, Elmunzer&quot; ) + theme_minimal() + #theme_ipsum_rc()+ theme(panel.grid = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.ticks.y = element_line(), plot.title = element_markdown(), legend.position = &quot;none&quot;) + guides(fill = guide_legend(reverse = TRUE)) The waffle plot is an interesting hack of ggplot. The geom_waffle() is actually a faceted plot, with one row of facets (examine the code above). You can change the scaler constant to make each square count for N cases. You can learn more about the many capabilities of the {waffle} package - including pictograms and an alternative to pie charts - here. Note that we have used colors in the title in place of a legend, by coloring the outcomes with the corresponding colors, using the {ggtext} extension package, which allows you to add color, backgrounds, images, bold face, or italic face to text in ggplots, using markdown/HTML tags. You can learn more about the many capabilities of the {ggtext} package and what it can do here. 27.5 An Alluvial Plot An alluvial plot depicts flow, like a river, which can split off branches and re-unite streams. This kind of plot can be helpful to show patient flow from one state to the next. This requires the {ggalluvial} package, which you may need to install and then load with the library() function. The example below shows the flow of patients with chest pain from ED triage to hospitalization and an outcome of survived or died, stratified by gender. datafr &lt;- tibble::tribble( ~gender, ~triage, ~next_day, ~outcome, ~count, &quot;Male&quot;, &quot;ER&quot;, &quot;Hospitalized&quot;, &quot;Survived&quot;, 211, &quot;Male&quot;, &quot;ER&quot;, &quot;Hospitalized&quot;, &quot;Survived&quot;, 43, &quot;Male&quot;, &quot;ER&quot;, &quot;Discharged&quot;, &quot;Died&quot;, 280, &quot;Male&quot;, &quot;ER&quot;, &quot;Discharged&quot;, &quot;Died&quot;, 15, &quot;Male&quot;, &quot;Observation&quot;, &quot;Hospitalized&quot;, &quot;Survived&quot;, 67, &quot;Male&quot;, &quot;Observation&quot;, &quot;Hospitalized&quot;, &quot;Died&quot;, 11, &quot;Male&quot;, &quot;Observation&quot;, &quot;Discharged&quot;, &quot;Survived&quot;, 415, &quot;Male&quot;, &quot;Observation&quot;, &quot;Discharged&quot;, &quot;Died&quot;, 5, &quot;Female&quot;, &quot;ER&quot;, &quot;Hospitalized&quot;, &quot;Survived&quot;, 219, &quot;Female&quot;, &quot;ER&quot;, &quot;Hospitalized&quot;, &quot;Survived&quot;, 33, &quot;Female&quot;, &quot;ER&quot;, &quot;Discharged&quot;, &quot;Died&quot;, 250, &quot;Female&quot;, &quot;ER&quot;, &quot;Discharged&quot;, &quot;Died&quot;, 45, &quot;Female&quot;, &quot;Observation&quot;, &quot;Hospitalized&quot;, &quot;Survived&quot;, 88, &quot;Female&quot;, &quot;Observation&quot;, &quot;Hospitalized&quot;, &quot;Died&quot;, 27, &quot;Female&quot;, &quot;Observation&quot;, &quot;Discharged&quot;, &quot;Survived&quot;, 402, &quot;Female&quot;, &quot;Observation&quot;, &quot;Discharged&quot;, &quot;Died&quot;, 14) %&gt;% mutate(gender = as_factor(gender), triage = as_factor(triage), next_day = as_factor(next_day), outcome = as_factor(outcome)) ggplot(datafr, aes(y = count, axis1 = gender, axis2 = triage, axis3 = next_day)) + geom_alluvium(aes(fill = outcome), width = 1/12) + geom_stratum(width =1/12, fill = &quot;black&quot;, color = &quot;grey&quot;) + geom_label(stat = &quot;stratum&quot;, aes(label = after_stat(stratum))) + scale_x_discrete(limits = c(&quot;gender&quot;, &quot;triage&quot;, &quot;next_day&quot;), expand = c(.10, .10)) + ggtitle(&quot;Patients Presenting with Chest Pain&quot;) + scale_fill_manual(values = c(&quot;#1a85ff&quot;, &quot;#d41159&quot; )) Now try this yourself. Copy the code below (click on the copy icon in the top right of the code chunk), paste it into your RStudio IDE, and edit to: show the additive effects of ethanol use, cirrhosis, and HCC on death rates. Code the outcome as Survived or Died. datafr &lt;- tibble::tribble( ~Ethanol_Use, ~Cirrhosis, ~HCC, ~outcome, ~count, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Survived&quot;, 4, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Died&quot;, 28, &quot;Yes&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Survived&quot;, 12, &quot;Yes&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Died&quot;, 45, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Survived&quot;, 2, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Died&quot;, 4, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Survived&quot;, 57, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Died&quot;, 26, &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Survived&quot;, 3, &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Died&quot;, 10, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Survived&quot;, 32, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Died&quot;, 26, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Survived&quot;, 1, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Died&quot;, 3, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Survived&quot;, 297, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Died&quot;, 15 ) %&gt;% mutate(Ethanol_Use = as_factor(Ethanol_Use), Cirrhosis = as_factor(Cirrhosis), HCC = as_factor(HCC), outcome = as_factor(outcome)) ggplot(datafr, aes(y = count, axis1 = ____, axis2 = ____, axis3 = ____)) + geom_alluvium(aes(fill = outcome), width = 1/12) + geom_stratum(width =1/12, fill = &quot;black&quot;, color = &quot;grey&quot;) + geom_label(stat = &quot;stratum&quot;, aes(label = after_stat(stratum))) + scale_x_discrete(limits = c(&quot;____&quot;, &quot;____&quot;, &quot;____&quot;), expand = c(.10, .10)) + ggtitle(&quot;Patients Presenting with Hepatitis C Infection&quot;) + scale_fill_manual(values = c(&quot;#1a85ff&quot;, &quot;#d41159&quot; )) ## Error in parse(text = input): &lt;text&gt;:26:32: unexpected input ## 25: ggplot(datafr, ## 26: aes(y = count, axis1 = __ ## ^ alluvial1-solution datafr &lt;- tibble::tribble( ~Ethanol_Use, ~Cirrhosis, ~HCC, ~outcome, ~count, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Survived&quot;, 4, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Died&quot;, 28, &quot;Yes&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Survived&quot;, 12, &quot;Yes&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Died&quot;, 45, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Survived&quot;, 2, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Died&quot;, 4, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Survived&quot;, 57, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Died&quot;, 26, &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Survived&quot;, 3, &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Died&quot;, 10, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Survived&quot;, 32, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Died&quot;, 26, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Survived&quot;, 1, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Died&quot;, 3, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Survived&quot;, 297, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Died&quot;, 15 ) %&gt;% mutate(Ethanol_Use = as_factor(Ethanol_Use), Cirrhosis = as_factor(Cirrhosis), HCC = as_factor(HCC), outcome = as_factor(outcome)) ggplot(datafr, aes(y = count, axis1 = Ethanol_Use, axis2 = Cirrhosis, axis3 = HCC)) + geom_alluvium(aes(fill = outcome), width = 1/12) + geom_stratum(width =1/12, fill = &quot;black&quot;, color = &quot;grey&quot;) + geom_label(stat = &quot;stratum&quot;, aes(label = after_stat(stratum))) + scale_x_discrete(limits = c(&quot;Ethanol_Use&quot;, &quot;Cirrhosis&quot;, &quot;HCC&quot;), expand = c(.10, .10)) + ggtitle(&quot;Patients Presenting with Hepatitis C Infection&quot;) + scale_fill_manual(values = c(&quot;#1a85ff&quot;, &quot;#d41159&quot; )) Now try this again. Copy the code below (click on the copy icon in the top right of the code chunk), paste it into your RStudio IDE, and edit to: show the progression of inpatients through therapies for Acute Severe Ulcerative colitis through the first 90 days of therapy. Code the outcome as Intact or Colectomy. Use the examples above to build your alluvial plot datafr &lt;- tibble::tribble( ~Day_1_Therapy, ~Day_7_Therapy, ~Day_28_Therapy, ~Day_90_Therapy, ~outcome, ~count, &quot;IVCS + Upa&quot;, &quot;Pred + Upa&quot;, &quot;Upa&quot;, &quot;Upa&quot;, &quot;Intact&quot;, 19, &quot;IVCS + Upa&quot;, &quot;Pred + Upa&quot;, &quot;Upa&quot;, NA, &quot;Colectomy&quot;, 3, &quot;IVCS + Upa&quot;, &quot;Pred + Upa&quot;, NA, NA, &quot;Colectomy&quot;, 4, &quot;IVCS + Upa&quot;, &quot;Cyclo&quot;, &quot;Cyclo + IFX&quot;, &quot;IFX&quot;, &quot;Intact&quot;, 12, &quot;IVCS + Upa&quot;, &quot;IFX&quot;, &quot;IFX + Aza&quot;, &quot;IFX + Aza&quot;, &quot;Intact&quot;, 9, &quot;Upa&quot;, &quot;Upa&quot;, &quot;Upa&quot;, &quot;Upa&quot;, &quot;Intact&quot;, 12, &quot;Upa&quot;, &quot;Upa&quot;, &quot;Upa&quot;, NA, &quot;Colectomy&quot;, 5, &quot;Upa&quot;, &quot;Upa&quot;, NA, NA, &quot;Colectomy&quot;, 7, &quot;Upa&quot;, &quot;Cyclo&quot;, &quot;Cyclo + IFX&quot;, &quot;IFX&quot;, &quot;Intact&quot;, 9, &quot;Upa&quot;, &quot;IFX&quot;, &quot;IFX + Aza&quot;, &quot;IFX + Aza&quot;, &quot;Intact&quot;, 7 ) %&gt;% mutate(Day_1_Therapy = as_factor(Day_1_Therapy), Day_7_Therapy = as_factor(Day_7_Therapy), Day_28_Therapy = as_factor(Day_28_Therapy), Day_90_Therapy = as_factor(Day_90_Therapy), outcome = as_factor(outcome)) alluvial2-solution datafr &lt;- tibble::tribble( ~Day_1_Therapy, ~Day_7_Therapy, ~Day_28_Therapy, ~Day_90_Therapy, ~outcome, ~count, &quot;IVCS + Upa&quot;, &quot;Pred + Upa&quot;, &quot;Upa&quot;, &quot;Upa&quot;, &quot;Intact&quot;, 19, &quot;IVCS + Upa&quot;, &quot;Pred + Upa&quot;, &quot;Upa&quot;, NA, &quot;Colectomy&quot;, 3, &quot;IVCS + Upa&quot;, &quot;Pred + Upa&quot;, NA, NA, &quot;Colectomy&quot;, 4, &quot;IVCS + Upa&quot;, &quot;Cyclo&quot;, &quot;Cyclo + IFX&quot;, &quot;IFX&quot;, &quot;Intact&quot;, 12, &quot;IVCS + Upa&quot;, &quot;IFX&quot;, &quot;IFX + Aza&quot;, &quot;IFX + Aza&quot;, &quot;Intact&quot;, 9, &quot;Upa&quot;, &quot;Upa&quot;, &quot;Upa&quot;, &quot;Upa&quot;, &quot;Intact&quot;, 12, &quot;Upa&quot;, &quot;Upa&quot;, &quot;Upa&quot;, NA, &quot;Colectomy&quot;, 5, &quot;Upa&quot;, &quot;Upa&quot;, NA, NA, &quot;Colectomy&quot;, 7, &quot;Upa&quot;, &quot;Cyclo&quot;, &quot;Cyclo + IFX&quot;, &quot;IFX&quot;, &quot;Intact&quot;, 9, &quot;Upa&quot;, &quot;IFX&quot;, &quot;IFX + Aza&quot;, &quot;IFX + Aza&quot;, &quot;Intact&quot;, 7 ) %&gt;% mutate(Day_1_Therapy = as_factor(Day_1_Therapy), Day_7_Therapy = as_factor(Day_7_Therapy), Day_28_Therapy = as_factor(Day_28_Therapy), Day_90_Therapy = as_factor(Day_90_Therapy), outcome = as_factor(outcome)) ggplot(datafr, aes(y = count, axis1 = Day_1_Therapy, axis2 = Day_7_Therapy, axis3 = Day_28_Therapy, axis4 = Day_90_Therapy)) + geom_alluvium(aes(fill = outcome), width = 1/12) + geom_stratum(width =1/12, fill = &quot;black&quot;, color = &quot;grey&quot;) + geom_label(stat = &quot;stratum&quot;, aes(label = after_stat(stratum))) + scale_x_discrete(limits = c(&quot;Day_1_Rx&quot;, &quot;Day_7_Rx&quot;, &quot;Day_28_Rx&quot;, &quot;Day_90_Rx&quot;), expand = c(.18,0.1)) + ggtitle(&quot;Patients Presenting with Acute Severe UC&quot;) + scale_fill_manual(values = c(&quot;#1a85ff&quot;, &quot;#d41159&quot; )) 27.6 Lollipop Plots While bar charts are quite popular for comparing continuous variables across categories, they have limitations. Humans are good at comparing length, but the bars add width, which is a distraction. Bar charts are also often used for counts, and it is not always clear whether a continuous or a discrete count variable is being plotted (a waffle chart can clear up discrete counts). For a continuous variable, you have a single point estimate (the end of the bar), and it is better to emphasize this estimate, without giving up the benefit of comparing lengths (which humans are good at). A lollipop plot emphasizes the continuous value, while de-emphasizing the width of a bar. Let’s look at an example below. medicaldata::covid_testing %&gt;% mutate(positive = case_when(ct_result &lt; 45 ~ 1, ct_result &gt;= 45 ~ 0)) %&gt;% group_by(demo_group) %&gt;% count(positive) %&gt;% filter(!is.na(positive)) %&gt;% mutate(freq = n/sum(n)) %&gt;% filter(positive==1) %&gt;% ggplot() + aes(x = fct_reorder(demo_group, freq), y = freq) + geom_lollipop(point.size = 5, point.colour = &quot;red&quot;) + scale_y_continuous(labels = scales::percent_format(scale = 100)) + labs(y = &quot;Percent Positive&quot;, x = &quot;Demographic Category&quot;) ## Warning: Using the `size` aesthetic with geom_segment was deprecated in ggplot2 3.4.0. ## ℹ Please use the `linewidth` aesthetic instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. 27.7 Dumbbell Plots The Dumbbell Plot is a visualization that shows change between two points (usually 2 time points) in our data. It gets the name because of its dumbbell shape. It’s a great way to show changes in data between two points (think start and finish). Note that a bit of data wrangling needs to be done to produce the correct data format for geom_dumbbell(). You may need to pivot_wider() to get 2 columns of data on distinct dates (in this case, month 1 vs month 4). See the data wrangling below to get mean age for these 2 months. medicaldata::covid_testing %&gt;% filter(!str_detect(patient_class, &quot;surgery&quot;)) %&gt;% mutate(pan_month = ceiling((pan_day)/30)) %&gt;% filter(pan_month %in% c(1,4)) %&gt;% pivot_wider(names_from = pan_month, values_from = age, id_cols = patient_class, values_fn = function(x) mean(x, na.rm = TRUE), names_prefix = &quot;month_&quot;) -&gt; dumb_covid_data dumb_covid_data ## # A tibble: 6 × 3 ## patient_class month_1 month_4 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 inpatient 3.42 8.68 ## 2 not applicable 9.11 24.6 ## 3 emergency 2.25 13.5 ## 4 recurring outpatient 2.21 6.93 ## 5 observation 2.55 12.2 ## 6 outpatient 6.10 19.3 dumb_covid_data %&gt;% ggplot(aes(x = month_1, xend = month_4, y = patient_class, group = patient_class)) + geom_dumbbell(size = 2, # size of line size_x =4, size_xend = 4, # dot size colour = &quot;lightblue2&quot;, #line color colour_x = &quot;dodgerblue&quot;, # 1st dot color colour_xend = &quot;blue&quot;) + # end dot color labs(x = &quot;Mean Patient Age&quot;, y = &quot;Patient Class&quot;, title = &quot;Increases in Mean Patient Age at a Pediatric Hospital \\nfrom Month 1 to Month 4 of the Pandemic&quot;, subtitle = &quot;Keeping the Young Ones Safe at Home&quot;) + xlim(1,25) + # set limits on x axis theme_linedraw() + theme(plot.title.position = &quot;plot&quot;) # align title and subtitle to left edge, rather than to plot area+ Now, this is a nice basic dumbbell plot. But you may want to make the direction of change from pre to post a bit more obvious with arrows. We will start with loading some packages and creating a dataset with a ‘change’ variable for the change in C-reactive protein between day 1 and day 5 of a hospitalization for acute severe ulcerative colitis. library(tidyverse) library(ggtext) dat &lt;- tibble::tribble(~id, ~crp1, ~crp5, &quot;001&quot;, 47, 4, &quot;002&quot;, 14, 58, &quot;003&quot;, 34, 6, &quot;004&quot;, 129, 12, &quot;005&quot;, 81, 3, &quot;006&quot;, 65, 7) dat %&gt;% mutate(change = crp5-crp1) %&gt;% mutate(linedir = case_when(change&lt;0 ~ -1, TRUE ~ 1)) -&gt; dat To help plot the points, we will add a long version of this simple dataset, created with pivot_longer. dat_long &lt;- dat %&gt;% pivot_longer(starts_with(&quot;crp&quot;), names_prefix = &quot;crp&quot;, names_to = &quot;day&quot;) Now we will make the arrow plot (a fancier version of the dumbbell plot, with added directionality). We will use ggtext to help us turn our title into a color legend. #set custom colors custom_days &lt;- c(&quot;#1e90ff&quot;, &quot;#1874cd&quot;) custom_dir &lt;- c(&quot;limegreen&quot;, &quot;firebrick&quot;) ggplot() + # geom segment will plot arrows from the dat dataset geom_segment(data = dat, aes(x = crp1, xend = crp5, y = parse_number(id), yend = parse_number(id), color = as_factor(linedir)), linewidth = 1.5, arrow = arrow(angle = 25, length = unit(0.5, &quot;cm&quot;))) + # geom point will plot the points from the dat_long dataset geom_point(data = dat_long, aes(x = value, y = parse_number(id), fill = day), size = 4, shape = 22) + theme_linedraw(base_size = 14) + theme(plot.title = element_markdown()) + # notice how we color the text in the title - this is allowed by `element_markdown` in the theme for plot.title. This makes the text function as a legend for the plot labs(x = &quot;CRP in mg/L&quot;, y = &quot;Patient ID&quot;, title = &quot;Change in CRP from &lt;span style = &#39;color:#1e90ff;&#39;&gt;Day 1&lt;/span&gt; to &lt;span style = &#39;color:#1874cd;&#39;&gt;Day 5&lt;/span&gt;&quot;) + scale_y_continuous(breaks = 1:6) + scale_x_continuous(breaks = c(0,25,50,75,100,125,150)) + theme(legend.position = &quot;none&quot;) + # turn off the actual legend scale_fill_manual(values = custom_days) + scale_color_manual(values = custom_dir) + coord_flip() # flip it so CRP goes up or down This is another variant on the dumbbell plot that helps show directionality. We have used {ggtext} to format and color words in the title so that they can work as a legend. We have used custom colors for the arrows to show good (CRP going down) and bad (CRP rising) outcomes and directionalitywith the arrowheads. 27.8 Spaghetti Plots with Summary Smoothed Lines for Change Over Time The Spaghetti Plot is a visualization that shows change over multiple time points for longitudinal data, which lets you see change in each individual as a line. It gets the name because the result (with method = “lm”) looks a bit like you scattered uncooked spaghetti (straight lines) on the plot. It’s a great way to show changes in data over multiple time points, and there are multiple variants, including summary smoothed lines. Note that a bit of data wrangling needs to be done to produce the correct data format for geom_line(). You may need to pivot_longer() to get 1 row of data for each data point, and an id for each individual (multiple points making up a line. This id will often be a patient id (pat_id). We will read in some simulated data below for 4 time points. The variables are time point, the value, ses (2 categories), elderly (2 categories), and pat_id for 8 patients. The code below will illustrate the basic spaghetti plot. dat &lt;- tibble::tribble(~time, ~value, ~ses, ~elderly, ~pat_id, 0,0,1,1,1, 1,3,1,1,1, 2,5,1,1,1, 3,8,1,1,1, 0,0,2,1,2, 1,4,2,1,2, 2,7,2,1,2, 3,9,2,1,2, 0,0,1,2,3, 1,5,1,2,3, 2,9,1,2,3, 3,11,1,2,3, 0,0,2,2,4, 1,5,2,2, 4, 2,9,2,2,4, 3,15,2,2,4, 0,0,1,1,5, 1,5,1,1,5, 2,6,1,1,5, 3,9,1,1,5, 0,0,2,1,6, 1,5,2,1,6, 2,8,2,1,6, 3,13,2,1,6, 0,0,1,2,7, 1,4,1,2,7, 2,8,1,2,7, 3,14,1,2,7, 0,0,2,2,8, 1,6,2,2,8, 2,8,2,2,8, 3,16,2,2,8) ggplot(dat, aes(x = time, y = value, group = factor(pat_id))) + geom_smooth(formula = y ~ x, se = FALSE, method = &quot;lm&quot;) + xlab(&quot;Observation Time Point&quot;) + ylab(&quot;Y&quot;) As you can see, a bit like spilled (uncooked) spaghetti, with a line for each patient. Each patient is the same (default) color. Note that it is critical to group y the patient id (group = factor(pat_id)) so that ggplot knows which points go together as a line. If you remove this bit of code for the group argument, you get chaos from geom_smooth() or geom_line(). We can also let each patient’s line follow their actual values, rather than a fitted line, with a few modifications. Try this below. ggplot(dat, aes(x = time, y = value, group = factor(pat_id))) + geom_point() + geom_line() + xlab(&quot;Observation Time Point&quot;) + ylab(&quot;Y&quot;) Now each patient is represented by a line (and points) with more detail than a fitted straight line. We can also chose to color these lines in two classes by ses (SocioEconomic Status) by setting color = factor(ses). We can make the legend neater by putting it inside the plot boundaries with theme (legend.position), and use the x and y range from 0 to 1 to position it as below. ggplot(dat, aes(x = time, y = value, group = factor(pat_id), color = factor(ses))) + geom_point() + geom_line() + theme(legend.position = c(0.8, 0.2)) + xlab(&quot;Observation Time Point&quot;) + ylab(&quot;Y&quot;) ## Warning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2 ## 3.5.0. ## ℹ Please use the `legend.position.inside` argument of `theme()` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. If we want to summarize the overall pattern, we can use a geom_smooth() with the default loess smoothing. We set the color to “black”, rather than the color of either SES group. We need to turn off the grouping with group = NULL to get a single summary line. Note the loess smoothing produces a curve. ggplot(dat, aes(x = time, y = value, group = factor(pat_id), color = factor(ses))) + geom_point() + geom_line() + theme(legend.position = c(0.8, 0.2)) + xlab(&quot;Observation Time Point&quot;) + ylab(&quot;Y&quot;) + geom_smooth(formula = y ~ x, se=FALSE, size=2, method = &quot;loess&quot;, color = &quot;black&quot;, aes(group = NULL)) If we want to get fancy, we can also make summary curves for each ses group, and facet the plot by elderly status, as below. elderly_labels &lt;- c( `1` = &quot;Young&quot;, `2` = &quot;Old&quot;) ggplot(dat, aes(x = time, y = value, group = factor(pat_id), color = factor(ses))) + geom_point() + geom_line() + theme(legend.position = c(0.8, 0.2)) + xlab(&quot;Observation Time Point&quot;) + ylab(&quot;Y&quot;) + geom_smooth(se=FALSE, size=2, method = &quot;loess&quot;, aes(group = NULL, color = factor(ses))) + facet_grid(~elderly) This gives us a plot faceted into two graphs, one for the elderly on the right, and the non-elderly on the left. Each individual is represented by points and a connected line. SES status is indicated by color, and a summary curve of each SES group is a thicker (size=1) loess curve. Now try this yourself. Copy the code below (click on the copy icon in the top right of the code chunk), paste it into your RStudio IDE, and edit to: (Note you only have to read in the data (dat) once, just copy and edit the ggplot thereafter) dat &lt;- tibble::tribble(~ patid, ~week, ~crp, ~fcp, ~flare, ~dz_type, 1,1,0.7,191,1,&quot;uc&quot;, 1,3,1.1,302,1,&quot;uc&quot;, 1,8,1.5,507,1,&quot;uc&quot;, 2,1,0.8,214,1,&quot;cd&quot;, 2,3,1.2,412,1,&quot;cd&quot;, 2,8,1.6,647,1,&quot;cd&quot;, 3,1,0.7,137,0,&quot;uc&quot;, 3,3,0.5,101,0,&quot;uc&quot;, 3,8,0.4,58,0,&quot;uc&quot;, 4,1,0.5,112,0,&quot;cd&quot;, 4,3,0.3,81,0,&quot;cd&quot;, 4,8,0.1,44,0,&quot;cd&quot;, 5,1,0.6,119,0,&quot;uc&quot;, 5,3,0.4,87,0,&quot;uc&quot;, 5,8,0.3,57,0,&quot;uc&quot;, 6,1,0.7,216,0,&quot;cd&quot;, 6,3,0.5,161,0,&quot;cd&quot;, 6,8,0.3,92,0,&quot;cd&quot;, 7,1,0.9,267,1,&quot;uc&quot;, 7,3,1.1,412,1,&quot;uc&quot;, 7,8,1.9,692,1,&quot;uc&quot;, 8,1,0.7,212,1,&quot;cd&quot;, 8,3,1.1,342,1,&quot;cd&quot;, 8,8,1.6,517,1,&quot;cd&quot;, 9,1,0.9,197,0,&quot;uc&quot;, 9,3,0.6,134,0,&quot;uc&quot;, 9,8,0.4,86,0,&quot;uc&quot;, 10,1,0.5,143,0,&quot;cd&quot;, 10,3,0.4,101,0,&quot;cd&quot;, 10,8,0.3,64,0,&quot;cd&quot;, 11,1,0.7,217,0,&quot;uc&quot;, 11,3,0.4,153,0,&quot;uc&quot;, 11,8,0.3,51,0,&quot;uc&quot;) ggplot(dat, aes(x = week, y = crp, group = factor(patid), color= factor(patid))) + geom_smooth(formula = y ~ x, se = FALSE, method = &quot;lm&quot;) + xlab(&quot;Week&quot;) + ylab(&quot;CRP&quot;) See the initial plot above for CRP with smooth lines for each patient, then try it for FCP. Now plot the CRP values, and change the grouping to patid without colors, and use geom_point() and geom_line() rather than geom_smooth to see the CRP trends in black. Now plot the CRP values, and add to the aes, color = factor(dz_type) OR color= factor(flare) to group = factor(patid) Now plot the FCP values, and add the geom_smooth with group = NULL and color = factor(flare). Also facet_grid by dz_type, and see if you can improve the default legend title and labels (might need to google these). Click on the Solution buttons below to toggle showing or hiding each solution. Solution 1 ggplot(dat, aes(x = week, y = crp, group = factor(patid), color= factor(patid))) + geom_smooth(formula = y ~ x, se = FALSE, method = &quot;lm&quot;) + labs(x = &quot;Week&quot;, y = &quot;CRP&quot;, title = &quot;CRP by week&quot;) + scale_x_continuous(breaks = c(1,3,8)) + expand_limits(x=0) Solution 2 ggplot(dat, aes(x = week, y = crp, group = factor(patid))) + geom_point() + geom_line() + labs(x = &quot;Week&quot;, y = &quot;CRP&quot;, title = &quot;CRP by week&quot;) + scale_x_continuous(breaks = c(1,3,8)) + expand_limits(x=0) Solution 3 ggplot(dat, aes(x = week, y = crp, group = factor(patid), color = factor(flare))) + geom_point() + geom_line() + labs(x = &quot;Week&quot;, y = &quot;CRP&quot;, title = &quot;CRP by week&quot;) + scale_x_continuous(breaks = c(1,3,8)) + expand_limits(x=0) + labs(color = &quot;Flare&quot;) Solution 4 ggplot(dat, aes(x = week, y = fcp, group = factor(patid), color = factor(flare))) + geom_point() + geom_line() + labs(x = &quot;Week&quot;, y = &quot;FCP&quot;, title = &quot;FCP by week&quot;) + scale_x_continuous(breaks = c(1,3,8)) + expand_limits(x=0) + geom_smooth(se=FALSE, size=2, method = &quot;loess&quot;, aes(group = NULL, color = factor(flare))) + facet_grid(~dz_type) + labs(color = &quot;Flare&quot;) + scale_color_discrete(breaks = c(&quot;1&quot;, &quot;0&quot;), labels = c(&quot;Yes&quot;, &quot;No&quot;)) 27.9 Swimmer Plots The Swimmer Plot is a visualization that shows treatment timelines, with each patient in their own “lane”. It gets the name because it looks a bit like a pool at a swim meet, where you can see the progress of each patient over time. These can help visualize treatment or measurement patterns, clinical events, time-varying covariates, outcomes, and loss to follow-up in longitudinal data settings. These work well with a moderate number of patient courses (usually 10-50), and can be illuminating when new approaches to therapy are being tried in small numbers of patients, like a case series. Note that this is not done with a particular package, but with standard geom_line and geom_point, but with a lot of customization in ggplot worth learning about. This section borrows heavily from a nice blog post from statistician Kat Hoffman here. Note that a bit of data wrangling needs to be done to produce the correct data format for swimmer plots. We will read in some simulated data of COVID patients from spring 2020 from Kat Hoffman. The original data includes one row per day for each patient, with dichotomous outcomes for the events we are interested in: intubation status, use of steroids, the first day of severe hypoxia status, and death. # install.packages(c(&quot;tidyverse&quot;,&quot;gt&quot;,&quot;RCurl&quot;,&quot;rmarkdown&quot;)) library(tidyverse) library(gt) library(rmarkdown) dat_long &lt;- read_csv(&quot;https://raw.githubusercontent.com/kathoffman/steroids-trial-emulation/main/data/dat_trt_timeline.csv&quot;, col_types = list(id = &quot;c&quot;, steroids = &quot;c&quot;, death = &quot;c&quot;, severe = &quot;c&quot;)) dat_long |&gt; head() ## # A tibble: 6 × 6 ## id day intubation_status steroids death severe ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 797 0 Not intubated 0 0 0 ## 2 797 1 Not intubated 0 0 0 ## 3 797 2 Not intubated 0 0 1 ## 4 797 3 Not intubated 0 0 0 ## 5 797 4 Not intubated 0 0 0 ## 6 797 5 Not intubated 0 0 0 We can use geom_line to plot the length of stay, with day on thex axis and lines colored by intubation status and grouped by patient id. dat_long |&gt; ggplot(aes(x=day, y=id, col = intubation_status, group=id)) + geom_line() + theme_bw() While this is very simple, it gives you a quick look at how these 30 simulated patients did in the hospital. We can add steroid use by day as colored points with geom_point, in one added line of code, as seen below. dat_long |&gt; ggplot(aes(x=day, y=id, col = intubation_status, group=id)) + geom_point(aes(x=day, y=id, col = steroids)) + geom_line() + theme_bw() This gets a bit messy, as we have different colors of points (steroids on/steroids off) obscuring the colors of the lines indicating intubation. It is time for a bit of data wrangling. To help clarify things in data wrangling step 1, let’s create new variables to specify on which day(s) steroids were used, the first day that severe hypoxia was present, and when death occurred. These variables will have lots of NA values when things did not occur - so that we won’t plot points when the events did not occur (NA days), and will have days for the values when the events occurred, which makes these easier to plot on the x axis. These NAs will be removed (and generate a lot of warnings) when plotting, so I will use an option to turn off messages and warnings in this section. knitr::opts_chunk$set(message=F, warning=F) dat_swim &lt;- dat_long |&gt; mutate(severe_this_day = case_when(severe == 1 ~ day), steroids_this_day = case_when(steroids == 1 ~ day), death_this_day = case_when(death == 1 ~ day)) In in data wrangling step 2, it would also make it easier to read the plot if the patients were arranged by length of stay (max_day), so we will use fct_reorder() to make the patient ids (factors) ordered by length of stay. dat_swim &lt;- dat_swim |&gt; group_by(id) |&gt; mutate(max_day = max(day)) |&gt; ungroup() |&gt; mutate(id = fct_reorder(factor(id), max_day)) head(dat_swim) |&gt; paged_table() After this data wrangling, now we can plot the data again, arranged by LOS and with only the steroid used days as visible points. dat_swim |&gt; ggplot() + geom_line(aes(x=day, y=id, col = intubation_status, group=id)) + geom_point(aes(x=steroids_this_day, y=id, col=&quot;Steroids&quot;, shape=&quot;Steroids&quot;)) + theme_bw() This is nicer to look at, though the legend is still a bit of a mess, and you can now clearly see that steroids were largely used for intubated patients at this point. It would look nicer if the lines were nearly as thick as the points, so that they are less obscured. Let’s fix this with a larger geom_line size, and format the steroid points with a shape for contrast. dat_swim |&gt; ggplot() + geom_line(aes(x=day, y=id, col = intubation_status, group=id), size=1.8) + geom_point(aes(x=steroids_this_day, y=id, col=&quot;Steroids&quot;), stroke=2, shape=15) + theme_bw() Now we add important clinical events - we can add severe hypoxia events and death events to the plot, with additional point geoms with distinct shapes for each of these. dat_swim |&gt; ggplot() + geom_line(aes(x=day, y=id, col = intubation_status, group=id), size=1.8) + geom_point(aes(x=steroids_this_day, y=id, col=&quot;Steroids&quot;), stroke=2, shape=15) + theme_bw() + geom_point(aes(x=severe_this_day, y=id, col=&quot;Severe hypoxia&quot;), size=2, stroke=1.5, shape=21) + geom_point(aes(x=death_this_day, y=id, col=&quot;Death&quot;), size=2, stroke=1.5, shape=4) We can fine-tune the colors and improve the legend name below. We will save the plot as p, and add more to it in future steps. # define colors for all geometries with a color argument cols &lt;- c(&quot;Severe hypoxia&quot; = &quot;#b24745&quot;, # red &quot;Intubated&quot; = &quot;#483d8b&quot;, # navy &quot;Not intubated&quot; = &quot;#74aaff&quot;, # light blue &quot;Steroids&quot;=&quot;#ffd966&quot;, # gold &quot;Death&quot; = &quot;#000000&quot;) # black p &lt;- dat_swim |&gt; ggplot() + geom_line(aes(x=day, y=id, col = intubation_status, group=id), size=1.8) + geom_point(aes(x=steroids_this_day, y=id, col=&quot;Steroids&quot;), stroke=2, shape=15) + theme_bw() + geom_point(aes(x=severe_this_day, y=id, col=&quot;Severe hypoxia&quot;), size=2, stroke=1.5, shape=21) + geom_point(aes(x=death_this_day, y=id, col=&quot;Death&quot;), size=2, stroke=1.5, shape=4) + scale_color_manual(values = cols, name=&quot;Patient Status&quot;) p This is really coming along. But the legend symbols are accurate for colors, but don’t reflect the shapes we used, as we did not use aes() to create the shapes. To override the default shapes, lines, etc. in the legend, we need to use the guides() function, and override guide_legend(). This lets you manually specify the shapes. Let’s start by first defining the corresponding shapes (with NA when we don’t want a point), then overriding the shapes, and update our plot. shape_override &lt;- c(4, NA, NA, 21, 15) # order matches `cols`:severe, intubation (yes/no), steroids, death, with the appropriate shapes # modify the color legend to include the correct shapes p + guides(color = guide_legend( override.aes = list( shape = shape_override) )) That worked well. Now let’s remove the lines though Death, Severe Hypoxia, and Steroids, by overriding the line type (1 for a standard line or NA for no line), then fine tune the stroke and size for each of these geom points. Note that for shapes 21-24 in R, you have to separately specify stroke (for outer line) and fill (if any), while shapes 1-20 just require a size. line_override &lt;- c(NA,1,1,NA,NA) # order matches `cols`:severe, intubation (yes/no), steroids, death stroke_override &lt;- c(1.2,1,1,1,1.4) # order matches `cols`:severe, intubation (yes/no), steroids, death size_override &lt;- c(2.5,2.5,2.6,2.5,2) # order matches `cols`:severe, intubation (yes/no), steroids, death p &lt;- p + guides(color = guide_legend( override.aes = list( shape = shape_override, linetype = line_override, stroke = stroke_override, size = size_override) )) p Now the legend looks nice. Let’s add a few more aesthetic tweaks, including title and better axis labels. p &lt;- p + labs(x=&quot;Days since hospitalization&quot;,y=&quot;Patient\\nnumber&quot;,title=&quot;COVID Treatment Timeline for 30 Patients&quot;) + scale_x_continuous(expand=c(0,0)) + # remove extra white space theme(# text=element_text(family=&quot;Poppins&quot;, size=11), title = element_text(angle = 0, vjust=.5, size=12, face=&quot;bold&quot;), axis.title.y = element_text(angle = 0, vjust=.5, size=12, face=&quot;bold&quot;), axis.title.x = element_text(size=15, face=&quot;bold&quot;, vjust=-0.5, hjust=0), axis.text.y = element_text(size=6, hjust=1.5), axis.ticks.y = element_blank(), legend.position = c(0.8, 0.3), legend.title = element_text(colour=&quot;black&quot;, size=13, face=4), legend.text = element_text(colour=&quot;black&quot;, size=10), legend.background = element_rect(size=0.5, linetype=&quot;solid&quot;, colour =&quot;gray30&quot;), panel.grid.minor = element_blank(), panel.grid.major.x = element_blank() ) p And we are done. You can see how this can illustrate the hospital course for a number of patients, and transmit a lot of longitudinal information quickly when the number of patients is not too long. Let’s try another swimmer plot, using some simulated data from a study of patients after liver transplant. Some of these patients develop ascites (increased fluid in the abdominal peritoneal cavity) that requires large volume paracentesis to remove. If this becomes frequent, it can cause major fluid shifts and problems with kidney function. Sometimes taking the spleen out of the system with splenectomy (surgical removal) or SAE (splenic artery embolism) can reduce the need for large volume paracentesis. Let’s look at this with a small dataset of 12 patients who developed ascites after liver transplantation and received SAE (splenic artery embolization). Run the code chunk below to read in the data. In this code chunk, we do a bit of data wrangling as well, properly formatting the dates, and calculating the length of time in days before or after the SAE (splenic artery embolization). Note that the default units are seconds, so we need to divide by (3600*24) to get days. library(tidyverse) library(readxl) library(lubridate) library(openxlsx) swim_liver &lt;- read.csv(&#39;data/swim_liver.csv&#39;) |&gt; mutate(olt_date = mdy(olt_date), sae_date = mdy(sae_date), lvp_date = mdy(lvp_date), eofu_date = mdy(eofu_date), pat_id = factor(pat_id)) The key events are olt - orthotopic liver transplant, sae (splenic artery embolism), lvp (large volume paracentesis), and eofu (end of follow up). Each patient has an id and multiple events occur. Each patient also has a MELD score (meld = model for end-stage liver disease), which measures how sick they were before the liver transplant (higher scores are worse). We will start by drawing the line segments from liver transplant to end of followup, colored by meld score at the time of transplant. swim_liver %&gt;% ggplot() + geom_segment(aes(x = start, xend = end, y = fct_reorder(pat_id, meld), yend = fct_reorder(pat_id, meld), color = meld)) + geom_vline(xintercept = 0) + theme_bw() Now, let’s add the large volume paracentesis events as points with geom_point. swim_liver %&gt;% filter(days_from_sae &lt;= end) |&gt; ggplot() + geom_segment(aes(x = start, xend = end, y = fct_reorder(pat_id, meld), yend = fct_reorder(pat_id, meld), color = meld)) + geom_point(aes(x=days_from_sae, y = fct_reorder(pat_id, meld)), color = &quot;black&quot;) + geom_vline(xintercept = 0) + theme_bw() + scale_color_continuous(low = &quot;dodgerblue1&quot;, high = &#39;dodgerblue4&#39;) Now we can increase the linewidth and the size of the points to make this clearer. swim_liver %&gt;% filter(days_from_sae &lt;= end) |&gt; ggplot() + geom_segment(aes(x = start, xend = end, y = fct_reorder(pat_id, meld), yend = fct_reorder(pat_id, meld), color = meld), size = 2) + geom_point(aes(x=days_from_sae, y = fct_reorder(pat_id, meld)), size =3) + geom_vline(xintercept = 0) + theme_bw() + scale_color_continuous(low = &quot;dodgerblue1&quot;, high = &#39;dodgerblue4&#39;) The labels on axes and the legend are a bit of a mess still. We can clean this up and add red circles for the transplant events. We can move the legend inside the plot, and add some explanatory text as an annotation. It appears that the SAE (at day 0 in this pre-post swimmer plot) provides a lot of benefit to the mild to moderate MELD patients by reducing their need for large volume paracentesis. Those with severely high MELD scores don’t seem to get as much benefit. swim_liver %&gt;% filter(days_from_sae &lt;= end) |&gt; ggplot() + geom_segment(aes(x = start, xend = end, y = fct_reorder(pat_id, meld), yend = fct_reorder(pat_id, meld), color = meld), size = 2) + geom_point(aes(x=days_from_sae, y = fct_reorder(pat_id, meld)), size =3) + geom_point(aes(x = start, y = fct_reorder(pat_id, meld)), shape =1, color = &quot;red&quot;, stroke =2, size =3) + geom_vline(xintercept = 0) + annotate(&quot;text&quot;, x = -225, y= 11.5, label = &quot;Red circles represent\\nthe OLT date, \\nEach black dot represents\\none large volume\\nparacentesis, \\n Splenic Intervention at Day 0&quot;) + theme_bw() + scale_color_continuous(low = &quot;dodgerblue1&quot;, high = &#39;dodgerblue4&#39;) + labs(x=&quot;Days Relative to Splenic Intervention&quot;,y=&quot;Patient\\nnumber&quot;,title=&quot;Large Volume Paracentesis\\nTimeline for 12 Patients from OLT Date\\nto End of FollowUp&quot;) + theme(# text=element_text(family=&quot;Poppins&quot;, size=11), title = element_text(angle = 0, vjust=.5, size=12, face=&quot;bold&quot;), axis.title.y = element_text(angle = 0, vjust=.5, size=12, face=&quot;bold&quot;), axis.title.x = element_text(size=15, face=&quot;bold&quot;, vjust=-0.5, hjust=0), axis.text.y = element_text(size=10, hjust=1.5), axis.ticks.y = element_blank(), legend.position = c(0.12, 0.6), legend.title = element_text(colour=&quot;black&quot;, size=13), legend.text = element_text(colour=&quot;black&quot;, size=10), legend.background = element_rect(size=0.5, linetype=&quot;solid&quot;, colour =&quot;gray30&quot;), panel.grid.minor = element_blank(), panel.grid.major.x = element_blank() ) You can explore other (similar) approaches to swimmer plots, including the {swimmer} package here in a blog post by Jessica Weiss. 27.10 Adding Significance Comparisons with {ggsignif} It is common to compare continuous outcomes across categories with scatter plots or box plots, but we often see comparison bars and p values added. This can be added to a ggplot with the {ggsignif} package. Let’s load some libraries and some data in the code chunk below. Then we will do a basic boxplot. library(tidyverse) library(ggsignif) library(medicaldata) dat &lt;- medicaldata::diabetes ggplot(dat) + aes(x = fct_lump(as_factor(pregnancy_num), n = 3), y = `glucose_mg-dl`) + geom_boxplot() + labs(y = &quot;Glucose in mg/dL&quot;, x = &quot;Pregnancy Number&quot;) + theme_bw() There seems to be a downward trend of fasting serum glucose from 0 to 2 pregnancies, then a rise in glucose with &gt;=3 pregnancies. Now imagine that you would like to know if the difference in mean glucose between 0 and 2 pregnancies, or 2 and more than 2, are significant. And you want to display it on your plot. You can use the geom_signif() geom from the {ggsignif} package. The arguments include the: - comparisons = list(c(“cat1”, “cat2”)) # in quotes with names, or use the numbers of categories from left to right - y_position = NN # manually control where on y axis - tip_length = 1 (can use 0, 0.5, modify as needed - xmin and xmax - can set the width. If you have more than one comparison, can use a vector, i.e. xmin = c(0.1, 1.8) - annotation - can replace p value with “NS” or “**“, or whatever you want - vjust = -0.2 (set a value to adjust the vertical justification of the annotation of p value - above or below the bar as needed) library(tidyverse) library(ggsignif) library(medicaldata) dat &lt;- medicaldata::diabetes ggplot(dat) + aes(x = fct_lump(as_factor(pregnancy_num), n = 3), y = `glucose_mg-dl`) + geom_boxplot() + labs(y = &quot;Glucose in mg/dL&quot;, x = &quot;Pregnancy Number&quot;) + theme_bw() + geom_signif(y_position = 200, comparison = list(c(1,3)), tip_length = 0.005) + geom_signif(y_position = 195, comparison = list(c(1,2)), tip_length = 0.01) + geom_signif(y_position = 197, comparison = list(c(3,4)), tip_length = 0.02) + geom_signif(y_position = 179, comparison = list(c(2,3)), tip_length = 0.02, annotation = &quot;NS&quot;) We can add specific pairwise comparisons and position their height (on the y axis) with geom_signif. You can learn more about the {ggsignif} package at its webpage. Now try this yourself. Copy the code below (click on the copy icon in the top right of the code chunk), paste it into your RStudio IDE, and edit to: compare spring to summer compare summer to winter put these at appropriate y_postions with appropriate tip_lengths - your choice library(tidyverse) library(ggsignif) library(medicaldata) dat &lt;- medicaldata::abm |&gt; mutate(season = case_when(month &gt;5 &amp; month &lt;9 ~ &quot;summer&quot;, month &gt;2 &amp; month &lt;6 ~ &quot;spring&quot;, month &gt;8 &amp; month &lt;12 ~ &quot;fall&quot;, TRUE ~ &quot;winter&quot;)) ggplot(dat) + aes(x = season, y = csf_gluc) + geom_boxplot() + labs(y = &quot;CSF Glucose in mg/dL&quot;, x = &quot;Season&quot;) + theme_bw() Solution ggsignif library(tidyverse) library(ggsignif) library(medicaldata) dat &lt;- medicaldata::abm |&gt; mutate(season = case_when(month &gt;5 &amp; month &lt;9 ~ &quot;summer&quot;, month &gt;2 &amp; month &lt;6 ~ &quot;spring&quot;, month &gt;8 &amp; month &lt;12 ~ &quot;fall&quot;, TRUE ~ &quot;winter&quot;)) ggplot(dat) + aes(x = season, y = csf_gluc) + geom_boxplot() + labs(y = &quot;CSF Glucose in mg/dL&quot;, x = &quot;Season&quot;) + theme_bw() + geom_signif(y_position = 200, comparison = list(c(2,3)), tip_length = 0.005) + geom_signif(y_position = 190, comparison = list(c(3,4)), tip_length = 0.01) "],["customizing-plot-scales.html", "Chapter 28 Customizing Plot Scales 28.1 Goals for this Chapter 28.2 Packages Needed for this chapter 28.3 A Flipbook of Where We Are Going With Scales 28.4 A Basic Scatterplot 28.5 But what if you want the scale for risk to start at 0? 28.6 But this axis does not really start at Exactly 0 28.7 Control the Limits and the Breaks 28.8 Test what you have learned 28.9 Continuous vs. Discrete Plots and Scales 28.10 Using Scales to Customize a Legend 28.11 Test what you have learned", " Chapter 28 Customizing Plot Scales 28.1 Goals for this Chapter learn how to use scales to control x and y axes learn how to use scales to control shape, color, and alpha learn how to use scales to control the legend learn how to use scales for dates, percents, log, ordinals, dollars, and scientific notation 28.2 Packages Needed for this chapter You will need {tidyverse}, {medicaldata}, and {scales} # install.packages(&#39;tidyverse&#39;) # install.packages(&#39;medicaldata&#39;) # install.packages(&#39;scales&#39;) library(tidyverse) library(medicaldata) library(scales) 28.3 A Flipbook of Where We Are Going With Scales See the flipbook below, which contains some examples of what you can do with customized scales. These control both the axes and the legend(s). You can click on the flipbook arrows and move forward or backward in the slides with the left and right arrows to see what each line of code actually does. Go forward and backward until you understand the function of each line. You can use the the icons in the bottom bar to expand to full screen or share this flipbook. If you are in full screen mode, you can use the Home button to go the the first slide and the End button to go to the last slide, and the Escape key to get out of full screen mode. 28.4 A Basic Scatterplot Let’s start with a scatterplot of age vs risk of PEP in the indo_rct dataset indo_rct &lt;- medicaldata::indo_rct indo_rct %&gt;% ggplot() + aes(x = age, y = risk, color = outcome) + geom_jitter() The axes cover the whole range by default, whith a bit of space added at the edges. This occurs because the default for scale_(x|y)continuous* for continuous variables adds 5% at either end so that points are not right at the edge. Similarly, the scale_discrete function for discrete variables adds 0.6 of a category to the width to either side. 28.5 But what if you want the scale for risk to start at 0? You can do this, by taking control of the scales. In this case, the scale_y_continuous() function. indo_rct %&gt;% ggplot() + aes(x = age, y = risk, color = outcome) + geom_jitter() + scale_y_continuous(limits = c(0,6)) Now try this yourself. Copy the code above (click on the copy icon in the top right of the code chunk), paste it into your RStudio IDE, and edit to: change the x axis so that it starts at age 15, and ends at 90. Click on the Solution button to toggle showing or hiding the solution. Solution indo_rct %&gt;% ggplot() + aes(x = age, y = risk, color = outcome) + geom_jitter() + scale_y_continuous(limits = c(0,6)) + scale_x_continuous(limits = c(15,90)) ## Warning: Removed 1 row containing missing values or values outside the scale range ## (`geom_point()`). 28.6 But this axis does not really start at Exactly 0 You can see that the x- and y-axes extend a bit past 0. This is because there is a default expansion of the scales (5% for continuous variables). You can control this default with the expand() function. Let’s see how this works to make the y-axis start at exactly zero. You can set the expansion term as a multiplier (mult) or an additive (add). indo_rct %&gt;% ggplot() + aes(x = age, y = risk, color = outcome) + geom_jitter() + scale_y_continuous(limits = c(0,6), expand = expansion(mult =0)) Now try this yourself. Copy the code above (click on the copy icon in the top right of the code chunk), paste it into your RStudio IDE, and edit to: Change the x axis so that it starts at age 0, and ends at 85. Make the x-axis expansion multiplier zero (not the default of 0.05). Click on the Solution button to toggle showing or hiding the solution. Solution indo_rct %&gt;% ggplot() + aes(x = age, y = risk, color = outcome) + geom_jitter() + scale_y_continuous(limits = c(0,6)) + scale_x_continuous(limits = c(0,85), expand = expansion(mult = 0)) ## Warning: Removed 1 row containing missing values or values outside the scale range ## (`geom_point()`). 28.7 Control the Limits and the Breaks You can see that ggplot picks sensible breaks, but the defaults might not always work for you. Let’s change the risk scale to breaks of 0.5, using the breaks argument. Note that using the limits argument also lets you establish the limits of the y-axis. indo_rct %&gt;% ggplot() + aes(x = age, y = risk, color = outcome) + geom_point() + scale_y_continuous(limits = c(0,6), breaks = seq(0, 6, by = 0.5)) Now try this yourself. Copy the code above (click on the copy icon in the top right of the code chunk), paste it into your RStudio IDE, and edit to: Change the x axis so that it starts at age 0, and ends at 95, with breaks at every decade from 10-90 (but not zero). Click on the Solution button to toggle showing or hiding the solution. Solution indo_rct %&gt;% ggplot() + aes(x = age, y = risk, color = outcome) + geom_jitter() + scale_y_continuous(limits = c(0,6)) + scale_x_continuous(limits = c(0,95), expand = expansion(mult = 0), breaks = seq(10, 90, by = 10)) Notice that the y axis has the default 5% multiplier, but the x axis does not, so it has limits exactly at 0 and 95. 28.8 Test what you have learned (correct answers will be green!) You can set the start and end points of an axis with the limits argument TRUEFALSE You can set the ticks on an axis with the breakstickslines argument in a scales function. To expand the margin of a plot on one side by a specific amount, you use the multsqrtadd argument in the expand argument within a scales function. 28.9 Continuous vs. Discrete Plots and Scales You can see below that ggplot picks sensible spacing and breaks for a discrete scale, but the defaults might not always work for you. indo_rct %&gt;% ggplot() + aes(x = rx, y = risk, color = outcome) + geom_jitter() + theme(legend.position = c(0.85, 0.5)) + scale_y_continuous(limits = c(0.5,6), breaks = seq(0.5, 6, by = 0.5)) ## Warning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2 ## 3.5.0. ## ℹ Please use the `legend.position.inside` argument of `theme()` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. Let’s expand the x axis to the righ to make room for a legend in the plot on the right, using the expand argument. We can change the axis name and position as well. indo_rct %&gt;% ggplot() + aes(x = rx, y = risk, color = outcome) + geom_jitter() + theme(legend.position = c(0.85, 0.5)) + scale_y_continuous(limits = c(0.5,6), breaks = seq(0.5, 6, by = 0.5)) + scale_x_discrete(expand = expansion(add =c(0.6,1.5)), name = &quot;Treatment&quot;, position = &quot;top&quot;) Now try this yourself. Copy the code above (click on the copy icon in the top right of the code chunk), paste it into your RStudio IDE, and edit to: Change the x axis so that you add 1.5 to the left side (add 1.5, 0.6), move the legend to the left (0.15, 0.5) change the title to “Suppository” move the title position to the bottom Click on the Solution button to toggle showing or hiding the solution. Solution indo_rct %&gt;% ggplot() + aes(x = rx, y = risk, color = outcome) + geom_jitter() + theme(legend.position = c(0.15, 0.5)) + scale_y_continuous(limits = c(0.5,6), breaks = seq(0.5, 6, by = 0.5)) + scale_x_discrete(expand = expansion(add =c(1.5, 0.6)), name = &quot;Suppository&quot;, position = &quot;bottom&quot;) The legend position is based on the proportion of the x axis (0-1) and the y axis (0-1), so that legend.position (0,0) is the bottom left, and legend.position (1,1) is the top right. 28.10 Using Scales to Customize a Legend Legends are also scales, for discrete or continuous scales. You can use scales_(color|size|shape|alpha)_nnn functions to customize them. Let’s see an example below. medicaldata::indo_rct %&gt;% ggplot() + aes(x = rx, y = risk, color = outcome) + geom_jitter() + theme(legend.position = c(0.85, 0.5)) + scale_y_continuous(limits = c(0.5,6), breaks = seq(0.5, 6, by = 0.5)) + scale_x_discrete(expand = expansion(add =c(0.6,1.5)), name = &quot;Treatment&quot;, position = &quot;top&quot;) + scale_color_manual(name = &quot;Post-ERCP\\nPancreatitis&quot;, labels = c(&quot;no&quot;, &quot;yes&quot;), values = c(&quot;dodgerblue&quot;, &quot;red&quot;)) Now try this yourself. Copy the code above (click on the copy icon in the top right of the code chunk), paste it into your RStudio IDE, and edit to: Change the legend make the title “PEP” change the labels to “good” and “BAD” change the colors to “yellow” and “darkorchid” Click on the Solution button to toggle showing or hiding the solution. Solution medicaldata::indo_rct %&gt;% ggplot() + aes(x = rx, y = risk, color = outcome) + geom_jitter() + theme(legend.position = c(0.15, 0.5)) + scale_y_continuous(limits = c(0.5,6), breaks = seq(0.5, 6, by = 0.5)) + scale_x_discrete(expand = expansion(add =c(1.5, 0.6)), name = &quot;Suppository&quot;, position = &quot;bottom&quot;) + scale_color_manual(name = &quot;PEP&quot;, labels = c(&quot;good&quot;, &quot;BAD&quot;), values = c(&quot;yellow&quot;, &quot;darkorchid&quot;)) The legend position is based on the proportion of the x axis (0-1) and the y axis (0-1), so that legend.position (0,0) is the bottom left, and legend.position (1,1) is the top right. 28.11 Test what you have learned (multiple-choice, fill-in-the-blank, and TRUE/FALSE - correct answers will be green!) You can take complete control of colors with scale_color_ continuousdiscretemanual You can set the title of a color legend within the scale_color_discrete() function with the argument. You can set the names of each level of a discrete color legend within the scale_color_discrete() function with the argument. You can set each color of a discrete color legend within the scale_color_discrete() function with the values TRUEFALSE argument. 28.11.1 More Examples with Flipbooks Now try some challenging code exercises using scales in the learnr app below. Use your knowledge to try to do these without hints, but press the Hints button if needed. In each case, the 2nd hint is the solution. "],["helping-out-with-ggplot.html", "Chapter 29 Helping out with ggplot 29.1 ggx::gghelp() 29.2 Getting more help with theming with ggThemeAssist 29.3 Website helpers for ggplot 29.4 Getting Even more help with esquisse", " Chapter 29 Helping out with ggplot The {ggplot} package is extremely powerful, and has many extension packages that augment that power for data visualization. But the number of options, particularly for theming, can get overwhelming. This is especially true if you are not using {ggplot} every day. Medical day (and night) jobs can get in the way of great data visualizations. But there are several helper packages to make your life easier, including {ggx}, {ggThemeAssist}, and {esquisse}. 29.1 ggx::gghelp() Let’s start with {ggx}. The gghelp() function in this simple package converts natural language queries (in quotes) into a ggplot command string. It can be helpful for styling axes, labels, font size, title, and legends. It is limited by its library of commands and range of styling, but can be helpful in a pinch. Try a few questions below, and make your own. ggx::gghelp(&quot;how do I remove the legend&quot;) ## theme(legend.position = &quot;none&quot;) ggx::gghelp(&quot;how do I increase the font size of the title&quot;) ## theme(axis.title.x=element_text(size=rel(2))) ggx::gghelp(&quot;change the x axis label to &#39;systolic blood pressure&#39;&quot;) ## xlab(&#39;systolic blood pressure&#39;) 29.2 Getting more help with theming with ggThemeAssist ggThemeAssist is an RStudio add-in that you install when you install the {ggThemeAssist} package. It is used after you have your basic plot in place, with the right geom, and the x and y variables in place. Let’s start you out with a simple plot from the {medicaldata} package. This plots the fentanyl requirements for anesthesia in the supraclavicular dataset comparing high and low BMI, age, and gender effects. Run this code block to see what the basic plot looks like. plot1 &lt;- medicaldata::supraclavicular %&gt;% filter(!is.na(bmi)) %&gt;% mutate(gender_cat = case_when(gender == 1 ~ &quot;Male&quot;, gender == 0 ~ &quot;Female&quot;)) %&gt;% mutate(bmi_cat = case_when(bmi &lt;30 ~ &quot;low&quot;, bmi &gt;= 30 ~ &quot;high&quot;)) %&gt;% ggplot(aes(x=age, y = fentanyl, col = gender_cat)) + geom_point() + facet_wrap(. ~ bmi_cat) plot1 + theme(axis.text.y = element_text(family = &quot;serif&quot;), panel.background = element_rect(fill = &quot;antiquewhite&quot;), plot.background = element_rect(fill = &quot;white&quot;)) + labs(title = &quot;Fentanyl Requirements&quot;, x = &quot;Age&quot;, y = &quot;Fentanyl in mcg&quot;, colour = &quot;Gender&quot;, subtitle = &quot;by BMI and Age&quot;) ## Warning: Removed 1 row containing missing values or values outside the scale range ## (`geom_point()`). Now select the code that generates the plot. You can also assign the plot (with an assignment arrow) to an imaginative name, like plot1. You can then select this object as well. Once you have the plot selected in your code, you can activate ggThemeAssist in one of two ways: Go to your Addins dropdown menu, and select ggThemeAssist type in the Console: ggthemeAssistGaget(plot1) Either approach will open up an interactive window, with 6 tabs and a bunch of options. These tabs include: Settings Panel and Background Axis Title and Label Legend Subtitle and Caption Open these up and experiment. You will see the results as you change options. When you are happy with the result, click on the Done button in the top right. This will add all of your thematic changes as valid R code to the existing plot object. 29.3 Website helpers for ggplot Several websites provide quick help for ggplot needs, and are worth bookmarking. The Aesthetics Helper, at https://ggplot2tor.com/aesthetics/, provides a quick guide to which aesthetics are required (green), and which other aesthetics are available (optional, in orange) to map variables in your dataset to components of a plot for each geom. The Guide to Scales, at https://ggplot2tor.com/scales, helps you find the proper names of scales in ggplot2, by selecting your variable type and (if needed) the aesthetic for the scale. Then by clicking on one of the available scales, you can get example code with appropriate syntax for multiple arguments. This can be very helpful in preventing frustration with not having the scales quite right. The R Graph Gallery, at https://www.r-graph-gallery.com, is a popular overview of available graph types. You can quickly scan a bunch of plots based on distributions, correlations, rankings, parts of a whole, change over time, maps, and flow and select one that looks interesting. When you find one you like, you can click on it and get the underlying ggplot code. Another popular web gallery with code is the Top 50 ggplot2 visualizations, at http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html Cedric Scherer has a lengthy free tutorial with lots of great examples at https://www.cedricscherer.com/2019/08/05/a-ggplot2-tutorial-for-beautiful-plotting-in-r/ There is also a gallery of all the many extension packages people have built as add-ons to ggplot, often for specific and specialized plotting needs. Take a loot at https://exts.ggplot2.tidyverse.org/gallery/ Packages ggridges, ggalluvial, ggmosaic, ggdist, gghalves, and ComplexUpset have proven quite popular. Take a look at all the options for extending ggplot. 29.4 Getting Even more help with esquisse {esquisse} is an RStudio add-in that you install when you install the {esquisse} package. It is used to create plots from scratch in ggplot. A nice website on how to get started can be found at: https://cran.r-project.org/web/packages/esquisse/vignettes/get-started.html But the two ways to get started are to either: run esquisser(dataframe) in the Console, with the dataframe that you want to make a plot from, or In the Addins menu, select ggplot2_builder under ESQUISSE Either approach opens up a new window. If you did not specify a dataframe, it will ask you to select one, either from the Global Environment, or from a data package. For our purposes, select the {medicaldata} package, and the dataframe blood_storage. This will give you a window with many options, and a sandbox full of variables. To look at the data, click on the Show Data icon at top left You can drag variables into different aesthetic mappings. Start with PreopPSA for x TimeToRecurrence for y Age mapped to color FamHx or AA mapped to Size You can drag variables out of mappings and back to the variable sandbox if needed You can click on the Settings Gear at the top right to activate more aesthetics You can click on the geom icon at top left to change the plot type You can edit the Title and Labels with this tab You can edit Plot Options You can edit the plot appearance When you are happy with it, you can click on the Code tab, and copy it to your script. {esquisse} can get you started on good plots, and remind you of ggplot options you may have forgotten (or never knew) about. There are a number of fancy plots and extensions it can not do, and it will not clean your data for you, or reorder factors. But it can be really helpful if you are not plotting very often or if you are just getting started with ggplot. "],["functions-1.html", "Chapter 30 Functions 30.1 Don’t repeat yourself 30.2 Your Turn 30.3 Freestyle 30.4 Read More", " Chapter 30 Functions Nearly everything in R and the tidyverse is built on functions. Every command you write that ends with parentheses is a function. The parentheses contain arguments (unless you just use the defaults), which the function acts upon. If you type a function into the console and forget the parentheses, you may be surprised at what you get back when you press the Enter key. Try this with the sd function by running the chunk below sd At first this looks like computer gobbledygook, but if you look at it closely, the first line sets up the structure of the function and its arguments, and the second line defines the function as the square root of the variance of a vector that contains numbers. You are seeing the inner workings of the sd function. Other functions may be written in other languages (like C++) for more speed, but you can use R to write more R functions. When you try this for another function, like filter in the dplyr package, it is less informative. As you can see when you unpack the function below. dplyr::filter 30.1 Don’t repeat yourself Functions are especially helpful when you do something repeatedly, or do the same thing on several variables or several datasets. Let’s start with a simple plot of Ct (COVID viral load) vs age for inpatients. Run the code chunk below. covid %&gt;% filter(patient_class == &quot;inpatient&quot;) %&gt;% ggplot() + aes(x = age, y = ct_result) + geom_point() + theme_linedraw() + labs(y = &quot;viral load (in Ct)&quot;, title = &quot;Patient class: inpatient&quot;) This is great, but you would like a similar plot for ER patients, observation patients, outpatients, etc. How do you do this without multiple copy-paste and careful edits of the key variables (often with errors)? First, you need to avoid hard-coding the specific values that change from plot to plot. In our next version of this plot, we will set an envronment variable (patient_class_choice_env) to “inpatient”, then use that variable to: filter the data set the title (using the glue function) patient_class_choice_env = &quot;inpatient&quot; covid %&gt;% filter(.data$patient_class == .env$patient_class_choice_env) %&gt;% ggplot() + aes(x = age, y = ct_result) + geom_point() + theme_linedraw() + labs(y = &quot;viral load (in Ct)&quot;, title = glue(&quot;Patient class: {patient_class_choice_env}&quot;)) The use of variable pronouns is very important in the filter step. .data$patient_class means the variable “patient_class” in the currently in-use dataframe. .env$patient_class_choice_env means the variable “patient_class_choice_env” in the current environment (check the Environment pane). This can be especially helpful when these variables have the same names - the .data pronoun helps you refer specifically to variables in the dataframe, and the .env pronoun helps you refer specifically to variables in the environment. It is usually better to give these slightly different names. In this case, I have added the suffix, “choice_env” for the variable in the environment in which I have specified the value chosen. Let’s try another example. In the code chunk below, edit the patient_class_choice_env variable to the value “emergency”, and then run the code chunk. patient_class_choice_env = &quot;emergency&quot; covid %&gt;% filter(.data$patient_class == .env$patient_class_choice_env) %&gt;% ggplot() + aes(x = age, y = ct_result) + geom_point() + theme_linedraw() + labs(y = &quot;viral load (in Ct)&quot;, title = glue(&quot;Patient class: {patient_class_choice_env}&quot;)) Fairly slick, right? You can edit and run through each value for patient_class. But what if you want to automate this, and just produce all the plots for all the possible values? To do this, you have to turn your plot into a function. To make a function, you first need a chunk of code with no hard-coded values. Then, you wrap the code in curly braces, and preface it with “function(arguments)” Then you assign it to a function name. Examine, then run the example below. make_covid_plot &lt;- function(patient_class_choice_env) { covid %&gt;% filter(.data$patient_class == .env$patient_class_choice_env) %&gt;% ggplot() + aes(x = age, y = ct_result) + geom_point() + theme_linedraw() + labs(y = &quot;viral load (in Ct)&quot;, title = glue(&quot;Patient class: {patient_class_choice_env}&quot;)) } make_covid_plot(&quot;recurring outpatient&quot;) Note that this creates a function object named make_covid_plot in your Environment pane. And you still have to call the function with the argument “recurring outpatient” to get one plot. Generally, you should write functions when you find yourself copy-pasting the same code several times. Each function should be no more than 20-30 lines. If longer, break it up into a couple of functions. You can do this repeatedly, over several values for patient_class. Try this below by editing the code chunk to make plots for “emergency” and “not applicable” patient classes. make_covid_plot(&quot;outpatient&quot;) make_covid_plot(&quot;observation&quot;) This is better, but it is still not completely automated. Let’s automate calling the function over several values with the map function. map takes each element of the vector patient_class and uses it as input for make_covid_plot(). map returns a list of created plots. We can return these with bracket references to items 1,2, and 3 in the list. patient_class &lt;- c(&quot;emergency&quot;, &quot;inpatient&quot;, &quot;observation&quot;) plots &lt;- map(patient_class, make_covid_plot) plots[[1]] plots[[2]] plots[[3]] We can make this simpler with the walk function. The walk function is like map, but it does not return values, only side effects (like printing). In this case, it is applying the print function to each element of the plots list. walk(plots, print) We can automate this further, and not need to supply the vector of patient_class values. We can automate it by applying the make_covid_plot function to all available patient_class values. To demonstrate this, we need a more general function, with 2 arguments: one for the dataset, and one for for patient_class. We will test this on the “inpatient” class. The filtering operation will be moved outside of the function make_covid_plot_2 &lt;- function(data, patient_class) { data %&gt;% # note data argument # filtering now done outside of function ggplot() + aes(x = age, y = ct_result) + geom_point() + theme_linedraw() + labs(y = &quot;viral load (in Ct)&quot;, title = glue(&quot;Patient class: {patient_class}&quot;)) } data_inpatient &lt;- covid %&gt;% filter(patient_class == &quot;inpatient&quot;) make_covid_plot_2(data_inpatient, patient_class = &quot;inpatient&quot;) Now we can try this in a tidy pipeline. We will first subset the data by nesting it with the nest function. Take a look at what this does covid %&gt;% nest(data = -patient_class) ## # A tibble: 5 × 2 ## patient_class data ## &lt;chr&gt; &lt;list&gt; ## 1 observation &lt;tibble [28 × 16]&gt; ## 2 outpatient &lt;tibble [65 × 16]&gt; ## 3 emergency &lt;tibble [124 × 16]&gt; ## 4 recurring outpatient &lt;tibble [11 × 16]&gt; ## 5 inpatient &lt;tibble [111 × 16]&gt; We have essentially grouped the data in to 5 distinct tibbles (dataframes) in the list-column named data. These are dataframes in a column nested inside of a larger dataframe. Now we can make a plot from each of these smaller dataframes, using the mutate function and the map function, and our original make_covid_plot function. covid %&gt;% nest(data = -patient_class) %&gt;% mutate(plots = map(patient_class, make_covid_plot)) ## # A tibble: 5 × 3 ## patient_class data plots ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; ## 1 observation &lt;tibble [28 × 16]&gt; &lt;gg&gt; ## 2 outpatient &lt;tibble [65 × 16]&gt; &lt;gg&gt; ## 3 emergency &lt;tibble [124 × 16]&gt; &lt;gg&gt; ## 4 recurring outpatient &lt;tibble [11 × 16]&gt; &lt;gg&gt; ## 5 inpatient &lt;tibble [111 × 16]&gt; &lt;gg&gt; Now we have a column that contains the plots. We can pull these out of the dataframe into a vector with the pull function (because walk works on vectors), then print them to the Plots tab with the walk function. covid %&gt;% nest(data = -patient_class) %&gt;% mutate(plots = map(patient_class, make_covid_plot)) %&gt;% pull(plots) %&gt;% walk(print) Note that we could also walk the ggsave function if we wanted to save these plots as tiffs or pdfs or png files. We can use our more generalizable function make_covid_plot_2 in this pipeline if we use map2, which is like map, but for functions with 2 arguments. The arguments of the map2 function include the two arguments (data, patient_class) for making plots, and then the function (make_covid_plot_2). covid %&gt;% nest(data = -patient_class) %&gt;% mutate(plots = map2(data, patient_class, make_covid_plot_2)) %&gt;% pull(plots) %&gt;% walk(print) This version of the pipeline will automatically process all patient classes in the dataset, whatever they are called, without us having to specify them. 30.2 Your Turn Let’s look at how to do this with the prostate dataset. We will start with a simple violin and jitter plot of time to recurrence by baseline Gleason score (bgs), in the subgroup where rbc_age_group = 1. rbc_age_group = 1 prostate %&gt;% filter(rbc_age_group == 1) %&gt;% ggplot() + aes(x = bgs, y = time_to_recurrence, fill = bgs) + geom_violin() + geom_jitter(width = 0.2) + theme_minimal() + theme(legend.position = &quot;none&quot;) + labs(x = &quot;Baseline Gleason Score&quot;, y = &#39;Time to Recurrence&#39;, title = glue(&quot;Preop PSA by baseline Gleason Score for RBC Age: {rbc_age_group}&quot;)) We would like to make this plot for each level of rbc age (rbc_age_group). Let’s walk through the process of how to build this into a function, and how to map it across all the values of rbc_age_group. First, let’s avoid hard-coding the value for rbc_age_group. Use .data$var for a variable in a column, and .env$var for an environment variable. Edit both sides of logic test in the filter statement in the code chunk below to eliminate hard coding the filter variable and the filter value. Then, check that this works for other values by changing the rbc_age_group environmental variable value to 2 or 3. rbc_age_group = 1 prostate %&gt;% filter(rbc_age_group == 1) %&gt;% ggplot() + aes(x = bgs, y = time_to_recurrence, fill = bgs) + geom_violin() + geom_jitter(width = 0.2) + theme_minimal() + theme(legend.position = &quot;none&quot;) + labs(x = &quot;Baseline Gleason Score&quot;, y = &#39;Preoperative PSA&#39;, title = glue(&quot;Preop PSA by baseline Gleason Score for RBC Age: {rbc_age_group}&quot;)) Now make this into a function, named make_plot. Edit the chunk below to turn it into a function by wrapping the code in curly braces on the preceding and following line prefacing the first curly brace with function(argument) - in this case, the argument will be rbc_age_group. assigning the function to the name make_plot Then run make_plot(1) rbc_age_group = 1 { prostate %&gt;% filter(.data$rbc_age_group == .env$rbc_age_group) %&gt;% ggplot() + aes(x = bgs, y = time_to_recurrence, fill = bgs) + geom_violin() + geom_jitter(width = 0.2) + theme_minimal() + theme(legend.position = &quot;none&quot;) + labs(x = &quot;Baseline Gleason Score&quot;, y = &#39;Preoperative PSA&#39;, title = glue(&quot;Preop PSA by baseline Gleason Score for RBC Age: {rbc_age_group}&quot;)) } Now, let’s automate calling the function, with a vector of the values of rbc_age_group, and running the function over each of these with map(vector, function). Edit the vector and function in the code chunk below to use the map function to create a list of plots. Hint - the vector is provided, and your new function name is make_plot. When it is working, simplify the plots1-3 by replacing them with walk(plots, print) rbc_age_group = 1:3 plots &lt;- map(vector, func) plots[[1]] plots[[2]] plots[[3]] Now let’s make this a more generalized function with 2 arguments - data, and rbc_age_group. Edit the code chunk below to create a new function, make_plot2. Remember to: wrap the code in curly braces on the preceding and following line preface the first curly brace with function(arguments) - in this case, the arguments will be data, rbc_age_group. assigning the function to the name make_plot2 Remove the filter step Replace the filter step with a separate (outside the function) filter step to filter for rbc_age_group ==1, that saves the result to data_prostate_1 Then run make_plot2 rbc_age_group = 1 make_plot2 &lt;- function(arg1, arg2){ prostate %&gt;% filter(.data$rbc_age_group == .env$rbc_age_group) %&gt;% ggplot() + aes(x = bgs, y = time_to_recurrence, fill = bgs) + geom_violin() + geom_jitter(width = 0.2) + theme_minimal() + theme(legend.position = &quot;none&quot;) + labs(x = &quot;Baseline Gleason Score&quot;, y = &#39;Preoperative PSA&#39;, title = glue(&quot;Preop PSA by baseline Gleason Score for RBC Age: {rbc_age_group}&quot;)) } data_prostate_1 &lt;- prostate %&gt;% filter(rbc_age_group == 1) make_plot2(data_prostate_1, rbc_age_group = 1) Now let’s try to use make_plot in a tidy pipeline in the chunk below. In the chunk below, you want to nest the data by rbc_age_group, and map the make_plot function over the values of rbc_age_group. Edit both of the var values in the code chunk below to rbc_age_group. Run it to see the nested tibbles and nested plots in your new dataframe. prostate %&gt;% nest(data = -var) %&gt;% mutate(plots = map(var, make_plot)) Now pull out the plots and print them with pull and walk by editing the code chunk below. Pipe this code into the pull and walk functions by adding two lines of code. Remember that the argument for pull is the plotscolumn. Remember that the argument for walk is the print function. prostate %&gt;% nest(data = -rbc_age_group) %&gt;% mutate(plots = map(rbc_age_group, make_plot)) Now let’s make this even more generalizable with the make_plot2 functiion, which has 2 arguments, for data and rbc_age_group. Edit the code chunk below to replace arg1 with the data column, and func with make_plot2. See if this runs prostate %&gt;% nest(data = -rbc_age_group) %&gt;% mutate(plots = map2(arg1, rbc_age_group, func)) %&gt;% pull(plots) %&gt;% walk(print) This version of the pipeline should run for all values of rbc_age_group. 30.3 Freestyle Now try this on your own - and use the outline mode to jump back and forth to previous code chunks to make this easier. NOTE - need to FIX, Infert REMOVED 1. Make a plot of age (on the y axis) vs by parity (x axis) in the infert dataset with violin and jitter plots, as in the prostate example prostate-plot-1. This should be filtered for education == “0-5yrs”. Edit to make appropriate axis labels as appropriate. 2. Make a non-hard-coded version, by editing the filter statement with .data and .env variables, and edit the title with glue as in prostate-plot-2. 3. Make this into a function, make_infert_plots, as in prostate-plot-3. Try this with different values for education. 4. Set the levels of education with a vector as in prostate-plot 4, make plots with the map function, and print these out, with the walk function 5. Now make a more generalizable function, make_infert_plots2, by adding a data argument, as in prostate-plot-5. 6. Now nest the data by education, and mutate up some plots with make_infert_plots, as in prostate-plot-6 7. Then pull these plots and print them out with walk, as in prostate-plot-7 8. Now make a nested and generalizable version for all values of education, using your make_infert_plots2 function, as in prostate-plot-8 30.3.1 Acknowledgement This chapter is inspired by a lesson from Claus Wilke at https://wilkelab.org/SDS375/slides/functional-programming 30.4 Read More More on these topics can be found in R for Data Science - Chapter 19: Functions R for Data Science - Chapter 21.5: Map Functions Purrr::map documentation A blog post on how to use purrr:map to make plots for all 50 states and put them into a powerpoint presentation. "],["using-found-web-data.html", "Chapter 31 Using Found (Web) Data 31.1 Found Poetry 31.2 Found Data 31.3 Download Example 31.4 Datapasta (small table) Example 31.5 Your Turn 31.6 {rvest} Example 31.7 Your Turn 31.8 API example with {tidycensus} 31.9 Challenges 31.10 Advanced Challenge - Dynamic Websites", " Chapter 31 Using Found (Web) Data 31.1 Found Poetry You will, on occasion, find a useful table of data online, already in electronic format, that would be useful for you to use as an outcome or as an independent variable in an analysis. It would be silly to re-type these data, as they are already in electronic format. I call this ‘Found Data’, as opposed to data you generate, collect, and curate yourself, in part as a reference to the concept of ‘Found Poetry’, where a poet finds a text, and then adds line breaks to put it into verse form. Several classic examples were intermittently published in the Village Voice in New York City, championing the “Found Poetry” of the New York Yankees’ announcer Phil Rizzuto. From an April 21, 1991 broadcast: Field of Butterflies Absolutely! If you don’t get a little A few butterflies No matter what you do On the first day of anything You’re not human It is important to check and validate any data you find on the web. It may be out of date, or simply wrong. Be careful to use reliable sources (The CDC, the Census Bureau, or sites like KFF) as often as you can. 31.2 Found Data You might find data on population, income, or socioeconomic markers organized by geography (state, city, province), or other data that you can use to enrich your analysis. There are four major options to bring these found data onto your local computer and into your local project. Download the data, usually as a .csv or .xlsx file, and read it into R using read_csv() or read_excel(). Look for a download button first. A good example is the KFF (Kaiser Family Foundation) website, which has a lot of useful data on health care, and often has a download button for the data. One insurance example here. Look for the download button (downward arrow into a file tray) at the top right of the data frame. Particularly for small, one-off tables, copy the table and use the {datapasta} package to paste it into R. You may need to do a bit of data cleaning, but this is pretty straightforward, and you can save the table as a csv once it is cleaned, and just re-load this with read_csv() in the future. Use the {rvest} package to scrape the data from a website. This is a bit more advanced, but can be very useful if the data are updated frequently on a website, and it is important (e.g. for a dashboard) to have the freshest, up-to-date data. Look for a package that uses an API (Application Programming Interface) to the data website, and you can use the package to access the data directly (like {tidycensus} for US Census data). 31.3 Download Example You will find datasets that are really useful (and often really big) online, and you generally will want to download these along with the documentation to help you understand the data. Documentation often supplies details and meta-data about how the data were collected, organized, and cleaned. One good example from the Centers of Disease Control (CDC) in the US is the Social Vulnerability Index (SVI). This is a dataset that is updated every two years, and is used to help identify vulnerable communities that may need extra support in the event of a disaster. The data are available at the CDC website here. You can choose a single state, or the whole US to download. New data are available every 2 years. You can also select the SVI data in the US by county or census tract. The documentation files for these datasets are also available in links on the right side of this page. You can just download a table of the data, or include the shapefiles for the geographic units (counties, states, census tracts) that will allow you to create maps of the data. 31.4 Datapasta (small table) Example You will on occasion find a smallish table that could be helpful for your analysis. I often use population by state for US data. It can be useful to normalize state-level data by the state population, and it can be helpful to pull in a table of these data. An example of a table of state populations is available at the online Encyclopedia Brittanica, at https://www.britannica.com/topic/largest-U-S-state-by-population. You can copy the entire table (Cmd-C / Ctrl-C), then use the datapasta package add-in to paste it into R. First, make sure you have loaded {datapasta}, by running the code chunk below. library(datapasta) Start by copying the table from the website (Ctrl-C / Cmd-C). Recreate the code: pop_data &lt;- paste_from_datapasta_here from the code chunk below in your local version of R Studio. Delete the “paste_from_datapasta_here” in your local R Studio and leave your cursor there. Now go to the top of your RStudio window, and find the “Addins” dropdown. Click on this dropdown and find the DATAPASTA commands section. Use the ‘Paste as data.frame’ add-in to paste the data into R. Paste it into the indicated spot in the code chunk below. 6, Then run this code. This will create a data frame called pop_data with the data you pasted in, which will appear in your Environment tab. pop_data &lt;- paste_from_datapasta_here Now you have the data in, but it is still a bit icky and in need of some data cleaning. Open up the pop_data dataframe by clicking on the name in the Environment tab, and look at the data. What needs to be cleaned up? Click here to see the solution The first row is the header, but the names are icky, and not in standard lower case with underscores (snake_case). You can use the janitor::clean_names() function to fix this. The state names have ranking numbers before them, which need to be removed. You can use the mutate() and str_remove(\"\\\\d+\\\\. \") function to remove these. Note the double backslashes in the str_remove() function to use escape characters for d (digits) and the period (used for all punctuation). The population estimates include “(2023 est.)”, which also needs to be removed. Use the mutate() and str_remove(\"\\\\(2023 est.\\\\) \") function to remove these. Note the double backslashes in the str_remove() function to use escape characters for parentheses. The population census numbers include “(2020)”, which also needs to be removed, with mutate() and str_remove(\"\\\\(2020\\\\) \") functions. The population numbers are in a character format, and need to be converted to numeric. You can use the dplyr::mutate() and as.numeric() functions to convert these. the cleaned u_s_state variable name is still a bit icky - go ahead and use rename(new_name = old_name) to rename it to state. Take a few minutes to clean up these data. If needed, websearch str_remove() and as.numeric() to see how they work. Details on how to match digits and punctuation in regular expressions can be found at https://www.regular-expressions.info/quickstart.html. 31.5 Your Turn Take a look at the web page at US state poverty data. This is a website with 3 tables on poverty in US states and territories. Inspect this web page a bit. Take a look at these from the datapasta perspective, and try to copy the US Census Bureau table (the first one, but compy without the messy headers) to your local RStudio. You can use the {datapasta} Addin menu to paste the data into R and assign it to an object. Then clean up the data as needed. Give this a try in your local RStudio, using the instructions below to scrape the US Census Bureau table. Check your solution by clicking on the “Click here to see the solutions” button below. Copy the US Census Bureau table (the first table) by selecting and Cmd-C/Ctrl-C. Since the headers are a bit messy, skip these (we will use purrr::set_names later).You may also choose to skip the summary line for the United States at the end (or filter it out later). Go to your local RStudio, be sure {datapasta} is loaded, and select the Addin to paste a data.frame. Assign the data with the assignment arrow to a new data_poverty object. Clean up the data as needed. You will need to set the names of the columns, remove the summary line for the US, remove the % symbol from the percentage with str_remove(), and then convert the numeric columns from character to numeric. See below for a data cleaning solution. Click here to see the solutions data_poverty &lt;- data.frame( stringsAsFactors = FALSE, V1 = c(&quot;Mississippi&quot;,&quot;Louisiana&quot;, &quot;New Mexico&quot;,&quot;West Virginia&quot;,&quot;Kentucky&quot;,&quot;Arkansas&quot;, &quot;Alabama&quot;,&quot;District of Columbia&quot;,&quot;Oklahoma&quot;, &quot;South Carolina&quot;,&quot;Tennessee&quot;,&quot;Georgia&quot;,&quot;Texas&quot;,&quot;Arizona&quot;, &quot;North Carolina&quot;,&quot;Michigan&quot;,&quot;Ohio&quot;,&quot;New York&quot;,&quot;Florida&quot;, &quot;Missouri&quot;,&quot;Indiana&quot;,&quot;South Dakota&quot;,&quot;Montana&quot;,&quot;Nevada&quot;, &quot;California&quot;,&quot;Oregon&quot;,&quot;Illinois&quot;,&quot;Pennsylvania&quot;,&quot;Idaho&quot;, &quot;Rhode Island&quot;,&quot;Kansas&quot;,&quot;Delaware&quot;,&quot;Iowa&quot;,&quot;Maine&quot;, &quot;Wisconsin&quot;,&quot;Vermont&quot;,&quot;Wyoming&quot;,&quot;North Dakota&quot;, &quot;Nebraska&quot;,&quot;Alaska&quot;,&quot;Washington&quot;,&quot;Virginia&quot;,&quot;Massachusetts&quot;, &quot;Connecticut&quot;,&quot;Colorado&quot;,&quot;New Jersey&quot;,&quot;Minnesota&quot;, &quot;Hawaii&quot;,&quot;Utah&quot;,&quot;Maryland&quot;,&quot;New Hampshire&quot;), V2 = c(2883074,4532187,2053909, 1755591,4322881,2923585,4771614,669089,3833712,4950181, 6603468,10238369,28013446,7012999,10098330,9753541, 11350378,19009098,20793628,5942813,6491632,849910, 1036490,2987817,38589882,4096744,12418504,12387061, 1722972,1017028,2828498,941266,3051284,1304038, 5659485,599938,566858,735842,1869467,719445,7372433, 8255575,6637329,3466935,5563823,8713792,5476956, 1381577,3102049,5894835,1312770), V3 = c(564439,845230,381026,300152, 717895,470190,762642,103391,585520,726470,965213, 1461572,3984260,990528,1411939,1337256,1546011, 2581048,2772939,772992,838149,108863,132476,381695, 4853434,506558,1488670,1480430,205676,117785,323644, 107641,339090,144384,620947,64700,61006,77491, 193820,74369,751044,826708,653454,339156,544232,842704, 511185,127971,283360,531553,97418), V4 = c(&quot;19.58%&quot;,&quot;18.65%&quot;,&quot;18.55%&quot;, &quot;17.10%&quot;,&quot;16.61%&quot;,&quot;16.08%&quot;,&quot;15.98%&quot;,&quot;15.45%&quot;,&quot;15.27%&quot;, &quot;14.68%&quot;,&quot;14.62%&quot;,&quot;14.28%&quot;,&quot;14.22%&quot;,&quot;14.12%&quot;, &quot;13.98%&quot;,&quot;13.71%&quot;,&quot;13.62%&quot;,&quot;13.58%&quot;,&quot;13.34%&quot;,&quot;13.01%&quot;, &quot;12.91%&quot;,&quot;12.81%&quot;,&quot;12.78%&quot;,&quot;12.78%&quot;,&quot;12.58%&quot;,&quot;12.36%&quot;, &quot;11.99%&quot;,&quot;11.95%&quot;,&quot;11.94%&quot;,&quot;11.58%&quot;,&quot;11.44%&quot;, &quot;11.44%&quot;,&quot;11.11%&quot;,&quot;11.07%&quot;,&quot;10.97%&quot;,&quot;10.78%&quot;,&quot;10.76%&quot;, &quot;10.53%&quot;,&quot;10.37%&quot;,&quot;10.34%&quot;,&quot;10.19%&quot;,&quot;10.01%&quot;,&quot;9.85%&quot;, &quot;9.78%&quot;,&quot;9.78%&quot;,&quot;9.67%&quot;,&quot;9.33%&quot;,&quot;9.26%&quot;,&quot;9.13%&quot;, &quot;9.02%&quot;,&quot;7.42%&quot;) ) |&gt; set_names(c(&quot;state&quot;,&quot;pop&quot;,&quot;pop_poverty&quot;, &quot;pct_poverty&quot;)) |&gt; filter(state != &quot;United States&quot;) |&gt; mutate(pct_poverty = str_remove(pct_poverty, &quot;%&quot;)) |&gt; mutate(across(c(pop, pop_poverty, pct_poverty), as.numeric)) 31.6 {rvest} Example The {rvest} package is a powerful tool for scraping (‘harvesting’) data from websites. It is a bit more advanced, but can be very useful if the data are updated frequently on a website, and fresh data are important. First, make sure that you have loaded the {rvest} package by running the code chunk below. library(rvest) The general workflow is to: Find a website with a useful table of data that is not in a viewport (dynamically generated by javascript - these are ones that you can not select or copy). This is true for most tables, particularly on Wikipedia, and is generally true of any table that you can select to copy. Copy the URL of the website and put it (in quotes) into the read_html() function. Assign this result to an object, like webpage. Use the html_nodes('table') function to get a list of the nodes of the html that contain the tabular data you want. Generally, you will get a node for anything that looks like a table with cells on the webpage. Many of these will not be what you want. But if it clearly is a table or a ‘wikitable’, it will work. You can then use the html_table() function to convert these nodes into a list of data frames. You can then use the pluck(N) function from the {purrr} package to extract the Nth data frame from the list of data frames. Let’s try this out. The URL “https://en.wikipedia.org/wiki/Health_insurance_coverage_in_the_United_States” has a table of US states and their health insurance coverage. We can use the {rvest} package to scrape this data. First, copy the URL of the website, and put it into the read_html() function. Assign this result to an object, like wiki_page. wiki_page &lt;- read_html(&quot;https://en.wikipedia.org/wiki/Health_insurance_coverage_in_the_United_States&quot;) Next, ask {rvest} to find all the tables on the page. You can do this by using the html_nodes() function with the argument 'table'. Assign this result to an object, like tables. tables &lt;- wiki_page %&gt;% html_nodes(&quot;table&quot;) Go ahead and inspect this by clicking on the tables object in the Environment tab. You will see a list of nodes, each of which is a table on the webpage. You can click on the blue arrow to the left of each one to see more detail about the header and body to help determine which one you want. As a general rule, a box or sidebar or ‘nowraplinks’ are not helpful. But if you see a wikitable with a header and body, that is likely the one you want. In this case, node 5 looks promising. Take a peek at the actual webpage and see if you can figure out what each of the other box, sidebar, or nowraplinks actually are. If you are not sure, you can also convert all of these nodes to tables with html_table() and then decide which one you want. Copy and run the code chunk below to help you decide which of the 8 “tables” is useful. wiki_page %&gt;% html_nodes(&quot;table&quot;) |&gt; html_table() ## [[1]] ## # A tibble: 9 × 1 ## X1 ## &lt;chr&gt; ## 1 &quot;This article is part of a series on&quot; ## 2 &quot;Healthcare reform in theUnited States&quot; ## 3 &quot;History\\nDebate&quot; ## 4 &quot;Legislation\\nPrecedingSocial Security Amendments of 1965EMTALA (1986)\\nHIPAA… ## 5 &quot;Reforms\\nObama administration proposals\\nPublic opinion\\nReform advocacy gro… ## 6 &quot;Systems\\nFree market\\nHealth insurance exchange\\nNationalized insurance\\nPub… ## 7 &quot;Third-party payment models\\nAll-payer rate setting\\nCapitation\\nFee-for-serv… ## 8 &quot;United States portal Health care portal&quot; ## 9 &quot;.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.m… ## ## [[2]] ## # A tibble: 9 × 3 ## Year `Number Uninsured (Mil)` `Uninsured Percent` ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 2010 48.2 18.2% ## 2 2013 (Pre-ACA) 44.3 16.6% ## 3 2016 28.2 10.4% ## 4 2017 28.9 10.7% ## 5 2018 30.1 11.1% ## 6 2019 32.8 12.1% ## 7 2020 31.2 11.5% ## 8 2021 29.6 11.0% ## 9 2022H 27 9.9% ## ## [[3]] ## # A tibble: 1 × 2 ## X1 X2 ## &lt;lgl&gt; &lt;chr&gt; ## 1 NA This section relies largely or entirely upon a single source. Relevant … ## ## [[4]] ## # A tibble: 1 × 2 ## X1 X2 ## &lt;lgl&gt; &lt;chr&gt; ## 1 NA This section relies largely or entirely upon a single source. Relevant … ## ## [[5]] ## # A tibble: 52 × 17 ## Division `1999` `2000` `2001` `2002` `2003` `2004` `2005` `2006` `2007` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 United States 13.6 13.1 13.5 13.9 14.6 14.3 14.6 15.2 14.7 ## 2 Alabama 12 12.5 12.4 12.2 12.5 12 14 15.1 11.7 ## 3 Alaska 18.3 17.4 14.8 18 17.5 15.3 16.9 16.4 17.6 ## 4 Arizona 19.4 16.4 16.7 16.4 16.4 16.2 19.1 20.8 17.8 ## 5 Arkansas 13.9 14.1 16.4 16.5 17.2 15.9 17.2 18.6 15.7 ## 6 California 19 17.5 18 16.5 17.3 17.5 18 17.8 17.5 ## 7 Colorado 14.1 12.9 14.6 14.5 15.3 15.2 16.2 16.5 16 ## 8 Connecticut 7.3 8.9 8.2 8.6 9.4 10.3 10.1 8.7 8.6 ## 9 Delaware 9.7 8.5 8.5 9.2 9.6 13.1 11.6 11.9 10.6 ## 10 District of C… 14 12.8 12.3 13 12.7 12 12.4 10.9 9.3 ## # ℹ 42 more rows ## # ℹ 7 more variables: `2008` &lt;dbl&gt;, `2009` &lt;dbl&gt;, `2010` &lt;dbl&gt;, `2011` &lt;dbl&gt;, ## # `2012` &lt;dbl&gt;, `2013` &lt;dbl&gt;, `2014` &lt;dbl&gt; ## ## [[6]] ## # A tibble: 1 × 2 ## X1 X2 ## &lt;lgl&gt; &lt;chr&gt; ## 1 NA This section relies largely or entirely upon a single source. Relevant … ## ## [[7]] ## # A tibble: 11 × 14 ## vteInsurance vteInsurance `` `` `` `` `` `` `` `` ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 &quot;Types of insur… &quot;Health\\nAc… Heal… &quot;Acc… Life &quot;Lon… Busi… &quot;Bon… Resi… &quot;Boi… ## 2 &quot;Health&quot; &quot;Accident\\n… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 3 &quot;Life&quot; &quot;Longevity … &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 4 &quot;Business&quot; &quot;Bond\\nBusi… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 5 &quot;Residential&quot; &quot;Boiler\\nBu… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 6 &quot;Transport/Comm… &quot;Aviation\\n… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 7 &quot;Other&quot; &quot;Reinsuranc… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 8 &quot;Insurance poli… &quot;Act of God… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 9 &quot;Insurance by c… &quot;Australia\\… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 10 &quot;History&quot; &quot;Mesopotami… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 11 &quot;Category\\nList… &quot;Category\\n… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## # ℹ 4 more variables: `` &lt;chr&gt;, `` &lt;chr&gt;, `` &lt;chr&gt;, `` &lt;chr&gt; ## ## [[8]] ## # A tibble: 6 × 2 ## X1 X2 ## &lt;chr&gt; &lt;chr&gt; ## 1 Health &quot;Accident\\nAccidental death and dismemberment\\nDental… ## 2 Life &quot;Longevity insurance\\nMortgage life\\nTerm life\\nUniti… ## 3 Business &quot;Bond\\nBusiness interruption\\nBusiness owner\\nCollate… ## 4 Residential &quot;Boiler\\nBuilder&#39;s risk\\nContents\\nEarthquake\\nFlood\\… ## 5 Transport/Communication &quot;Aviation\\nGAP insurance\\nInland marine\\nPublic auto\\… ## 6 Other &quot;Reinsurance\\nCatastrophe bond\\nInsurance-linked secu… Now we can pluck out table 5, convert it to an html_table, and then convert it to a tibble. We can then use the set_names() function to assign the column names, and assign this to a new object, like data_ins. Run the code chunk in your local RStudio and take a look at the resulting data_ins object. library(tidyverse) tables %&gt;% html_table() |&gt; pluck(5) |&gt; as_tibble() |&gt; purrr::set_names(c(&#39;state&#39;, 1999:2014)) -&gt; data_ins Open and inspect the data_ins object. Note that we brought along a ‘United States’ weighted summary row from the original web table, which may or may not be something you want. You can use the filter() function to remove this row if you want. 31.7 Your Turn Take a look at the web page at “https://en.wikipedia.org/wiki/List_of_epidemics_and_pandemics” to find two interesting tables on pandemics. Inspect this web page a bit. You will see that there are two tables that are of interest (out of 22 nodes identified by html_nodes(). The first is on the top 10 pandemics by death toll, and the second contains a long chronology of pandemics. Also, look out for other boxes and sidebars that {rvest} might consider as tables. Give this a try in your local RStudio, using the instructions below to scrape the 2 interesting tables. Check your solution by clicking on the “Click here to see the solutions” button below. Use the {rvest} package to scrape these two tables. Read the html from the URL and assign the result to an object called wiki_pandemic. Use the html_nodes() function with the argument 'table' to find all the tables on the page. Use the html_table() function to convert this node into a list of data frames. Use the pluck() function to pick out the table you want (scrape these one at a time). Use the as_tibble() function to convert these data frames into tibbles. Use the set_names() or janitor::clean_names() function to assign the column names. Then scrape the second (chronology) table. Assign these to the objects pandemic_data and chron_pandemics. Click here to see the solutions wiki_pandemic &lt;- read_html(&quot;https://en.wikipedia.org/wiki/List_of_epidemics_and_pandemics&quot;) wiki_pandemic %&gt;% html_nodes(&quot;table&quot;) %&gt;% pluck(1) |&gt; html_table() |&gt; as_tibble() |&gt; purrr::set_names(c(&#39;rank&#39;, &#39;epidemic&#39;, &#39;disease&#39;, &#39;death_toll&#39;, &#39;percent_lost&#39;, &#39;years&#39;, &#39;location&#39;)) -&gt; pandemic_data wiki_pandemic %&gt;% html_nodes(&quot;table&quot;) %&gt;% pluck(2) |&gt; html_table() |&gt; as_tibble() |&gt; janitor::clean_names() -&gt; chron_pandemics 31.8 API example with {tidycensus} An API (Application Programming Interface) is a way to access data from a website. The data are generally in a structured format, like JSON or XML, and can be accessed by sending a request to a URL. The {httr} package is a powerful (general) tool for working with APIs. Folks who use a particular API often find it easier to make custom functions to access the data, and when generally useful, share these in an R packages. The {tidycensus} package is a wrapper around the US Census API that makes it easier to access data from the US Census. Kyle Walker, a Professor of Geography at Texas A&amp;M, created and maintains this package. To use {tidycensus}, you need to sign up for a (free) API KEY from the US Census bureau. The tidycensus website has instructions on how to do this. Once you have your API key, you can use the census_api_key() function to set your API key in your R environment. You only need to do this once. For each of the thousands of variables collected by the US Census Bureau, you can get an estimate and a margin of error (MOE) by the geographical division you request (from national down to census block). The {tidycensus} package makes it easy to get these estimates and margins of error for a given geography. The get_acs() function is the workhorse of the package. It takes a geography, a list of variables, and a year as arguments, and returns a tibble with the estimates and margins of error for each variable from the American Community Survey (ACS). Note that the variables have icky names (variable ids) like “P001001” for total population. Finding the variables you want can be a bit of a project. See section 2.3 of the TidyCensus book [here](https://walker-data.com/census-r/an-introduction-to-tidycensus.html) for strategies on how to load the list of variables into a dataset and then search for the concepts (income, population, etc) that you want. The Census Bureau explainer on variable ids can be found [here](https://www.census.gov/content/dam/Census/library/publications/2021/acs/acs_summary_file_handbook_2021_ch03.pdf) Explore the tidycensus webpage a bit, especially the articles tab. This can be very helpful if you have US health data divided by a geographical unit. You may also want to map these data, and the {tigris} and {mapgl} packages can help you with that. We will save the deep dive on these for a later chapter. 31.9 Challenges Try to use the {datapasta} or the {rvest} approaches on the following webpages: life_expectancy by county hospital beds data by county gun deaths by state COVID Deaths by City US state population data US state GDP data 31.10 Advanced Challenge - Dynamic Websites Sites that dynamically generate tables of data with JavaScript can be difficult to scrape data from, as these do not have data in their static HTML code. A good example is the KFF health website described above in the first of four ways (downloading) found data on the web. You can scrape data from this kind of site with the help of a ‘headless’ programmable web browser, like the {chromote} package. This is complicated but doable. There is a nice youtube video demonstration here. "],["linear-regression-and-broom-for-tidying-models.html", "Chapter 32 Linear Regression and Broom for Tidying Models 32.1 Packages needed 32.2 Building a simple base model with {lm} 32.3 Is Your Model Valid? 32.4 Making Predictions with Your Model 32.5 Choosing predictors for multivariate modeling – testing, dealing with collinearity 32.6 presenting model results with RMarkdown 32.7 presenting model results with a Shiny App", " Chapter 32 Linear Regression and Broom for Tidying Models Linear regression allows you to: estimate the effects of predictors (independent variables) on an outcome (dependent variable), assuming that there is a linear relationship Make predictions about future cases (patients) with their measured predictors on this continuous outcome. Let’s look at a simple linear model to predict annual health care expenses. library(tidyverse) library(mlbench) library(broom) library(cutpointr) ## ## Attaching package: &#39;cutpointr&#39; ## The following object is masked from &#39;package:bayestestR&#39;: ## ## auc library(janitor) library(easystats) library(medicaldata) dm_data &lt;- data(&quot;PimaIndiansDiabetes2&quot;, package = &quot;mlbench&quot;) # build model, all variables dm_mod &lt;- glm(diabetes ~ ., data = PimaIndiansDiabetes2, family = &quot;binomial&quot;) # output summary(dm_mod) ## ## Call: ## glm(formula = diabetes ~ ., family = &quot;binomial&quot;, data = PimaIndiansDiabetes2) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.004e+01 1.218e+00 -8.246 &lt; 2e-16 *** ## pregnant 8.216e-02 5.543e-02 1.482 0.13825 ## glucose 3.827e-02 5.768e-03 6.635 3.24e-11 *** ## pressure -1.420e-03 1.183e-02 -0.120 0.90446 ## triceps 1.122e-02 1.708e-02 0.657 0.51128 ## insulin -8.253e-04 1.306e-03 -0.632 0.52757 ## mass 7.054e-02 2.734e-02 2.580 0.00989 ** ## pedigree 1.141e+00 4.274e-01 2.669 0.00760 ** ## age 3.395e-02 1.838e-02 1.847 0.06474 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 498.10 on 391 degrees of freedom ## Residual deviance: 344.02 on 383 degrees of freedom ## (376 observations deleted due to missingness) ## AIC: 362.02 ## ## Number of Fisher Scoring iterations: 5 #tidy version tidy(dm_mod) ## # A tibble: 9 × 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) -10.0 1.22 -8.25 1.64e-16 ## 2 pregnant 0.0822 0.0554 1.48 1.38e- 1 ## 3 glucose 0.0383 0.00577 6.64 3.24e-11 ## 4 pressure -0.00142 0.0118 -0.120 9.04e- 1 ## 5 triceps 0.0112 0.0171 0.657 5.11e- 1 ## 6 insulin -0.000825 0.00131 -0.632 5.28e- 1 ## 7 mass 0.0705 0.0273 2.58 9.89e- 3 ## 8 pedigree 1.14 0.427 2.67 7.60e- 3 ## 9 age 0.0340 0.0184 1.85 6.47e- 2 # model performance glance(dm_mod) ## # A tibble: 1 × 8 ## null.deviance df.null logLik AIC BIC deviance df.residual nobs ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 498. 391 -172. 362. 398. 344. 383 392 # augment data with fitted predictions and residuals dm_data_plus &lt;- augment(dm_mod) %&gt;% mutate(pct_prob = 100 * plogis(.fitted)) %&gt;% relocate(diabetes, .fitted, pct_prob) %&gt;% arrange(-.fitted) # select a cut point for classification cp &lt;- dm_data_plus %&gt;% cutpointr(pct_prob, diabetes, pos_class = &quot;pos&quot;, method= maximize_metric, metric = sum_sens_spec) ## Assuming the positive class has higher x values cp ## # A tibble: 1 × 16 ## direction optimal_cutpoint method sum_sens_spec acc sensitivity ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 &gt;= 28.5839 maximize_metric 1.57504 0.772959 0.830769 ## specificity AUC pos_class neg_class prevalence outcome predictor ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;fct&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.744275 0.862361 pos neg 0.331633 diabetes pct_prob ## data roc_curve boot ## &lt;list&gt; &lt;list&gt; &lt;lgl&gt; ## 1 &lt;tibble [392 × 2]&gt; &lt;rc_ctpnt [393 × 10]&gt; NA summary(cp) ## Method: maximize_metric ## Predictor: pct_prob ## Outcome: diabetes ## Direction: &gt;= ## ## AUC n n_pos n_neg ## 0.8624 392 130 262 ## ## optimal_cutpoint sum_sens_spec acc sensitivity specificity tp fn fp tn ## 28.5839 1.575 0.773 0.8308 0.7443 108 22 67 195 ## ## Predictor summary: ## Data Min. 5% 1st Qu. Median Mean 3rd Qu. 95% ## Overall 0.8690932 3.071251 8.953085 22.94296 33.16327 53.11714 88.92870 ## neg 0.8690932 2.674187 6.392249 13.48437 21.10577 28.96611 69.31582 ## pos 3.7635587 14.863216 34.854283 62.18036 57.46376 80.93884 92.17256 ## Max. SD NAs ## 99.46861 28.45645 0 ## 97.91551 20.49784 0 ## 99.46861 26.71998 0 plot(cp) plot_metric(cp) # classify based on cut point dm_data_plus &lt;- dm_data_plus %&gt;% mutate(pred_yes_dm = case_when(pct_prob &gt; cp$optimal_cutpoint ~ &quot;pred_yes_dm&quot;, TRUE ~ &quot;pred_no&quot;)) %&gt;% relocate(pred_yes_dm, .after =pct_prob) # check confusion matrix dm_data_plus %&gt;% tabyl(diabetes, pred_yes_dm) %&gt;% adorn_totals(&quot;both&quot;) %&gt;% adorn_percentages() %&gt;% adorn_pct_formatting() ## diabetes pred_no pred_yes_dm Total ## neg 74.4% 25.6% 100.0% ## pos 17.7% 82.3% 100.0% ## Total 55.6% 44.4% 100.0% #check model performance performance::check_model(dm_mod, panel = FALSE) # use panel = TRUE in Rmarkdown to get 2x3 panels for 6 plots # performance::model_performance(dm_mod) ## # Indices of model performance ## ## AIC | AICc | BIC | Tjur&#39;s R2 | RMSE | Sigma | Log_loss | Score_log ## ------------------------------------------------------------------------------ ## 362.021 | 362.492 | 397.763 | 0.364 | 0.376 | 1.000 | 0.439 | -74.015 ## ## AIC | Score_spherical | PCP ## --------------------------------- ## 362.021 | 0.009 | 0.718 #try a different model dm_mod2 &lt;- glm(diabetes ~ glucose + mass + pedigree + age, data = PimaIndiansDiabetes2, family = &quot;binomial&quot;) # build a really simple (NULL) model as a baseline dm_mod3 &lt;- glm(diabetes ~ 1, data = PimaIndiansDiabetes2, family = &quot;binomial&quot;) summary(dm_mod3) ## ## Call: ## glm(formula = diabetes ~ 1, family = &quot;binomial&quot;, data = PimaIndiansDiabetes2) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.62362 0.07571 -8.237 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 993.48 on 767 degrees of freedom ## Residual deviance: 993.48 on 767 degrees of freedom ## AIC: 995.48 ## ## Number of Fisher Scoring iterations: 4 # compare models # compare_performance(dm_mod, dm_mod2, dm_mod3, rank = TRUE) # plot(compare_performance(dm_mod, dm_mod2, dm_mod3, rank = TRUE)) + labs(subtitle = &quot;Larger Area is Better&quot;) # plot(compare_performance(dm_mod, dm_mod2, rank = TRUE)) + labs(subtitle = &quot;Larger Area is Better&quot;) #test_performance(dm_mod, dm_mod2, dm_mod3) # save model to RDS saveRDS(dm_mod, &quot;dm_mod.RDS&quot;) This is a simple web application that lets users who are not familiar with R use your model. They can enter values for the 3 predictor variables (gender, age, BMI) for a new patient, and predict their annual health insurance expenses in dollars. This web app produces a table with the inputs, and shows the output when you click the PREDICT button. Try it out here: Model Predictions Shiny Web App. Enter different predictor data points, and recalculate the expenses. You can click on the About tab for an explanation of the model, and even explore the publicly shared underlying code on GitHub (link in the About tab). We will walk through how to build, test, and share your own models in this chapter. 32.1 Packages needed {tidyverse} {medicaldata} {broom} {easystats} you can install this one (Not on CRAN) with install.packages(\"easystats\", repos = \"https://easystats.r-universe.dev\") {performance} {insight} {gtsummary} Note that the base modeling function lm() comes from the {stat} package, which loads by default when you start R. 32.2 Building a simple base model with {lm} The simplest model is called the null model, with no predictors. This model uses the mean value of the outcome to estimate it. In the blood_storage (prostate cancer) dataset in {medicaldata}, the mean time to recurrence is 32.92 months. To build a simple null model, you will need two main arguments to the lm() function: the formula the data The formula follows the format dependent_variable ~ independent_variables. Note that the data argument is not the first argument, so it does not automatically play well with pipes. You can pipe in data if you make the data argument explicit, and set it to data = . Let’s look at a simple example: Copy the code chunk below and run it in your RStudio Console. medicaldata::blood_storage %&gt;% lm(TimeToRecurrence ~ NULL, data = .) ## ## Call: ## lm(formula = TimeToRecurrence ~ NULL, data = .) ## ## Coefficients: ## (Intercept) ## 32.92 The output tells you the Call - the model being run, and then all the coefficients. In the case of the NULL model, the only coefficient is the intercept. This intercept is equal to the mean value of the outcome variable, TimeToRecurrence, in months. With no other predictor variables, this is the best estimate available for time to recurrence. We can also output the results as a nice tibble, using the tidy() function from the {broom} package. medicaldata::blood_storage %&gt;% lm(TimeToRecurrence ~ NULL, data = .) %&gt;% broom::tidy() ## # A tibble: 1 × 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 32.9 1.61 20.5 1.04e-59 This model has only one term, the intercept. It estimates every value of time to recurrence with the mean, 32.91. This is a pretty poor model, but is a place to start. Let’s look at how good this model is, using another function from the {broom} package. We can glance() our model, again output into a nice tibble. medicaldata::blood_storage %&gt;% lm(TimeToRecurrence ~ NULL, data = .) %&gt;% broom::glance() ## # A tibble: 1 × 12 ## r.squared adj.r.squared sigma statistic p.value df logLik AIC BIC ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 0 28.6 NA NA NA -1502. 3009. 3016. ## # ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt; The r.squared and adj.r.squared are both 0, so we are capturing none of the variation in the data with this null model. The log likelihood is -1502, and the AIC 3009, and BIC 3016 (these are both high because this is a crummy model). AIC is Akaike’s Information Criterion, and estimates the out-of-sample prediction error and relative quality of a statistical model. A higher number indicates more information lost. Lower numbers for AIC = higher quality models. BIC is the Bayesian Information Criterion, which like AIC, penalizes models for the number of parameters to reduce overfitting. BIC also considers the number of observations in the data, which AIC does not. Lower values of BIC are better, and BIC is generally always higher than AIC, but absolute values do not matter, only relative values when comparing models on the same dataset for the same outcome. If we improve the model (with useful predictor variables), the BIC should go down. Let’s add some predictors: Age, TVol (tumor volume), and sGS (surgical Gleason score), and see if we do better. medicaldata::blood_storage %&gt;% lm(TimeToRecurrence ~ Age + TVol + sGS, data = .) %&gt;% broom::glance() ## # A tibble: 1 × 12 ## r.squared adj.r.squared sigma statistic p.value df logLik AIC BIC ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.0130 0.00334 28.5 1.34 0.260 3 -1472. 2954. 2972. ## # ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt; We are now explaining some (about 0.33% = 100*the adjusted R-squared) of the variation with this predictor, and the log likelihood (-1472) got closer to zero, and the AIC (2954) and BIC (2972) were reduced, showing that this is a better model than the NULL model (though still not great). 32.2.0.1 Key Takeaways use lm() to build the model argument: formula = outcome ~ predictor1 + predictor2 + … argument: data = . with the pipe tidy() from {broom} to see the model table of estimates glance() from {broom}to see measures of model accuracy 32.2.0.2 Your turn with licorice! Pipe the licorice data into an lm() function, with a formula argument and the data = . argument. Use the outcome of pacu30min_throatPain. Use predictors like intraOp_surgerySize, treat, preOp_pain, preOp_gender, and preOp_smoking. Then pipe the result into the function tidy() to see the model, and (separately) into the function glance() to evaluate the model quality. Copy the code chunk below into RStudio as a start. Use tidy() to see the model table, and glance() to look at the performance of the model. medicaldata::licorice_gargle %&gt;% lm(formula = pacu30min_throatPain ~ var1 + var2 + var3, data = .) Show the solution medicaldata::licorice_gargle %&gt;% lm(formula = pacu30min_throatPain ~ intraOp_surgerySize + treat + preOp_pain + preOp_gender + preOp_smoking, data = .) %&gt;% tidy() ## # A tibble: 6 × 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.376 0.365 1.03 0.304 ## 2 intraOp_surgerySize 0.316 0.143 2.21 0.0283 ## 3 treat -0.690 0.154 -4.48 0.0000117 ## 4 preOp_pain 1.96 0.835 2.35 0.0197 ## 5 preOp_gender -0.265 0.160 -1.65 0.100 ## 6 preOp_smoking 0.0652 0.0956 0.682 0.496 medicaldata::licorice_gargle %&gt;% lm(formula = pacu30min_throatPain ~ intraOp_surgerySize + treat + preOp_pain + preOp_gender + preOp_smoking, data = .) %&gt;% glance() ## # A tibble: 1 × 12 ## r.squared adj.r.squared sigma statistic p.value df logLik AIC BIC ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.143 0.124 1.17 7.59 0.00000130 5 -364. 741. 765. ## # ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt; 32.2.0.3 Interpreting the Model Estimates For the full model with 5 predictors (shown in the hidden solution above - Click the button to show it), you get a tidied tibble with 6 rows and 5 columns. These are The first column is the term - these include the (Intercept) and each of the predictors you called in the model. the second column is the estimate. This is the point estimate of the effect of each predictor in the multivariable model. For the intraOp_surgerySize predictor, this is 0.316. This means that for each unit or level increase of intraOp_surgerySize, which is defined on a 1-3 scale from small to large, the pacu_30min_throat pain (on a 0-10 scale), increases by 0.316 points. So a large surgery (2 levels larger than small) will result in, on average, a pacu_30min_throat pain score 0.632 points higher than a small surgery. similarly, the estimate for preop_gender is -0.265. This means that for each 1 point increase in the level of preop_gender, coded as 0=male, 1=female, the pacu_30min_throat pain score goes doen by -0.265 points. In this case, that means that the average pacu_30min_throat pain score in females was 0.265 points lower than in males. the std.error column tells you about the variance of this estimate, and can help you calculate confidence intervals around the point estimated if needed. the statistic is the t value for the estimate, which allows you to calculate p values with a t test. Values with a large absolute value (farther from zero) imply a stronger effect. Values of the statistic &gt; 1.96 (absolute value) correspond to a p value &lt; 0.05. the p value is the significance of the estimate for that particular predictor variable. Low values (often &lt; 0.05) are considered significant for traditional, historical reasons (it is an arbitrary cutoff). 32.2.0.3.1 Check your work: For the full model with 5 predictors, the which predictor variable has the largest estimated effect on pacu30min_throatpain? intraOp_surgerySizepreOp_paingenderFemalesmokingtreatLicorice For the full model with 5 predictors, what is the BIC value (using the glance function)? -3647653097417 32.2.0.4 Your turn with supra! Use the supraclavicular dataset to build a model with the outcome onset_sensory, with predictors (independent variables) age, bmi, gender, and group. Output the regression table with tidy() and the model measures with glance()  Copy the code chunk below into RStudio as a start medicaldata::supraclavicular %&gt;% lm(formula = onset_sensory ~ var1, data = .) %&gt;% glance() Show Solution medicaldata::supraclavicular %&gt;% lm(formula = onset_sensory ~ age + bmi + gender + group, data = .) %&gt;% glance() ## # A tibble: 1 × 12 ## r.squared adj.r.squared sigma statistic p.value df logLik AIC BIC ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.0356 -0.00504 11.5 0.876 0.481 4 -383. 779. 794. ## # ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt; 32.2.0.4.1 For the full model with 4 predictors, what is the Adjusted R squared value? 0.036301.7-383.30.48-0.005 32.2.1 Producing manuscript-quality tables with {gtsummary} Let’s take your model above, and rather than pipe it into tidy() or glance(), pipe it into the tbl_regression() function from the {gtsummary} package. medicaldata::supraclavicular %&gt;% lm(formula = onset_sensory ~ age + bmi + gender + group, data = .) %&gt;% tbl_regression() #yytrkfivjp table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #yytrkfivjp thead, #yytrkfivjp tbody, #yytrkfivjp tfoot, #yytrkfivjp tr, #yytrkfivjp td, #yytrkfivjp th { border-style: none; } #yytrkfivjp p { margin: 0; padding: 0; } #yytrkfivjp .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #yytrkfivjp .gt_caption { padding-top: 4px; padding-bottom: 4px; } #yytrkfivjp .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #yytrkfivjp .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #yytrkfivjp .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #yytrkfivjp .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #yytrkfivjp .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #yytrkfivjp .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #yytrkfivjp .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #yytrkfivjp .gt_column_spanner_outer:first-child { padding-left: 0; } #yytrkfivjp .gt_column_spanner_outer:last-child { padding-right: 0; } #yytrkfivjp .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #yytrkfivjp .gt_spanner_row { border-bottom-style: hidden; } #yytrkfivjp .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #yytrkfivjp .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #yytrkfivjp .gt_from_md > :first-child { margin-top: 0; } #yytrkfivjp .gt_from_md > :last-child { margin-bottom: 0; } #yytrkfivjp .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #yytrkfivjp .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #yytrkfivjp .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #yytrkfivjp .gt_row_group_first td { border-top-width: 2px; } #yytrkfivjp .gt_row_group_first th { border-top-width: 2px; } #yytrkfivjp .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #yytrkfivjp .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #yytrkfivjp .gt_first_summary_row.thick { border-top-width: 2px; } #yytrkfivjp .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #yytrkfivjp .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #yytrkfivjp .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #yytrkfivjp .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #yytrkfivjp .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #yytrkfivjp .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #yytrkfivjp .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #yytrkfivjp .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #yytrkfivjp .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #yytrkfivjp .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #yytrkfivjp .gt_left { text-align: left; } #yytrkfivjp .gt_center { text-align: center; } #yytrkfivjp .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #yytrkfivjp .gt_font_normal { font-weight: normal; } #yytrkfivjp .gt_font_bold { font-weight: bold; } #yytrkfivjp .gt_font_italic { font-style: italic; } #yytrkfivjp .gt_super { font-size: 65%; } #yytrkfivjp .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #yytrkfivjp .gt_asterisk { font-size: 100%; vertical-align: 0; } #yytrkfivjp .gt_indent_1 { text-indent: 5px; } #yytrkfivjp .gt_indent_2 { text-indent: 10px; } #yytrkfivjp .gt_indent_3 { text-indent: 15px; } #yytrkfivjp .gt_indent_4 { text-indent: 20px; } #yytrkfivjp .gt_indent_5 { text-indent: 25px; } #yytrkfivjp .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #yytrkfivjp div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } Characteristic Beta 95% CI p-value age -0.02 -0.20, 0.15 0.8 bmi 0.00 -0.39, 0.38 >0.9 gender 3.0 -1.9, 7.8 0.2 group 2.4 -2.2, 7.1 0.3 Abbreviation: CI = Confidence Interval This produces a nice looking table, suitable for Rmarkdown documents, with output to Word or Powerpoint. You can even convert this to other formats: to a tibble with as_tibble() to a gt object with as_gt() then use gt formatting to a flextable object with as_flextable() then add formatting with flextable 32.2.1.1 Takeaways for Linear Modeling start with data - pipe into model lm(formula, data = .) model can be piped into tidy() for an estimates table model can be piped into glance() for measures of the model model can be piped into tbl_regression() for a publication-quality table 32.3 Is Your Model Valid? Key assumptions of linear regression Homogeneity of variance (homoscedasticity): The error variance should be constant Linearity: the relationships between the predictors and the outcome variable should be linear Independence: The errors associated with one observation are not correlated with the errors of any other observation Normality: the errors should be normally distributed. Technically normality is necessary only for hypothesis tests to be valid. These assumption can be checked easily with the {performance} package in the {easystats} meta-package ({tidyverse} is another meta-package of packages). In the code chunk below, we assign the model to the object name supra_model, and then run check_model from the {performance} package. supra_model &lt;- medicaldata::supraclavicular %&gt;% lm(formula = onset_sensory ~ age + bmi + gender + group, data = .) performance::check_model(supra_model, panel = FALSE) This produces a nice set of six plots in the Plots tab) with some guidance in the subtitles on how to interpret the plots. There is a less pretty version in base R, using plot(model_name), which also works to produce four of these 6 plots. You can also formally test for heteroscedasticity. The variance of your residuals should be homogenous. check_heteroscedasticity(supra_model) ## OK: Error variance appears to be homoscedastic (p = 0.427). A green output that starts with OK for check_heteroscedasticity, indicating homoscedasticity (homgeneous residual variance), is good. 32.4 Making Predictions with Your Model We can use the linear model to make predictions about the individual observations in our data, or in future data. Let’s start with adding model predictions to each observation in our dataset. This is often called the training data as it was the data the model was trained on. You can add predictions (fitted results) to your dataframe with the augment() function from the {broom} package. We augment this dataframe with the model predictions, and then relocate them to the beginning (leftmost columns) of the tibble. supra_data_plus &lt;- augment(supra_model) %&gt;% relocate(onset_sensory, .fitted, .resid) %&gt;% arrange(-.fitted) supra_data_plus ## # A tibble: 100 × 12 ## onset_sensory .fitted .resid .rownames age bmi gender group .hat .sigma ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 19 16.5 2.46 52 18 22.1 1 2 0.0800 11.5 ## 2 10 16.5 -6.51 99 19 24.4 1 2 0.0726 11.5 ## 3 14 16.5 -2.50 24 19 25.1 1 2 0.0719 11.5 ## 4 4 16.5 -12.5 6 21 22.0 1 2 0.0712 11.5 ## 5 8 16.3 -8.30 87 28 30.4 1 2 0.0517 11.5 ## 6 9 16.3 -7.27 74 31 21.0 1 2 0.0522 11.5 ## 7 6 16.3 -10.3 19 28 39.8 1 2 0.0974 11.5 ## 8 39 16.2 22.8 39 31 29.6 1 2 0.0442 11.3 ## 9 38 16.2 21.8 48 32 24.4 1 2 0.0422 11.3 ## 10 3 16.2 -13.2 43 32 35.4 1 2 0.0610 11.4 ## # ℹ 90 more rows ## # ℹ 2 more variables: .cooksd &lt;dbl&gt;, .std.resid &lt;dbl&gt; The dataframe supra_data_plus includes a prediction of the outcome (.fitted) for each observation. We can compare these predictions to the outcome (onset_sensory) and see how the residuals (.resid) are calculated (onset_sensory minus .fitted). The Cook’s D variable (.cooksd) is a measure of how large the effect on the model would be if you deleted that particular observation. Large values for Cook’s distance sugest that these observations are outliers that pull the model in one direction (have high leverage), and indicate an influential data point. Review any observation with a .cooksd &gt; 1 carefully. 32.4.1 Predictions from new data You can also input new observations (in a data frame) to the model, and predict the outcome for these observations. First, we need to create a dataframe that matches the predictor variables for the supra_model. You might get a dataframe of new observations from a colleague. It is important that this is in the same format, with exactly the same variable names as the original data. new_data &lt;- tibble(age = c(27, 38, 51), bmi = c(30.4, 34.2, 41.1), gender = c(2, 1, 1), group = c(2, 1, 2)) new_data ## # A tibble: 3 × 4 ## age bmi gender group ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 27 30.4 2 2 ## 2 38 34.2 1 1 ## 3 51 41.1 1 2 To make predictions with the new data, you use the base {stats} function predict(), with arguments for the model, and the new data. predict(object = supra_model, newdata = new_data) ## 1 2 3 ## 19.27186 13.62400 15.77457 This gives us predictions for each of the 3 rows of the new_data dataframe, of the outcome onset_sensory. 32.5 Choosing predictors for multivariate modeling – testing, dealing with collinearity interactions 32.5.1 Challenges 32.6 presenting model results with RMarkdown 32.6.1 Challenges 32.7 presenting model results with a Shiny App 32.7.1 Challenges "],["logistic-regression-and-broom-for-tidying-models.html", "Chapter 33 Logistic Regression and Broom for Tidying Models 33.1 The Model Summary 33.2 Evaluating your Model Assumptions 33.3 Converting between logit, odds ratios, and probability", " Chapter 33 Logistic Regression and Broom for Tidying Models Logistic regression allows you to: Estimate the effects of predictors (independent variables) on an dichotomous outcome (dependent variable), like alive/dead, remission/not in remission. Make predictions about future cases (patients) with their measured predictors on this continuous outcome. Let’s look at a simple logistic model to predict recurrence in prostate cancer. prostate &lt;- medicaldata::blood_storage %&gt;% janitor::clean_names() prostate %&gt;% glm(formula = recurrence ~ fam_hx + b_gs, data = ., family = binomial) -&gt; prostate_model prostate_model ## ## Call: glm(formula = recurrence ~ fam_hx + b_gs, family = binomial, ## data = .) ## ## Coefficients: ## (Intercept) fam_hx b_gs ## -3.4485 -0.8983 1.1839 ## ## Degrees of Freedom: 313 Total (i.e. Null); 311 Residual ## (2 observations deleted due to missingness) ## Null Deviance: 281.9 ## Residual Deviance: 246.8 AIC: 252.8 We use the glm() function from the base stats package, which is for generalized linear model. This function can use a variety of model families, including logistic, poisson, gamma, quasibinomial, gamma, etc., and the family of models needs to be specified in the family argument. The formula for the dependent variable (outcome) ~ independent variables (predictors) is the same as with linear modeling with the lm() function. We specify the dataset with the data argument, and when we the pipe, we set data = .. When you print out the prostate model, you get the Call (the glm function and arguments) the coefficients for the intercept and each predictor the degrees of freedom how many observations were deleted due to missingness (IMPORTANT, DO NOT BLOW BY THIS), two values for Deviance and AIC. Let’s walk through what these mean: the coefficients estimate how much a change of one unit in each predictor will affect the outcome (in logit units - more about this later). The degrees of freedom are related to the number of observations, and how many predictors you have used. If you look at the mean value in the prostate dataset for recurrence, it is 0.1708861, which means that 17% of the participants experienced a recurrence of prostate cancer. If you are calculating the mean of 315 of the 316 observations, and you know the overall mean of all 315, you (mathematically) know the value of the last observation - recurrence or not - it has no degrees of freedom. So for 316 observations, you have n-1 or 315, degrees of freedom. For each predictor in your model you ‘use up’ one degree of freedom. The degrees of freedom affect the significance of the test statistic (T, or chi-squared, or F statistic). how many observations were deleted due to missingness - the logistic model will only work on complete cases, so if one of your predictors or the outcome is frequently missing, your effective dataset size will shrink rapidly. You want to know if this is an issue, as this might change which predictors you use (avoid frequently missing ones), or lead you to consider imputation of missing values. Null Deviance and Residual Deviance. The null deviance is measured for the null model, with only an intercept. The residual deviance is measured for your model with predictors. Your residual deviance should be lower than the null deviance. You can even measure whether your model is significantly better than the null model by calculating the difference between the Null Deviance and the Residual Deviance. This difference [281.9 - 246.8 = 35.1] has a chi-square distribution. You can look up the value for chi-square with 2 degrees (because you had 2 predictors) of freedom. Or you can calculate this in R with pchisq(q = 35.1, df=2, lower.tail = TRUE) which gives you a p value of 1. The AIC is Aikaike’s Information Criterion, which estimates prediction error. A lower values is better when comparing similar models. 33.1 The Model Summary You can get more information from a summary of the model. summary(prostate_model) ## ## Call: ## glm(formula = recurrence ~ fam_hx + b_gs, family = binomial, ## data = .) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -3.4485 0.4347 -7.932 2.15e-15 *** ## fam_hx -0.8983 0.4785 -1.877 0.0605 . ## b_gs 1.1839 0.2193 5.399 6.70e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 281.88 on 313 degrees of freedom ## Residual deviance: 246.81 on 311 degrees of freedom ## (2 observations deleted due to missingness) ## AIC: 252.81 ## ## Number of Fisher Scoring iterations: 5 Again, you get the call (to orient you to which model). The Deviance Residuals should have a Median near zero, and be roughly symmetric around zero. If the median is close to zero, the model is not biased in one direction (the outcome is not over- nor under-estimated). Now, in addition to estimates, we get standard errors for each estimate (which can be used to calculate confidence intervals), z statistic values for each predictor, and the resulting p value (calculated with the statistic and the degrees of freedom). As a general rule of thumb, a z value with an absolute value of &gt; 1.96 should have a p value less than 0.05, and an absolute value &gt; 2.576 should have a p value of less than 0.01. These values should sound familiar from the normal distribution (95% and 99% confidence interval Z values). 33.2 Evaluating your Model Assumptions You can do this in base R with plot(model), but there is a prettier version in the {performance} package in the {easystats} meta-package. Just run the check_model() function on your model. You can set the argument panel = TRUE for a multipanel figure, or panel = FALSE for single figures in the Plots tab. Try it both ways to see which you prefer. If the multipanel seems too small, click on the Zoom button in the Plots tab to make it bigger. check_model(prostate_model, panel = FALSE) This generates graphs with nice subtitles to help you interpret the output. Big deviations should make you worry about one or more of the model assumptions, and may require rescaling one of your predictors. If all is well, you want to look at how your model predictors actually predict the outcome. You make a nicer looking regression table with the tidy() function from the {broom} package. prostate_model %&gt;% broom::tidy() ## # A tibble: 3 × 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) -3.45 0.435 -7.93 2.15e-15 ## 2 fam_hx -0.898 0.478 -1.88 6.05e- 2 ## 3 b_gs 1.18 0.219 5.40 6.70e- 8 This model has 3 terms: an intercept, and two predictors. The family history predictor (fam_hx) is not significant, but trends toward an association with a decreased odds of recurrence, while the baseline Gleason score (b_gs) is significant and is associated with an 18% increased log-odds of recurrence for each extra point in the Gleason score. Note that this is expressed in logit, or log-odds, not probability, which can take some finagling to get to percentages and probabilities. A positive estimate indicates that increasing that predictor will be associated with increasing odds of the outcome. Conversely, a negative estimate indicates that increasing that predictor will be associated with decreasing odds of the outcome. The quantity log[p/(1-p)] is called the logarithm of the odds, also known as the log-odds or logit. Despite this being commonly written as “log”, it is not base 10 logarithms, but the natural log, with the base e (2.718…). Why would anyone use logit? It is really hard to model zeroes and ones (dichotomous outcomes). The logit is a link function, or a way to convert zeroes and ones to a continuous function that does not cross zero or one. Once you have a continuous function, you can use generalized linear models to model it. Why not just model probability? For complicated mathematical reasons, it was easier to convert probabilities to odds and then take the natural log. There will be times when using logistic regression that it will be fairly painful to convert between probabilities and odds and logit units. But R has functions to do that for us. We just have to watch out for when we have probabilities vs. odds vs. logit. One way is to look at the range of the estimates. Probabilities always have a range from zero to 1. Logit units generally range from about -4 to +4, with zero meaning an equal probability of no event or the event outcome occurring. Odds ratios can range from very small (but positive) numbers to very large positive numbers. You can see this by re-running broom::tidy() with the exp = TRUE option. This will exponentiate the logit, or log-odds estimates, to give us the estimates as odds ratios. prostate_model %&gt;% broom::tidy(exp = TRUE) ## # A tibble: 3 × 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.0318 0.435 -7.93 2.15e-15 ## 2 fam_hx 0.407 0.478 -1.88 6.05e- 2 ## 3 b_gs 3.27 0.219 5.40 6.70e- 8 Now the estimates are all positive, with the previously most negative (intercept was logit -3.45) now being a small positive number of 0.0318, and the most positive (b_gs was logit 1.18) now a larger positive odds ratio of 3.27. These odds ratios versions of the estimates are more easily interpretable than logit scores. Odds ratios of less than one means that an increase in that predictor makes the outcome less likely to occur, and an odds ratio of greater than one means that an increase in that predictor makes the outcome more likely to occur. For example, the odds ratio estimate of 0.407 means that for someone with a positive family history of prostate cancer, the odds of their having a recurrence are 59.3% ((1-0.407) x 100) lower than someone without a family history. Similarly, for each unit increase in the baseline Gleason score (b_gs), the odds of recurrence increase by 227% ((3.27-1) x 100). 33.3 Converting between logit, odds ratios, and probability Let’s step back and try a real-world example. If the percent probability of snow on january 10th is 72%, then p, the probability is 0.72. The probability of no snow (1-p) is 1-0.72 = 0.28. The odds of snow are p/(1-p) = 0.72/0.28 = 2.57. If we take the natural log of these odds, this gives us an estimate in logit terms, with ln(2.57) = 0.944. This estimate in logit units is what you get as a default estimate from logistic regression. To convert these logit estimates back to probability, you need to do the reverse. First, exponentiate the logit estimate of 0.944, exp(0.944) = 2.57. This is the odds ratio. To convert odds to probability - calculate odds / (1 + odds) = 2.57/3.57 = 0.72, which is the probability. To get the percent probability, you can multiply the probability by 100 to get 72%. Fortunately, R has functions to help us do this sort of conversion. You just have to be able to recognize which units (logit, odds, or probability) that you are looking at. We can look at the overall quality of the model with the glance() function in {broom}. Let’s look at 2 versions of the model, one with fam_hx only, and one with both predictors. prostate %&gt;% glm(recurrence ~ fam_hx, data = ., family = binomial) %&gt;% broom::glance() ## # A tibble: 1 × 8 ## null.deviance df.null logLik AIC BIC deviance df.residual nobs ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 289. 315 -142. 288. 296. 284. 314 316 prostate %&gt;% glm(recurrence ~ fam_hx + b_gs, data = ., family = binomial) %&gt;% broom::glance() ## # A tibble: 1 × 8 ## null.deviance df.null logLik AIC BIC deviance df.residual nobs ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 282. 313 -123. 253. 264. 247. 311 314 You can see that adding the baseline Gleason score improves the model, as it lowers both AIC and BIC. This is not surprising, as it was a significant predictor. You can add predicted (fitted) values and residuals for each observation in your dataset with broom::augment() model &lt;- prostate %&gt;% glm(recurrence ~ fam_hx + b_gs, data = ., family = binomial) augment(model) ## # A tibble: 314 × 10 ## .rownames recurrence fam_hx b_gs .fitted .resid .hat .sigma .cooksd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 0 3 0.103 1.13 0.0244 0.890 0.00771 ## 2 2 1 0 2 -1.08 1.66 0.00607 0.887 0.00604 ## 3 3 0 0 3 0.103 -1.22 0.0244 0.890 0.00948 ## 4 4 0 0 1 -2.26 -0.445 0.00532 0.892 0.000186 ## 5 5 0 0 2 -1.08 -0.764 0.00607 0.891 0.000695 ## 6 6 0 0 1 -2.26 -0.445 0.00532 0.892 0.000186 ## 7 7 0 0 1 -2.26 -0.445 0.00532 0.892 0.000186 ## 8 8 1 0 1 -2.26 2.17 0.00532 0.884 0.0173 ## 9 9 0 0 1 -2.26 -0.445 0.00532 0.892 0.000186 ## 10 10 0 0 2 -1.08 -0.764 0.00607 0.891 0.000695 ## # ℹ 304 more rows ## # ℹ 1 more variable: .std.resid &lt;dbl&gt; Note that the fitted data are both positive and negative, with a range within +/- 4. This should tell you that they are in logit (log-odds) units (ln(p/1-p)), in which 0 is a 50% probability of either outcome. We can do a variety of other things with this model in base R. Let’s look at a few. If you just want the coefficients and a 95% confidence interval for each (in logit units), you can use the coef() and the confint() functions. coef(model) # estimated coefficients for predictors ## (Intercept) fam_hx b_gs ## -3.4485111 -0.8982539 1.1839261 confint(model) # 95% confidence interval for coefficients ## Waiting for profiling to be done... ## 2.5 % 97.5 % ## (Intercept) -4.3420982 -2.63133270 ## fam_hx -1.9305806 -0.02633492 ## b_gs 0.7619884 1.62560896 If you would prefer these as odds ratios, you can exponentiate these. exp(coef(model)) # show the odds ratios, rather than log-odds for coefficients ## (Intercept) fam_hx b_gs ## 0.03179294 0.40728019 3.26717619 exp(confint(model)) # 95% confidence interval for coefficients, now expressed as odds ratios ## Waiting for profiling to be done... ## 2.5 % 97.5 % ## (Intercept) 0.0130092 0.07198247 ## fam_hx 0.1450639 0.97400882 ## b_gs 2.1425321 5.08151255 Notice that these are all now greater than zero, rather than from -4 to 4. You can also use functions to make predictions (fitted) from your data, or even from new data. The default output is in logit units, but if you use the “response” type argument in the predict() function, you get probabilities on a zero to 1 scale. predict(model) %&gt;% head() # predictions for each observation ## 1 2 3 4 5 6 ## 0.1032671 -1.0806590 0.1032671 -2.2645850 -1.0806590 -2.2645850 # in the prostate dataset on the logit scale # from around -4 (very unlikely to have event) # to +4 (very likely to have event) predict(model, type = &quot;response&quot;) %&gt;% head() # predictions for each observation in ## 1 2 3 4 5 6 ## 0.52579385 0.25338133 0.52579385 0.09409879 0.25338133 0.09409879 # the prostate dataset using 0-1 probabilities # (can multiply by 100 to get percent probability # if you prefer) You can then classify these probabilities as likely (&gt;0.5) or unlikely (&lt;=0.5) and compare these class predictions to the true recurrence outcomes. By calculating the mean of the observations that match, you can calculate an overall accuracy of your classification model. probabilities &lt;- predict(model, type = &quot;response&quot;) predicted.classes &lt;- ifelse(probabilities &gt; 0.5, 0, 1) # predictions as pos or neg mean(predicted.classes == prostate$recurrence) ## Warning in predicted.classes == prostate$recurrence: longer object length is ## not a multiple of shorter object length ## [1] 0.193038 # calcuated accuracy You can even make predictions on new data (in this case, a random 3% sample of the original dataset) predict(model, newdata = slice_sample(prostate, prop = 0.03), type = &quot;response&quot;) ## 1 2 3 4 5 6 7 ## 0.09409879 0.52579385 0.12143477 0.04058836 0.09409879 0.09409879 0.09409879 ## 8 9 ## 0.04058836 0.25338133 Let’s see how this works with another dataset, from which we will use predictors to classify diabetes cases. We will start by loading the data into dm_data, and building an “all predictors” model, by specifying the formula predictors as “.” - this means to use all other variables (except the outcome variable) as predictors. Look at the model output for problems. data(&quot;PimaIndiansDiabetes2&quot;, package = &quot;mlbench&quot;) dm_data &lt;- PimaIndiansDiabetes2 rm(PimaIndiansDiabetes2) # build model, with all variables dm_mod &lt;- glm(diabetes ~ ., data = dm_data, family = &quot;binomial&quot;) dm_mod ## ## Call: glm(formula = diabetes ~ ., family = &quot;binomial&quot;, data = dm_data) ## ## Coefficients: ## (Intercept) pregnant glucose pressure triceps insulin ## -1.004e+01 8.216e-02 3.827e-02 -1.420e-03 1.122e-02 -8.253e-04 ## mass pedigree age ## 7.054e-02 1.141e+00 3.395e-02 ## ## Degrees of Freedom: 391 Total (i.e. Null); 383 Residual ## (376 observations deleted due to missingness) ## Null Deviance: 498.1 ## Residual Deviance: 344 AIC: 362 Did you notice that 376 observations were deleted due to missingness? We can use the vis_miss() function from the {visdat} package to figure out which are the problem variables. visdat::vis_miss(dm_data) It looks like triceps and insulin measurements were missing fairly often. Would a model without these measures be better? Let’s try. dm_mod_miss &lt;- glm(diabetes ~ glucose + pressure + mass + pedigree + age, data = dm_data, family = &quot;binomial&quot;) dm_mod_miss ## ## Call: glm(formula = diabetes ~ glucose + pressure + mass + pedigree + ## age, family = &quot;binomial&quot;, data = dm_data) ## ## Coefficients: ## (Intercept) glucose pressure mass pedigree age ## -9.014890 0.034567 -0.007433 0.088641 0.923290 0.034523 ## ## Degrees of Freedom: 723 Total (i.e. Null); 718 Residual ## (44 observations deleted due to missingness) ## Null Deviance: 931.9 ## Residual Deviance: 685.7 AIC: 697.7 Apparently not. Even with all the missing data, the AIC of the reduced model is 697.7, and the AIC of the full model was 362. This suggests that insulin and triceps measurements are pretty helpful in predicting diabetes. Let’s look at how well the full model works, with our usual battery of model functions. # output summary(dm_mod) ## ## Call: ## glm(formula = diabetes ~ ., family = &quot;binomial&quot;, data = dm_data) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.004e+01 1.218e+00 -8.246 &lt; 2e-16 *** ## pregnant 8.216e-02 5.543e-02 1.482 0.13825 ## glucose 3.827e-02 5.768e-03 6.635 3.24e-11 *** ## pressure -1.420e-03 1.183e-02 -0.120 0.90446 ## triceps 1.122e-02 1.708e-02 0.657 0.51128 ## insulin -8.253e-04 1.306e-03 -0.632 0.52757 ## mass 7.054e-02 2.734e-02 2.580 0.00989 ** ## pedigree 1.141e+00 4.274e-01 2.669 0.00760 ** ## age 3.395e-02 1.838e-02 1.847 0.06474 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 498.10 on 391 degrees of freedom ## Residual deviance: 344.02 on 383 degrees of freedom ## (376 observations deleted due to missingness) ## AIC: 362.02 ## ## Number of Fisher Scoring iterations: 5 # test model assumptions check_model(dm_mod) # tidy version of estimates tidy(dm_mod) ## # A tibble: 9 × 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) -10.0 1.22 -8.25 1.64e-16 ## 2 pregnant 0.0822 0.0554 1.48 1.38e- 1 ## 3 glucose 0.0383 0.00577 6.64 3.24e-11 ## 4 pressure -0.00142 0.0118 -0.120 9.04e- 1 ## 5 triceps 0.0112 0.0171 0.657 5.11e- 1 ## 6 insulin -0.000825 0.00131 -0.632 5.28e- 1 ## 7 mass 0.0705 0.0273 2.58 9.89e- 3 ## 8 pedigree 1.14 0.427 2.67 7.60e- 3 ## 9 age 0.0340 0.0184 1.85 6.47e- 2 # model performance glance(dm_mod) ## # A tibble: 1 × 8 ## null.deviance df.null logLik AIC BIC deviance df.residual nobs ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 498. 391 -172. 362. 398. 344. 383 392 OK, let’s make some predictions, and convert these to percent probability (0-100 range). # augment data with fitted predictions and residuals dm_data_plus &lt;- augment(dm_mod) %&gt;% mutate(pct_prob = 100 * plogis(.fitted)) %&gt;% relocate(diabetes, .fitted, pct_prob) %&gt;% arrange(-.fitted) dm_data_plus ## # A tibble: 392 × 17 ## diabetes .fitted pct_prob .rownames pregnant glucose pressure triceps insulin ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 pos 5.23 99.5 446 0 180 78 63 14 ## 2 neg 3.85 97.9 229 4 197 70 39 744 ## 3 pos 3.61 97.4 547 5 187 76 27 207 ## 4 pos 3.37 96.7 207 8 196 76 29 280 ## 5 pos 3.27 96.3 160 17 163 72 41 114 ## 6 neg 3.18 96.0 488 0 173 78 32 265 ## 7 pos 3.02 95.3 44 9 171 110 24 240 ## 8 pos 2.86 94.6 371 3 173 82 48 465 ## 9 neg 2.58 93.0 745 13 153 88 37 140 ## 10 pos 2.50 92.4 260 11 155 76 28 150 ## # ℹ 382 more rows ## # ℹ 8 more variables: mass &lt;dbl&gt;, pedigree &lt;dbl&gt;, age &lt;dbl&gt;, .resid &lt;dbl&gt;, ## # .hat &lt;dbl&gt;, .sigma &lt;dbl&gt;, .cooksd &lt;dbl&gt;, .std.resid &lt;dbl&gt; # arrange puts the high-probability cases first set.seed(1234) dm_data_plus %&gt;% slice_sample(n=10) %&gt;% select(diabetes:.rownames) ## # A tibble: 10 × 4 ## diabetes .fitted pct_prob .rownames ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 neg -2.16 10.4 624 ## 2 neg -2.80 5.75 225 ## 3 neg 0.0250 50.6 609 ## 4 neg -0.158 46.1 192 ## 5 pos -0.491 38.0 486 ## 6 pos 0.146 53.6 697 ## 7 neg 0.00702 50.2 646 ## 8 neg -1.38 20.1 182 ## 9 neg 0.355 58.8 658 ## 10 neg -2.69 6.37 761 # a random sample of 10 You can see the relationship between the fitted values (on the logit scale) and the percent probability of diabetes. Some of the high-probability folks are still negative (rowname 609), while others with lower predicted probability alread have diabetes (rowname 486). A fancier way to classify based on your predictions is to pick an optimal cutpoint, with the {cutpointr} package. You can do this with a number of different metrics you can choose, and different methods. The code chunk below demonstrates some of the helpful output from {cutpointr}. There are 15 different methods, and 20 differnt metric options to choose from, at this website. Here we start with maximize_metric and sum_sens_spec. # select a cut point for classification cp &lt;- dm_data_plus %&gt;% cutpointr(pct_prob, diabetes, pos_class = &quot;pos&quot;, method= maximize_metric, metric = sum_sens_spec) ## Assuming the positive class has higher x values cp ## # A tibble: 1 × 16 ## direction optimal_cutpoint method sum_sens_spec acc sensitivity ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 &gt;= 28.5839 maximize_metric 1.57504 0.772959 0.830769 ## specificity AUC pos_class neg_class prevalence outcome predictor ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;fct&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.744275 0.862361 pos neg 0.331633 diabetes pct_prob ## data roc_curve boot ## &lt;list&gt; &lt;list&gt; &lt;lgl&gt; ## 1 &lt;tibble [392 × 2]&gt; &lt;rc_ctpnt [393 × 10]&gt; NA summary(cp) ## Method: maximize_metric ## Predictor: pct_prob ## Outcome: diabetes ## Direction: &gt;= ## ## AUC n n_pos n_neg ## 0.8624 392 130 262 ## ## optimal_cutpoint sum_sens_spec acc sensitivity specificity tp fn fp tn ## 28.5839 1.575 0.773 0.8308 0.7443 108 22 67 195 ## ## Predictor summary: ## Data Min. 5% 1st Qu. Median Mean 3rd Qu. 95% ## Overall 0.8690932 3.071251 8.953085 22.94296 33.16327 53.11714 88.92870 ## neg 0.8690932 2.674187 6.392249 13.48437 21.10577 28.96611 69.31582 ## pos 3.7635587 14.863216 34.854283 62.18036 57.46376 80.93884 92.17256 ## Max. SD NAs ## 99.46861 28.45645 0 ## 97.91551 20.49784 0 ## 99.46861 26.71998 0 plot(cp) plot_metric(cp) You can then use the cutpoint to classify observations, and see how accurate your model is. # classify based on cut point dm_data_plus &lt;- dm_data_plus %&gt;% mutate(pred_dm = case_when(pct_prob &gt; cp$optimal_cutpoint ~ &quot;pred_yes&quot;, pct_prob &lt;= cp$optimal_cutpoint ~ &quot;pred_no&quot;)) %&gt;% mutate(pred_dm = factor(pred_dm, levels = c(&quot;pred_no&quot;, &quot;pred_yes&quot;))) %&gt;% relocate(pred_dm, .after = pct_prob) # check confusion matrix dm_data_plus %&gt;% tabyl(diabetes, pred_dm) %&gt;% adorn_totals(&quot;both&quot;) %&gt;% adorn_percentages() %&gt;% adorn_pct_formatting() ## diabetes pred_no pred_yes Total ## neg 74.4% 25.6% 100.0% ## pos 17.7% 82.3% 100.0% ## Total 55.6% 44.4% 100.0% You can also check model assumptions, and model performance, even against competing models. Let’s build some competing models below. #check model assumptions performance::check_model(dm_mod, panel = FALSE) # use panel = TRUE in Rmarkdown # to get 2x3 panels for 6 plots # performance::model_performance(dm_mod) ## # Indices of model performance ## ## AIC | AICc | BIC | Tjur&#39;s R2 | RMSE | Sigma | Log_loss | Score_log ## ------------------------------------------------------------------------------ ## 362.021 | 362.492 | 397.763 | 0.364 | 0.376 | 1.000 | 0.439 | -74.015 ## ## AIC | Score_spherical | PCP ## --------------------------------- ## 362.021 | 0.009 | 0.718 #try a simpler model dm_mod2 &lt;- glm(diabetes ~ glucose + mass + pedigree, data = dm_data, family = &quot;binomial&quot;) tidy(dm_mod2) ## # A tibble: 4 × 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) -8.46 0.668 -12.7 8.65e-37 ## 2 glucose 0.0379 0.00347 10.9 9.62e-28 ## 3 mass 0.0810 0.0142 5.69 1.27e- 8 ## 4 pedigree 0.867 0.296 2.93 3.40e- 3 glance(dm_mod2) ## # A tibble: 1 × 8 ## null.deviance df.null logLik AIC BIC deviance df.residual nobs ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 975. 751 -365. 738. 756. 730. 748 752 # build a really simple (NULL) model as a baseline dm_mod3 &lt;- glm(diabetes ~ 1, data = dm_data, family = &quot;binomial&quot;) summary(dm_mod3) ## ## Call: ## glm(formula = diabetes ~ 1, family = &quot;binomial&quot;, data = dm_data) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.62362 0.07571 -8.237 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 993.48 on 767 degrees of freedom ## Residual deviance: 993.48 on 767 degrees of freedom ## AIC: 995.48 ## ## Number of Fisher Scoring iterations: 4 # compare models # compare_performance(dm_mod, dm_mod2, dm_mod3, rank = TRUE) # plot(compare_performance(dm_mod, dm_mod2, dm_mod3, rank = TRUE)) + labs(subtitle = &quot;Larger Area is Better&quot;) # plot(compare_performance(dm_mod, dm_mod2, rank = TRUE)) + labs(subtitle = &quot;Larger Area is Better&quot;) # save model to RDS for later use in predictions or web apps. saveRDS(dm_mod, &quot;dm_mod.RDS&quot;) 27.1 Choosing predictors for multivariate modeling – testing, dealing with collinearity interactions 27.1.1 Challenges 27.2 presenting model results with RMarkdown 27.2.1 Challenges 27.3 presenting model results with a Shiny App 27.3.1 Challenges "],["fast-and-frugal-trees-with-the-fftrees-package.html", "Chapter 34 Fast and Frugal Trees with the {FFTrees} Package 34.1 Setup 34.2 The Breast Cancer Dataset 34.3 Building a FFTrees Model for Breast Cancer 34.4 Your Turn with Heart Disease Data 34.5 Your Turn to Build and Interpret a Model 34.6 Now build your FFTrees model to predict improved status (vs. death)", " Chapter 34 Fast and Frugal Trees with the {FFTrees} Package Tree-based models are one of the earliest forms of machine learning, which have some specific advantages over traditional linear or logistic regression models. As a general rule, tree-based models handle interactions between independent predictor variables well, while traditional models struggle with interactions. This can be helpful in biology and medicine where things like cations and electrochemical balance have inevitable interactions. Tree-based models use a series of binary splits to create a tree structure that predicts the outcome. The tree is built by selecting the best split at each node, based on the predictor variables. The tree is grown until a stopping criterion is met, such as a minimum number of cases in a node, or a maximum depth of the tree. Each split is optimized to create a more pure ‘branch’ of one outcome. The tree is then pruned to avoid overfitting, and the final tree is used to make predictions on new data. The original tree-based models were CART (Classification and Regression Trees) models, which were developed by Breiman et al. in the 1980s. The CART algorithm is a recursive partitioning algorithm that creates binary splits in the data to create a tree structure. The tree is grown until a stopping criterion is met, such as a minimum number of cases in a node, or a maximum depth of the tree. The tree is then pruned to avoid overfitting, and the final tree is used to make predictions on new data. We have since developed more complicated tree-based models, like random Forests, which start with a random subset of predictor variables and begin partitioning the observations. This uses the entirety of the information more completely than a single tree. A single tree is often not very accurate, but a forest of trees, called a random forest, can be very accurate. Random forests are an ensemble method that creates many trees, each on a random subset of the data, and averages the predictions of the trees to create a more accurate prediction. Random forests are one of the most accurate machine learning algorithms available, and are widely used in biology and medicine. The advantage of a single tree is its transparency. You can see where and what the splitting nodes are, and gain a better understanding of the reasons for the outcome. These are also referred to as ‘white box’ models, as opposed to ‘black box’ models like neural networks and random Forests, which are difficult to interpret. These are also easier to use in clinical practice. In order to get the best of both worlds, we can use a fast and frugal tree model, which is a simple tree model that is easy to interpret and use in clinical practice. The {FFTrees} package makes the fftrees algorithm easy to use in R. We will work through 3 example datasets and show the use of the FFTrees package to create a simple tree model. We will use the FFTrees package to create a simple tree model to diagnose breast cancer from a digitized biopsy slide, to identify heart disease in at-risk people, and to predict survival in tuberculosis in the strep_tb trial. 34.1 Setup Install the “FFTrees” package from CRAN. Load this package with library(FFTrees). Load the “medicaldata” package with library(medicaldata). 34.2 The Breast Cancer Dataset This dataset is from the UCI Machine Learning Repository, and each observation comes from a digitized image of a fine needle aspirate (FNA) of a breast mass. The dataset contains 569 observations and 32 variables, including the diagnosis of breast cancer (malignant or benign) and 30 features that are computed from a digitized image of the FNA. The features describe characteristics of the cell nuclei present in the image. The dataset is available in the {FFTrees} package as breast_cancer, and details can be found at: breast_cancer-FNA. An edge detection algorithm was used to identify the edges of the nuclei, and from these borders, cell and nuclear features were derived, including: diagnosis - TRUE (cancer) or FALSE (not cancer) thickness - thickness of clumps (1-10) cellsize.unif - uniformity of cell size (1-10) cellshape.unif - uniformity of cell shape (1-10) adhesion - a score for how much cells are adherent to each other (1-10) epithelial - a score for how much epithelium is present (1-10) nuclei.bare - a score for how many bare nuclei (without cytoplasm or cell membrane) are found (1-10) chromatin - a score for presence of bland chromatin (1-10) nucleoli - a score for presence of normal nucleoli (1-10) mitoses - a score for presence of mitoses (1-10) Make predictions about future cases (patients) with their measured predictors on this continuous outcome. Load the data into RStudio by copying and running the code below. data(&quot;breastcancer&quot;) 34.2.1 Data Inspection You can inspect the breastcancer data in the data Viewer by going to the Environment pane and clicking on it to open the dataset. Take a look, and get a rough sense of which variables (with high scores) are associated with a TRUE diagnosis of breast cancer. In the data Viewer, you can click on the variable diagnosis to sort observations to look at the predictor variable values for TRUE and FALSE cases. Clicking on the diagnosis variable again will sort the observations in the reverse order. 34.2.2 Check Your Progress How many observations are there in the breast cancer dataset? 200683811 What is the range of the mitoses variable? 1-21-100-400 34.3 Building a FFTrees Model for Breast Cancer We will build a simple tree model to predict the diagnosis of breast cancer from the features of the cell nuclei. Let’s walk through the code block below, which builds a tree model using the FFTrees function from the FFTrees package. We will name the resulting model breast.fft, and use the assignment arrow to make this happen. We will use the FFTrees function to build the model. We will specify the first argument as the formula for the model, which is diagnosis ~ ., meaning we will predict the diagnosis from all other variables in the dataset. We will specify the second argument as the data, which is breastcancer. We will specify the train.p argument as 0.5, which means we will randomly use half of the data to train the model and half to test the model. We will specify the main argument as “Breast Cancer”, which will be the title of the plot. We will specify the decision.labels argument as c(\"Healthy\", \"Disease\"), which will be the labels for the outcome variable in the plot. This works because the underlying value for FALSE is 0, and the underlying value for TRUE is 1, so that these are in the correct order. set.seed(123) # the seed is used to get reproducible outcomes, as the random split into train and test will give slightly different results each time. # note we are not using the cost argument - we will use the default for this. breast.fft &lt;- FFTrees(formula = diagnosis ~ ., data = breastcancer, train.p = 0.5, main = &quot;Breast Cancer&quot;, decision.labels = c(&quot;Healthy&quot;, &quot;Disease&quot;)) Now copy this code block and run it in your local RStudio instance. This should rank the predictor variables (cues), train some FFT models on the training data, rank them by their performance on the test data, and give you a short printout. You should also see a new assigned object, breast.fft in your Environment pane. To see the fft object, copy and run the code below: breast.fft ## Breast Cancer ## FFTrees ## - Trees: 6 fast-and-frugal trees predicting diagnosis ## - Cost of outcomes: hi = 0, fa = 1, mi = 1, cr = 0 ## ## FFT #1: Definition ## [1] If cellsize.unif &lt;= 2, decide Healthy. ## [2] If cellshape.unif &gt; 2, decide Disease, otherwise, decide Healthy. ## ## FFT #1: Training Accuracy ## Training data: N = 342, Pos (+) = 120 (35%) ## ## | | True + | True - | Totals: ## |----------|--------|--------| ## | Decide + | hi 116 | fa 9 | 125 ## | Decide - | mi 4 | cr 213 | 217 ## |----------|--------|--------| ## Totals: 120 222 N = 342 ## ## acc = 96.2% ppv = 92.8% npv = 98.2% ## bacc = 96.3% sens = 96.7% spec = 95.9% ## ## FFT #1: Training Speed, Frugality, and Cost ## mcu = 1.4, pci = 0.84, cost_dec = 0.038 This prints out the (default) assigned cost of 1 for false positives (fa for false alarm) and false negatives (mi for miss), the definition of the best tree model (with 2 nodes or branch points), the best tree model’s performance on the training data, and some accuracy statistics. Now let’s plot how this model does on the test data. Copy and run the code below: plot(breast.fft, data = &quot;test&quot;) You may need to click the Zoom button at the top left of your Plots pane to get a good view. This shows us that among the 341 randomly selected test cases (342 used for training), only 35% had TRUE breast cancer. Then it shows model 1, which has 2 nodes, splitting on uniformity of cell size below 3, and uniformity of cell shape below 3. You can see how each split ‘purifies’ the outcomes - never perfectly, but pretty well. There is a confusion matrix at the lower left to show us false negatives and false positives - also known as hits, misses, false alarms, and correct rejections. The model (on the Testing Set) has a sensitivity of 0.89, specificity of 0.96, and accuracy of 0.93. The bacc variable is balanced accuracy, which is sens * 0.5 + spec * 0.5. The mcu is mean cues used per observation, and pci is percent of cues ignored. There is an ROC curve at the lower right comparing the model to alternative types of model, including CART, logistic regression, random forest, and support vector machine models. They are all quite good, and sensitivity and specificity are well balanced. In some cases, sensitivity and specificity are not well balanced. You may place a greater negative value on missed diagnoses, and want to shift the model to be more sensitive. You can do this by changing the cost of a miss (mi) to be higher than the cost of a false alarm (fa). You can do this by changing the cost argument in the FFTrees function. For example, you could set cost = c(fa = 1, mi = 2). This would mean that a missed diagnosis is twice as costly as a false alarm. You can also change the cost of a false alarm by setting fa = 2 and mi = 1. This would mean that a false alarm is twice as costly as a missed diagnosis. It depends on the clinical situation and your judgement, but you should think about the relative cost/harm of these two types of errors and adjust the cost argument if needed. You can see the accuracy of each predictor by plotting these with the code below: plot(breast.fft, what = &quot;cues&quot;) ## Plotting cue training statistics: ## — Cue accuracies ranked by bacc You can see that predictor (cue) #9 is not great. You can print these out with: breast.fft$cues$stats$train ## cue class threshold direction n hi fa mi cr sens ## 1 thickness integer 4 &gt; 342 108 46 12 176 0.9000000 ## 2 cellsize.unif integer 2 &gt; 342 118 18 2 204 0.9833333 ## 3 cellshape.unif integer 2 &gt; 342 117 21 3 201 0.9750000 ## 4 adhesion integer 1 &gt; 342 104 39 16 183 0.8666667 ## 5 epithelial integer 2 &gt; 342 110 23 10 199 0.9166667 ## 6 nuclei.bare numeric 1 &gt; 342 114 25 6 197 0.9500000 ## 7 chromatin integer 3 &gt; 342 98 8 22 214 0.8166667 ## 8 nucleoli integer 2 &gt; 342 98 11 22 211 0.8166667 ## 9 mitoses integer 1 &gt; 342 51 7 69 215 0.4250000 ## spec ppv npv acc bacc wacc dprime ## 1 0.7927928 0.7012987 0.9361702 0.8304094 0.8463964 0.8463964 2.086002 ## 2 0.9189189 0.8676471 0.9902913 0.9415205 0.9511261 0.9511261 3.473574 ## 3 0.9054054 0.8478261 0.9852941 0.9298246 0.9402027 0.9402027 3.234896 ## 4 0.8243243 0.7272727 0.9195980 0.8391813 0.8454955 0.8454955 2.032886 ## 5 0.8963964 0.8270677 0.9521531 0.9035088 0.9065315 0.9065315 2.628155 ## 6 0.8873874 0.8201439 0.9704433 0.9093567 0.9186937 0.9186937 2.835223 ## 7 0.9639640 0.9245283 0.9067797 0.9122807 0.8903153 0.8903153 2.683437 ## 8 0.9504505 0.8990826 0.9055794 0.9035088 0.8835586 0.8835586 2.537226 ## 9 0.9684685 0.8793103 0.7570423 0.7777778 0.6967342 0.6967342 1.655776 ## cost_dec cost cost_cue ## 1 -0.16959064 -0.16959064 0 ## 2 -0.05847953 -0.05847953 0 ## 3 -0.07017544 -0.07017544 0 ## 4 -0.16081871 -0.16081871 0 ## 5 -0.09649123 -0.09649123 0 ## 6 -0.09064327 -0.09064327 0 ## 7 -0.08771930 -0.08771930 0 ## 8 -0.09649123 -0.09649123 0 ## 9 -0.22222222 -0.22222222 0 And see that counting mitoses (#9) is not a great use of your pathologist’s time, with a sensitivity of 0.425. Several of these potential predictors are just not that useful, compared to size and shape uniformity. You can see the best model in text (words) with: inwords(breast.fft, tree = 1) ## [1] &quot;If cellsize.unif &lt;= 2, decide Healthy.&quot; ## [2] &quot;If cellshape.unif &gt; 2, decide Disease, otherwise, decide Healthy.&quot; which gives you a simple decision algorithm. If you want to see the accuracy for all of the trees generated, you can use breast.fft$trees$stats$test ## # A tibble: 6 × 20 ## tree n hi fa mi cr sens spec far ppv npv dprime ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 341 106 11 13 211 0.891 0.950 0.0495 0.906 0.942 2.86 ## 2 2 341 97 5 22 217 0.815 0.977 0.0225 0.951 0.908 2.88 ## 3 3 341 116 37 3 185 0.975 0.833 0.167 0.758 0.984 2.89 ## 4 4 341 88 5 31 217 0.739 0.977 0.0225 0.946 0.875 2.62 ## 5 5 341 119 59 0 163 1 0.734 0.266 0.669 1 3.49 ## 6 6 341 119 67 0 155 1 0.698 0.302 0.640 1 3.38 ## # ℹ 8 more variables: acc &lt;dbl&gt;, bacc &lt;dbl&gt;, wacc &lt;dbl&gt;, cost_dec &lt;dbl&gt;, ## # cost_cue &lt;dbl&gt;, cost &lt;dbl&gt;, pci &lt;dbl&gt;, mcu &lt;dbl&gt; You can see the definitions of all trees with: breast.fft$trees$definitions ## # A tibble: 6 × 7 ## tree nodes classes cues directions thresholds exits ## &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 2 i;i cellsize.unif;cellshape.unif &gt;;&gt; 2;2 0;0.5 ## 2 2 3 i;i;n cellsize.unif;cellshape.unif;… &gt;;&gt;;&gt; 2;2;1 0;0;… ## 3 3 2 i;i cellsize.unif;cellshape.unif &gt;;&gt; 2;2 1;0.5 ## 4 4 4 i;i;n;i cellsize.unif;cellshape.unif;… &gt;;&gt;;&gt;;&gt; 2;2;1;2 0;0;… ## 5 5 3 i;i;n cellsize.unif;cellshape.unif;… &gt;;&gt;;&gt; 2;2;1 1;1;… ## 6 6 4 i;i;n;i cellsize.unif;cellshape.unif;… &gt;;&gt;;&gt;;&gt; 2;2;1;2 1;1;… If sensitivity is really important, you might choose model 5 or 6, which both have a sensitivity of 1. You can also predict the outcome for new data from the best training tree with: predict(breast.fft, newdata = breastcancer[1:10,], type = &quot;prob&quot;) ## ✔ Applied 6 FFTs to &#39;test&#39; data. ## ✔ Generated predictions for tree 1. ## # A tibble: 10 × 2 ## prob_0 prob_1 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0.986 0.0144 ## 2 0.0787 0.921 ## 3 0.986 0.0144 ## 4 0.0787 0.921 ## 5 0.986 0.0144 ## 6 0.0787 0.921 ## 7 0.986 0.0144 ## 8 0.986 0.0144 ## 9 0.986 0.0144 ## 10 0.986 0.0144 This gives you the probability of FALSE (no cancre) and TRUE (cancer) for the first 10 observations in the dataset. You can also use type = \"class\" to get the predicted class (FALSE or TRUE) for each observation, or use type = “both” if you want to see both. You can also manually control which predictors go into the model. For example, you could use only bare nuclei and bland chromatin predictors with the code below: breast.fft &lt;- FFTrees(formula = diagnosis ~ nuclei.bare + chromatin, data = breastcancer, train.p = 0.5, main = &quot;Breast Cancer&quot;, decision.labels = c(&quot;Healthy&quot;, &quot;Disease&quot;)) plot(breast.fft, data = &quot;test&quot;) Or you can manually specify a model with the example code below:. Copy and paste into your local RStudio instance. breast.fft &lt;- FFTrees(diagnosis ~ ., data = breastcancer, my.tree = &quot;If thickness &gt; 6, predict TRUE. If chromatin &gt;3, predict TRUE. Otherwise, predict FALSE.&quot;) plot(breast.fft, data = &quot;train&quot;) 34.4 Your Turn with Heart Disease Data We will now use one of the other datasets in the FFTrees package, heartdisease. Load this dataset with the code below. Copy and paste into your local RStudio instance. Then click on the dataset in your Environment pane (it will appear as a Promise under Values) to see the data. data(heartdisease) This dataset from the Cleveland Clinic has 14 variables: diagnosis - 0=healthy, 1=disease age - age in years sex - sex, 0=female, 1=male cp - chest pain type: 1=typical angina, 2=atypical angina, 3=non-anginal pain, 4=asymptomatic trestbps - resting blood pressure systolic in mmHg chol - serum cholesterol in mg/dL fbs - fasting blood sugar &gt; 120, 0=no, 1=yes restecg - resting electrocardiographic results, 0=normal, 1=ST-T wave abnormality, 2=left ventricular hypertrophy thalach - maximum heart rate achieved during thallium study exang - exercise induced angina, 0=no, 1=yes oldpeak - ST depression induced by exercise relative to rest slope - the slope of the peak exercise ST segment, 1=upsloping, 2=flat, 3=downsloping ca - number of major vessels open during catheterization thal - thallium study results: 3=normal, 6=fixed defect, 7=reversible defect Take a look at which variables seem to correlate with heart disease. You can sort by the diagnosis variable and scroll a bit to get a first impression of the data. Now, let’s build a model to predict heart disease. We will use all of the variables in the dataset. Copy and paste the code below into your local RStudio instance. I have left several black spaces for you to fill in. set.seed(111) # note that the actual seed number does not matter, but if you change it, the randomization of train and test (and your results) will change slightly heart.fft &lt;- FFTrees(--- ~ ., data = &#39;---&#39;, train.p = 0.5, main = &quot;Heart Disease&quot;, decision.labels = c(&quot;---&quot;, &quot;---&quot;)) ## Error in -~.: invalid argument to unary operator Fix the code, then run it. If the model is not running, peek at the solution below. Click here to see the Solution set.seed(111) heart.fft &lt;- FFTrees(diagnosis ~ ., data = heartdisease, train.p = 0.5, main = &quot;Heart Disease&quot;, decision.labels = c(&quot;Healthy&quot;, &quot;Heart Disease&quot;)) ## Warning in comp_pred(formula = x$formula, data.train = x$data$train, data.test ## = x$data$test, : 4 cases in the test data could not be predicted by &#39;e&#39; due to ## new factor values. These cases will be excluded ## Warning in comp_pred(formula = x$formula, data.train = x$data$train, data.test ## = x$data$test, : NAs introduced by coercion ## Warning in !ix_NA_pred &amp; !ix_NA_crit: longer object length is not a multiple of ## shorter object length ## Warning in comp_pred(formula = x$formula, data.train = x$data$train, data.test ## = x$data$test, : 4 cases in the test data could not be predicted by &#39;e&#39; due to ## new factor values. These cases will be excluded ## Warning in comp_pred(formula = x$formula, data.train = x$data$train, data.test ## = x$data$test, : 4 cases in the test data could not be predicted by &#39;e&#39; due to ## new factor values. These cases will be excluded ## Warning in comp_pred(formula = x$formula, data.train = x$data$train, data.test ## = x$data$test, : 4 cases in the test data could not be predicted by &#39;e&#39; due to ## new factor values. These cases will be excluded You can then plot the model. plot(heart.fft, data = &quot;test&quot;) You can see the accuracy of each predictor by plotting the cues with the code below: plot(heart.fft, what = &quot;cues&quot;) ## Plotting cue training statistics: ## — Cue accuracies ranked by bacc You can see that one predictor (cue) #13 when used in isolation is almost a coin flip. You can print these out with: heart.fft$cues$stats$train ## cue class threshold direction n hi fa mi cr sens spec ## 1 age numeric 56 &gt; 152 47 31 23 51 0.6714286 0.6219512 ## 2 sex numeric 0 &gt; 152 56 45 14 37 0.8000000 0.4512195 ## 3 cp character a = 152 55 19 15 63 0.7857143 0.7682927 ## 4 trestbps numeric 124 &gt; 152 53 50 17 32 0.7571429 0.3902439 ## 5 chol numeric 253 &gt; 152 39 22 31 60 0.5571429 0.7317073 ## 6 fbs numeric 0 &gt; 152 14 12 56 70 0.2000000 0.8536585 ## 7 restecg character hypertrophy = 152 46 32 24 50 0.6571429 0.6097561 ## 8 thalach numeric 145 &lt;= 152 37 18 33 64 0.5285714 0.7804878 ## 9 exang numeric 0 &gt; 152 36 11 34 71 0.5142857 0.8658537 ## 10 oldpeak numeric 0.8 &gt; 152 48 24 22 58 0.6857143 0.7073171 ## 11 slope character flat,down = 152 47 31 23 51 0.6714286 0.6219512 ## 12 ca numeric 0 &gt; 152 53 20 17 62 0.7571429 0.7560976 ## 13 thal character rd,fd = 152 42 18 28 64 0.6000000 0.7804878 ## ppv npv acc bacc wacc dprime cost_dec ## 1 0.6025641 0.6891892 0.6447368 0.6466899 0.6466899 0.7491666 -0.3552632 ## 2 0.5544554 0.7254902 0.6118421 0.6256098 0.6256098 0.7122113 -0.3881579 ## 3 0.7432432 0.8076923 0.7763158 0.7770035 0.7770035 1.5126224 -0.2236842 ## 4 0.5145631 0.6530612 0.5592105 0.5736934 0.5736934 0.4143740 -0.4407895 ## 5 0.6393443 0.6593407 0.6513158 0.6444251 0.6444251 0.7564326 -0.3486842 ## 6 0.5384615 0.5555556 0.5526316 0.5268293 0.5268293 0.2089082 -0.4473684 ## 7 0.5897436 0.6756757 0.6315789 0.6334495 0.6334495 0.6785982 -0.3684211 ## 8 0.6727273 0.6597938 0.6644737 0.6545296 0.6545296 0.8392760 -0.3355263 ## 9 0.7659574 0.6761905 0.7039474 0.6900697 0.6900697 1.1323661 -0.2960526 ## 10 0.6666667 0.7250000 0.6973684 0.6965157 0.6965157 1.0219430 -0.3026316 ## 11 0.6025641 0.6891892 0.6447368 0.6466899 0.6466899 0.7491666 -0.3552632 ## 12 0.7260274 0.7848101 0.7565789 0.7566202 0.7566202 1.3801880 -0.2434211 ## 13 0.7000000 0.6956522 0.6973684 0.6902439 0.6902439 1.0196178 -0.3026316 ## cost cost_cue ## 1 -0.3552632 0 ## 2 -0.3881579 0 ## 3 -0.2236842 0 ## 4 -0.4407895 0 ## 5 -0.3486842 0 ## 6 -0.4473684 0 ## 7 -0.3684211 0 ## 8 -0.3355263 0 ## 9 -0.2960526 0 ## 10 -0.3026316 0 ## 11 -0.3552632 0 ## 12 -0.2434211 0 ## 13 -0.3026316 0 And look at the sens (0.84) and spec (0.16) numbers to find this (order is rearranged) - this was an isolated elevated fasting blood sugar without considering symptoms, demographics, or thallium results - sensitive but not specific (note that # 12 is an isolated EKG, and that this dataset is from the pre-Troponin (or even CK-MB) era.) 34.4.1 Test what you have learned What is the decision criterion for the first node, cp? aa (atypical angina) = Healthya (typical angina) = Heart Diseaseta (totally asymptomatic) = Heart Diseasenp (non-anginal pain) = Heart Disease How many people of the 151 in the testing set predicted to be healthy by this model actually had heart disease? 162353 34.5 Your Turn to Build and Interpret a Model We will now look at the strep_tb dataset from the {medicaldata} package. This dataset has 13 variables: patient_id - a unique identifier for each patient arm - treatment arm, Control or Strep dose_strep_g - dose of Streptomycin in grams gender - M or F baseline_condition 1=Good, 2=Fair, 3=Poor baseline_temp - coded as 1-4 baseline_esr - erythrocyte sedimentation rate - levels 1-4 baseline_cavitation - cavitation on chest x-ray as yes or no. improved - FALSE (died) or TRUE (improved) there are some other outcome variables like strep_resistance and radiologic_6m, but we will focus on improved. However, we do not want to use these as predictors, so we will clean up the dataset a bit. Copy and run the code below to remove some extraneous variables for our purposes today. strep_tb &lt;- medicaldata::strep_tb |&gt; dplyr::select(-strep_resistance,-rad_num, -radiologic_6m, -dose_strep_g, -dose_PAS_g, -patient_id) 34.6 Now build your FFTrees model to predict improved status (vs. death) You will get just a starter bit of code to get you going. Pull up the (FFTrees} package website. Fix up this code and run it in your local RStudio to answer the questions below. set.seed(99) tb.fft &lt;- FFTrees(outcome ~ , data = name, train.p = , main = &quot;Streptomycin TB&quot;, decision.labels = ) ## Error in parse(text = input): &lt;text&gt;:2:29: unexpected &#39;,&#39; ## 1: set.seed(99) ## 2: tb.fft &lt;- FFTrees(outcome ~ , ## ^ Fix the code, then run it. If the model is not running, peek at the solution below. Click here to see the Solution set.seed(99) tb.fft &lt;- FFTrees(improved ~ ., data = strep_tb, train.p = 0.5, main = &quot;TB Outcomes&quot;, decision.labels = c(&quot;Died&quot;, &quot;Improved&quot;)) You can then print the model: # code here Show Code print(tb.fft) ## TB Outcomes ## FFTrees ## - Trees: 6 fast-and-frugal trees predicting improved ## - Cost of outcomes: hi = 0, fa = 1, mi = 1, cr = 0 ## ## FFT #1: Definition ## [1] If baseline_condition != {1_Good,2_Fair}, decide Died. ## [2] If baseline_esr = {3_21-50,2_11-20}, decide Improved. ## [3] If arm = {Streptomycin}, decide Improved, otherwise, decide Died. ## ## FFT #1: Training Accuracy ## Training data: N = 54, Pos (+) = 28 (52%) ## ## | | True + | True - |Totals: ## |----------|--------|--------| ## | Decide + | hi 21 | fa 4 | 25 ## | Decide - | mi 7 | cr 22 | 29 ## |----------|--------|--------| ## Totals: 28 26 N = 54 ## ## acc = 79.6% ppv = 84.0% npv = 75.9% ## bacc = 79.8% sens = 75.0% spec = 84.6% ## ## FFT #1: Training Speed, Frugality, and Cost ## mcu = 1.63, pci = 0.73, cost_dec = 0.204 For the best model (#1), how many patients were predicted to die, but still lived? 262521 What did the best model predict would happen to patients with very low or very high ESR? Did not knowImprovedDied What did the best model predict would happen to patients with very high (level 4, over 38.2C) temperatures? Did not knowDiedImproved You can then plot the model on the test data set: # code here Show Code plot(tb.fft, data = &quot;test&quot;) For the best model (#1), what is the decision criterion at the first node? baseline_temp = 4 -&gt; Diedbaseline condition = not 1 or 1 -&gt; Diedbaseline_esr = 4 -&gt; Died By the confusion matrix on the test set, how many people predicted to improve actually died? 918422 You can see the accuracy of each predictor by plotting the cues with the code below: # code here Show Code plot(tb.fft, what = &quot;cues&quot;) ## Plotting cue training statistics: ## — Cue accuracies ranked by bacc What are the two best single predictors of TB outcome? baseline_temp &amp; baseline_esrbaseline_esr &amp; baseline_conditionbaseline_esr &amp; arm What are the two worst single predictors of TB outcome? baseline_cavitation &amp; baseline_conditiongender &amp; baseline_cavitationbaseline_esr &amp; baseline_temp "],["a-gentle-introduction-to-shiny.html", "Chapter 35 A Gentle Introduction to Shiny 35.1 What is Shiny? 35.2 The Basic Structure of a Shiny App 35.3 The User Interface Section Structure 35.4 The Server Section Structure 35.5 How to Run an App 35.6 Building a Very Simple App (Version 1) 35.7 Edit this App (Version 2) 35.8 Building a User Interface for Inputs and Outputs 35.9 Building a Functioning Server Section 35.10 Building a Simple Shiny App (Version 3) 35.11 Publishing Your Shiny App on the Web 35.12 More to Explore", " Chapter 35 A Gentle Introduction to Shiny 35.1 What is Shiny? Shiny is both an R package {shiny}, and a web framework for building web applications using R. The {shiny} package helps you share your models, plots, or tables so that other people can use them in an interactive way. Anyone with access to the web can look up your Shiny app model on their phone (or computer), enter a few values for predictor variables, and get an estimate for a continuous or a dichotomous outcome, without doing any calculations on their own. This is a really powerful way to share your models. It is often valuable to publish (serve) your model on a website before publishing in a medical journal, so that you can put the link to the Shiny app for the model in the manuscript. It can sound a little intimidating to set out to build a web application if you have limited (or no) programming experience, but the {shiny} package and the teaching materials at the end of this chapter are designed to make it manageable. 35.2 The Basic Structure of a Shiny App A Shiny app has two sections, as seen in the diagram below: the user interface (ui) section which accepts inputs from users, and displays output values to users the server section, which ingests the input, processes the data, renders output values to HTML, and sends these back to the user interface (ui). You can see the flow of inputs and return values in the diagram below. Note that IDs and values in the user interface section are referred to with quotes (“ID”, “value”), and IDs and values in the server section are referred to with dollar signs (input$ID, output $value). This can be a source of confusion (and syntax errors in your code), as the same user inputs and return values have different reference formats in each section of the Shiny app. Remember to use quotes to refer to input IDs and output values in the user interface section, and dollar signs to refer to the same IDs and output values in the server section. Structure of a Shiny App 35.2.1 The weirdness of a Shiny app Shiny apps use a different programming style from what we are used to for data analysis. We normally use what is called an imperative programming style, in which we write commands that are carried out in order, as soon as we run them. In contrast, Shiny apps use what is called a declarative programming style, which outlines higher-level goals, and lets the web app execute functions when it is activated by new input. When it is run, the Shiny app listens for new input, and reacts to this input by: Accepting the input in the user interface (ui) section Executing functions (making new model predictions, generating a plot) in the server section Rendering the output to HTML in the server section Displaying the output in the user interface (ui) section A Shiny app is reactive to new input. 35.3 The User Interface Section Structure The user interface (also known as the “front end” of an app is what the user sees and interacts with. This is often set up as a few sections: The titlePanel The sidebarPanel, where the user inputs data, which are assigned to specific “ID”s. The mainPanel, where resulting values from the server are displayed as output “values”. These can be model predictions, plots, tables, or other forms of R output. To set up this structure, the code needs to be structured into sections, which are built with functions, as seen below. When coding a user interface (ui) in a basic Shiny app: You add a title to the titlePanel(). You add input widgets and their labels to the sidebarPanel(). You add titles, text and output to the mainPanel(). The code to accomplish this has a similar hierarchy, as seen in the figure below. Using this basic template, you will add and define arguments to the: titlePanel() sidebarPanel() with specific typeInputs() mainPanel() with specific typeOutputs() 35.4 The Server Section Structure The server section is often described as the “back end” of the app. The user does not see what happens in the server section but this is where the actual data processing occurs. The server section accesses the inputs from the user as input$ID, where each input was assigned a unique “ID” in the user interface. The server code will then process this data to generate outputs (model predictions, tables, plots, etc.), which are rendered to HTML. These HTML rendered results are then assigned to unique output$values. Once the outputs have been assigned to unique output$values, the user interface can access them as “value” (in quotes), and output them to the mainPanel(), using the appropriate typeOutput(\"value\"). 35.5 How to Run an App The code part of running a Shiny app is always the same, and is quite simple. The function is shinyApp() and the two arguments identify the user interface (ui) and the server code (server) being used. Code to Run the Shiny App To actually run the app, activating its listening for new input, and displaying new output in the ui, you can click on the Run App button (with the green triangle icon) at the top of the Source Pane (top left pane by default). Use a keyboard shortcut - Cmd+Shift+Enter on Mac, Ctrl-Shift-Enter on Windows From the command line, call shiny::runApp() with the path argument being the path to the directory containing app.R. 35.5.1 How to Stop an App When your Shiny app is running, R is busy - the R prompt is not visible, and the console pane toolbar displays a stop sign icon. You can also tsee that the R Console pane has an “away message”. It says something like #&gt; Listening on http://127.0.0.1:8763. This tells you the URL where your Shiny app can be found. The URL 127.0.0.1 is the standard address that means “my computer”, and 8763 is a randomly assigned port number. You can open a browser on your computer, and enter that URL to open another copy of your Shiny app. You can stop your app by: Clicking the stop sign icon on the R Console pane toolbar. Closing the Shiny app window. Clicking in the Console pane, then pressing Esc (or Ctrl-C if using the command line). 35.6 Building a Very Simple App (Version 1) We will build a simple app to illustrate the flow of information between the ui and the server. Open up RStudio, in a new session. Select: File/New File/Shiny Web App. Give the Application a name, like shiny-test, leave the default structure (Single File app.R), and select the directory to save it in, then click on the Create button. You get the basic template for a basic Shiny app, with some comments to guide you. Inspect the user interface section, and the server section. Now let’s run this app to see what it does. Click on the Run App button at the top of the source pane. This should open an app window, titled Old Faithful Geyser Data. The inputSlider in the sidebarPanel starts at a default value of 30, and the mainPanel displays a histogram. You can slide the input value to a different Number of Bins, and the histogram will rapidly be redrawn, in reaction to your new input. 35.6.1 The ui section If you have screen space, arrange and resize the windows so that the source window and the Shiny app are side by side. Start by inspecting the ui section. The sidebarPanel has one input, with an ID of “bins”, with range from 1=50, and a default value of 30. Can you find the code that defines this? The mainPanel has only the plotOutput, but no code to make the plot. It is displaying a “distPlot” that was created by the server section. 35.6.2 The server section Now scroll down to the server section. This has a renderPlot function that renders a plot and assigns it to output$distPlot. It uses input$bins from the ui and the faithful dataset to create the histogram plot in base R. Note that the ui section uses quotes to refer to variables and the server section uses $ format to refer to variables. This means that the “bins” input in the ui appears in the server as input$bins, and the output$distPlot in the server section appears as “distPlot” in the ui mainPanel. 35.7 Edit this App (Version 2) Go back to your app.R session of RStudio. Notice that the Console pane does not have an active R prompt (&gt;). It is Listening on http://127.0.0.1/7787 - note that the port number - the random 4 digit number at the end, will likely be different each time. Stop running the app, by closing the app window, or clicking on the stop sign at the top right of the Console pane. In the Source Pane tab for app.R, scroll to the ui and within that, the titlePanel. Edit the title to “Medical Textbooks”. Now replace sliderInput with selectInput. Change the inputID from “bins” to “book”. Change the label from “Number of bins:” to “Select a Textbook:” Delete the min, max, and value arguments. Add a choices argument, with choices = list(\"Textbook of Surgery\", \"Textbook of Gastroenterology\", \"Diseases of the Liver and Biliary System\"). Double check that all your parentheses still match, and that you still have a comma between sidebarPanel and mainPanel. Now Run the app again. You should see a new sidebar, with a dropdown selection with 3 choices. The mainPanel should no longer work, as the expected “bins” input is no longer there. We will leave the mainPanel in its non-working state for now, and move to the server section to process the input$book data. Scroll down to the server section. Change output$distPlot to output$name. Now change the renderPlot to renderText. Now delete everything inside of renderText from # generate bins to border = 'white'). After renderText there is now only an open parenthesis followed by an open curly brace, and a few lines later these are closed with a curly brace and a parenthesis. If there is not much space between these, put in a few returns to open up some space. Then paste the following into the renderText between the paren/curly brace combinations: output$name &lt;- renderText({ if(input$book == &quot;Textbook of Surgery&quot; ) {author = &quot;David Sabiston&quot; } else if(input$book == &quot;Textbook of Gastroenterology&quot; ) {author = &quot;Tachi Yamada&quot; } else if (input$book == &quot;Diseases of the Liver and Biliary System&quot; ) {author = &quot;Sheila Sherlock&quot; } author }) This R code checks the input phrase, and assigns a particular value for author based on the phrase, much like a case_when function, but using the if/else if construction. Then it returns the value for the new variable, author. This is renderText-ed into the output$name. This will be sent to the ui as “name”. Now let’s scroll back up to the mainPanel of the ui, and use this \"name\" variable to generate an output. Find the mainPanel, and delete the plotOutput. Inside the parentheses for mainPanel, paste the following: h3(&quot;Who Wrote It?&quot;), br(), textOutput(&quot;name&quot;) This will print Who Wrote It? in header 3 format, followed by a line break, followed by the name from the server. Now we have accepted input in the ui, processed in in the server, and displayed it in the mainPanel of the ui. Our app is ready to run - click the Run App arrow. This should run a very simple Shiny app that reacts to user input and changes the output in the mainPanel to identify the correct computer for each computer catchphrase. Save this for a (later) Version 3. Hopefully, this exercise helped you understand the flow of information from the ui to the server and back to the ui. Let’s learn more about ui input widgets and server code to get you ready to build a Shiny app to share a model. 35.8 Building a User Interface for Inputs and Outputs 35.8.1 Inputs You have a number of options for obtaining input values from the users of your Shiny app. These are a variety of ‘widgets’. 35.8.1.1 Shiny Input Widgets for Your User Interface (UI) It can be hard to keep track of all the possible input options for your User Interface (UI), but this Shiny Widgets Gallery lets you scroll through a bunch of examples, and then see the code to see how to make it work (and copy, paste, and modify for your own Shiny app). Common input widgets include: Numeric (numericInput()) - good for exact values, but users can only input numbers. Good for savvy users and exact values in a big range. Slider (sliderInput()) or a slider range (min to max). Faster and less prone to errors than numeric input, but it is harder to be exact with fingers on a phone screen. Good for a small range of values. A dropdown list of choices (can be multiple if needed) (selectInput()) Radio buttons from a list of choices (radioButtons()), or true/false (single checkbox) - checkboxInput(). File upload (for a new dataset) (fileInput()) Date input (dateInput()) or Date Range (dateRangeInput()) 35.8.1.2 Assign Each Input to an input “ID” = input$ID For each input, there is an input type, and a unique function for that input type, like numericInput() for asking the user for a number. You will use the first argument to this function to assign the inputID. This is a short helpful name for this variable, like “age”, or “creatinine”. These are assigned with quotes in the user interface section. For example, you might use numericInput(inputID = \"age\", label = \"Type in the age\", min =1, max = 100, value = 35) The same variables will be referred to in the server section as input$age or input$creatinine. The arguments for each input function in the user interface are a lot alike. These include: inputID - the name to use to look up the value of the widget (as a character string). e.g. inputID = \"age\". Note that the server section will refer to this same value as input$age, while the user interface will refer to it as “age”. They are the same thing. label - the label to display to the user above the input box in the sidebarPanel. e.g. label = \"Enter numeric age here\". choices (if a list of choices is used) This argument is used for dropdown lists or multiple checkboxes. e.g. choices = list(\"Hispanic\"= 1, \"Not Hispanic\" = 2). value or selected (a default value if the user does not make a selection). The default value is used for numeric or slider input, and the default selected is used for dropdown lists or radio button lists. e.g. value = 50, or selected = 2. 35.8.2 Outputs When the server section assigns rendered outputs to output$value identifiers, you will need to refer to these in the user interface section to display them in the mainPanel. To display these, you use a typeOutput function - these include tableOutput(\"value\"), plotOutput(\"value\"), textOutput(\"value\"), etc. The server section could render a table of model outputs, and assign this to output$table1. The UI section would then be able to display this output in the mainPanel with tableOutput(\"table1\"). Note that table 1 is referred to in the ui by its value name in quotes (“table1”), rather than in the server style of output$table1. 35.8.2.1 Use the Correct Output Function for the Rendered output$ID it Comes from Each type of output from the server has a different typeOutput function used in the ui to display the output value. Be sure to use the right typeOutput function. Several examples are shown below. Server rendering &amp; assignment UI Output function renderText() -&gt; output$prediction textOutput(“prediction”) renderPrint() -&gt; output$model textOutput(“model”) renderPlot() -&gt; output$plot1 plotOutput(“plot1”) renderTable() -&gt; output$table1 tableOutput(“table1”) renderDataTable() -&gt; output$dt dataTableOutput(“dt”) Note that renderText can only handle character strings, while renderPrint can handle any printed output. A data table differs from a regular table in that it will show a page of data at a time, rather than a whole dataset, and will allow users to page through the data or sort it. 35.9 Building a Functioning Server Section The server section defaults are straightforward, and are the bread of the sandwich that you will build for data processing. The default content is server &lt;- function(input, output) { } and all of the data import, data processing, rendering of objects to HTML, and assigning outputs to output$ID happens between the curly braces. 35.9.1 Using the input values &amp; Data Data values from the user in the ui section are each assigned an inputID in quotes, like “height_cm”, or “weight_kg”. These can be accessed in the server section with input$height_cm or input$weight_kg. 35.9.2 Wrangling and Calculating You can calculate with input values, and mutate to create new variables. What does the server section below calculate? how would you access it in the ui section? server &lt;- function(input, output) { output$bc_ratio &lt;- renderText({ bc_ratio &lt;- input$bun_mg-dl/input$creat_mg_dl bc_ratio }) } Show Answers This calculates the Blood Urea Nitrogen to Creatinine ratio textOutput(“bc_ratio”) 35.9.3 Rendering to HTML Outputs Each output you create has to be rendered to HTML. This will require (after wrangling and calculating the output, and returning the value) using a render function in the server section. Each render function is for a distinct type of object, and wraps around your output with parentheses AND curly braces. Render Functions for the Server Section render function creates renderDataTable DataTable renderImage images (saved as a link to a source file) renderPlot plots renderPrint any printed output renderTable data frame, matrix, other table like structures renderText character strings renderUI a Shiny tag object or HTML 35.10 Building a Simple Shiny App (Version 3) We are now going to edit your shiny app to calculate BMI, using the formula: [Body Mass Index = weight in kg/(height in meters)^2]. Re-open the Shiny app file, app.R. Your serverPanel should still have a selectInput with 3 choices. Delete this and replace it with a numericInput() for weight, and a sliderInput() for height, as shown below sidebarPanel( numericInput( inputID = &quot;weight_kg&quot;, label = &quot;Enter weight in kilograms&quot;, value = 70), sliderInput( inputID = &quot;height_m&quot;, label = &quot;Enter height in meters&quot;, value = 1.7, min = 0.5, max = 2.7) ) Now scroll down to the server section. You can delete the if else section in renderText between the parenthesis/curly brace pairs. Change the name of the output$name to output$bmi. Then in the renderText section, calculate the BMI, as shown below. server &lt;- function(input, output) { output$bmi &lt;- renderText({ bmi &lt;- input$weight_kg/(input$height_m)^2 bmi }) } This will take the input values from the user and calculate BMI, then render it as text, and then assign it to output$bmi. Now let’s scroll back up to the mainPanel in the ui section. Your mainPanel should currently be set up to display the bc_ratio. Replace the header (h3) with “The Body Mass index is:”. Then change the textOutput argument to “bmi”. Then change the titlePanel (scroll up) to “BMI Calculator”. Now your BMI app should be ready to run. Give this a shot, and troubleshoot if needed. 35.11 Publishing Your Shiny App on the Web There are 4 major options for sharing your Shiny App on the web. ShinyApps.io is a web service that will let you share your shiny apps. You sign up for an account, then you can publish your Shiny apps for free. The free account level has a limited number of apps (10), and a limited number of hours of usage per month, but this will often do for simple models without a lot of usage. You can update your account from the free tier to accomodate more usage per month if it is popular. There are a number of tiers (Starter, Basic, Standard, and Professional) at different price points and usage volumes. Each app gets a unique web URL, which you can share with others, in the format: https://username.shinyapps.io/webapp_name/. Shiny Server - this is a good option if your app will have a lot of use and you have access to your own hardware or virtual server. You can download Shiny Server here. You can host your own Shiny apps for free, but there is a fair amount of setup involved. A walkthrough of how to do this can be found here. Set up a Shiny Server instance for on-demand use with a server service like Digital Ocean - They will host your web app for $5 per month. There is a basic walk-through on how to set this up here from Dean Attali. This is a walkthrough on how to deploy a Shiny app with Amazon Web Services (AWS). If you have access to RStudio Connect at your workplace, your RSC administrator can help you publish Shiny apps. 35.12 More to Explore This chapter is just the tip of the iceberg in terms of what you can do with Shiny web applications built in R. A gallery of great examples of what you can do with Shiny can be found at the link above. These examples also include code that you can copy and modify for your own purposes. These are great for seeing what is possible with Shiny (it is more than you would think!) Some excellent resources for learning more about Shiny web apps, dashboards, etc. can be found at: Lots of introductory material can be found at the RStudio Tutorial Webpage with 32 video lessons in 3 parts. Follow the link to get started. How to Build a Shiny App from Scratch is a nice free e-book, and a more complete introduction to building Shiny apps. The Mastering Shiny e-book takes you further under the hood, explaining how Shiny works, with excellent explanations of reactivity and more advanced Shiny programming. "],["sharing-models-with-shiny.html", "Chapter 36 Sharing Models with Shiny 36.1 Setting up and Saving Models 36.2 Building a Shiny App for the Linear Model 36.3 Building a Shiny App for the Logistic Model 36.4 Building a Shiny App for the Random Forest Model 36.5 Challenge Yourself", " Chapter 36 Sharing Models with Shiny In this chapter we will practice Sharing your predictive models with Shiny Apps for research or clinical use. 36.0.1 Packages Needed for this Chapter This chapter will require {tidyverse}. {medicaldata}, {shiny}, and {mlbench} packages. You may already have these packages installed. If not, these can be installed with the code below if you copy the code chunk to your RStudio Console pane and run these installation functions. # Install the packages below if you do not have these already installed. install.packages(&#39;tidyverse&#39;) install.packages(&#39;medicaldata&#39;) install.packages(&#39;shiny&#39;) install.packages(&#39;mlbench&#39;) We will walk through how to do this for a few example models. 36.1 Setting up and Saving Models We will start by building and saving several models. When needed, we can move these model objects (model.RDS) to the folder where the Shiny app will be located. For now, open an RStudio session in a directory where you can find the saved models, then copy and run the code chunks below to save the 3 models as *.RDS files. 36.1.1 Linear Model We will use one of the {medicaldata} datasets to build a linear model. We will use the supraclavicular dataset to model the onset of sensory function after anesthesia in minutes, using treatment group as the main predictor, adjusted for age, bmi, and gender. We will then save this linear model to an RDS file, using the saveRDS() function. library(tidyverse) library(medicaldata) library(shiny) supra_linear_model &lt;- medicaldata::supraclavicular %&gt;% lm(formula = onset_sensory ~ age + bmi + gender + group, data = .) saveRDS(supra_linear_model, &quot;linear_model.RDS&quot;) 36.1.2 Logistic Model We will use the Pima Indian dataset from {mlbench} to build a logistic model. We will classify individuals for the outcome of type 2 diabetes with 4 predictor variables. We will then save this logistic model to an RDS file, using the saveRDS() function. library(mlbench) library(shiny) data(&quot;PimaIndiansDiabetes2&quot;) dm_logit_mod &lt;- glm(diabetes ~ glucose + mass + pedigree + age, data = PimaIndiansDiabetes2, family = &quot;binomial&quot;) saveRDS(dm_logit_mod, &quot;logit_model.RDS&quot;) 36.1.3 Random Forest Model We will also use the Pima Indian dataset from {mlbench} to build a random forest model with the {tidymodels} package. This approach requires more steps, but is more flexible, as you can swap out the engine and its parameters, the pre-processing recipe, and (if needed) tune hyperparameters in the pipeline, allowing you to easily create and compare several versions of models. We will again predict the outcome of diabetes with all of the predictor variables available. We will then save this random forest model to an RDS file, using the saveRDS() function. library(tidymodels) library(mlbench) data(&quot;PimaIndiansDiabetes2&quot;) set.seed(123) splits &lt;- initial_split(PimaIndiansDiabetes2 %&gt;% na.omit(), strata = diabetes) dm_training &lt;- training(splits) dm_testing &lt;- testing(splits) dm_rf_mod &lt;- rand_forest(mtry = 4, min_n = 2, trees = 500) %&gt;% set_engine(&quot;ranger&quot;, num.threads = 8) %&gt;% set_mode(&quot;classification&quot;) rf_recipe &lt;- recipe(diabetes ~ ., data = dm_training) %&gt;% step_zv(all_predictors()) %&gt;% step_normalize(all_predictors()) rf_workflow &lt;- workflow() %&gt;% add_model(dm_rf_mod) %&gt;% add_recipe(rf_recipe) rf_fit &lt;- rf_workflow %&gt;% fit(data = dm_training) # predict(rf_fit, dm_testing, type = &quot;prob&quot;) # augment(rf_fit, dm_testing) saveRDS(rf_fit, &quot;rf_model.RDS&quot;) 36.2 Building a Shiny App for the Linear Model 36.2.1 The Default Shiny App Let’s start by opening a default Shiny app using the ‘Old Faithful’ template. This will build an app.R web app in a folder. We will need to move the file linear.RDS to this folder to have access to the model. To set up the default Shiny App, open a new RStudio session. Then Select: File/New File/Shiny Web App. Give the Application a name, like linear-model, leave the default structure (Single File app.R), and Select the directory to save it in (I put it into my experiments directory), then Click on the Create button. Now go to your file manager for your computer, and find the file named “linear_model.RDS”, and copy/paste/move it into your linear-model folder. Now your Shiny app will have access to the model. We will now edit the “Old Faithful” Shiny app to turn it into the Linear Model Shiny app that we want. Having the structure in place and editing piece by piece is pretty helpful. Let’s go step by step. Editing and coding in Shiny apps can be frustrating at first, as the structure is very particular, and a bit persnickety. Every comma, parenthesis, and curly brace is there for a reason, and it is very easy to get these wrong. It is very helpful to 1. Have the rainbow parentheses option turned on in your version of RStudio. You can turn this on with Tools/Global Options/Code/Display and select the checkbox for Rainbow Parentheses. When this is on, paired parentheses are color-matched, and when you reach the red close-parenthesis, you know you have closed all of the open expressions. 2. Watch your commas - you will need one between each input, but no comma after the last input. 3. Watch the red dot Xs at the left side of your code. Hover over these to help figure out what is wrong, and how to fix it. 4. If you are totally stuck, there are several Solution buttons to bail you out. 5. Don’t get down on yourself if you are struggling with Shiny - the syntax is hard when you are getting started, and the details of parentheses, curly braces, and commas are fairly unforgiving. Keep plugging away - you will get this working! Find and run the app.R file in the linear-model folder. This should produce the “Old Faithful” histogram, where x is the waiting time in minutes to the next eruption. Close the shiny app, and go to the app.R file. In the ui section, Change the title from “Old Faithful Geyser Data to”Linear Model Predictions for Supraclavicular Anesthesia”. Reload/Run the App to make sure this worked, and nothing else broke. 36.2.2 Editing the ui sidebarPanel for the Input Predictor Variables The linear model for predicting onset of sensory function has 4 predictors: group, gender, age, and bmi. The group value can be 1 or 2, the gender 0 or 1, the BMI ranges from 19-44, and the age ranges from 18 to 74 in the supraclavicular dataset. In the ui sidebarPanel section, replace the sliderInput for bins with one for BMI, with the appropriate range, and a default value of 32. Re-run the app to make sure that worked. Note that the mainPanel will now fail, without the “bins” input. That is OK. In the ui sidebarPanel section, copy/paste to add a similar sliderInput for age from 18 to 74, with a default of 40. Make sure you have a comma between each Input. Check to make sure you have parentheses and commas in all the right places. Feel free to undo (Cmd-Z or control-Z to start over). In the ui sidebarPanel section, add a comma, then a new selectInput for the group variable, with choices of 1 and 2. Instead of min, max, and value, you will need choices = list(1,2). Test run the App again. Copy/paste to add a similar selectInput for gender, with values of 0 and 1. Don’t forget the comma between Inputs. Test run the App again. Now add (before the first sliderInput) a header for your sidebar, with a line for h3(\"Input Values\"). Be sure to follow this with a comma before the first Input. Test run the App again. If your version is not working, check the Solution button below and compare it to your code for the ui section. You should have 5 distinct entries in the sidebarPanel - one h3 title, and 4 Inputs. Solution ui &lt;- fluidPage( # Application title titlePanel(&quot;Linear Model Predictions for Supraclavicular Anesthesia&quot;), # Sidebar with a slider input for number of bins sidebarLayout( sidebarPanel( h3(&quot;Input Values&quot;), sliderInput(&quot;bmi&quot;, &quot;Select the BMI:&quot;, min = 19, max = 44, value = 32), sliderInput(&quot;age&quot;, &quot;Select the Age:&quot;, min = 18, max = 74, value = 40), selectInput(&quot;group&quot;, &quot;Select the Group:&quot;, choices = list(1,2)), selectInput(&quot;gender&quot;, &quot;Select the Gender:&quot;, choices = list(0,1)) ), # Show a plot of the generated distribution mainPanel( plotOutput(&quot;distPlot&quot;) ) ) ) Now we have the inputs all set in the sidebarPanel. Let’s take these 4 inputs (and the model) to the server section, and set it up to make predictions. 36.2.3 Editing the server section to make Predictions Scroll down to the server section of app.R. Now delete everything from output$distPlot to the }) at the end, before the final curly brace } - leave that one in place. Now you should have several lines of open space between the two curly braces. The server section will generate predictions in 4 steps, two of which are reactive to inputs. For step 1, we will read in the model. Copy this line of code into the server section: model &lt;- readRDS(\"linear_model.RDS\"). This just reads the model object in, and stores it in the variable model. No inputs yet. Run the app again to make sure it works. For step 2, we will read in the input values, and store them as a dataframe. These have to be wrapped in reactive({ }) as they are reacting to inputs. Paste this code chunk into the server section next: input_df &lt;- reactive({ data.frame(bmi = input$bmi, age = input$age, group = as.double(input$group), gender = as.double(input$gender)) }) Notice that the drop-down choice values have to be converted to doubles, which is their data type in the original dataset for modeling. This creates a function input_df() that we can use in the prediction step. Run the app again to make sure it works. For step 3, we will make the predictions. We will use the model and input_df. Again, this is reactive to the input values, so we will wrap the predict() function in reactive({ }). We will use input_df() with parentheses, like a function, as it had reactive inputs. Then we will assign this result to pred. Paste the code chunk below into the server section next. pred &lt;- reactive({ predict(model, input_df()) }) Run the app again to make sure it works. For step 4, we will render the prediction to HTML text for display in the mainPanel of the ui, and assign it to output$pred. Again, because pred had reactive inputs, we use it as pred() inside the renderText({ }) function. output$pred &lt;- renderText({pred()}) Run the app again to make sure it works. Now you should have an output$pred to display in the ui. If your version of the server section is not working, check the Solution button below and compare it to your code for the ui section. You should have 4 distinct entries in the server section - the model, the input_df, pred, and output$pred. Solution server &lt;- function(input, output) { model &lt;- readRDS(&quot;linear_model.RDS&quot;) input_df &lt;- reactive({ data.frame(bmi = input$bmi, age = input$age, group = as.double(input$group), gender = as.double(input$gender)) }) pred &lt;- reactive({ predict(model, input_df()) }) output$pred &lt;- renderText({pred()}) } 36.2.4 Editing the mainPanel in the ui section to display your Prediction Now we just have to show the text in output$pred. Scroll up to the ui section, and find the mainPanel. We will just put in some introductory text, followed by a blank line (line break), and then use a textOutput() function to show the prediction (“pred”). Copy and paste the code chunk below into the mainPanel. h3(&quot;The predicted onset of sensory perception in minutes is:&quot;), br(), textOutput(&quot;pred&quot;) Now run the app.R one more time. If all went well, you should now have a linear model Shiny app that predicts (with default values) the return of sensory function after supraclavicular anesthesia in 10.63524 minutes. You can test different inputs to see their effects on the predicted time of onset of sensory function. 36.3 Building a Shiny App for the Logistic Model Now we will turn to the logistic model for predicting the diagnosis of diabetes. Not surprisingly, serum glucose (from 44-199) will be an important predictor. We will use the logistic diabetes model that we created at the beginning of this chapter. The other 3 predictors we will use are named mass (BMI, from 18-67), pedigree (a score for diabetes frequency in ancestors), and age in years (range 21-81). 36.3.1 The Default Shiny App Again, we will start by opening a default Shiny app using the ‘Old Faithful’ template. This will build an app.R web app in a folder. We will need to move the file logit_model.RDS to this folder to have access to the model. To set up the default Shiny App, open a new RStudio session. Then Select: File/New File/Shiny Web App. Give the Application a name, like logistic-model, leave the default structure (Single File app.R), and Select the directory to save it in (I put it into my experiments directory), then Click on the Create button. Now go to your file manager for your computer, and find the file named “logit_model.RDS”, and copy/paste/move it into your logistic-model folder. Now your Shiny app will have access to the model. We will now edit the “Old Faithful” Shiny app to turn it into the Linear Model Shiny app that we want. Having the structure in place and editing piece by piece is pretty helpful. Let’s go step by step. Find and run the app.R file in the logistic-model folder. This should produce the “Old Faithful” histogram, where x is the waiting time in minutes to the next eruption. Close the shiny app, and go to the app.R file. In the ui section, Change the title from “Old Faithful Geyser Data to”Logistic Model Predictions for Diabetes”. Reload/Run the App to make sure this worked, and nothing else broke. 36.3.2 Editing the ui sidebarPanel for the Input Predictor Variables The logistic model for classifying individuals into type 2 diabetes vs not diabetes has 4 predictors: glucose, mass (bmi), predigree (score), and mass (actually BMI) These values all have the data type of numeric double. Scroll to the ui sidebarPanel section, and replace the sliderInput for bins with one for glucose, with a helpful label to guide users to enter the glucose value, with the appropriate range of 44-199, and a default value of 125. Re-run the app to make sure that worked. Note that the mainPanel will now fail, without the “bins” input. That is OK. Using this example, copy/paste the sliderInput to create input widgets for mass (range 18-67), age (range 21-81), and pedigree (score range 0.8-2.4). Pick your own user-facing labels and default values. Make sure that you have a comma between each sliderInput, but not one at the end. Re-run the app after you add each sliderInput to make sure everything still works. If you have done everything right, you should have 4 usable sliderInputs. If you are having a hard time, compare your ui section code to the code chunk Solution below. Solution # Define UI for application that draws a histogram ui &lt;- fluidPage( # Application title titlePanel(&quot;Logistic Model Predictions for Diabetes&quot;), # Sidebar with a slider input for number of bins sidebarLayout( sidebarPanel( sliderInput(&quot;glucose&quot;, &quot;Enter the glucose value:&quot;, min = 44, max = 199, value = 125), sliderInput(&quot;mass&quot;, &quot;Enter the BMI:&quot;, min = 18, max = 67, value = 42), sliderInput(&quot;age&quot;, &quot;Enter the age in years:&quot;, min = 21, max = 81, value = 51), sliderInput(&quot;pedigree&quot;, &quot;Enter the pedigree score:&quot;, min = 0.8, max = 2.4, value = 1.6) ), # Show a plot of the generated distribution mainPanel( plotOutput(&quot;distPlot&quot;) ) ) ) Now we have the inputs all set in the sidebarPanel. Let’s take these 4 inputs (and the model) to the server section, and set it up to make predictions. 36.3.3 Editing the server section to make Predictions Scroll down to the server section of app.R. Now delete everything from output$distPlot to the }) at the end, before the final curly brace } - leave that one in place. Now you should have several lines of open space between the two curly braces. Add a few blank lines if you need more room. The server section will generate predictions in 4 steps, two of which are reactive to inputs. For step 1, we will read in the model. Copy this line of code into the server section: model &lt;- readRDS(\"logit_model.RDS\"). This just reads the model object in, and stores it in the variable model. No inputs yet. Run the app again to make sure it works. For step 2, we will read in the input values, and store them as a dataframe. These have to be wrapped in reactive({ }) as they are reacting to inputs. Paste this code chunk into the server section next: input_df &lt;- reactive({ data.frame(glucose = input$glucose) }) Now add 3 more lines to the data.frame() function, for input$mass, input$age, and input$pedigree. Assign these to the correct variable names, and use commas in the right places to complete the input_df. This creates a function input_df() that we can use in the prediction step. Run the app again to make sure it works. For step 3, we will make the predictions. We will use the model and input_df. Again, this is reactive to the input values, so we will wrap the predict() function in reactive({ }). We will use input_df() with parentheses, like a function, as it had reactive inputs. To get probabilities (rather than logit units, the default prediction), we need to add the argument type = \"response\". Then we will assign this result to pred. Paste the code chunk below into the server section next. pred &lt;- reactive({ predict(model, input_df(), type = &quot;response&quot;) }) Run the app again to make sure it works. For step 4, we will render the prediction to HTML text for display in the mainPanel of the ui, and assign it to output$pred. Again, because pred had reactive inputs, we use it as pred() inside the renderText({ }) function. output$pred &lt;- renderText({pred()}) Run the app again to make sure it works. Now you should have an output$pred to display in the ui. If your version of the server section is not working, check the Solution button below and compare it to your code for the ui section. You should have 4 distinct entries in the server section - the model, the input_df, pred, and output$pred. Solution server &lt;- function(input, output) { model &lt;- readRDS(&quot;logit_model.RDS&quot;) input_df &lt;- reactive({ data.frame(glucose = input$glucose, mass = input$mass, age = input$age, pedigree = input$pedigree) }) pred &lt;- reactive({ predict(model, input_df(), type = &quot;response&quot;) }) output$pred &lt;- renderText({pred()}) } 36.3.4 Editing the mainPanel in the ui section to display your Prediction Now we just have to show the prediction text in the mainPanel. Scroll up to the ui section, and find the mainPanel. Now just put in some introductory text about the probability of type 2 diabetes formatted in the header3 level with h3(\"Text\"), followed by a blank line (line break - br()), and then use a textOutput() function to show the prediction (“pred”). If you are having a hard time, you can check the Solution below Solution mainPanel( h3(&quot;The predicted probability of type 2 diabetes is:&quot;), br(), textOutput(&quot;pred&quot;) ) Now run the app.R one more time. If all went well, you should now have a logistic model Shiny app that predicts (with default values) the probability of type 2 diabetes as 0.8304044. You can test different inputs to see their effects on the predicted probability of type 2 diabetes. 36.4 Building a Shiny App for the Random Forest Model 36.5 Challenge Yourself How would you use the linear model predictions to plot these predictions compared to all of the other observations in the dataset? (Hint: augment the dataset with broom::augment predictions for each observation, then plot these with gray dots, and use the input data to make a new prediction plotted with a colored dot) How would you add confidence intervals to your predictions, and how would you add these to your displayed output in the mainPanel? "],["introduction-to-r-markdown.html", "Chapter 37 Introduction to R Markdown 37.1 What Makes an Rmarkdown document? 37.2 Trying out RMarkdown with a Mock Manuscript 37.3 Inserting Code Chunks 37.4 Including Plots 37.5 Including Tables 37.6 Including Links and Images 37.7 Other languages in code chunks 37.8 Code Chunk Options 37.9 How It All (Rmarkdown + {knitr} + Pandoc) Works 37.10 Knitting and Editing (and re-Knitting() Your Rmd document 37.11 Try Out Other Chunk Options 37.12 The setup chunk 37.13 Markdown syntax 37.14 2nd Header 37.15 Line Breaks and Page Breaks 37.16 Making Lists 37.17 The Easy Button - Visual Markdown Editing 37.18 Inline Code 37.19 A Quick Quiz", " Chapter 37 Introduction to R Markdown Rmarkdown Wizards, courtesy of Alison Horst Rmarkdown is an authoring framework for creating a variety of data-driven documents reproducibly with R. This e-book is itself a set of RMarkdown documents, assembled with the {bookdown} package. In many ways, Rmarkdown is a critical package for the R ecosystem, as it is a key enabler of reproducible reports in many formats. RMarkdown is a simple formatting syntax that allows you to mix text and code to document data analysis, and author MS Word, MS Powerpoint, HTML, PDF, web dashboards, web apps, and poster documents. Rmarkdown documents are fully reproducible and support more than a dozen output formats. If your data changes, or you decide to change a part of your analysis, you can reproduce the entire (new version) of the document with a single click of the Knit button (You can also use Cmd/Ctrl+Shift+K). This button is found at the top of the top left pane in RStudio. Knit button When you click the Knit button a document will be generated that includes both text content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this (which will run and produce output below. In this case, showing the contents of the covid_testing dataset.): covid &lt;- medicaldata::covid_testing glimpse(covid) ## Rows: 15,524 ## Columns: 17 ## $ subject_id &lt;dbl&gt; 1412, 533, 9134, 8518, 8967, 11048, 663, 2158, 3794, 4… ## $ fake_first_name &lt;chr&gt; &quot;jhezane&quot;, &quot;penny&quot;, &quot;grunt&quot;, &quot;melisandre&quot;, &quot;rolley&quot;, &quot;… ## $ fake_last_name &lt;chr&gt; &quot;westerling&quot;, &quot;targaryen&quot;, &quot;rivers&quot;, &quot;swyft&quot;, &quot;karstar… ## $ gender &lt;chr&gt; &quot;female&quot;, &quot;female&quot;, &quot;male&quot;, &quot;female&quot;, &quot;male&quot;, &quot;female&quot;… ## $ pan_day &lt;dbl&gt; 4, 7, 7, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 1… ## $ test_id &lt;chr&gt; &quot;covid&quot;, &quot;covid&quot;, &quot;covid&quot;, &quot;covid&quot;, &quot;covid&quot;, &quot;covid&quot;, … ## $ clinic_name &lt;chr&gt; &quot;inpatient ward a&quot;, &quot;clinical lab&quot;, &quot;clinical lab&quot;, &quot;c… ## $ result &lt;chr&gt; &quot;negative&quot;, &quot;negative&quot;, &quot;negative&quot;, &quot;negative&quot;, &quot;negat… ## $ demo_group &lt;chr&gt; &quot;patient&quot;, &quot;patient&quot;, &quot;patient&quot;, &quot;patient&quot;, &quot;patient&quot;,… ## $ age &lt;dbl&gt; 0.0, 0.0, 0.8, 0.8, 0.8, 0.8, 0.8, 0.0, 0.0, 0.9, 0.9,… ## $ drive_thru_ind &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, … ## $ ct_result &lt;dbl&gt; 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45… ## $ orderset &lt;dbl&gt; 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, … ## $ payor_group &lt;chr&gt; &quot;government&quot;, &quot;commercial&quot;, NA, NA, &quot;government&quot;, &quot;com… ## $ patient_class &lt;chr&gt; &quot;inpatient&quot;, &quot;not applicable&quot;, NA, NA, &quot;emergency&quot;, &quot;r… ## $ col_rec_tat &lt;dbl&gt; 1.4, 2.3, 7.3, 5.8, 1.2, 1.4, 2.6, 0.7, 1.0, 7.1, 2.5,… ## $ rec_ver_tat &lt;dbl&gt; 5.2, 5.8, 4.7, 5.0, 6.4, 7.0, 4.2, 6.3, 5.6, 7.0, 3.8,… The Knit button (at the top of the top left pane of RStudio) runs render(\"file.Rmd\", output = document-type) for you in a background (clean) session of R. 37.1 What Makes an Rmarkdown document? An Rmarkdown document is a plain-text file with the *.Rmd file extension. It is composed of four types of content: The YAML header (at the top), surrounded at top and bottom by 3 dashes (—) Text narrative - the meat of your manuscript Code chunks, surrounded at top and bottom by 3 back-ticks (```), and the chunk header in braces, like {r plot-figure} Note that the first code chunk is always named setup and is often used to load libraries and set up document options. Inline code, which does calculations in your text to provide calculated values like means, medians, and p values. This essentially provides an interface like a ‘lab notebook’ for data analysis. You can use code chunks to run the analysis, and text to document what you are doing in the analysis, how it worked, and interpret the results. When the analysis is ready, you can polish up your document to produce a final manuscript. Code outputs, including tables and plots, are incorporated into the document. You can choose to show or hide the code chunks in the final document with options in the chunk header, like: {r, echo = FALSE} - runs code, but does not show it. or {r, echo = TRUE} - runs code and shows the code. 37.2 Trying out RMarkdown with a Mock Manuscript Open up RStudio. Start a new Project. Click - File - New Project… - Version Control &gt; - Git &gt; Now paste the following into the Repository URL: box https://github.com/higgi13425/rmd4medicine.git add a directory name, like rmd4medicine click on Create Project Find the Files tab in the lower right quadrant. Click to open the prep folder Click to open the mockstudy_analysis.Rmd file. This file should open in the top left quadrant of RStudio. If there are warnings at the top of the file that you need to install packages, click on the Install button. 37.3 Inserting Code Chunks You can add code to your document to process your data and display results. To insert a code chunk into your Rmarkdown document, click on the green +c button at the top center of the top left pane in RStudio. The dropdown menu will allow you to choose R code or several other computer languages, For now, click on R. This inserts a gray code chunk, which starts and stops with 3 back-ticks. The starting back-ticks are followed by braces containing a lower-case r, designating what follows as R code. You can name your individual code chunks with specific names, based on what they do. You can click to the right of the lower-case r, before the closing brace, and add a space, then a name for the code chunk. If the chunk name contains multiple words, connect these with hyphens, as in the code chunk below. Avoid spaces, periods, and underscores in chunk names. head(covid) ## # A tibble: 6 × 17 ## subject_id fake_first_name fake_last_name gender pan_day test_id clinic_name ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1412 jhezane westerling female 4 covid inpatient wa… ## 2 533 penny targaryen female 7 covid clinical lab ## 3 9134 grunt rivers male 7 covid clinical lab ## 4 8518 melisandre swyft female 8 covid clinical lab ## 5 8967 rolley karstark male 8 covid emergency de… ## 6 11048 megga karstark female 8 covid oncology day… ## # ℹ 10 more variables: result &lt;chr&gt;, demo_group &lt;chr&gt;, age &lt;dbl&gt;, ## # drive_thru_ind &lt;dbl&gt;, ct_result &lt;dbl&gt;, orderset &lt;dbl&gt;, payor_group &lt;chr&gt;, ## # patient_class &lt;chr&gt;, col_rec_tat &lt;dbl&gt;, rec_ver_tat &lt;dbl&gt; 37.3.1 Code Chunk Icons You may have noticed 3 small icons at the top right of each code chunk. From left to right, these are a (settings) gear, a downward arrowhead with a green baseline (run all of the preceding chunks), and a rightward (run) arrow. Check these out and experiment with them. Code Chunk Icons Icon Uses Settings Gear Allows you to Name the code chunk Set options for this chunk Run Chunks Above (down arrow) Runs all of the preceding code chunks, including the setup chunk Run Chunk (rightward arrow) Runs the entire current chunk 37.4 Including Plots You can also embed plots using code chunks, for example: covid %&gt;% ggplot() + aes(x = pan_day, y = ct_result) + geom_point() + labs(title = &quot;COVID Testing in First 100 Days of Pandemic&quot;, x = &quot;Pandemic Day, 2020&quot;, y = &quot;Cycle Threshold \\n45 is a Negative Test&quot;) Note that the echo = FALSE parameter was added to the top of the plot code chunk to prevent printing of the R code that generated the plot. This is an example of a chunk option. 37.5 Including Tables You can also use code chunks to include tables in your document. covid %&gt;% count(demo_group, gender) %&gt;% gt() %&gt;% tab_header(title = &quot;Demographics of COVID Testing&quot;, subtitle = &quot;By Group and Gender&quot;) %&gt;% tab_source_note(source_note = &quot;From CHOP, 2020&quot;) %&gt;% cols_label(demo_group = &quot;Group&quot;, gender = &quot;Gender&quot;, n = &quot;Count&quot;) #rdfkkvlepw table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #rdfkkvlepw thead, #rdfkkvlepw tbody, #rdfkkvlepw tfoot, #rdfkkvlepw tr, #rdfkkvlepw td, #rdfkkvlepw th { border-style: none; } #rdfkkvlepw p { margin: 0; padding: 0; } #rdfkkvlepw .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #rdfkkvlepw .gt_caption { padding-top: 4px; padding-bottom: 4px; } #rdfkkvlepw .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #rdfkkvlepw .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #rdfkkvlepw .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #rdfkkvlepw .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #rdfkkvlepw .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #rdfkkvlepw .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #rdfkkvlepw .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #rdfkkvlepw .gt_column_spanner_outer:first-child { padding-left: 0; } #rdfkkvlepw .gt_column_spanner_outer:last-child { padding-right: 0; } #rdfkkvlepw .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #rdfkkvlepw .gt_spanner_row { border-bottom-style: hidden; } #rdfkkvlepw .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #rdfkkvlepw .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #rdfkkvlepw .gt_from_md > :first-child { margin-top: 0; } #rdfkkvlepw .gt_from_md > :last-child { margin-bottom: 0; } #rdfkkvlepw .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #rdfkkvlepw .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #rdfkkvlepw .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #rdfkkvlepw .gt_row_group_first td { border-top-width: 2px; } #rdfkkvlepw .gt_row_group_first th { border-top-width: 2px; } #rdfkkvlepw .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #rdfkkvlepw .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #rdfkkvlepw .gt_first_summary_row.thick { border-top-width: 2px; } #rdfkkvlepw .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #rdfkkvlepw .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #rdfkkvlepw .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #rdfkkvlepw .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #rdfkkvlepw .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #rdfkkvlepw .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #rdfkkvlepw .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #rdfkkvlepw .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #rdfkkvlepw .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #rdfkkvlepw .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #rdfkkvlepw .gt_left { text-align: left; } #rdfkkvlepw .gt_center { text-align: center; } #rdfkkvlepw .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #rdfkkvlepw .gt_font_normal { font-weight: normal; } #rdfkkvlepw .gt_font_bold { font-weight: bold; } #rdfkkvlepw .gt_font_italic { font-style: italic; } #rdfkkvlepw .gt_super { font-size: 65%; } #rdfkkvlepw .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #rdfkkvlepw .gt_asterisk { font-size: 100%; vertical-align: 0; } #rdfkkvlepw .gt_indent_1 { text-indent: 5px; } #rdfkkvlepw .gt_indent_2 { text-indent: 10px; } #rdfkkvlepw .gt_indent_3 { text-indent: 15px; } #rdfkkvlepw .gt_indent_4 { text-indent: 20px; } #rdfkkvlepw .gt_indent_5 { text-indent: 25px; } #rdfkkvlepw .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #rdfkkvlepw div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } Demographics of COVID Testing By Group and Gender Group Gender Count client female 314 client male 290 misc adult female 1214 misc adult male 1227 other adult female 126 other adult male 97 patient female 6178 patient male 6077 unidentified male 1 From CHOP, 2020 Note that this code chunk is using the {gt} package to format the table. Other popular approaches to table formatting include the {flextable} package and the knitr::kable() function. 37.6 Including Links and Images 37.6.1 Links You can add hypertext links to your text (without a code chunk) with a description in square brackets followed immediately by the URL in (parentheses), like this: [text description here](http://www.link.com) As an example, the link to the Rmarkdown cheatsheet can be found at this link. 37.6.2 Images You can add images to your text if they are in the same project as your Rmarkdown document. You have to specify the path to the image file correctly. It is often helpful to collect your images in an images folder or a figures folder. If you have already generated your figures with other R scripts, they can be placed into your manuscript document from a figures folder. You can add images to your text with an exclamation point, followed by a caption in square brackets followed immediately by the path to the image file in (parentheses), on a line of its own, separated from the text, like this: ![Caption for this Figure 1](images/figure_1.png) You can also insert an image using a code chunk and the knitr function include_image(), like this, which gives you more options to control figure size, alignment, height, and width with code chunk options: knitr::include_graphics(&#39;images/datasaurus-dozen.png&#39;) (note that echo = TRUE and eval=FALSE as code chunk options means that this code is shown, but not run) An example shown below is an image of the “datasaurus dozen” used to illustrate what summary measures can hide in data distributions, as seen below in 12 data distributions with the same mean and standard deviation, one of which happens to look like a T. Rex. You should always visualize your data. There might be a dinosaur in there. (note that echo = FALSE and eval=TRUE as code chunk options means that the code chunk used to include this image code is run, but not shown) Source for Image: https://juliasilge.com/blog/datasaurus-multiclass/ 37.7 Other languages in code chunks You can use a number of different open-source languages in addition to R if needed to do your data analysis, including SQL, shell code with Unix Bash, C, C++ via Rcpp, Stan, and D3. Any of these options can be chosen from the Insert Code button dropdown (green +c button). 37.8 Code Chunk Options When you are working through a data analysis, you usually want to display the code that led to a result. For the final manuscript, you may want to hide the code and just display the results. You can accomplish this with echo=TRUE to display code, and echo=FALSE to hide the code. Code chunk options should be added to the top of each code chunk, in the chunk header after the name of the code chunk, and separated from the chunk name (and from each other) by commas. The chunk header (material between the braces) must be written on one line. You must not break the line with a return, or it will not work. Code Chunk Options Option Values Output eval TRUE/FALSE Whether or not the code is run. echo TRUE/FALSE Show or hide the code include TRUE/FALSE Whether or not the resulting output of a code chunk is displayed in the document. FALSE means that the code will run, but will not display results. include = FALSE is often used for the setup chunk. warning TRUE/FALSE Whether warnings generated from your code will be displayed in the document. message TRUE/FALSE Whether messages generated from your code will be displayed in the document. fig.align default, left, right, center Where on the page the output figure should align. Text options should be in quotes, like fig.align = \"right\" fig.width default = 7 figure width in inches fig .height default = 7 figure height in inches error TRUE/FALSE If TRUE, will not stop building the document if there is an error in a code chunk. cache TRUE/FALSE If TRUE, will store the results and not re-run the chunk. Helpful for long, slow calculations. But watch out for this if your data change and your results do not(!!). Note that there are many more chunk options which you can use if needed, and these can be found here. 37.9 How It All (Rmarkdown + {knitr} + Pandoc) Works rmarkdown processing from rstudio.com Rmarkdown is an R-flavored version of the markdown language. This is a universal, open-source markup language for creating formatted documents from plain text. Markdown documents end with the file extension *.md. An open-source program named pandoc converts *.md documents to output documents like MS Word, PDF, HTML, MS Powerpoint, etc. When you click the Knit button or run the render() function, R Markdown feeds the .Rmd file to knitr, which executes all of the code chunks and creates a new markdown (.md) document which includes the code and its output. The markdown file generated by {knitr} is then processed by pandoc which is responsible for creating the finished format. This may sound complicated, but R Markdown makes it extremely simple by encapsulating all of the above processing into a single render() function (or the Knit button). 37.10 Knitting and Editing (and re-Knitting() Your Rmd document Find the Knit button at the top of the file, and click it to convert this *.Rmd . It will automagically knit the document first to markdown (to *.md and then from *.md to *.HTML. Scroll through the document to see what has been created. Go back to the Rmd document. Now try the following: in the YAML header, edit the author to your name edit the date to the current (or a different) date edit the output from html_document to word_document find the glimpse code chunk. After the chunk name glimpse, add a comma, then the option echo=FALSE Add this same option to a few of of the other code chunks (feel free to use copy-paste, but make sure you don’t end up with duplicate commas, as this will cause errors) Now click on the Knit button again. You should get a new version of the document, now in MS Word format, with the code chunks hidden, and a new author and date. The Word document is in a particular default format, but you can change this by specifying a template word file in the YAML header. 37.11 Try Out Other Chunk Options Try adding different chunk options, including include = FALSE eval = FALSE, echo = TRUE eval=TRUE, echo = FALSE 37.12 The setup chunk The setup chunk is a special code chunk, which is usually the first code chunk at the top of your RMarkdown document. Typically it includes two types of code: libraries to be loaded data to be loaded in the background and often looks something like this: library(tidyverse) library(here) data &lt;- read_csv(here(&quot;data/my_data_file.csv&quot;)) (note that for display purposes, I am using the chunk options eval = FALSE, echo = TRUE, while in a real setup chunk, I would use include = FALSE, which runs the code but does not display the code nor the output. I also had to change the chunk name to setup2 because only unique chunk names are allowed). Scroll to the setup chunk at the top of your Rmd document to see what a working setup chunk looks like. 37.13 Markdown syntax Markdown is a popular markup language that allows you to add formatting elements to text, including bold, italics, and code formatting. We make text Bold by surrounding the words with double asterisks. We make text Italic by surrounding the words with single underscores or single asterisks. We make text Bold and Italic by surrounding the words with triple underscores or triple asterisks. We can make text in code-font by surrounding it with single back-ticks. You can also format level 1 to level 5 headings. These are done by preceding the heading (on its own line) with 1-5 hashtags. 37.14 2nd Header 37.14.1 3rd Header 37.14.1.1 4th level Header 37.14.1.1.1 5th level header (note that I did not use a level 1 header, which would have forced a new chapter in bookdown). There is only one level 1 header in this chapter - the chapter title. 37.15 Line Breaks and Page Breaks If you simply hit return in your *.Rmd document, you will see a line break in your text. But this is only a semantic line break, as the knitted document will smush these lines together. You can create a deliberate line break by adding 2 or more spaces to the end of a line of text. This will work in any output format. The downside of this is that these line breaks are not visible, until you Knit the document. Line breaks can be inserted (for HTML output) by using html tags The HTML tag for line breaks is &lt;br&gt;. But these are kind of annoying to type, and 2 spaces at the end of each line is pretty easy, but less visible when you are looking at the text in the Rmd. Note that you need a blank line before headers for them to be recognized as headers and formatted properly 37.16 Making Lists 37.16.1 Ordered Lists You can create an ordered list by preceding items with numbers and period: First Second Third 37.16.2 Un-ordered lists You can create an un–ordered list with the - + or * keys as your leading bullets. chickadee carrot quartz 37.16.3 Nested Lists You can create nested lists by tab-indenting with a new symbol, using - for level 1, + for level 2, etc. Birds Hawk Vegetables Carrot Baby Ball Nantes Minerals Gneiss 37.17 The Easy Button - Visual Markdown Editing While it is helpful to know all of the formatting options for headers, italics, bold, etc. for troubleshooting, it is not as simple as a modern word processor with menu buttons. So RStudio came up with the Visual Markdown Editor. This can be activated for your RMarkdown document by clicking on a button in the top right of your Rmd document pane. It looks a bit like a compass, or possibly an Angstrom symbol (if you were a chemistry major). If you toggle this button to on, your Rmarkdown document now has basic word processor functions, including live formatting - What You See Is What You Get (WYSIWIG). A new submenu appears at the top of the document, with buttons to select the heading level (or normal text, or code block), as well as bold, italic, and underline. You can insert lists, tables, block-quotes, links, citations, cross-references within a document, images, horizontal lines, special characters, and math equations. There is a drop-down menu to help you format tables. You can even insert comments into a shared manuscript. 37.17.1 Try inserting a list, a table and a block-quote In your practice RMarkdown document, from the Rmarkdown Visual Editor View, Insert a short list of endoscopic procedures, types of dialysis, or interventions done through a catheter Insert a small 3 column table with columns for ethnicity (Hispanic/Non-Hispanic), retirement status (Retired/Not Retired), and Count Insert the following as a block quote: “Don’t judge each day by the harvest you reap but by the seeds that you plant.” -Robert Louis Stevenson 37.18 Inline Code You will often want to insert a result into your text, like a percent reduction in an endpoint, or a p value. Rather than copying and pasting from somewhere else (which are prone to error, or forgetting to update), you can do these calculations right in your text, using inline R code. For example, if you want to say that we evaluated NN COVID PCR tests for this study, you can calculate how many rows in your dataset with R, right in the text. To do this, you bracket the code with single back-ticks, and start with the letter r immediately after the first back-tick, so that Rmarkdown knows that R code is coming. After the lower-case r, you can insert your code expression, like nrow(covid) to give you the number of rows (observations). Putting this together, this looks like `r nrow(covid)`. When you insert this in the middle of a sentence in your text (inline code), this lets you write sentences in your manuscript like the following, which calculate the actual number in the text (and automatically update when your data changes): We evaluated 15524 COVID PCR tests in this study. 37.18.1 Try inserting some in-line R code Try this yourself. Select the correct code to insert the proper results, as illustrated below (note that these would be surrounded by single back-ticks) The mean cycle threshold in this study was r covid %&gt;% mean(ct_result, na.rm = TRUE) %&gt;% format(digits = 5) r covid %&gt;% median(ct_result, na.rm = TRUE) %&gt;% format(digits = 7) r covid %&gt;% sd(ct_result, na.rm=TRUE) %&gt;% format(digits =3) The standard deviation of the cycle threshold in this study was r covid %&gt;% mean(ct_result, na.rm = TRUE) %&gt;% format(digits = 5) r covid %&gt;% median(ct_result, na.rm = TRUE) %&gt;% format(digits = 7) r covid %&gt;% sd(ct_result, na.rm=TRUE) %&gt;% format(digits =3) Correct answers should produce this output when knit: The mean cycle threshold in this study was 44.122 and the standard deviation was 3.98. 37.19 A Quick Quiz Which code chunk option hides the code? eval = TRUEwarning = FALSEecho = FALSE Which code chunk always comes first, and includes libraries and data import steps? plotsetuptop_chunk What is the name of the code block (and the markup language it is written in), set off with 3 hyphens(—) at the very top of your Rmarkdown document, that tells pandoc how to format the final document? HTMLYAMLSPAMformatter What symbols do you use to make text bold in Rmarkdown? one asterisktwo asterisksunderscoresExclamation points Which {knitr} function do you use to add images to your document with a code chunk? paste()include_image()insert()insert_pic() "],["rmarkdown-output-options.html", "Chapter 38 Rmarkdown Output Options 38.1 Microsoft Word Output from Rmarkdown 38.2 PDF Output from RMarkdown 38.3 Microsoft Powerpoint Output from Rmarkdown", " Chapter 38 Rmarkdown Output Options While HTML is convenient for rapid output and iteration, most end-products for medical research are either Word documents, PDFs, or PowerPoint slides. There are many options for Rmarkdown output, including the markdown(*.md) document that results from Knitting. The *.md document is then translated by pandoc into options including: MS Word word_document PDF pdf_document PowerPoint powerpoint_presentation Rich Text Format document - rtf_document OpenDocument file odt_document LaTeX typesetting document latex_document ConTeXt typesetting document context_document HTML html_document Github-formatted markdown github_document And some other presentation formats xaringan::moon_reader slidy_presentation beamer_presentation ioslides_presentation 38.1 Microsoft Word Output from Rmarkdown Changing the output of a Rmarkdown document to Microsoft Word is easy - you can either: click on the dropdown arrow next to the Knit button, and select, Knit to Word, or change the output: option in the YAML header to word_document These will use the default formatting for Microsoft Word, which is OK, but may not produce the font, text color (too much blue!), or the heading sizes that you want. This is fixable, by using your own MS Word template document (aka style reference document). If you have a Word document named “my-styles.docx”, this can serve as your styles template. You just have to : Have the file in the same folder as the *.Rmd document, or in a nearby folder, preferably in the same project. Change the output: field of your YAML header to look like this: --- title: &quot;My Title&quot; author: Me date: January 7, 2027 output: word_document: reference_docx: my-styles.docx --- Note that the placement of the new-lines (returns), colons, and indents are critical to make this output format work. And if your reference.docx template is in a folder within your project, you need to put the path - i.e. styles-template/reference.docx if it is in the styles-template folder. 38.1.1 Making a Styles Reference File for Microsoft Word The easiest way to make a reference_docx file is to knit a new rmarkdown file to Microsoft Word, then reformat the resulting Word document to the format that you want. Then save the resulting word document as my-styles.docx in your project folder, usually near your Rmarkdown file. It is often helpful to have each level of heading (1-5) present in your template *.docx file, so that you can make sure that all of the header levels and the body text are formatted the way that you want them. 38.1.2 Let’s Practice This. Open RStudio. Open the rmd4medicine project that you created in the previous chapter (if you did not, go back and do this, then return here). Click on the Git tab in the top right in RStudio. Click on the downward green arrow icon to pull down the latest files in this project from GitHub. Open the prep folder, then open the style-rmd.Rmd file. Knit this document to Microsoft Word. Save the resulting document as word-styles.docx in the same directory as your Rmd file We will use this docx document as a template (after we reformat) 38.1.3 Re-formatting Your Template Open the word document, Select the Home ribbon, then the Styles window launcher (Styles Pane) in the Styles group. Select the Title. It has the Title style. Scroll down to Title style in the Styles Window. Change the font, the color, the size, etc. until you like the look. Then click on the dropdown arrow to the right of the Title style, and select ‘Update Title to Match Selection’. Then repeat the process for body text, Heading1, Heading2, Heading3, etc. There is a nice video walkthrough of where to click here. When you are happy with the formatting, then save this document as word-styles.docx. 38.1.4 Using Your New Styles Template Use File/New File/Rmarkdown to open a new *.Rmd file. Go to the top of your Rmarkdown document, to the YAML Header It should have 2 lines of 3 dashes, with a title, author, date, and output: html_document between them You need to change this to (note that these are real indent tabs) output: (indent)word_document: (indent)(indent)reference_docx: word-styles.docx Note the placement of the colons, what is on each line, and the number of indents are critical to making this work. 38.1.5 Now you are ready! Now save this document and knit - you will get the format that you intended. And you can use this template for any future Rmarkdown document - just be sure that you have word-styles.docx in the same folder where your Rmarkdown document lives. 38.2 PDF Output from RMarkdown Most of the time, you will not need PDF output. Many journals prefer that you submit MS Word files in *.docx format and image files in tiff, bmp, or jpeg formats. Then their web server will generate the PDF. But if you are determined to make your own PDFs from Rmarkdown files, you can. It just takes a bit of setup. 38.2.1 LaTeX and tinytex First, you need a translator for all of the things PDFs can do. A complete version uses TeX or LaTeX to get all kinds of typesetting functions. Most of the time, you need a much smaller subset of TeX, which is where the {tinytex} package comes in handy. To use {tinytex}, copy the code chunk below, and run it in your local RStudio console (once only). install.packages(&#39;tinytex&#39;) tinytex::install_tinytex() More details on how to use and maintain {tinytex} can be found here. 38.2.2 Knitting to PDF Now that the installation of {tinytex} is complete, you can Knit to PDF. Open your favorite Rmarkdown document, and knit to PDF in one of two ways: Click on the dropdown arrow next to the Knit button, and select Knit to PDF. Edit the YAML output: key to pdf_document (with no quotes). Then click on the Knit button. This will open up a new window with your auto-generated PDF document. 38.3 Microsoft Powerpoint Output from Rmarkdown To get Powerpoint output, you can simply change the output: key to powerpoint_presentation. You can even add a formatted powerpoint template (like my-styles.pptx) to get the fonts and colors and headings the way you like them (remember to use the indents, like this: --- title: &quot;My Title&quot; author: Me date: January 7, 2027 output: powerpoint_presentatino: reference_docx: my-styles.pptx --- A simple Powerpoint template can be found [here](https://github.com/mfherman/mattherman/blob/master/static/ppt/template-no-title.pptx. But the knitted result often won’t be quite right out of the gate, as slides, unlike word documents, need explicit separators between slides. You will create a new slide each time you insert a Level1/2 Heading, or (more commonly) each time you have 3 or more dashes on a single line. Since most Word Documents don’t have a lot of Level1 Headings, an Rmd document that works well for MS Word will usually have way too many words/lines per Powerpoint slide. You will usually have to Start After the YAML with a Level 1 header Divide up your slides with 3-dash breaks ---. Start Each new slide with a Level 1 or Level 2 header Convert the text into pithy bullet points (usually level 3 and 4 headers and body text) Insert only one image or plot per slide (you can reformat them later in PPT) Set up your template pptx file - often enlarging the area for the image, and removing the separate title slide is helpful (as in the example template above). Oftentimes, you will just be wanting to get the images and plots from your project into PPT, and add text and formatting later. This will be less than completely reproducible, but can be faster than writing a whole PowerPoint presentation in Rmd. 38.3.1 Tables in Powerpoint You can use the {flextable} package to make formatted tables for Powerpoint. This package can be found here. Alternatively, many people use knitr::kable() to print out tables on PowerPoint slides. If you want more than basic formatting, you can use the {kableExtra} package, found here to style your kable tables. 38.3.2 Images in Powerpoint You can add a code chunk and create a plot on a slide with code in the code chunk, using fig.width and fig.height chunk options to control the dimensions of the plot. You can include a graphic (picture, other plot, etc.) in a code chunk with knitr::include_graphics(\"path/to/filename\"), with a code chunk like this: knitr::include_graphics(here(&quot;images/echocardiogram.jpg&quot;)) This is often helpful if you have already created your images or graphics, and just need to pull them into powerpoint from a folder. You can use chunk options like fig.width=12 and fig.height=7 to control the size of the image on the slide. Note that if you are using these options frequently, it may be easier to set these globally (for the whole presentation) in the setup chunk, as options in knitr:opts_chunk$set(), rather than in each code chunk. 38.3.3 Plots in Powerpoint Note that plots come in from R to Powerpoint as included graphics. They can be re-sized, but not edited, once they are in Powerpoint. This is good for reproducibility, but if you are still fiddling with your plots, it may be best to save the conversion to Powerpoint until the final version. You can put multiple plots on one slide if you use the {patchwork} package to set them up as a multipanel figure. If you want plots in PPT that are editable (less reproducible, but sometimes handy), you will want to use the {mschart} package, which will output charts in Microsoft format that can be included in PowerPoint slides and will still be editable within PowerPoint. title: “Customizing Plot Scales” author: “Peter Higgins” date: “10/21/2021” output: html_document # install.packages(&#39;tidyverse&#39;) # install.packages(&#39;tidyverse&#39;) # install.packages(&#39;tidyverse&#39;) # install.packages(&#39;tidyverse&#39;) library(tidyverse) ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ── ## ✔ dplyr 1.1.4 ✔ readr 2.1.5 ## ✔ forcats 1.0.0 ✔ stringr 1.5.1 ## ✔ ggplot2 3.5.2 ✔ tibble 3.2.1 ## ✔ lubridate 1.9.4 ✔ tidyr 1.3.1 ## ✔ purrr 1.0.4 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors library(medicaldata) library(webexercises) library(scales) ## ## Attaching package: &#39;scales&#39; ## ## The following object is masked from &#39;package:purrr&#39;: ## ## discard ## ## The following object is masked from &#39;package:readr&#39;: ## ## col_factor indo_rct &lt;- medicaldata::indo_rct "],["adding-citations-to-your-rmarkdown.html", "Chapter 39 Adding Citations to your RMarkdown", " Chapter 39 Adding Citations to your RMarkdown ## Goals for this Chapter install Zotero and its web browser extensions learn how to use the Rmarkdown visual editor to add citations download csl (Citation Style Language) files to format citations for a particular journal style format citations in a particular csl style ## Packages Needed for this chapter You will need {tidyverse}, {medicaldata}, and {rmarkdown}, and an updated version of RStudio (at least version 1.4). If needed, copy the block of code below into your RStudio and run the code to load these packages. You can remove the hashtags from the install.packages functions to install these packages if needed. ## Getting Set Up for Citations You are probably familiar with some sort of commercial reference manager software, which can store and format references for manuscripts. Common products include EndNote and RefMan. RStudio markdown uses an open-source reference manager named Zotero. Zotero is free, and includes (separately) web browser extensions for Google Chrome, Firefox, and several other browsers. These “Zotero connectors” allow you to browse the web to a reference (i.e. browsing in PubMed), and allow you to save the reference to a Zotero library with a single click, without leaving your browser. We will start by downloading and installing Zotero and a web extension. Go to the Zotero web page here and download the most current version of Zotero for your computer system. Zotero download page Installation is straightforward - click on the downloaded file to start the installation process. ### Installing the Zotero Connector It is very helpful to add a web extension plugin to your usual browser in order to make it easier to build libraries of references. Open your favorite browser and search for zotero connector. In Google Chrome, this will take you to the chrome web store, where you can click on the button “Add to Chrome” to install the Zotero Connector. You may have difficulties with Apple Safari 13, as currently (as of November 2021) the ZC extensions work better with Chrome and Firefox. The issue with Apple Safari 13 is expected(?) to be fixed by Mac OS Monterey, available in early 2022. When the Zotero Connector is installed and active, there should be a new icon at the top right of your browser window, to the right of the URL. This is a rectangle with a folded upper right corner, which looks a bit like a dog-eared page of a book. If you don’t see this, you may need to widen your browser window, or make sure that your extension is turned on (go to Manage Extensions) If you hover over this, the pop-up text should read, “Save to Zotero”. ### Registration for Zotero If you choose to register for a free Zotero account, you can log in to get access to 300 MB of cloud reference storage for free. More storage is more expensive, in several tiers, up to the Unlimited plan which is $130 USD per year as of November 2021. This is not entirely necessary, but can be convenient to have a single site for your reference libraries accessible from any computer. ## Building your First Zotero Collection Open the Zotero Application. In the left pane is a listing of your Collections of references. Click on File/New Collection (or right click on My Library) to start a new collection of references. Give it a name related to some area of your research in which you already know a few relevant references. In the example below, I created a Collection for “Severe UC” (ulcerative colitis). This is stored within your My Library folder Zotero collections ## Adding References to Your Zotero Collection Now you can go to PubMed and search for some of your go-to references in this field. ## Inline Code and Caching In the example below, the Zotero Connector is able to sense that this is a reference, and the dog-eared page icon is active in the top right of the web browser (in this case, Google Chrome). If I click on the icon, this reference is saved to my default library (the first listed), or I can use the dropdown arrow to save it to a different library. Switch back to Zotero to see that the reference has been added to your library. Pubmed reference Flip back to Pubmed in the browser, and search for other helpful references, and add them to your collection. Aim for at least 5 distinct references (for now) that we can add to an rmarkdown document. Include one on some sort of methodology that you commonly use, and at least one of your own published articles. When you find helpful references, click on the Zotero Connector icon to add them to your Zotero collection. Pubmed reference ::: tip Tip - you can export your MyBibliography from your Pubmed NCBI page in RIS or BibTeX format, and then import these (Zoetero File/Import) into your My Publications collection in Zotero to have these handy. ::: ## Inserting References into Documents (Rmarkdown) Versions of RStudio 1.4+ are tightly integrated with Zotero, to make citations while you write easier. These are easily created in the RStudio Visual Editor. To use the RSVE, open RStudio. When you have RStudio open, start a new project, with File/New Version Control/Git. Enter this URL: https://github.com/higgi13425/rmd-cite.git. Name the project rmd-cite. Create the project. Now open the file ‘manuscript.Rmd’. Your file will be in the top left pane by default, and there will be an icon at the top right that looks a little like a geometry compass, or possibly more like an Angstrom symbol (if you were chemistry major). Click on this link to make your document more like a word processor, where “what you see is what you get” (WYSIWYG). You can control styles, bold, italic, numbering, etc. from the RSVE menus, which are found in a ribbon below the main Knit menu. You can toggle this visual editor on and off to see the underlying rmarkdown symbols, code, etc. when needed. Now scroll down to the sentence, “Insert the second citation here.” Click between the last “e” and the period to prepare to insert a reference. Click on the Insert menu, and select “@ Citation”. This opens up a window to Zotero. Zotero with Rmarkdown In the left sidebar, select Zotero, then (within the My Library folder) the particular library that you created. Now select the reference that you want to use. Then click the insert button. This will insert the reference into a references.bib file, which is the default bibliography file for each document. RStudio will create a new references.bib file if you don’t have one already. You can also insert citations with the @ toolbar button, or the shortcut Shift-Cmd-F8 (Mac)/ Shift-Ctrl-F8 (Windows). The citation will appear in the text like this: Inserted Reference You can click on the reference to see how it will be formatted in your bibliography. Insert 5 (or more) references into your document in the 5 locations where the text requests a reference. The storage and formatting of references works because of a few settings in the YAML header at the top of the document. The key one is bibliography: references.bib. This tells Rmarkdown where to look for the references for this document, and Zotero by default puts the references in this file (which can be found under your Files tab in RStudio. ### Formatting your Bibliography The default formatting for Rmarkdown bibliographies is the Chicago style. You can choose from many other journal styles, using *.csl files. These Citation Style Language files are available for nearly every journal. You can download new *.csl files for the journals you frequently publish in from the Zotero Style Repository here. Just search for the desired Journal title, and download the *.csl file. Then move this file (copy/paste) from your Downloads folder to the working directory for this project. The *.csl file should be stored in same working directory as your rmarkdown file. You should already have 2 csl files in this directory (so download a different one for variety): gastroenterology.csl the-new-england-journal-of-medicine.csl When this new *.csl file is in place, you can change the bibiography style from the default by adding a line to the YAML header, just below the bibliography: references.bib line. Add a new line just below it with csl: the-new-england-journal-of-medicine.csl to set the format to the NEJM, or csl: gastroenterology.csl to set to the format of the journal Gastroenterology. See the formatting changes when you hover/click the references. Knit the manuscript with each of the csl formats. Now try knitting to the format of the other journal you downloaded. Zotero Search ## Inserting References into Documents (MS Word) Zotero is bundled with a variety of plug-ins for word processors, which are added in the background. If you open your word processor, in this case, Microsoft Word, you will notice that you now have a Zotero tab on the ribbon menu. Zotero in Word Click on the Zotero menu tab, and you will have options to add a bibliography, or a particular citation. Zotero new citation The first time you try to add a citation or a bibliography, Zotero will ask you which journal to use as the default format. It has several examples available as defaults, but you will probably want to add formatting for journals specific to your specialty. You can change this later by clicking on Document Preferences within the Zotero menu. You can select one of the available styles, , click on the “Manage Styles” link below and to the right of the list of Citation Styles. This will bring up the Style Manager window shown below. Click on the “Get Additional Styles” button below the list of Styles. Zotero new styles This opens up the Zotero Style Repository. You can search for the Journal title that you want for your citation format. Once you have the formatting style sorted, you can start to insert footnotes or endnotes. A red search box will open. Start typing a search term, and options in your Zotero collection will pop up. Zotero style repository Click on one or more to select references. Then press the return key to insert the reference into your manuscript. Zotero reference If you like, you can change the formatting of all of the inserted references to a different style by clicking on Document Preferences in the Zotero menu. "],["quarto-is-a-next-generation-rmarkdown.html", "Chapter 40 Quarto is a Next-Generation RMarkdown 40.1 Goals for this Chapter 40.2 Packages Needed for this chapter 40.3 Introducing Quarto 40.4 A Tour of Quarto 40.5 Opening a New Quarto Document 40.6 Annotating code in Quarto 40.7 The Visual Editor vs. Source Editor in Quarto 40.8 Adding Code Chunks 40.9 Organized Options in Code Chunks with the Hash-Pipe #| 40.10 Stating Global Options in Your YAML Header 40.11 Figures 40.12 Tables 40.13 Inline Code and Caching 40.14 Quarto at the Command Line 40.15 Citations in Quarto 40.16 Challenge Yourself 40.17 Exploring further", " Chapter 40 Quarto is a Next-Generation RMarkdown 40.1 Goals for this Chapter introduce Quarto Install Quarto CLI Explore Quarto Features 40.2 Packages Needed for this chapter You will need {tidyverse}, {medicaldata}, {rmarkdown}, {flextable), {gt}, and updated versions of R and RStudio. If needed, copy the block of code below into your RStudio and run the code to load these packages. You can remove the hashtags from the install.packages functions to install these packages if needed. # install.packages(&#39;tidyverse&#39;) # install.packages(&#39;medicaldata&#39;) # install.packages(&#39;rmarkdown&#39;) # install.packages(&#39;flextable&#39;) # install.packages(&#39;gt&#39;) library(tidyverse) library(medicaldata) library(rmarkdown) library(flextable) library(gt) 40.3 Introducing Quarto Quarto is the next-generation version of RMarkdown. RMarkdown grew organically, with many spinoffs (blogdown, bookdown, posterdown), with great creativity. But there was not master plan in mind, and a fair number of hacky workarounds became standard. There was some inconsistency between implementations, there was no command-line interface, the approach was specific to R, and past decisions made some new features impossible to implement. So the folks at Posit (formerly RStudio) decided to rebuild RMarkdown from scratch with a coherent master plan, a command line interface, the ability to use many languages (including Python, bash, Julia, etc.), and pathways to more features that were not possible in RMarkdown. In many ways, Quarto documents (*.qmd) look a lot like rmd documents. There is a familiar YAML header, text and code chunks, formatting with markdown tags, and the ability to use Pandoc to render (instead of knit) documents to a variety of output formats. Let’s take a moment to go to the quarto page. Click on the Get Started button to go to the installation page. Now click on the Download Quarto CLI button to download the right version of quarto for your computer. Note that installing a current version of RStudio will also install the Quarto CLI, but it is not an R package. Installation is straightforward - go to your downloads folder, and click on the downloaded file to start the installation process. Once this is complete, and the original package moved to the trash, you are ready to open RStudio and work with Quarto documents and presentations. 40.4 A Tour of Quarto Quarto is an authoring framework that lets you create a variety of output documents, including HTML, MS Word, MS Powerpoint, and others, from a mix of text and code chunks. You can show (during analysis) or hide (for manuscript) code chunks, and show or hide the output. Quarto is a great way to document your background, analysis, and conclusions. It is also a useful format for collaborating and for code review. Think of it as an analytic notebook that can fold up your code and present results when needed. You can open a New File/Quarto Document, or a New File/Quarto Presentation. Your Document format options are HTML, PDF, or MS Word. The visual editor is on by default, which gives you and WYSIWYG (What You See Is What You Get) environment, like MS Word or Google Docs. You can also switch to the source editor for more control of formatting. 40.5 Opening a New Quarto Document Try this yourself - in RStudio, open New File/Quarto Document, and select HTML as the format. Give it a title and author, then click the Create button. The default document starts with a YAML chunk, which controls the document output and global options, which looks something like this: --- title: &quot;Prostate data&quot; date: 2022-09-12 format: html --- The rest of the document consists of explanatory text and code chunks. The explanatory text can be formatted in the Visual Editor (as in MS Word) or in the source editor with markdown tags for bold, italic, etc. 40.6 Annotating code in Quarto There are many times that you want to annotate code for collaborators or for your future self. This can be a bit clunky if mixed in with the code. Annotation of code can be done more neatly with Quarto. You first add the code-annotations style to the YAML header as shown below (options - below, hover, or select), then add comments as numbers between angle brackets (you can apply the same number to more than one line), then detail the numbers with full comments below the code chunk, as shown below --- # Add to YAML header code-annotations: hover --- library(tidyverse) library(medicaldata) medicaldata::abm |&gt; #&lt;1&gt; mutate(gluc_ratio = csf_gluc/blood_gluc, #&lt;2&gt; wbc_ratio = csf_wbc/blood_wbc) #&lt;2&gt; Take the abm dataset, and then add new columns for glucose and wbc ratio Then, when you hover over the comment number, the text comment is shown. The select option requires clicking the number. This requires at least Quarto version &gt;= 1.3, and when rendered, looks like this (with the annotation markers that you can hover over circled in red in this case): Quarto code annotation 40.7 The Visual Editor vs. Source Editor in Quarto When the Visual Editor is activated by its toggle button, you will see a toolbar at the top of your source pane that looks like this: This allows you to easily apply bold, italic, or code formatting, insert headers of several levels, bulleted or numbered lists, links, images, or tables. The Source Editor toggle button gives you a display that is not as pretty, but it shows all the markdown tags, and gives you finer control of formatting, and looks more like this: ## Text formatting *italic* **bold** ~~strikeout~~ `code` superscript^2^ subscript~2~ [underline]{.underline} [small caps]{.smallcaps} ## Headings # 1st Level Header ## 2nd Level Header ### 3rd Level Header ## Lists - Bulleted list item 1 - Item 2 - Item 2a - Item 2b 1. Numbered list item 1 2. Item 2. The numbers are incremented automatically in the output. ## Links and images &lt;http://example.com&gt; [linked phrase](http://example.com) ![optional caption text](path/quarto.png){fig-alt=&quot;Quarto logo&quot;} ## Tables | First Header | Second Header | |--------------|---------------| | Content Cell | Content Cell | | Content Cell | Content Cell | 40.8 Adding Code Chunks To add a new code chunk, type Cmd/Ctrl + Option + I or choose the green C (chunk) icon at the top right of the source pane (left of the Run button), and select R from the dropdown menu, or you could manually type 3 backticks (```) then {r} alone on a line at the top and then 3 backticks (```) alone on a line at the bottom of the code chunk. Note that you can insert code chunks from a variety of languages. To insert new text, just type plain text, and format as desired with markdown tags or the Visual Editor buttons. You can use the Outline toggle button to turn on or off the outline in the right sidebar of the Source pane. It uses your headings to create a nested outline. 40.9 Organized Options in Code Chunks with the Hash-Pipe #| Previously in Rmarkdown, you could state options for your code chunk after the {r} header, inside of the curly braces. This could get a bit messy and sometimes hard to read. You can now add options to each code chunk with the hash-pipe operator (#|) right after the {r} header, starting on the next line, with one option on each line. This looks something like: Some of the popular options are Options for Code Chunks Option What it Does echo Shows (true) or hides (false) code eval whether or not to evaluate the code and show results label name of the chunk (must be unique in your qmd document) include show chunk and output (true), or just run without any output (often used for the setup chunk to load libraries quietly) fig.width, fig.height sets these, default unit is inches warning whether to show text warnings message whether to show text messages cache Cache and use previous result (true) - helpful if long calculation you don’t want to repeat fig.cap set the figure caption results: hide hides printed output fig-show: hide hides plots All of the possible options for a code chunk can be found here. Code chunks and their outcomes: Option Run code Show Code Output Plots Messages Warnings eval: false N Y N N N N include: false Y N N N N N echo: false Y N Y Y Y Y results: hide Y Y N Y Y Y fig-show: hide Y Y Y N Y Y message: false Y Y Y Y N Y warning: false Y Y Y Y Y N 40.10 Stating Global Options in Your YAML Header 40.10.1 Code Options and Code Folding To add global code options for all code chunks, you can set the execute options in your YAML section to things like echo: false. Note that you need to add a return after execute: to make a new line, then keep the default indent when you add options like eval: false or fig-show: hide. To fold (hide) your code with an option for the user to click on a Code button to see it, set up your YAML chunk at the top of the qmd document with the format: html: option of code-fold: true. Note that this requires the correct line breaks and indents to work. --- title: &quot;Quarto Document&quot; execute: echo: false format: html: code-fold: true --- 40.10.2 Parameters You can also render a quarto document to prepare a report for one subset of your data, and set the key parameter in the YAML chunk. For example, you can run an fuel economy report with a plot only for SUVs, as seen below. --- title: &quot;Report by Vehicle Class&quot; output: html_document params: my_class: &quot;suv&quot; --- #| label: setup #| include: false library(tidyverse) class &lt;- mpg |&gt; filter(class == params$my_class) # Fuel economy plot for `r params$my_class` ggplot(class, aes(x = displ, y = hwy)) + geom_point() + geom_smooth(se = FALSE) 40.11 Figures There are a number of options for controlling figure output. Figure sizing is controlled with: fig-width (width of figure created by R, in inches) fig-height (height of figure created by R, in inches) fig-asp (for aspect ratio - can only specify 2 of width, height, and aspect ratio), the ratio of height to width out-width - often set to 70% of the width of the page and centered with fig.align, out.width = “70%” out-height Other options: fig-cap: “Caption Goes Here” fig-alt: “Alternative text if the image is not shown” fig-align: “center”, or “default”, “left”, “right” layout-ncol: 2 - this creates 2 columns 40.12 Tables Markdown tables can be inserted in the Visual Editor with Insert&gt;Table. You can also generate tables from your data with a code chunk. The default display is what you would normally see in the Console, with minimal formatting. You can pipe any table generated with a code chunk into a package for formatting tables and get much nicer HTML, Word, or PDF tables. The {flextable} package will work for any format, while the {gt} package is excellent for HTML and PDF. The knitr::kable() function will work for converting console output to HTML, and the {kableExtra} package will add nicer formatting. Other packages that can work well with tables include reactable, stargazer, huxtable, tables, and ascii. Here are two examples from the abm (bacterial menintgitis) dataset with flextable and gt, using conditional formatting to highlight high blood band count and low csf glucose. # Flextable medicaldata::abm |&gt; select(csf_wbc, csf_gluc, blood_band_pct, gram) |&gt; arrange(-csf_wbc) |&gt; head(7) |&gt; as_flextable() |&gt; # i is row, j is column bold(i = ~ csf_gluc &lt; 25, j = ~ csf_gluc) |&gt; color(color = &quot;red&quot;, i = ~ blood_band_pct &gt; 5, j = ~ blood_band_pct) .cl-c61031fa{}.cl-c60bb36e{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-c60bb378{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(153, 153, 153, 1.00);background-color:transparent;}.cl-c60bb379{font-family:'Helvetica';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-c60bb382{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(255, 0, 0, 1.00);background-color:transparent;}.cl-c60d43c8{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-c60d43d2{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-c60d53f4{width:0.837in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d53fe{width:0.846in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d53ff{width:1.373in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d5400{width:0.829in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d5408{width:0.837in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d5409{width:0.846in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d540a{width:1.373in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d5412{width:0.829in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d5413{width:0.837in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d5414{width:0.846in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d541c{width:1.373in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d541d{width:0.829in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d541e{width:0.837in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d5426{width:0.846in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d5427{width:1.373in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d5428{width:0.829in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d5429{width:0.837in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d542a{width:0.846in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d5430{width:1.373in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d5431{width:0.829in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d5432{width:0.837in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d543a{width:0.846in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d543b{width:1.373in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d543c{width:0.829in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d5444{width:0.837in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d5445{width:0.846in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d5446{width:1.373in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d5447{width:0.829in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d544e{width:0.837in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d544f{width:0.846in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d5450{width:1.373in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-c60d5451{width:0.829in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}csf_wbccsf_glucblood_band_pctgramnumericnumericnumericnumeric100,000248478,900141150,0004436,0007538432,2002428,000152121,6002001n: 7 You can learn more about the many formatting options in {flextable} here. # gt package medicaldata::abm |&gt; select(csf_wbc, csf_gluc, blood_band_pct, gram) |&gt; arrange(-csf_wbc) |&gt; head(7) |&gt; gt() |&gt; tab_style(style = cell_text(weight = &quot;bold&quot;), locations = cells_body( columns = csf_gluc, rows = csf_gluc &lt; 25)) |&gt; tab_style(style = cell_text(color = &quot;red&quot;), locations = cells_body( columns = blood_band_pct, rows = blood_band_pct &gt; 5)) #euuxvhzazt table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #euuxvhzazt thead, #euuxvhzazt tbody, #euuxvhzazt tfoot, #euuxvhzazt tr, #euuxvhzazt td, #euuxvhzazt th { border-style: none; } #euuxvhzazt p { margin: 0; padding: 0; } #euuxvhzazt .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #euuxvhzazt .gt_caption { padding-top: 4px; padding-bottom: 4px; } #euuxvhzazt .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #euuxvhzazt .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #euuxvhzazt .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #euuxvhzazt .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #euuxvhzazt .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #euuxvhzazt .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #euuxvhzazt .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #euuxvhzazt .gt_column_spanner_outer:first-child { padding-left: 0; } #euuxvhzazt .gt_column_spanner_outer:last-child { padding-right: 0; } #euuxvhzazt .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #euuxvhzazt .gt_spanner_row { border-bottom-style: hidden; } #euuxvhzazt .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #euuxvhzazt .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #euuxvhzazt .gt_from_md > :first-child { margin-top: 0; } #euuxvhzazt .gt_from_md > :last-child { margin-bottom: 0; } #euuxvhzazt .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #euuxvhzazt .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #euuxvhzazt .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #euuxvhzazt .gt_row_group_first td { border-top-width: 2px; } #euuxvhzazt .gt_row_group_first th { border-top-width: 2px; } #euuxvhzazt .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #euuxvhzazt .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #euuxvhzazt .gt_first_summary_row.thick { border-top-width: 2px; } #euuxvhzazt .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #euuxvhzazt .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #euuxvhzazt .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #euuxvhzazt .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #euuxvhzazt .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #euuxvhzazt .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #euuxvhzazt .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #euuxvhzazt .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #euuxvhzazt .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #euuxvhzazt .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #euuxvhzazt .gt_left { text-align: left; } #euuxvhzazt .gt_center { text-align: center; } #euuxvhzazt .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #euuxvhzazt .gt_font_normal { font-weight: normal; } #euuxvhzazt .gt_font_bold { font-weight: bold; } #euuxvhzazt .gt_font_italic { font-style: italic; } #euuxvhzazt .gt_super { font-size: 65%; } #euuxvhzazt .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #euuxvhzazt .gt_asterisk { font-size: 100%; vertical-align: 0; } #euuxvhzazt .gt_indent_1 { text-indent: 5px; } #euuxvhzazt .gt_indent_2 { text-indent: 10px; } #euuxvhzazt .gt_indent_3 { text-indent: 15px; } #euuxvhzazt .gt_indent_4 { text-indent: 20px; } #euuxvhzazt .gt_indent_5 { text-indent: 25px; } #euuxvhzazt .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #euuxvhzazt div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } Total Leukocytes in CSF [count/mm^3] CSF Glucose [mg/dl] blood_band_pct Gram Smear Result 100000 24 8 4 78900 14 1 1 50000 NA 4 4 36000 75 38 4 32200 NA 2 4 28000 15 2 1 21600 20 0 1 You can learn more about the many formatting options in {gt} here. 40.13 Inline Code and Caching You can run R code and place the output into your text. much like Rmarkdown, by placing a single backtick before r and another single backtick after the code needed. For example, you can write out “my two-sided p value is `r 2*(1-pnorm(7, mean = 5, sd = 1.1))`,” which shows the code as written. When this R code between the backticks is evaluated (when you render the document), the resulting p value is shown. This will read: My two-sided p value is 0.0690363. 40.14 Quarto at the Command Line As you work on a *.qmd document (in this case, named document.qmd), you will want to preview it in an adjacent browser window. You can do this at the command line (Terminal in Mac, Run cmd in Windows) with quarto preview document.qmd --to html for the html version, or quarto preview document.qmd --to docx for the Microsoft Word version. To render your saved qmd document from the command line, you can use with quarto render document.qmd --to html for the html version, or quarto render document.qmd --to docx for the Microsoft Word version. The render commands will produce a final document. 40.15 Citations in Quarto Citations in Quarto work much like they do in Rmarkdown. In the Visual Editor, you can use Insert&gt;Citation. You can enter a DOI (Digital Object Identifier), pull a reference from a Zotero library, pull references with PubMed IDs, or get references from a bibliography file (a *.bib file in the same directory as your document). If you add a citation using one of the first three methods, the visual editor will automatically create a bibliography *.bib file for you and add the reference to it. It will also add a bibliography field (required to identify the file) to the document YAML. As you add more references, this file will get populated with their citations. When Quarto renders your file, it will build and append a bibliography to the end of your document. The bibliography will contain each of the cited references from your bibliography file, but it will not contain a section heading. As a result it is common practice to end your file with a section header for the bibliography, such as # References. You can change the style of your citations and bibliography by referencing a CSL (citation style language) file (with the full path to the file) in the csl field in the YAML header. bibliography: my_bibliography.bib csl: R/csl_files/gastroenterology.csl You can find many journal bibliography styles (and download them) at https://www.zotero.org/styles or https://github.com/citation-style-language/styles. 40.16 Challenge Yourself Create a new Quarto Document, and do a simple analysis of one of the {medicaldata} datasets with code chunks that generate a table and a figure, and add some text about your conclusions. Add some header text for the different sections. Try rendering this document (separately) to both HTML and MS Word. Experiment with the visual editor and the source editor. Insert a code chunk, a citation (try this DOI - 10.1016/j.cgh.2021.05.038), a table, and a horizontal line. Toggle back and forth to compare WYSIYG to markdown tags. Render the document and peek at the YAML and the end of the document to see how it handles the citation. With a quarto document open, toggle the Outline button at the top right of the Source pane, and see how your heading text becomes a nested outline. Experiment with the code chunk options in section 34.9, and render the chunks to see what the different options do. Take a code chunk that generates a plot, and experiment with the figure options in chapter sections 9 and 11. Render the document, and see if you get the output you expected. 40.17 Exploring further The Quarto Getting Started Tutorials found (in left sidebar) here The Quarto Chapter in R for Data Science. The Quarto website is the definitive reference here "],["cmd-line.html", "Chapter 41 Running R from the UNIX Command Line 41.1 What is the UNIX Command line? 41.2 Why run R from the command line? 41.3 How do you get started? 41.4 The Yawning Blackness of the Terminal Window 41.5 Where Are We? 41.6 Cleaning Up 41.7 Other helpful file commands 41.8 What about R? 41.9 What about just a few lines of R? 41.10 Running an R Script from the Terminal 41.11 Rendering an Rmarkdown file from the Terminal", " Chapter 41 Running R from the UNIX Command Line 41.1 What is the UNIX Command line? The command line is a very basic Terminal window with a prompt at which you can type commands, And do primitive but powerful things to your files. The UNIX computing environment was developed in the 1960s, and is still beloved and fetishized by brogrammers, who believe you are not truly a programmmer if you can’t code from the command line. This is silly. The major attraction to UNIX in the 1960s is that it was much better than punch cards. Which isn’t saying much. We have had 60 years of software advancement and user interface improvements, so we (most of time) should not have to put up with the inherent user hostility of the UNIX environment. UNIX is an early operating system, which is built around a ‘kernel’ which executes operating system commands, and a ‘shell’ which interprets your commands and sends them to the kernel for execution. The most common shell these days is named ‘bash’, which is a silly recursive brogrammer joke. You will sometimes see references to shell scripts or shell or bash programming. These are the same thing as command line programming. UNIX is a common under-the-hood language across many computers today, as the Apple iOS is built on top of UNIX, and the various versions of the LinuxOS are built on a UNIX-like kernel, with a similar command shell. The command line is often the least common denominator between different pieces of open-source software that were not designed to work together. It can occasionally be helpful to build a data pipeline from mismatched parts. However, there is a lot of low-quality user-hostile command line work involved to get it done, commonly referred to as “command-line bullshittery”. This is a common bottleneck that slows scientific productivity, and there is a vigorous discussion of it on the interwebs here and here (a counterpoint). Essentially, some argue that it is largely a waste of time and effort, while others see it as a valuable learning experience, like doing least squares regression by hand with a pencil. Running R from the command line is a bit like spending a day tuning your car’s engine by yourself. There is a case to be made that this will improve the efficiency and performance of your car, but it is also usually more efficient to pay someone else to do it, unless you are a car expert with a lot of free time. 41.2 Why run R from the command line? You can run R from the command line. It has none of the bells and whistles, nor any of the user conveniences of the RStudio Interactive Developer Environment (IDE). But it is how R was originally expected to be used when it was developed back in 2000 in New Zealand. Running R from the command line allows you to do powerful things, like process multiple files at once, which can be handy when you have multiple files of sequencing data from distinct observations, or you have a multistep data wrangling pipeline with several slow steps. For many years, this was the only way to easily apply code across multiple files to build a complex data pipeline. This is much less true today, with tools to handle file paths like the {here} and {fs} packages, run Python scripts from R with the {reticulate} package, run C++ scripts with Rcpp, and run bash, python, SQL, D3, and Stan scripts from Rmarkdown. You can use the {targets} package to manage multi-step data pipelines in different languages (similar to make). But some labs have been doing things at the command line for years, and find it hard to change. 41.3 How do you get started? First, you need to open a terminal window. And to do that, you need to find it. This is akin to getting under the hood of a car, and computer makers don’t exactly encourage it. 41.3.1 On a Mac Go to Finder/Applications/Utilities/Terminal 41.3.2 On a Windows PC Go to Applications/Terminal 41.4 The Yawning Blackness of the Terminal Window So, you have managed to open a terminal window, which has a standard UNIX prompt, ending in something like % or $. Not terribly helpful, is it? The bash shell is waiting for you to enter a command. No user interface for you! Let’s start with a introductory command, which can’t do any harm. Run the command below: whoami whoami ## peterhiggins Remember that UNIX started out as an operating system for terminals, and knowing who was logged in was a helpful thing, especially if the person logged in was being charged for mainframe time by the minute. You can string together two commands with a semicolon between them. Try the following: whoami;date ## peterhiggins ## Sat Apr 12 13:51:35 EDT 2025 OK, fine. This is sort of helpful. It was really important when you were on a terminal and paying by the minute for time on a mainframe back in 1969. And, on occasion, if you will need to use an entire computer cluster to run a script (or scripts) on a lot of data, you will likely have to use some of this command line knowledge. You can even schedule jobs (scripts) to run when your time is scheduled on the cluster with cron and crontab. At this point, it would be helpful to open a window with your Documents folder, and keep it side by side with the window in which you are reading this e-book. We will start working with files and directories, and it is helpful to see changes in your file/folder structure in real time. As we run commands in the bash shell, check them against what you see in the folder window. You may find that some files (dotfiles, starting with a period) are hidden from the user to prevent problems that occur when these are deleted. 41.5 Where Are We? OK, let’s start looking at files and directories. Start with the pwd command, which does not stand for password, but for print working directory. Run the code below in your Terminal window. pwd ## /Users/peterhiggins/Documents/RCode/rmrwr-book You can see the full path to your current directory. This can be a bit obscure if you are just looking at your folder structure, particularly at the beginning of the path. Fortunately, the {here} package handles a lot of this for you when you are working in Rstudio projects. We think of the directory as a tree, with a root - in this case, Users, and various branches as you build out folders and subfolders. We can move up and down the folders of the directory paths with the cd command, for change directory. Try this command in your Terminal Window, and see if you can figure out what it does. cd .. cd .. changes the directory up one level closer to the root directory. Note that there is a required space between cd and the ... You can also go directly to the root directory with cd /. It is straightforward to go up the directory tree, as each folder only has one parent. But it is tricky to go down the directory tree, as there are many possible branches/children, and you do not inherently know the names of these branches. We need to list the contents of your current directory with ls to know what is there. Try the ls command in your Terminal window cd /Users/peterhiggins/Documents/; ls ## (19) Higgins-Peter_Efficacy-and-Safety-of-Upadacitinib-recorded.mp4 ## (19) Higgins-Peter_Efficacy-and-Safety-of-Upadacitinib-recorded.pptx ## (19) Higgins-Peter_Efficacy-and-Safety-of-Upadacitinib-with-BackupBioIR.pdf ## (19) Higgins-Peter_Efficacy-and-Safety-of-Upadacitinib-with-BackupBioIR.pptx ## 1FQ_Crohn&#39;s Disease_23Oct2020 (002).doc ## 2 - AbbVie UC Core - Unmet Need_C2 (14) 738 PM ET.pptx ## 2 - AbbVie UC Core - Unmet Need_C2 (14) 954PM ET.pptx ## 2 - AbbVie UC Core - Unmet Need_C2 (7) Dr. H_PDRH_15Nov.pptx ## 2 - AbbVie UC Core - Unmet Need_C2_PDRH_29Sep.pptx ## 2012 resubmission ## 2020-Jun-05 AGA IMIBD meeting notest.docx ## 2020_Higgins_ClinResIBD_biosketch.doc ## 2021 AGA Invited Speaker Session Basic Hybrid Example.pdf ## 2021-07-13_Higgins_WH_signed_letter.docx ## 2021.Biobanking Program_InVivo_DRAFT-6.14.2021.docx ## 2021.Biobanking Program_InVivo_PDRH-6.21.docx ## 2021.Higgins AGA Distinguished Clinician.CO.docx ## 2022.10.19_MH_CCC_V2_PDRH.docx ## 203ClareScenes080119 copy.pdf ## 26NovEdits PDRH_Databank_Protocol v7_14Nov2016_Clean_.doc ## 2PM talks ## A Disease Monitoring Smart Set_PDRH.pptx ## A is for Allspice.2.0.docx ## A is for Allspice.docx ## ABT combo proposal Bcl2:JAK ## ABT263_HIO_report_toWord.docx ## ACG U-ACHIEVE and U-ACCOMPLISH.docx ## ACG abstracts ## ACG21_P19_Efficacy and Safety of Upadacitinib Induction Therapy in Patients With Moderately to Severely Active Ulcerative Col_vSub.pptx ## ACG_slideformat_ACG22_White_Background.pptx ## ACLS eCard Peter Higgins.pdf ## AGA DDW 2021 ## AGA IMIBD ## AGA IMIBD Councilor Career Discussion Guide.docx ## AGA IMIBD Webinar Outline.docx ## AIBD CAM Higgins.pdf ## AIBD CAM Higgins.pptx ## AIBD SoMe Higgins.pdf ## AIBD SoMe Higgins.pptx ## AIBD agreement.docx ## AIBD20Template.pptx ## AJGeditorial w Fletcher MRI 2015 ## AMAG DDW Clear draft_PDRH comments.docx ## APG1244_Milestone_report.docx ## ARead_RAC-Review_PHiggins.docx ## AS Propsal outline.docx ## ASUC_UC_protocol_comments_2020.docx ## ASatishchandran Propsal outline.docx ## AXL_Helmsley_pre-proposal_Higgins.docx ## AXL_fibrosis_Nov_2021.pptx ## A_Woodward_Score Sheet_PDRH.docx ## AbbVie_Contract_2021_K000013379_-_Peter_Higgins.pdf ## AbbVie_Contract_K000013378_-_Peter_Higgins_2021_adhoc.pdf ## Abbott PtVideo 2010 Grant App ## Abbott Talks ## Abbvie 2021.xlsx ## Abbvie_DocuSign_Dr_Higgins_Invoice.docx.pdf ## Abstract examples ## Accounts and Access (1) (1).docx ## Advice for participants in webinars.docx ## Advice for young mentors.docx ## Animation of NSAID.pptx ## Apple Pie Day 1.docx ## Apple Pie Day 2.docx ## Apple Pie Filling Nov 2024.docx ## Apple Pie ingredients.docx ## Applicant Research Design Task T32.docx ## Applying for Fellowship in Gastroenterology and Hepatology.docx ## Ashley_Simone letter rec.docx ## Autoimmune Summit.pptx ## Awais Chapter Stenosis ## B2. US Accomplishments.docx ## B4_IBD_pdrh.docx ## B4_IBD_pdrh.pdf ## BKochar_Frailty.pdf ## BM recommendation.docx ## Base R Notes.docx ## Beginners_GuideToR.pdf ## Best Practices Perils Excel ## Big data with Arrow and DuckDB with cameo.pptx ## Big data with Arrow and DuckDB with demo.pptx ## Big data with Arrow and DuckDB.pptx ## Biorepository rebuttal for P30 Core.docx ## Biosketch for K.pptx ## Biosketch_2020_Higgins_ClinResIBD_biosketch.doc ## Book1.csv ## Brazil 2015 ## Brazil.ItineraryNov2015.docx ## Butter BCS Chicken.docx ## CADHUM ## CAS.K.candidate.background_SB_PDRH.docx ## CAS.T32.Project.Description-JS.docx ## CAS.career.goals.obj.development.training_PDRH.docx ## CB6 and JAK_stat.pptx ## CB6 manuscript YF.docx ## CC360_The Risk of SARS.R1.docx ## CC360_The Risk of SARS.docx ## CCC_AZ_UC Case 1_COMPLETE.pptx ## CCF IBD Webcast 2020 Draft Deck_For Review.pptx ## CCFA EIC Candidate Interview Questions (candidates) jobin[1].doc ## CCFA Microbiota grant ## CCFA Reviewing ## CCFA SRA Microbiome 2011 ## CDC_proposal1.1.docx ## CIMI revise ## CLARE STOCKS.docx ## COVID Trials Feasibility ## COVID_MPox_P2PEP22.pptx ## CTSU Protocol Checklist_v1_PDRH_Jan2022.docx ## CU104 UC Synopsis v0.4 15Nov2022_PDRH.docx ## CYSIF.pdf ## CalenK08referenceLetter_PDRH_2023.docx ## CalenK08referenceLetter_PDRH_2023.pdf ## CaltechCampus Tour &amp; Information Session.webarchive ## Cancel Appt Epic.ppt ## Causal.png ## CellDeath_DDW_2021_ISS.pdf ## Chat and links from R.docx ## Chu RPG Review_PDRH.docx ## Clare Higgins Final ## Clare Investment Summary.docx ## Cleaning Medical Data.docx ## Cleveland.2010Trip ## Clinical Coordination and Intense Proactive Monitoring to Improve Utilization of Resources and Reduce Expenditures in High.docx ## Clinical Research Alliance ## Closing remarks.docx ## Copy of Crohns Colitis Congress 2023 Pediatric Session Agenda 07.17.2022_pdrh.xlsx ## Council Conversations Author Chat Guide.docx ## Coursera_Programming in R Notes.docx ## Cover Letter.docx ## Cover Letter.pdf ## CoverLetterPlus.pptx ## Crash&amp;Burn_ScriptV2_100318 copy.pdf ## Curacle CDA Higgins_20221011.docx ## DDW 2012 MTP Immunomodulator Talk ## DDW 2022 AGA Space Grid.xlsx ## DDW 2023 Fibrosis Talk.pptx ## DDW 2023 SoMe Talk- hellhole section.pptx ## DDW 2023 SoMe Talk.pptx ## DDW JAK for UC.pptx ## DDW2014SD16 ## DDW2021 CB6 powerpoint-2.pptx ## DDW2021_CB6_Antifibrotic_Higgins.pdf ## DDW21_JAK_Higgins.pdf ## Data workflow resources.docx ## DataCamp Courses by Topic.docx ## DeEscalationACG2016.pptx ## Demographics.pdf ## Documents ## Documents.Rproj ## DrHiggins IBD Data Request.xlsx ## Draft Postop IBD Surgery Care Protocols v2_SERedit.docx ## ECCO 2016 Amsterdam Schedule.docx ## ECCO 2019 UC PRO SS Abstract D1f_JP_UA_YO_AM_PDRH.docx ## ECCO 2022 UPA-UC Ext ind resp abstract_29Oct2021_PDRH.docx ## ECCO 2022 abstract^LN2 UPA-UC P3 Disease DurationExtent_v3.0_18Oct2021_PDRH.docx ## ECCO IHA3 ## ECCO2016Lycera30937.pptx ## EDI statement.docx ## EDI statement.pdf ## Editing your Rprofile.docx ## Efava.pptx ## Effect of medications on the recurrence of cancer in IBD patients.docx ## Electrical engineering interview questions.docx ## Employee Evaluations ## Endpoints in IBD talks ## Europe Talks ## Exploring Docker.docx ## FCP Sensor proposal draft.docx ## FDAtofaResponse.docx ## FFMI Kickstart-FinalReport 5-20-16-LJ.docx ## FITBITProtocol_28NOV2016_AbbVie.docx ## FITBITProtocol_4DEC2016_AbbVie.docx ## FMT_DDW_2021_ISS.pdf ## Faculty CV Review PPB Nov 2023.docx ## Faculty CV Reviewer Template_PDRH.docx ## Faculty Covering Kinnucan Inbox.xlsx ## Falk Symposium Miami 3.09 ## Feasibility and Pilot Studies.pptx ## Feb2021_ibdTrials.pptx ## FellowshipRec_Janson Jacob_Higgins_JB.docx ## FellowshipRec_Janson Jacob_Higgins_JB.pdf ## Fibrosis ## Fibrosis Symposium ## Fibrosis lab talks ## FibrosisIBDCedars2016.pptx ## Figures for PractGast_Higgins_ASUC_2023.pptx ## Figures-KC-JAMA.pptx ## Finance and Retirement Plans.docx ## Financial Priorities.docx ## Flexdashboard notes.docx ## Future_IBD_P2PEP22.pptx ## GCPcitiCompletionReport8018282.pdf ## GI T32 Competitive Renewal FINAL 05242017.docx ## GREAT3 slides ## Garmin Notes.docx ## General Social Media Tips.docx ## General format for Chapters in RMRWR.docx ## General thoughts about query letters.docx ## Getting Started with REDCap.docx ## Gibson-Doherty_Editorial_2020_Article_FastAndCuriousAnAlgorithmicApp.pdf ## Gibson_accel_IFX.pdf ## Git Fork and branch workflow.docx ## Git for MDs_2.pptx ## GitHub ## Github for MDs_1.pptx ## Github for MDs_3.pptx ## Glover_RPG_Review_PDRH.docx ## GoToMeeting Chats ## Govani2020_Article_UseOfAcceleratedInductionStrat.pdf ## GradPartyHigginsInvites.xlsx ## GrandRounds ## HPI-5016 IBD Patient Contact Info.xlsx ## HS movie.docx ## Helmsley Application Nov 2023.docx ## Higgins AGA Webinar Slides.pptx ## Higgins Bio.docx ## Higgins Biosketch 2022.docx ## Higgins New IBD.pptx ## Higgins Other Support 2021-2.docx ## Higgins Other Support 2021.docx ## Higgins Other Support.docx ## Higgins Refractory Proctitis.pptx ## Higgins biosketch2015KRao.doc ## Higgins biosketch2016KRao.doc ## Higgins-Peter_Efficacy-and-Safety-of-Upadacitinib-recorded.mp4 ## Higgins-peter.jpg ## HigginsACGMidwest2019_PerioperativeIBD.pptx ## HigginsP_FY22_CY21 Faculty Eval_pdrh.docx ## HigginsPeter_ CY 2022 Faculty Evaluation .docx ## Higgins_ACG2021.docx ## Higgins_Annual_Review_2024.docx ## Higgins_Assessment_Promotion_AReinink_letterhead_sig.docx ## Higgins_Assessment_Promotion_AReinink_letterhead_sig.pdf ## Higgins_IBD_AtoZ.pptx ## Higgins_LOS_IBDBiobank_Shah_Nusrat_2019.docx ## Higgins_LOS_KNewmanAGA_PDRH.docx ## Higgins_LOS_KNewmanAGA_PDRH.pdf ## Higgins_LOS_KNewmanF32_letterhead_sig.docx ## Higgins_LOS_KNewmanF32_letterhead_sig.pdf ## Higgins_Peter-The-Janus-Kinase-Inhibitors-Two-Faces-for-Efficacy-and-Safety.pptx ## Higgins_UM_CME_Pregnancy in IBD.pptx ## Higginslab server.pptx ## Histosonics article MLive 2023 .docx ## How To Assign PRO questionnaires - Inpatient ASUC.docx ## How To Log in to IBD Server.docx ## How To Log in to RStudio Server for HigginsLab.docx ## How To Log in to RStudio Server for Shiny.docx ## IBD 2020 - Honorarium reimbursement Form.docx ## IBD Biobank Cryostor.pptx ## IBD Center presentations ## IBD Clinical Chief Position.docx ## IBD Clinical Trials for MDsDearborn2017.pptx ## IBD Databank Talks on the Road ## IBD House Call and Readmission Data .xlsx ## IBD Insurance Pilot Results.docx ## IBD Insurance Survey for CCFA Partners Existing.docx ## IBD J Club Miri extended induction.pptx ## IBD J Club Tofa in TNFexp.pptx ## IBD Jclub Nov22 Cyclo_Vedo ASUC.pptx ## IBD Journal Club 13Feb2017.docx ## IBD Journal Club July 11.docx ## IBD Options.pptx ## IBD Osteoporosis 1 27 2022_PDRH.docx ## IBD Plexus meeting 21 Sep 2015 notes.docx ## IBD School ## IBD School 322 Script.docx ## IBD School 324 Script.docx ## IBD School 325 Script.docx ## IBD and biologics tweets.docx ## IBD in 20 years.pptx ## IBD inbox coverage.docx ## IBD video scripts ppt ## IBDInsuranceSurvey3.docx ## IBDMentoringConferenceCall4AbstractsPH.docx ## IBDSkinCa Copy.Data ## IBD_Deescalation_Apr_2019_PDRH.docx ## IBD_Endo_PDRH.docx ## IBDforLansing2017.pptx ## IMG_0006.jpg ## IMG_0008.jpg ## IMG_1523st.jpg ## IMIBD Councilors 2020-21.docx ## IMIBD Partners insurance 2020DDW.pptx ## IMIBD Plenary Intro.pptx ## IMIBD_expanded_descriptors.xlsx ## INTERNAL_BUDGET_Abbvie_Nav_Rux_Sept_2021.xlsx ## Ideas for CTA Phase 2.docx ## Image functions target.ai ## Image functions target.png ## Introduction to Application Supplement Photoacoustic.docx ## Invoice 401 to Buhlmann.docx ## Invoice 401 to Buhlmann.pdf ## Invoice AV50559_Abbvie_PDRH_Dec2021.doc ## Invoice AV50559_Abbvie_PDRH_Dec2021.pdf ## Invoice_6.2.22_AV53797_PDRH.docx ## JAK_DDW_2021_ISS.pdf ## JAMA Review on CD.docx ## JAMA.CD.Highlights_PDRH.docx ## JAMA_KC_Second JAMA.docx ## JAMA_Review_on_CD_Revisions_Tracked_Changes with edits_PDRH.docx ## JB_V1 Career Goals and Objectives 7.8.2020_PDRH.docx ## JB_V10 K23 Running Document.docx ## JB_V2 Candidate’s Background 7.7.2020_PDRH.docx ## JDix_Study_update.docx ## Jessica Sheehan Rec Letter Fellowship.docx ## Jessica Sheehan Rec Letter Fellowship.pdf ## Jessie Pfizer materials.docx ## Jessie Sheehan Projects ## Jordan_MH_Slides[72] - PDRH.pptx ## Jun2021_ibdTrials [Autosaved].pptx ## Jun2021_ibdTrials.pptx ## Jun2023Vacation.docx ## K Award Institutional Letter of Commitment.pptx ## K Candidate Section.pptx ## K105_Melmed_PROs in Practice_MB_bb_JLS.pptx ## K23 Aims - Shirley Cohen-Mekelburg 11.14.19.docx ## K23_morph_measurements_MockupManuscript_21JAN2019.docx ## KCRN Higgins Consulting Agreement for Curacle 7Oct2022.docx ## KP pdfs ## K_R_NIH_biosketches_2022.pptx ## Kelli Porzondek_Performance_Review_Sep_2021.docx ## LASSO.pptx ## LOI for CSI for RMed.docx ## Learning R discussion Jeremy Louissaint.docx ## Letter to Frank Hamilton.docx ## Letter_KNewman_K_MentorKamadaHiggins_PDRH_NK.docx ## Library ## Lin_Reviewer Score_PDRH.docx ## Links to drop during talk.docx ## Links to publications of Peter DR Higgins with AbbVie since 2020.docx ## List of Useful R Packages.docx ## LoR for Vitchapong Observer.doc ## LoR for Vitchapong Observer.pdf ## Log in to IBD Server.docx ## Low Enrollers ACD.xlsx ## MCTSU QC Time to Activation (002).pptx ## MDOutReachIBDSlides ## MEI_2020_PH_W9.pdf ## MEI_2021_PH_W9.pdf ## MEI_2021_W9.pdf ## MEI_2022_PDRH_W9.PDF ## MEI_ACH_Wire Transfer Form.docx ## MEI_W9_2024.pdf ## MIM-TESRIC PROTOCOL_Higgins_14Apr2020.docx ## MIM-TESRIC PROTOCOL_Higgins_26Aug2020.docx ## MM letterhead UMICH.docx ## Machine Learning Seville ## Managment of CD.pptx ## Manuscript v1.docx ## Manuscript v2.PDRH.docx ## McDonald, Nancy.pdf ## Megan McLeod Rec Letter Residency.docx ## MentoringAgendaDraftPH.docx ## Mertens_GUILD_LOR_PH.docx ## Mertens_GUILD_LOR_PH.pdf ## Meta analysis TB vs CD version 3.5.docx ## Michigan Medicine Gastroenterology Social Media Initiative.docx ## Michigan Medicine Model for COVID-19 Clinical Trial Oversight DRAFT (KSB 04.17.20)-AL-PDRH.docx ## Microbiota Forceps ## Microsoft User Data ## MultidisciplinaryIBDClinicPHv2.docx ## NoStairs.docx ## NordicTrackTC9iTreadmillManual.pdf ## Noro paper ## Notes on Spatial data workshop.docx ## Oct2019payPDRH.PDF ## Odd college lists.docx ## P Singh K grant aims 8-25_PDRH.docx ## P2PEP slide 2020 ## P2PEP slide 2020.pptx ## P2PEP2021_IBD_COVID.pptx ## P2PEP2021_Intro.pptx ## P2PEP2021_Spatial.pptx ## PDRH endowed chair bio.docx ## PDRH short bio.docx ## PHcv2019.docx ## PHcv2020.docx ## PHcv2022.docx ## PHcv2022.pdf ## PRO agenda videos VINDICO.docx ## PRO letter.docx ## PROs and Endpoints ## PS_K grant aims 6-25_PDRH.docx ## PTM LOS From PDRH.docx ## PTM LOS From PDRH.pdf ## Package List recruit ## Pain in IBD.pptx ## Patient Reported Outcomes Plan.docx ## Pearson 5 Notes.docx ## Ped trial draft.docx ## Perils of Excel.pptx ## Personal statement version 3!.docx ## Peter Higgins 2021 Vision Statment for the NSAC.docx ## Peter Higgins_Annual_Review.docx ## Peter_Higgins_photo_headshot.jpg ## Pfizer_Contract_for_Peter_Higgins_-_RD-20-D11.pdf ## Pictures ## Pie crust recipe.docx ## Pitch Letter - S is for Saffron.docx ## Pitching Notes.docx ## Poppy Eulogy backup.docx ## Poppy Eulogy.docx ## Possible Eastern College Tour.docx ## Powerpoint ## Prashant Rec Letter.docx ## Prashant Rec Letter.pdf ## PredictingIBD_DDW_2021_ISS.html ## PredictingIBD_DDW_2021_ISS.pdf ## Prj21015 UPA UC Other PROs manuscript D1 jp_JOL wz-di_JT_PDRH.docx ## Proposal for MCTSU Study Accrual Monitoring.docx ## PtEdOnRoad ## Purdue Disclosure Form_Higgins.docx ## Pyoderma Case ## Question 16.docx ## Quiros SRA- Higgins LoS draft_PDRH.docx ## Quiros SRA- Higgins LoS draft_PDRH.pdf ## R-medicine2024 sponsor prospectus text.docx ## R01 Fibrosis 2012 ## R01 ML revision ## R01 MachineLearn2010 ## R01.US.Revision ## RAC Update form.docx ## RCode ## RMRWR chapters.docx ## RMed 2023 Meeting 15 Mar.docx ## RMed21- Intro to Spatial.pptx ## RMed21-Opening remarks Day 1.pptx ## RMed21-Opening remarks Day 2.pptx ## RPPR Checklist .docx ## R_Medicine 2023 - Friday intro slides.pptx ## R_Medicine 2023 - Thursday intro slides.pptx ## R_Medicine 2024 - Friday intro slides.pptx ## R_Medicine 2024 - Thursday intro slides.pptx ## Ramp up clinical research_PH.xlsx ## Ramping up human subject research - MM 6-1-20 _KDA_PDRH_suggestions.docx ## Rec_Letter_Simone_Ashley.docx ## RecipeTin Lentil Chickpea Coconut Curry.docx ## Recordings ## Regueiro Chapter ## Reply_JAMA_Thiopurines.docx ## Research Statement.docx ## Research Statement.pdf ## Review Criteria for COVID Clinical Trials.docx ## Review guidelines_2017.docx ## Rice recipes ## Roasted Salted Cashews.docx ## Ryan CDA ## Ryan K ## S is for Saffron 3.0.docx ## S is for Saffron 3.1.docx ## S is for Saffron 3.2.docx ## S is for Saffron.2.0.docx ## SAINI-LOK-HIGGINS_T32 GI Fellowship Research Presentation 08292021.pptx ## SCM Mentor Letters.docx ## SDOH.png ## SEAN STOCKS.docx ## SIG_Template_IBD Program_FINAL.docx ## SOP for Samples for IBD Biobank.docx ## SPECIFIC AIMS 2_PDRH.docx ## SPir abstract 2700 ## Scanner pictures ## Scheduling Epic Schedule.pptx ## Scheduling Epic Schedules.pptx ## Scoring Sheet Ames_pdrh.docx ## Scoring Sheet_Albin_PDRHiggins.docx ## Scoring Sheet_Hayek_pdrh.docx ## Scoring Sheet_Janda_PDRHiggins.docx ## Screenwriting Contests.docx ## Sean Common App academic honors list.docx ## Sean Common App activities list.docx ## Sean Higgins Bordogni.mp4 ## Sean Higgins Brag Sheet.docx ## Sean Investment Summary.docx ## Sean Resume Tabular VBorder.docx ## Sean Resume Tabular.docx ## Sean Resume.docx ## Sean Summer Priorities 2016.docx ## Seattle Talk Dec 2012 ## SecureIBD.pptx ## Severe UC protocol ## SevereUC_Tofa_Presentation_IBD_Forum.pptx ## SevereUC_Tofa_Presentation_Pfizer.pptx ## Shail CT ## ShareRmd.html ## Sheehan Pfizer IBD Fellowship.docx ## Sherman Prize Nominee Questions.docx ## Shoreline West Tour Information.docx ## Short PA slides.pptx ## Shotwave thread.docx ## Should we accel IFX - survey.pdf ## Signing Clinical Research Infusion Orders.pdf ## SingleCell_DDW_2021_ISS.pdf ## SkinCancer.IBD.Gentics_Yanhua_PDRH.docx ## Slade UC review Walter ## SoMe_use_2020.png ## Social Media for GI.pptx ## Soulfege t shirts ## Source Code PT1.docx ## Specialty Pharmacist Referral Process_11162021.pptx ## Specific Aims.pdf ## Stairs.docx ## Stelara paper.docx ## Stelara paper_revised_PDRH_KCC.docx ## Structure of Aim 3.docx ## Surgery Topics ## Surveys ## T32 Competitive Renewal 2017 FINAL WM.pdf ## T32 Fellowship Annual Orientation 2022.pptx ## T32 summary statement.pdf ## T32_current_text_14June2019.docx ## TOPPIC ML draft v5SCM_YL_AKW_PDRH.docx ## TabaCrohn IBD J club.docx ## Tables.docx ## Taiwan talks ## Takeda Grants_Letter of Request_IBD School Videos_Medication Series_2018_.docx ## Takeda_IBD School Videos_Submission.pdf ## Task List 2020-2.docx ## Task List 2020-5.docx ## Task List 2020.docx ## Task List 2021.docx ## Task List 2022.docx ## Task List 2024.docx ## Tenure Plan ## Testing signatures with Adobe.pdf ## The Innovative IBD Center.docx ## The Risk of SARS.R1.Markup.docx ## Thiopurine talks Manitoba 2011 ## Thiopurines talks Vandy ## Tidymodels.docx ## Timelines for K submission.pdf ## Timelines for K submission.pptx ## Tips for Submitting DDW Abstracts for 2022.docx ## Tofa Inpatient ## Tofa in ICI Figure Legends_Final Draft_V2.docx ## Tofa inpatient induction Protocol_02NOV2018_PHforEdits.docx ## Tofa_Presentation_2_10_2021.pptx ## Toffee Separation Tips.docx ## Topics to Discuss with Bill.docx ## Trip to Hawaii 2023 GUILD.docx ## UC CD Impact Manuscript Tables__19Feb2021_PDRH.docx ## UC and CD Impact Manuscript_Draft 2_9Jan2022_PDRH.docx ## UC and CD Impact Manuscript_Draft1_19Feb2021_PDRH.docx ## UC2.jpg ## UCB Pt video 2010 Grant App ## UCRx_DDW_2021_ISS.pdf ## UC_protocol_comments_2020.docx ## UEGW 2010 ## UEI stidham files ## UM IBD Clinical Trials IBD referral form.docx ## UM Severe UC Protocol.docx ## UM Severe UC Protocolv3.0.docx ## UPA_U_ACHIEVE 1st draft_PDRH.docx ## US_R01 outcomes I.1.docx ## US_R01 outcomes I.1_Dillman.docx ## Untitled.docx ## Upa ASUC Concept Page.docx ## Upa IBD J Club.pdf ## Upa IBD J Club.pptx ## Upa M14-234 SS3 maintenance Q and A ECCO 2022.docx ## Upa outpatient vs Prednisone_PDRH.docx ## V8 Infliximab Outcomes_PDRH.docx ## VINDICO IBD ## VINDICO_PRO.pptx ## VideoVisitSchedulingQuickApptsforProviders.pdf ## VincentChen_K specific aims 2020-10-25.docx ## VirtualPtEdMar2020.v2.pdf ## Walk Letter of Reference.docx ## Walk Letter of Reference.pdf ## WebEx ## Wedding Dance Songs.docx ## Weekly Clinical T32 Seminar 2023.docx ## Why not excel.docx ## Zoom ## Zwift ## Zwift-Gift-Card.pdf ## aga institute council july 2020 meeting.pdf ## algorithms_thiopurine.pdf ## base-r-cheatsheet.pdf ## biomakers_fibrosisPDRH.docx ## blue_down_arrow - Gravit Designer.html ## bmj_imputation.pdf ## bowel disease_2108_PDRH.docx ## ccf_verily.docx ## cgh_factors_utilization.pdf ## clare_stocks_long_term.xlsx ## cycling core exercises.docx ## draft letter to patients.docx ## draft_GUILD_abstract.docx ## draft_tokenization letter Risa_Uste.docx ## early-career-faculty_Dec-2020.xlsx ## epic cancel_reschedule appointments.ppt ## epic schedule viewing_close.ppt ## escalator.html ## exercise1.xlsx ## exercise2.xlsx ## fellow graduation 2020.docx ## flag_contest_submission_PDRH.pdf ## hershey_long_term.xlsx ## hexStickers.jpg ## higgins2x3.jpg ## higgins_signature.docx ## iBike Rides ## imaging_stricture.xlsx ## introduce_clare.docx ## jama_cushing_crohn_review_2021.pdf ## learnr app diagram.jpg ## learnr app diagram.pptx ## letter Lowrimore.docx ## medicaldata_NHS_R_2021.pptx ## medicaldata_Rmedicine21.pdf ## medicaldata_Rmedicine21.pptx ## medicaldata_image_hex.ai ## messy_bp.xlsx ## mockstudy manuscript draft.docx ## nejm1966_beecher_ethics.pdf ## nejm_indomethacin.pdf ## nejm_statins.pdf ## orange_green_down_arrow - Gravit Designer.html ## orange_green_down_arrow- Gravit Designer.pdf ## pdrh_IBD_email.xlsx ## personal statement fellowship_PDRH.docx ## peterhiggins.jpg ## pink_down_arrow - Gravit Designer.html ## pink_up_arrow - Gravit Designer.pdf ## rehab schedule.docx ## seq-6.pdf ## signature.docx ## signature.fld ## signature.html ## signature.pdf ## signature.png ## sorted_steno.xlsx ## starting biologics.pptx ## stiff_bcl.R ## submitJanssen_IBD School Videos_12Jul2018.pdf ## tidyr_pivot.png ## tidyr_pivot.xcf ## tofa_checkpoint.pdf ## twitter.com.webarchive ## ucla1.jpg ## untidy_sheets.pptx ## user_testing_learnr tutorials.pptx ## weiser_topics.docx ## wga_min20.pdf ## zwift_training_pacepartner.xlsx ## {&quot;Attachments&quot;-[{&quot;__type&quot;-&quot;F.textClipping ## ~$ Severe UC Protocol.docx ## ~$Big data with Arrow and DuckDB with demo.pptx ## ~$Jun2021_ibdTrials.pptx ## ~$T Review Higgins.docx ## ~$cipeTin Lentil Chickpea Coconut Curry.docx ## ~$e crust recipe.docx ## ~$sk List 2020-5.docx ## ~$sk List 2020.docx ## ~$sk List 2021.docx You will see a listing of all files and folders in the current directory. You can get more details by adding the option (sometimes called a flag) -l cd /Users/peterhiggins/Documents/; ls -l The full listing will give you more details, including read &amp; write permissions, file size, date last saved, etc. Many UNIX commands have options, or flags, that modify what they do. Find a folder inside of your Documents folder. We will now go down a level in the directory tree. In my case, I will use the Powerpoint folder. In your Terminal window: change the directory to the Powerpoint directory list the contents of this folder cd /Users/peterhiggins/Documents/Powerpoint; ls ## 2016IBDClinTrialsforMDsDearborn.pptx ## 2016IntegratedDeckorMDsGB.pptx ## 2019 SCSG GI Symposium IBD SoA - Read-Only.pptx ## ADTC Flowchart-draft-RWS_14FEB2015.docx ## Acutely Ill IBD Patient protocol for ADTC-RWS.docx ## Annual Research Career Review 2021PH.pptx ## BE LGD Dearborn 2016.04.12.pptx ## CCF_Clinical_Trials.pptx ## CP1_Higgins Intro.pptx ## CP2_DiagnosingIBD_KC.pptx ## CP3_FMT_MMM.pptx ## CP4_SurgeryRegenbogen.pptx ## CP5_NutritionIBD_EH.pptx ## CP6_Infections2018.pptx ## CP7_PsychologicalStress_Riehl IBDFlint2018.pptx ## CP8_SteroidsWaljee.pptx ## CP9_ClinicalTrials2018.pptx ## ECCO 2022 UPA-UC ext duration oral_v2.0_3Feb2022_for QC.pptx ## ECCO22_Template.pptx ## Feasibility and Pilot Studies CTA.pptx ## FibrosisIBDCedars2016.pdf ## Getting Started in RStudio.pptx ## Higgins CCFA CTPROs in IBD.pptx ## Higgins CCFACT2017FundingClinicalResearch.pptx ## Higgins HK 2017IBD Nursing and Quality of Care.pptx ## Higgins HK 2017The Gut Microbiota and the Pathophysiology of IBD.pptx ## Higgins Microbiota for IBD Patient Ed.pptx ## HigginsAI talk for DDW2019.pptx ## HigginsDec2018AJG_SmokingStatus.pptx ## HigginsFALKMadridThioMtx2017.pptx ## Higgins_CCC_2018_Refractory_Rising_Bar_v3.pptx ## IBD Part 1 Higgins USMN.pptx ## IBD Part 2 Higgins USMN.pptx ## IBD Part 3 Higgins USMN.pptx ## IBD Part 4 Higgins USMN.pptx ## IBD and PTSD.pptx ## IBDUpdate.pptx ## IOIBD.Fibrosis.Higgins.2018.Amsterdam.pptx ## Integrated Slide Deck Dearborn 2016.04.12.pptx ## MER Stress Management Dearborn 4-14.pptx ## MichiganMedicine-IBDTemplate.potx ## Outcome Measures CTA.pptx ## PDRH RCR 2020.pptx ## PDR_Higgins_DeficienciesInIBD_AIBD2021.pptx ## PennThioMTX2017Higgins.pptx ## Pilot Feasibility Studies.pptx ## PragueRefractoryRisingBar2017.pptx ## Pregnancy in IBD.pptx ## Presentation1.pptx ## Regenbogen CRS for GI CME Course2016.pptx ## Senior Slide Show.pptx ## Social Media for GI.pptx ## SuperRough AI.pptx ## T32 Fellowship Annual Orientation 2023.pptx ## T32 GI Clinical Pink Sheet analysis.pptx ## T32 GI Fellowship Presentation 2023.pptx ## ThomsonRectalStumpComplicationsIBD2_13.pptx ## UEGweek2020.pptx ## UMHS IBD ADTC Encounter Note-DRAFT-RWS_15FEV2015.docx ## UMHS Talk- Moving Beyond AntiTNF 4-2016 FINAL v2.pptx ## UMich COVID-19 IBD.pptx ## Update on COVID and IBD.pptx ## Vertebrate Animals for K.pptx ## VirtualPtEdMar2020.v2.pptx ## VirtualPtEdMar2022Jan.pptx ## VirtualPtEd_2022_Deck.pptx ## VirtualPtEd_2022_Feb.pptx ## Writers Room.pptx ## ibd_meds_surgery_metan.pptx Great! You moved to a new directory and listed it. Now we will get fancy, and make a new directory within this directory with the mkdir command. Try this in your Terminal window: pwd; mkdir new_files; ls You have now made a new directory (folder) within the previous directory (pwd = present working directory), named new_files. Verify this in your Documents folder. You can now make changes to this directory and list the contents (it should currently be empty). Try this out in your Terminal Window (note edit the cd command to your own directory path). cd /Users/peterhiggins/Documents/Powerpoint/new_files; ls Note that you can abbreviate the current directory with ., so that you could have also used cd ./new_files You can create a new (empty) file in this directory with the touch command. Sometimes you need to create a new file, then write data to it. Try this out touch file_name; ls You can also create a file with data inside it with the cat &gt; command. Type in the following lines into your Terminal window. When complete, type control-D to be done and return to the Terminal prompt. cat stands for concatenate. cat &gt; file2.txt cat1 cat2 cat3 Now you can list the contents of this file with the cat command below. Give this a try cat file2.txt You can also list the directory of your new_files folder with ls to see the new folder contents. Try this ls Note that you don’t need to use the Terminal to run bash commands. You can do this from an Rmarkdown file. Take a moment to run pwd in your Terminal, to get the current directory. Now open Rstudio, and a new Rmarkdown document. Copy the path to the current directory from the Terminal. Switch back to the Rmarkdown document. Select one of the R code chunks (note the {r} at the top) and delete it. Now click on the Insert dropdown at the top of the document, and insert a Bash chunk. Now you can add UNIX commands (separated by a semicolon) to this code chunk, like cd (paste in path here); pwd; ls; cat file2.txt Then run this chunk. Now you can run terminal commands directly from Rmarkdown! 41.6 Cleaning Up OK, now we are done with the file file2.txt and the directory new_files. Let’s get rid of them with rm (for removing files) and rmdir for removing directories. In order, we will - Make sure we are in the right directory - remove the file with rm file2.txt - go up one level of the directory with cd .. - remove the directory with rmdir new_files Give this a try pwd; rm file2.txt; cd ..; rmdir new_files Verify all of this in your Documents window. This is great. But you can imagine a situation in which you mistakenly rm a file (or directory) that you actually needed. Unlike your usual user interface, when a file is removed at the command line, it is gone. It is not in the trash folder. It is really gone. There is something to be said for modern user interfaces, which are built for humans, who occasionally make mistakes. Sometimes we do want files or folders back. 41.7 Other helpful file commands Here are some file commands worth knowing cat filename - to print out whole file to your monitor less filename - to print out the first page of a file, and you can scroll through each page one at a time head filename - print first 10 lines of a file tail filename - print last 10 lines of a file cp file1 file2 - copy file1 to file2 mv file1.txt file.2.txt file3.txt new_folder - move 3 files to a new folder 41.8 What about R? So now you can get around directories, and find your files in the Terminal window, but you really want to run R. You can launch an R session from the Terminal Window (if you have R installed on your computer) by typing the letter R at the Terminal prompt Launch R R You get the usual R intro, including version number, and the R&gt; prompt. Now you can run R in interactive mode with available datasets, or your own datasets. Try a few standard tidyverse commands with the mtcars dataset. Give the examples below a try. You can use q() to quit back to the terminal (and reply “n” to not save the workplace image). head(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 mtcars %&gt;% filter(mpg &gt; 25) %&gt;% select(starts_with(&#39;m&#39;)|starts_with(&#39;c&#39;)) ## mpg cyl carb ## Fiat 128 32.4 4 1 ## Honda Civic 30.4 4 2 ## Toyota Corolla 33.9 4 1 ## Fiat X1-9 27.3 4 1 ## Porsche 914-2 26.0 4 2 ## Lotus Europa 30.4 4 2 41.9 What about just a few lines of R? Sometimes you will want to call R, run some code, and be done with R. You can call R, run a few lines, and quit in one go. You can add the flag -e (for evaluate) to the call to R, and put the R commands in quotes. Try the example below (note that this will not work if you are still in R - be sure you are back in the terminal with the % or $ prompt) R -e &quot;head(mtcars)&quot; or this example - note that single or double quotes does not matter - as long as they match. Try this R -e &#39;install.packages(palmerpenguins)&#39; You can also string together several commands with the semicolon between them. Try the example below. R -e &#39;library(palmerpenguins);data(penguins);tail(penguins)&#39; 41.10 Running an R Script from the Terminal Now we are stepping up a level - you have an R script that you have carefully created and saved as the myscript.R file. How do you run this from the Terminal? This is straightforward - you can call the Rscript command with your file name. Pick out a short R file you have written, make sure you are in the right directory where the file is, and use it as in the example below. Rscript myscript.R This launches R, runs your script, saves resulting output (if your script includes save or ggsave commands), closes R, and sends you back to the Terminal. Very nice! 41.11 Rendering an Rmarkdown file from the Terminal This is a little different, as you can’t just run an Rmarkdown file. Normally you would use the dropdown button to knit your file from Rstudio. But you can use the rmarkdown::render command to render your files to HTML, PDF, Word, Powerpoint, etc. Pick out a small Rmd file like output_file.Rmd below, make sure you are in the right directory where the file is, and try something like the example below. Note that this is one case where nesting different types of quotes (single vs. double) can come in handy. It helps to use single quotes around your filename and double quotes around the rmarkown::render command. Try it out Rscript -e &quot;rmarkdown::render(&#39;output_file.Rmd&#39;)&quot; So there you have it! Just enough to get you started with R from the command line. For further reading, check out these helpful links: Data Science at the Command line (e-book) R in Batch mode on Linux R tutorial for a Unix Environment The Linux Command Line: A Complete Introduction - a whole book on the topic Software Carpentry Command-Line Programs Scheduling jobs with cron "],["secure-passwords-in-r.html", "Chapter 42 Secure Passwords in R 42.1 Setting New Keys", " Chapter 42 Secure Passwords in R You will, not infrequently, need to use passwords to access secure or PHI protected data from databases or cloud storage or even password-protected excel files. It is important to sort out how to use passwords securely. You do not want to type out your password in a script. You can store passwords securely in variables on your computer for use later. If they are in a script, someone else can find them, especially if you are using version control and pushing code to Github. You can use the .gitignore file to make sure that git ignores certain files to back up to the repository, especially large files (graphics, etc. that can be regenerated), but it is better to avoid putting any passwords into your code at all. Each major computer operating system (Windows, MacOS, Linux) has its own secure credential store. You may know this as the ‘Credential Store’ on Windows, the ‘Keychain’ on MacOS, or the “Secret Service API’ on Linux. Each of these is a secure, password-protected store of passwords that you use for different websites for browser access. The {keyring} package in R gives you a single interface to all of these secure credential stores. Make sure you have this installed with install.packages('keyring') after you call library(keyring), you can store one or more secret passwords (keys). A key is defined by a service name (i.e. website) and a password. Once defined, this key persists in the keyring store of your operating system, and is only accessible to someone with the password to your computer. You can define a key once (interactively, or in an R script), and it will persist for use in future R sessions. Let’s see your current list of secrets. Run the code chunk below. library(keyring) key_list() ## service ## 1 Apple ID Authentication ## 2 com.apple.scopedbookmarksagent.xpc ## 3 ProtectedCloudStorage ## 4 ProtectedCloudStoragePublic ## 5 com.apple.cloudd.deviceIdentifier.Production ## 6 com.apple.cloudd.deviceIdentifier.Production ## 7 com.apple.cloudd.deviceIdentifier.Production ## 8 Safari Session State Key ## 9 PersonalFormsAutoFillDatabase ## 10 AirPlay Client Identity ## 11 AirPlay Client Peer ## 12 Call History User Data Key ## 13 com.apple.linkedin.oauth-token-nosync ## 14 Extended Preferences ## 15 fmfd-daemon-aps-token ## 16 iPhone Backup ## 17 com.apple.ids ## 18 com.apple.cloudd.deviceIdentifier.Production ## 19 com.apple.gs.icloud.auth.com.apple.account.AppleIDAuthentication.token-expiry-date ## 20 com.apple.gs.appleid.auth.com.apple.account.AppleIDAuthentication.token-expiry-date ## 21 ## 22 MSOpenTech.ADAL.1|aHR0cHM6Ly9sb2dpbi53aW5kb3dzLm5ldC9jb21tb24|aHR0cHM6Ly9vZmZpY2VhcHBzLmxpdmUuY29t|ZDM1OTBlZDYtNTJiMy00MTAyLWFlZmYtYWFkMjI5MmFiMDFj ## 23 AirPort Base Station ## 24 com.apple.iMovieApp: Google Plus OAuth2 ## 25 MSOpenTech.ADAL.1|aHR0cHM6Ly9sb2dpbi53aW5kb3dzLm5ldC9jb21tb24|CC3513A0-0E69-4B4D-97FC-DFB6C91EE132|ZDM1OTBlZDYtNTJiMy00MTAyLWFlZmYtYWFkMjI5MmFiMDFj ## 26 MSOpenTech.ADAL.1|aHR0cHM6Ly9sb2dpbi53aW5kb3dzLm5ldC9jb21tb24|aHR0cHM6Ly81ZDU1ZTE4MjRjNWE0NGU2OGJjMi1teS5zaGFyZXBvaW50LmNvbS8|ZDM1OTBlZDYtNTJiMy00MTAyLWFlZmYtYWFkMjI5MmFiMDFj ## 27 com.amazon.music ## 28 com.apple.cloudd.deviceIdentifier.Production ## 29 MSOpenTech.ADAL.1|aHR0cHM6Ly9sb2dpbi53aW5kb3dzLm5ldC80MzYzYjM3Yy01ZjNjLTRmZDctYTU2MS05NDMxMzFkYjc4YmM|CC3513A0-0E69-4B4D-97FC-DFB6C91EE132|ZDM1OTBlZDYtNTJiMy00MTAyLWFlZmYtYWFkMjI5MmFiMDFj ## 30 MSOpenTech.ADAL.1|aHR0cHM6Ly9sb2dpbi53aW5kb3dzLm5ldC80MzYzYjM3Yy01ZjNjLTRmZDctYTU2MS05NDMxMzFkYjc4YmM|aHR0cHM6Ly81ZDU1ZTE4MjRjNWE0NGU2OGJjMi1teS5zaGFyZXBvaW50LmNvbS8|ZDM1OTBlZDYtNTJiMy00MTAyLWFlZmYtYWFkMjI5MmFiMDFj ## 31 SSH ## 32 com.garmin.renu.client.MSAI ## 33 com.garmin.renu.service.MSAI ## 34 BackupIDSAccountToken ## 35 com.helpshift.data_com.microsoft.Outlook ## 36 com.helpshift.data_com.microsoft.Outlook ## 37 ## 38 Safari Forms AutoFill Encryption Key ## 39 com.apple.facebook.oauth-token-nosync ## 40 MetadataKeychain ## 41 com.apple.cloudd.deviceIdentifier.Production ## 42 com.apple.cloudd.deviceIdentifier.Production ## 43 com.apple.cloudd.deviceIdentifier.Production ## 44 com.apple.cloudd.deviceIdentifier.Production ## 45 com.apple.cloudd.deviceIdentifier.Production ## 46 com.apple.cloudd.deviceIdentifier.Production ## 47 com.apple.cloudd.deviceIdentifier.Production ## 48 com.apple.cloudd.deviceIdentifier.Production ## 49 com.apple.cloudd.deviceIdentifier.Production ## 50 com.apple.cloudd.deviceIdentifier.Production ## 51 com.apple.cloudd.deviceIdentifier.Production ## 52 com.apple.cloudd.deviceIdentifier.Production ## 53 ## 54 com.apple.assistant ## 55 com.apple.NetworkServiceProxy.Configuration ## 56 com.apple.NetworkServiceProxy.WaldoInfo.pie.v3.hosts ## 57 com.apple.NetworkServiceProxy.WaldoInfo.com.apple.parsecd ## 58 ## 59 com.apple.cloudd.deviceIdentifier.Production ## 60 com.citrix.receiver.nomas.HockeySDK ## 61 com.citrix.ReceiverHelper.HockeySDK ## 62 com.citrix.receiver.nomas.HockeySDK ## 63 com.citrix.ReceiverUpdater.HockeySDK ## 64 com.apple.twitter.oauth-token-nosync ## 65 com.apple.quicktimeplayerx.YouTube.oauth-token ## 66 com.apple.quicktimeplayerx.YouTube.oauth-refresh-token ## 67 com.helpshift.data_com.microsoft.Outlook ## 68 com.helpshift.data_com.microsoft.Outlook ## 69 com.garmin.cartography.mapupdate.express.itauth ## 70 com.apple.cloudd.deviceIdentifier.Production ## 71 Forms-{23D7314F-334F-49af-A1F1-87F222FEC590}u ## 72 com.citrix.XenAppViewer.HockeySDK ## 73 com.garmin.cartography.mapupdate.express.auth ## 74 GitHub - https://api.github.com ## 75 ## 76 ## 77 AGLegacy-{232FA8DF-2F1B-462c-846E-00BFBC1B5A44}u ## 78 ## 79 ## 80 ## 81 ## 82 Zoom Safe Storage ## 83 com.bluejeansnet.Blue ## 84 com.bluejeansnet.Blue ## 85 com.bluejeansnet.Blue ## 86 com.microsoft.SkypeForBusiness.HockeySDK ## 87 com.apple.assistant ## 88 Zoom Safe Meeting Storage ## 89 SWC Agent Database ## 90 Exchange ## 91 com.apple.account.AppleAccount.back-to-my-mac-token ## 92 com.apple.account.AppleIDAuthentication.token ## 93 com.apple.account.AppleIDAuthentication.token-expiry-date ## 94 AppleIDClientIdentifier ## 95 317E8977-13BE-4CD4-9FF3-F396535E48FC ## 96 com.apple.account.Google.oauth-token-nosync ## 97 Adobe User OS Info ## 98 com.apple.assistant ## 99 com.adobe.creativecloud.com.adobe.acc.pmp.C2A135575CF3D7EC0A495FA8.ThirdPartyPluginsInstall ## 100 ## 101 com.apple.assistant ## 102 AirPlay Server Identity ## 103 iOS Backup ## 104 Chrome Safe Storage ## 105 com.apple.account.GameCenter.token ## 106 com.apple.assistant ## 107 com.firebase.FIRInstallations.installations.1:177223194525:ios:76d203d5a1553972 ## 108 84ef17be-80f0-4750-a22c-c2a26ff1ba72 ## 109 84ef17be-80f0-4750-a22c-c2a26ff1ba72 ## 110 Microsoft Teams Identities Cache ## 111 Adobe App Info (Q0NMaWJyYXJ5MXt9MjAxODA3MjAwMQ) ## 112 discord Safe Storage ## 113 com.microsoft.rdc.macos ## 114 Teams Safe Storage ## 115 teamsIv ## 116 teamsKey ## 117 com.adobe.creativecloud.com.adobe.acc.container.C2A135575CF3D7EC0A495FA8.AdobeStock:NOTIFICATION_GUID_KEY ## 118 com.adobe.creativecloud.com.adobe.acc.container.C2A135575CF3D7EC0A495FA8.AdobeStock:NOTIFICATION_TIMESTAMP_KEY ## 119 com.adobe.creativecloud.com.adobe.acc.container.C2A135575CF3D7EC0A495FA8.AdobeStock:NOTIFICATION_ETAG_KEY ## 120 ## 121 com.apple.account.Google.oath-refresh-token ## 122 ## 123 Slack Safe Storage ## 124 com.adobe.creativecloud.com.adobe.acc.container.C2A135575CF3D7EC0A495FA8.AdobeStock:NOTIFICATION_KEY ## 125 ## 126 DBX_PASSWORDS_NMHAAARijI5FMx-jb14NyZYH9Q6BB4lBd1XpMc__40F9DF58-039E-40F1-A3CD-490226F560C6 ## 127 DBX_PASSWORDS_NMHAAARijI5FMx-jb14NyZYH9Q6BB4lBd1XpMc__7EB20C05-66C8-4151-9A03-3B433077E00F ## 128 Microsoft Teams Identities Cache ## 129 AdalCache ## 130 d211f69b-6302-418e-b36f-ae2aa01bdbfd ## 131 com.apple.continuity.encryption ## 132 biofire_api_key ## 133 FMFDStoreController ## 134 com.apple.assistant ## 135 com.apple.NetworkServiceProxy.ProxyToken ## 136 Microsoft Teams Safe Storage ## 137 iCloud ## 138 com.microsoft.OutlookCore.ServiceV2 ## 139 com.garmin.cartography.mapupdate.express.auth ## 140 ## 141 com.apple.NetworkServiceProxy.ProxyToken ## 142 Adobe User Info ## 143 com.apple.assistant ## 144 com.apple.NetworkServiceProxy.ProxyToken ## 145 com.apple.continuity.encryption ## 146 Adobe App Info (Q0NMaWJyYXJ5Mnt9MjAxODA3MjAwMQ) ## 147 com.apple.continuity.encryption ## 148 ## 149 ## 150 com.apple.continuity.encryption ## 151 com.apple.assistant ## 152 com.apple.assistant ## 153 com.apple.assistant ## 154 com.apple.ind.registration ## 155 TelephonyUtilities ## 156 TelephonyUtilities ## 157 com.adobe.creativecloud.com.adobe.acc.container.C2A135575CF3D7EC0A495FA8.AdobeStock:UPDATE_INDICATOR_VISIBILITY_KEY ## 158 Apple Persistent State Encryption ## 159 com.apple.NetworkServiceProxy.ProxyToken ## 160 com.apple.gs.icloud.auth.com.apple.account.AppleIDAuthentication.token ## 161 com.apple.gs.appleid.auth.com.apple.account.AppleIDAuthentication.token ## 162 com.apple.NetworkServiceProxy.ProxyToken ## 163 com.apple.NetworkServiceProxy.ProxyToken ## 164 Adobe App Info (Q0NYUHJvY2VzczF7fTIwMTgwNzIwMDE) ## 165 Adobe App Info (Q29yZVN5bmMxe30yMDE4MDcyMDAx) ## 166 Adobe App Info (Q3JlYXRpdmVDbG91ZDJ7fTIwMTgwNzIwMDE) ## 167 com.apple.NetworkServiceProxy.ProxyToken ## 168 com.apple.NetworkServiceProxy.ProxyToken ## 169 com.apple.NetworkServiceProxy.ProxyToken ## 170 OneAuthAccount ## 171 OneAuthAccount ## 172 ## 173 com.apple.assistant ## 174 Adobe App Info (QWNyb2JhdERDMXt9MjAxODA3MjAwMQ) ## 175 Adobe App Info (SWxsdXN0cmF0b3Ixe30yMDE4MDcyMDAx) ## 176 Adobe App Info (UGhvdG9zaG9wMXt9MjAxODA3MjAwMQ) ## 177 com.apple.assistant ## 178 com.apple.account.Google.oauth-expiry-date ## 179 com.apple.account.Google.oauth-token ## 180 com.apple.continuity.encryption ## 181 com.apple.NetworkServiceProxy.ProxyToken ## 182 OneAuthAccount ## 183 AirPort ## 184 AirPort ## 185 AirPort ## 186 AirPort ## 187 AirPort ## 188 AirPort ## 189 AirPort ## 190 AirPort ## 191 AirPort ## 192 AirPort ## 193 AirPort ## 194 AirPort ## 195 AirPort ## 196 AirPort ## 197 AirPort ## 198 AirPort ## 199 AirPort ## 200 AirPort ## 201 AirPort ## 202 AirPort ## 203 AirPort ## 204 AirPort ## 205 AirPort ## 206 AirPort ## 207 AirPort ## 208 AirPort ## 209 AirPort ## 210 AirPort ## 211 AirPort ## 212 AirPort ## 213 AirPort ## 214 AirPort ## 215 AirPort ## 216 AirPort ## 217 AirPort ## 218 AirPort ## 219 AirPort ## 220 AirPort ## 221 AirPort ## 222 AirPort ## 223 AirPort ## 224 AirPort ## 225 AirPort ## 226 AirPort ## 227 AirPort ## 228 AirPort ## 229 AirPort ## 230 AirPort ## 231 AirPort ## 232 AirPort ## 233 AirPort ## 234 AirPort ## 235 AirPort ## 236 AirPort ## 237 AirPort ## 238 AirPort ## 239 AirPort ## 240 AirPort ## 241 AirPort ## 242 AirPort ## 243 AirPort ## 244 AirPort ## 245 AirPort ## 246 AirPort ## 247 AirPort ## 248 AirPort ## 249 AirPort ## 250 com.citrix.receiver.nomas.HockeySDK ## 251 AirPort ## 252 AirPort ## 253 AirPort ## 254 AirPort ## 255 AirPort ## 256 AirPort ## 257 AirPort ## 258 AirPort ## 259 AirPort ## 260 AirPort ## 261 AirPort ## 262 WiFiAnalytics ## 263 BluetoothGlobal ## 264 BluetoothGlobal ## 265 BluetoothGlobal ## 266 BluetoothGlobal ## 267 BluetoothGlobal ## 268 BluetoothGlobal ## 269 BluetoothGlobal ## 270 BluetoothGlobal ## 271 ## 272 Remote Pairing Identity ## 273 BluetoothGlobal ## 274 AirPort ## 275 BluetoothLE ## 276 BluetoothGlobal ## 277 BluetoothGlobal ## 278 AirPort ## 279 AirPort ## 280 AirPort ## 281 AirPort ## 282 AirPort ## 283 AirPort ## 284 AirPort ## 285 AirPort ## 286 AirPort ## 287 AirPort ## 288 BluetoothGlobal ## 289 AirPort ## 290 AirPort ## 291 AirPort ## 292 AirPort ## 293 AirPort ## 294 AirPort ## 295 AirPort ## 296 AirPort ## 297 BluetoothLE ## 298 AirPort ## 299 BluetoothLE ## 300 AirPort ## 301 BluetoothGlobal ## 302 BluetoothLE ## 303 BluetoothGlobal ## 304 AF2710E6-F2E5-48E8-AFA4-28BBC7B9CEA8.XAUTH ## 305 AF2710E6-F2E5-48E8-AFA4-28BBC7B9CEA8.SS ## 306 FDB4238E-3A19-4058-AAEA-42DEAA52A9D8.XAUTH ## 307 FDB4238E-3A19-4058-AAEA-42DEAA52A9D8.SS ## 308 MobileBluetooth ## 309 MobileBluetooth ## 310 MobileBluetooth ## 311 MobileBluetooth ## 312 MobileBluetooth ## 313 WiFiAnalytics ## 314 WiFiAnalytics ## 315 WiFiAnalytics ## 316 AirPort ## username ## 1 pdr.higgins@gmail.com ## 2 com.apple.scopedbookmarksagent.xpc ## 3 default ## 4 default ## 5 com.apple.CallHistory ## 6 com.apple.clouddocs ## 7 com.apple.SafariShared.WBSCloudHistoryStore ## 8 ## 9 Safari ## 10 e9a97d4986bc3f7c54e215b19fda27051d7c6ce8dd2a8c716632ecb9baa5bce4 ## 11 bbefd137e887c47f8495be41c2e8a2d91ab38f84b8b483fc6f15b4758e3a7b18 ## 12 ## 13 higgi13425@yahoo.com ## 14 Safari ## 15 fmfd-aps-token-username ## 16 2bf4e0a1358f6080420ad18d262bcbd2202bdd72 ## 17 localdevice274d0a8a-5bf5-5aca-a3ab-362b925f54ca-AuthToken ## 18 com.apple.notes ## 19 pdr.higgins@gmail.com3FCF0381-C0B2-4534-9D76-8D992BDCA6BE ## 20 pdr.higgins@gmail.comBB68689C-4E3E-4E0E-8615-65B027B4B9D9 ## 21 bundleSeedID ## 22 cGhpZ2dpbnNAdW1pY2guZWR1 ## 23 80:ea:96:e7:43:ae ## 24 OAuth ## 25 cGhpZ2dpbnNAdW1pY2guZWR1 ## 26 cGhpZ2dpbnNAdW1pY2guZWR1 ## 27 amazon_cloud_player_remember_me ## 28 com.apple.largeattachment ## 29 cGhpZ2dpbnNAdW1pY2guZWR1 ## 30 cGhpZ2dpbnNAdW1pY2guZWR1 ## 31 /Users/peterhiggins/.ssh/id_rsa ## 32 appAnonID ## 33 appAnonID ## 34 pdr.higgins@gmail.com-AuthToken ## 35 com.helpshift.deviceUniqueIdentifier ## 36 __hs ## 37 Microsoft Office Identities Settings 2 ## 38 ## 39 higgi13425@yahoo.com ## 40 ## 41 com.apple.security.keychain ## 42 com.apple.SafariShared.WBSCloudBookmarksStore ## 43 com.apple.knowledgestore2 ## 44 com.apple.securedBluetooth ## 45 com.apple.CoreSuggestions.PseudoEvents ## 46 com.apple.security.PCSIdentityBackup ## 47 com.apple.siri.profile ## 48 com.apple.siri.knowledge ## 49 com.apple.bluetooth ## 50 com.apple.textinput.KeyboardServices ## 51 com.apple.icloud-rawhide2 ## 52 com.apple.icloud-rawhide3 ## 53 com.apple.WebKit.WebCrypto.master+com.apple.Safari ## 54 9980D418-5756-46F7-99F5-BAAFC46CB734 - Host Creation UUID ## 55 configuration ## 56 waldo ## 57 waldo ## 58 Microsoft Office Identities Cache 2 ## 59 com.apple.messages.cloud ## 60 deletionFlag ## 61 appAnonID ## 62 appAnonID ## 63 appAnonID ## 64 higgi13425@yahoo.com-FB80BBBE-58A2-4E35-8D1E-6BDB7458458A ## 65 com.apple.quicktimeplayerx.YouTube.oauth-token ## 66 com.apple.quicktimeplayerx.YouTube.oauth-refresh-token ## 67 AllHSProfiles ## 68 lastLoggedInIdentifier ## 69 3941332313 ## 70 com.apple.Maps.Sync ## 71 https://vplacesint.med.umich.edu/Citrix/vplacesAuth/ExplicitForms/Start ## 72 appAnonID ## 73 3941332313 ## 74 higgi13425 ## 75 /Users/peterhiggins/Library/Application Support/Adobe/Acrobat/DC/Security/reader_fss_signature_initialsk ## 76 /Users/peterhiggins/Library/Application Support/Adobe/Acrobat/DC/Security/workflowDataCacheReaderk ## 77 https://vplaces.med.umich.edu/ ## 78 /Users/peterhiggins/Library/Application Support/Adobe/Acrobat/DC/Security/ES_session_storek ## 79 /Users/peterhiggins/Library/Application Support/Adobe/Acrobat/DC/Security/Annssk.dat ## 80 /Users/peterhiggins/Library/Application Support/Adobe/Acrobat/DC/Security/acrobat_eureka_caching_key_storek ## 81 /Users/peterhiggins/Library/Application Support/Adobe/Acrobat/DC/Security/acrobat_fss_signature_initialsk ## 82 Zoom ## 83 PNConfigurationDeviceID ## 84 PNConfigurationUUID ## 85 pn_publishSequence ## 86 appAnonID ## 87 Siri Global - User Identifier ## 88 Zoom ## 89 SWC Agent Database ## 90 phiggins@email.med.umich.edu ## 91 pdr.higgins@gmail.com ## 92 pdr.higgins@gmail.com-FC61F671-38B7-4248-9B20-665F07014991 ## 93 pdr.higgins@gmail.com-3007D2C2-5FBA-4A98-985D-21E894F43011 ## 94 ## 95 317E8977-13BE-4CD4-9FF3-F396535E48FC ## 96 pdr.higgins@gmail.com ## 97 User OS Info ## 98 Siri Global - Logging User Identifier ## 99 ## 100 /Users/peterhiggins/Library/Application Support/Adobe/Acrobat/DC/Security/searchDataCachek ## 101 9980D418-5756-46F7-99F5-BAAFC46CB734 - Local Crypto Key Data ## 102 65b32966698820e956298f72d6a0a33993d934acbac7e7fe9732b0a5410bb4c8 ## 103 00008101-0005452E14C0001E ## 104 Chrome ## 105 pdr.higgins@gmail.com ## 106 9980D418-5756-46F7-99F5-BAAFC46CB734 - Server Certificate Data ## 107 1:177223194525:ios:76d203d5a1553972__FIRAPP_DEFAULT ## 108 com.microsoft.lync.certificate ## 109 com.microsoft.lync.key ## 110 Microsoft Teams Identities Cache_1f41d613-d3a1-4ead-918d-2a25b10de330 ## 111 App Info ## 112 discord ## 113 A9A5830D-F96E-4B23-A0D5-7014094728B0 ## 114 Teams ## 115 teams ## 116 teams ## 117 ## 118 ## 119 ## 120 /Users/peterhiggins/Library/Application Support/Adobe/Acrobat/DC/Security/DCAPIDiscoveryCacheAcrobatk ## 121 pdr.higgins@gmail.com ## 122 Microsoft Office Ticket Cache 2 ## 123 Slack App Store Key ## 124 ## 125 Microsoft Office Ticket Cache ## 126 AAARijI5FMx-jb14NyZYH9Q6BB4lBd1XpMc__40F9DF58-039E-40F1-A3CD-490226F560C6 ## 127 AAARijI5FMx-jb14NyZYH9Q6BB4lBd1XpMc__7EB20C05-66C8-4151-9A03-3B433077E00F ## 128 Microsoft Teams Identities Cache ## 129 adalcache ## 130 ## 131 handoff-decryption-key-3B5C995B-4A70-46EF-8FA5-AF6A8D8B7EB6 ## 132 ## 133 FMFDStoreControllerKey ## 134 Siri Global - AnalyticsIdentifiers.fixedDeviceId ## 135 CloudFlare_OHTTP_Relay_Carry ## 136 Microsoft Teams ## 137 1457225930 ## 138 com.microsoft.OutlookCore.AccountV2 ## 139 3481069885 ## 140 Microsoft Office Identities Cache 3 ## 141 CloudFlare_OHTTP_Relay_Carry_Staging ## 142 User DT ## 143 Siri Global - com.apple.assistant.music.fusetoken ## 144 Apple_2 ## 145 handoff-decryption-key-3FC361CC-4036-4255-B474-0F2B2357A185 ## 146 App Info ## 147 handoff-decryption-key-F0384A42-87AF-41F5-A4DD-E12353FD9024 ## 148 /Users/peterhiggins/Library/Application Support/Adobe/Acrobat/DC/Security/AcroMLDataCachek ## 149 /Users/peterhiggins/Library/Application Support/Adobe/Acrobat/DC/Security/workflowDataCachek ## 150 handoff-decryption-key-1D3B068C-DD25-4A0B-8016-371043696090 ## 151 9980D418-5756-46F7-99F5-BAAFC46CB734 - Assistant Identifier ## 152 9980D418-5756-46F7-99F5-BAAFC46CB734 - Logging Assistant Identifier ## 153 9980D418-5756-46F7-99F5-BAAFC46CB734 - Speech Identifier ## 154 9C1AC72F-511A-46E3-88E3-64885BB78814 ## 155 lastKnownFaceTimeCallerID ## 156 registeredProviders ## 157 ## 158 Window Bitmap Encryption ## 159 Akamai ## 160 pdr.higgins@gmail.com ## 161 pdr.higgins@gmail.com ## 162 CloudFlare ## 163 CloudFlare_OHTTP_Relay ## 164 App Info ## 165 App Info ## 166 App Info ## 167 Apple_Relay ## 168 Fastly ## 169 Fastly_OHTTP_Relay ## 170 e6c3d4cc-993c-41e5-82c6-68254c71767f.1f41d613-d3a1-4ead-918d-2a25b10de330.e66e77b4-5724-44d7-8721-06df160450ce ## 171 897557a6-f7f7-4e15-b896-bd49d6ddca75 ## 172 Microsoft Office Identities Settings 3 ## 173 9980D418-5756-46F7-99F5-BAAFC46CB734 - Validation Data ## 174 App Info ## 175 App Info ## 176 App Info ## 177 Siri Global - AnalyticsIdentifiers.checkpoint ## 178 pdr.higgins@gmail.com ## 179 pdr.higgins@gmail.com ## 180 handoff-own-encryption-key ## 181 Apple ## 182 e6c3d4cc-993c-41e5-82c6-68254c71767f ## 183 NETGEAR-Guest ## 184 villaflorida1 ## 185 Medosz_Front ## 186 buckeye 210 ## 187 medosz_8B ## 188 Verizon MIFI4510L E927 Secure ## 189 Michigania ## 190 U10C022B7 ## 191 Aran View ## 192 tep-modem-7fea ## 193 WebbNet ## 194 Stauntons_GuestWiFi ## 195 Amity Coffee ## 196 medosz_7B ## 197 iPhone ## 198 Evidera-Guest ## 199 ZyXEL202-203 ## 200 Caesar_Hall ## 201 safetourbus mobile 1 ## 202 Trans-CWB-2Andar (Me) ## 203 SBAD 2015 ## 204 Trans-CWB-3Andar (Me) ## 205 GVT-E3FC ## 206 Trans-CWB-3Andar (Fr) ## 207 Merck - 23/11 ## 208 Merck - 24/11 ## 209 WebbnetDown ## 210 CampusNet ## 211 ECCO16 ## 212 TonicLife2015 ## 213 MiFi4620L Jetpack E2D3 Secure ## 214 Peter&#39;s Wi-Fi Network ## 215 Peter&#39;s Library Wi-Fi Network ## 216 HiltonMTG ## 217 Samsung Galaxy S7 9350 ## 218 murphy2014 ## 219 STELARA ## 220 Fischer Hall ## 221 Stelara ## 222 murphy2014.2.4G ## 223 murphy2014.2.4 ## 224 PRINCESS ## 225 Knights Restaurant Public Wifi ## 226 SpeedNews ## 227 Apples and Oranges ## 228 Joe&amp;RosieWifi ## 229 ATTSzJhvMS ## 230 ZouZou&#39;s Cafe ## 231 CCFALink ## 232 colonial1 ## 233 Bayshore Resort ## 234 AB-Guest ## 235 Cardinal 5836 Guest ## 236 YOTEL-Wifi ## 237 internet-10NP ## 238 MAXIMILIAN ## 239 AIBD2017 ## 240 Sava&#39;s Guest ## 241 rstudio_conf ## 242 Jul_Menam ## 243 Jul note FE ## 244 HOME-4EB7 ## 245 HOME-1841-2.4 ## 246 Hotel_Famulus ## 247 Dennis&#39;s Wi-Fi Network_EXT ## 248 Masonic_Event ## 249 ICConnect ## 250 deletionFlag ## 251 ATTgUEMmbA ## 252 NETGEAR35 ## 253 AIBDWifiByBMS! ## 254 rstudio20 ## 255 MOTOBBCA ## 256 NETGEAR11 ## 257 Peter’s iPhone ## 258 Amplifi ## 259 MySpectrumWiFi68-2G ## 260 MySpectrumWiFi80-5G ## 261 WZ-Guest ## 262 com.apple.wifi.analytics.tokenStore.airportd ## 263 Identity Root ## 264 Encryption Root ## 265 Cloud Private Key Root ## 266 Cloud Public Key Root ## 267 Cloud Nonce Root ## 268 CT TKPeriod ## 269 CT TEK BUFF V2 LEN ## 270 Local Device Identifier ## 271 com.apple.LaunchServices.encr.3 ## 272 44CEED20-EF9C-42CF-A88D-13E49433198A ## 273 Local Device Static Random Address ## 274 Peter’s iPhone 13 ## 275 Public EC:A9:07:0C:94:EF Random D9:39:E3:50:39:3A ## 276 Non Connectable identity address ## 277 Non Connectable identity root ## 278 Long Pond Cottage-PRO ## 279 Webbnet ## 280 Gartland ## 281 NETGEAR34 ## 282 HOME-3EC2-5 ## 283 hug2g966693 ## 284 hug5g966693 ## 285 Long Pond Cottage ## 286 Fioptics07121 ## 287 Rust2933 ## 288 Cloud Master Key Root ## 289 Wildcats ## 290 NETGEAR35-5G ## 291 SkyTeam Lounge ## 292 Rydges-Guest ## 293 AGW_24 ## 294 TelstraE2D2C8 ## 295 SPARK GUEST ## 296 5404 Maryanna-5G ## 297 Public 90:81:58:09:40:F9 Random D9:39:E3:50:39:3A ## 298 NachoWifi ## 299 Public 08:FF:44:A2:D9:C1 Random D9:39:E3:50:39:3A ## 300 CCCongress25 ## 301 Cloud FC Address ## 302 Random F3:B3:86:10:2C:FD Random D9:39:E3:50:39:3A ## 303 Identity Root Key ## 304 phiggins ## 305 UM-off-campus-access ## 306 phiggins ## 307 UM-on-campus-wireless ## 308 28:37:37:36:35:C6 ## 309 35:09:06:E7:23:9D ## 310 90:9C:4A:09:DB:4E ## 311 DC:A9:04:03:D7:1A ## 312 1C:B3:C9:B2:DE:FF ## 313 com.apple.wifi.analytics.persistence ## 314 com.apple.wifi.analytics.persistence-iv ## 315 com.apple.wifi.analytics.persistence-tag ## 316 WEL This gives you a list of all the keys stored by your operating system credential store. 42.1 Setting New Keys You can add a new secret with key_set() key_set(service = &quot;secure_web&quot;, username = &quot;pdrh&quot;) This will open an interactive window for you to securely enter your hidden password. This is stored in your credential store. If you now run key_list(), and store it in a new object named keys, you can View this object and find new secret, named secure_web. Run the code chunk below. keys &lt;- key_list() View(keys) You may need to sort these secrets by service (click on the header of this column) to make it easier to find. Note that you see the service and username, but the password is not visible. To read the secret, you need to use the key_get() function. secure_web_pwd &lt;- key_get(service = &quot;secure_web&quot;, username = &quot;pdrh&quot;) secure_web_pwd This actually returns the password, in this case, to the console. You can use this to respond to a password request, or pass the password to a web API. These often use a function to retrieve data that requires the username and password as arguments. For the imaginary website, secure_web, we can use this approach to access web storage and retrieve files. secure_web_pwd &lt;- key_get(service = &quot;secure_web&quot;, username = &quot;pdrh&quot;) get_secure_web_files(username = &quot;pdrh&quot;, password = secure_web_pwd) If you want to delete a secret, you can use key_delete() key_delete(service = &quot;secure_web&quot;, username = &quot;pdrh&quot;) You can check this by regenerating your keys dataframe keys &lt;- key_list() View(keys) You will find that the secret for secure_web is now gone from your Credential Store. You can also use an R package named {credentials}, which is also popular, and it stores your credentials within git. https://happygitwithr.com/credential-caching.html "],["dates-and-times-in-r.html", "Chapter 43 Dates and Times in R 43.1 Data Types for Dates and Times 43.2 Using POSIXlt 43.3 Formatting dates 43.4 Including Plots 43.5 Including Tables 43.6 Other languages in code chunks 43.7 Code Chunk Options 43.8 Try Out Other Chunk Options 43.9 The setup chunk 43.10 The Easy Button - Visual Markdown Editing 43.11 A Quick Quiz", " Chapter 43 Dates and Times in R The horrors of dates and times (especially times and time zones) is a bane of computing. Dates have changed by government fiat (Gregorian to Julian, etc.) several times in history, and time zones and daylight savings time practices change more frequently. To add to the complications, there are many, many date formats around the world, with different countries and cultures mixing and matching days, months, and years willy-nilly to indicate a particular date. For this reason, there is an international standard, ISO 8601, for dates and times. The standard calls for listing all dates in YYYY-MM-DD format, with numbers for the 4 digit year, 2 digit month, and 2 digit day, as in 2021-04-17 for April 17, 2021. All numbers are zero-padded (necessary zeroes added to the left) to maintain 4 or two digits as needed. Use this format whenever you can, for consistency and to avoid errors that will be painful later. Insist that all of your collaborators use ISO8601 format, and your life will be vastly improved. Time in ISO8601 uses a 24 hour clock, and is formatted in two ways: the basic format is T[hh][mm][ss] and the extended format is T[hh]:[mm]:[ss]. Each number in a time is two digits, and is zero-padded when needed, so that one second after midnight is T00:00:01. When possible, use only dates in your data analysis. Times are complex and surprisingly painful, due to unusual cases that frequently cause trouble. These include: GMT (the time zone for Greenwich mean time) is close to, but not the same as UTC. Coordinated Universal Time (UTC) has no daylight savings, while GMT does. There are leap years, and leap seconds, to keep track of. January 30 + 1 month = NA, because there is no Feb 30. There are more than 24 time zones, because of episodic local changes. For example, tz = “America/Detroit” is not quite the same as Eastern Standard Time, as Michigan had daylight savings from 1916-1968, not from 1969-72, then returned to DST in 1973 and thereafter. With all of the odd geopolitical time zone and DST variations, there are now more than 600 distinct valid time zones that R keeps track of, and you can print these with the base R function OlsonNames(). Arthur David Olson was the original maintainer of the time zone database, which is now managed by the Internet Assigned Numbers Authority (IANA), currently led by Paul Eggert at UCLA. Unless you absolutely need time stamps to track intervals of less than a day, I strongly urge you to convert all date-times to simple ISO8601 dates. TZ 43.1 Data Types for Dates and Times Data for dates and times comes in several formats. - POSIXct - calendar time (also called continuous time or count time, as it counts seconds) - POSIXlt - local time (also called list time) - Date - date-time POSIX is probably unfamiliar to you - it stands for the Portable Operating System Interface for uniX used to make standards for UNIX across Operating systems. POSIX Dates use the reference point of 1970-01-01 T 0:00:00 UTC (midnight at the start of the year 1970 in coordinated universal time) as zero seconds. All dates after that are counted in seconds in POSIXct. Dates prior to 1970 are counted in negative seconds. POSIXct is very memory-efficient for storing dates, but not very human-readable. In the code chunk below, we will start with a ISO 8601 date, with a time zone. We will then print it out, and then show it as it is stored, are using the unclass function. Copy and run the code chunk to see the results. date1 &lt;- as.POSIXct(&quot;2018-01-16 04:34:45&quot;, tz = &quot;America/Detroit&quot;) date1 ## [1] &quot;2018-01-16 04:34:45 EST&quot; unclass(date1) ## [1] 1516095285 ## attr(,&quot;tzone&quot;) ## [1] &quot;America/Detroit&quot; You get a nicely formatted ISO8601 date when you print the date, but when it is unclassed, you get a large integer, which corresponds to the number of seconds since midnight, UTC on January 1, 1970. POSIXct dates are stored as integer seconds. 43.2 Using POSIXlt POSIXlt is another version of the POSIX standard, but in a more human-readable format. The ‘lt’ stands for local time, but it is often thought of as list time, as the data of POSIXlt is stored in a list format of human-readable items. POSIXlt stores separate items in a list. The list includes 10 distinct items: seconds (sec) minutes (min) hours (hour) day of month (mday) month (mon) - numeric, with January as zero, and December as 11 year (year) - since 1900 as zero, so the year 2018 = 118 weekday numeric (wday), with Sunday = 0, Saturday = 6 daylight savings (isdst), 0 for no, 1 for yes time zone (zone) Offset from UTC in seconds (gmtoff) In the code chunk below, we will start with the same ISO 8601 date, with a time zone. We will then print it out, and then show it as it is stored, are using the unclass function. We will then extract the month and year. Copy and run the code chunk to see the results. date2 &lt;- as.POSIXlt(date1) date2 ## [1] &quot;2018-01-16 04:34:45 EST&quot; unclass(date2) ## $sec ## [1] 45 ## ## $min ## [1] 34 ## ## $hour ## [1] 4 ## ## $mday ## [1] 16 ## ## $mon ## [1] 0 ## ## $year ## [1] 118 ## ## $wday ## [1] 2 ## ## $yday ## [1] 15 ## ## $isdst ## [1] 0 ## ## $zone ## [1] &quot;EST&quot; ## ## $gmtoff ## [1] -18000 ## ## attr(,&quot;tzone&quot;) ## [1] &quot;America/Detroit&quot; &quot;EST&quot; &quot;EDT&quot; ## attr(,&quot;balanced&quot;) ## [1] TRUE date2$mon ## [1] 0 date2$year ## [1] 118 Again, we get a nicely formatted ISO8601 date when you print the date, but when it is unclassed, you get a list of date items. When we extract the month and year, these can be surprising (January = 0, Year 2018 = 118). POSIXlt dates are stored as a list of date items. 43.3 Formatting dates as.Date strptime formatting codes the parsedate package 43.3.1 Code Chunk Icons Code Chunk Icons Icon Uses Settings Gear Allows you to Name the code chunk Set options for this chunk Run Chunks Above (down arrow) Runs all of the preceding code chunks, including the setup chunk Run Chunk (rightward arrow) Runs the entire current chunk 43.4 Including Plots covid &lt;- medicaldata::covid_testing covid %&gt;% ggplot() + aes(x = pan_day, y = ct_result) + geom_point() + labs(title = &quot;COVID Testing in First 100 Days of Pandemic&quot;, x = &quot;Pandemic Day, 2020&quot;, y = &quot;Cycle Threshold \\n45 is a Negative Test&quot;) 43.5 Including Tables covid %&gt;% count(demo_group, gender) %&gt;% gt() %&gt;% tab_header(title = &quot;Demographics of COVID Testing&quot;, subtitle = &quot;By Group and Gender&quot;) %&gt;% tab_source_note(source_note = &quot;From CHOP, 2020&quot;) %&gt;% cols_label(demo_group = &quot;Group&quot;, gender = &quot;Gender&quot;, n = &quot;Count&quot;) #fpflokttku table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #fpflokttku thead, #fpflokttku tbody, #fpflokttku tfoot, #fpflokttku tr, #fpflokttku td, #fpflokttku th { border-style: none; } #fpflokttku p { margin: 0; padding: 0; } #fpflokttku .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #fpflokttku .gt_caption { padding-top: 4px; padding-bottom: 4px; } #fpflokttku .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #fpflokttku .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #fpflokttku .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #fpflokttku .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #fpflokttku .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #fpflokttku .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #fpflokttku .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #fpflokttku .gt_column_spanner_outer:first-child { padding-left: 0; } #fpflokttku .gt_column_spanner_outer:last-child { padding-right: 0; } #fpflokttku .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #fpflokttku .gt_spanner_row { border-bottom-style: hidden; } #fpflokttku .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #fpflokttku .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #fpflokttku .gt_from_md > :first-child { margin-top: 0; } #fpflokttku .gt_from_md > :last-child { margin-bottom: 0; } #fpflokttku .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #fpflokttku .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #fpflokttku .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #fpflokttku .gt_row_group_first td { border-top-width: 2px; } #fpflokttku .gt_row_group_first th { border-top-width: 2px; } #fpflokttku .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #fpflokttku .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #fpflokttku .gt_first_summary_row.thick { border-top-width: 2px; } #fpflokttku .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #fpflokttku .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #fpflokttku .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #fpflokttku .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #fpflokttku .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #fpflokttku .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #fpflokttku .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #fpflokttku .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #fpflokttku .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #fpflokttku .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #fpflokttku .gt_left { text-align: left; } #fpflokttku .gt_center { text-align: center; } #fpflokttku .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #fpflokttku .gt_font_normal { font-weight: normal; } #fpflokttku .gt_font_bold { font-weight: bold; } #fpflokttku .gt_font_italic { font-style: italic; } #fpflokttku .gt_super { font-size: 65%; } #fpflokttku .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #fpflokttku .gt_asterisk { font-size: 100%; vertical-align: 0; } #fpflokttku .gt_indent_1 { text-indent: 5px; } #fpflokttku .gt_indent_2 { text-indent: 10px; } #fpflokttku .gt_indent_3 { text-indent: 15px; } #fpflokttku .gt_indent_4 { text-indent: 20px; } #fpflokttku .gt_indent_5 { text-indent: 25px; } #fpflokttku .katex-display { display: inline-flex !important; margin-bottom: 0.75em !important; } #fpflokttku div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after { height: 0px !important; } Demographics of COVID Testing By Group and Gender Group Gender Count client female 314 client male 290 misc adult female 1214 misc adult male 1227 other adult female 126 other adult male 97 patient female 6178 patient male 6077 unidentified male 1 From CHOP, 2020 43.6 Other languages in code chunks 43.7 Code Chunk Options Code Chunk Options Option Values Output eval TRUE/FALSE Whether or not the code is run. echo TRUE/FALSE Show or hide the code include TRUE/FALSE Whether or not the resulting output of a code chunk is displayed in the document. FALSE means that the code will run, but will not display results. include = FALSE is often used for the setup chunk. warning TRUE/FALSE Whether warnings generated from your code will be displayed in the document. message TRUE/FALSE Whether messages generated from your code will be displayed in the document. fig.align default, left, right, center Where on the page the output figure should align. Text options should be in quotes, like f ig.align = \"right\" fig.width default = 7 figure width in inches fig .height default = 7 figure height in inches error TRUE/FALSE If TRUE, will not stop building the document if there is an error in a code chunk. cache TRUE/FALSE If TRUE, will store the results and not re-run the chunk. Helpful for long, slow calculations. But watch out for this if your data change and your results do not(!!). 43.8 Try Out Other Chunk Options Try adding different chunk options, including include = FALSE eval = FALSE, echo = TRUE eval=TRUE, echo = FALSE 43.9 The setup chunk 43.10 The Easy Button - Visual Markdown Editing The mean cycle threshold in this study was r covid %&gt;% mean(ct_result, na.rm = TRUE) %&gt;% format(digits = 5) r covid %&gt;% median(ct_result, na.rm = TRUE) %&gt;% format(digits = 7) r covid %&gt;% sd(ct_result, na.rm=TRUE) %&gt;% format(digits =3) The standard deviation of the cycle threshold in this study was r covid %&gt;% mean(ct_result, na.rm = TRUE) %&gt;% format(digits = 5) r covid %&gt;% median(ct_result, na.rm = TRUE) %&gt;% format(digits = 7) r covid %&gt;% sd(ct_result, na.rm=TRUE) %&gt;% format(digits =3) ::: 43.11 A Quick Quiz Which code chunk option hides the code? eval = TRUEwarning = FALSEecho = FALSE Which code chunk always comes first, and includes libraries and data import steps? plotsetuptop_chunk What is the name of the code block (and the markup language it is written in), set off with 3 hyphens(—) at the very top of your Rmarkdown document, that tells pandoc how to format the final document? HTMLYAMLSPAMformatter What symbols do you use to make text bold in Rmarkdown? one asterisktwo asterisksunderscoresExclamation points Which {knitr} function do you use to add images to your document with a code chunk? paste()include_image()insert()insert_pic() "],["protecting-phi-protected-health-information.html", "Chapter 44 Protecting PHI (Protected Health Information) 44.1 Protecting (Not Inadvertently Sharing) PHI 44.2 Identifying PHI 44.3 Selectively Deleting PHI 44.4 Problems with PHI-free data 44.5 Encrypting PHI 44.6 Sharing synthetic data with {synthpop}", " Chapter 44 Protecting PHI (Protected Health Information) If you are working with medical data, there is a good chance that you are frequently working with Protected Health Information (PHI). PHI is any information in a medical record that can be used to identify an individual, and that was created, used, or disclosed in the course of providing a healthcare service, such as a diagnosis or treatment. PHI includes many common identifiers, such as names, addresses, dates of birth, and Social Security numbers. PHI also includes any other information that could be used to identify a patient, such as medical record numbers, photographs, and biometric data. It is CRITICAL to maintaining your credibility as a data analyst, as well as your access to medical data, that you take the necessary steps to protect PHI. This includes not sharing PHI, encrypting data, and using synthetic data when possible. 44.1 Protecting (Not Inadvertently Sharing) PHI The first important step in protecting PHI is to not share it. This means not sharing data that contains PHI, and not sharing code that contains PHI. This is especially important when backing up data to the cloud, or sharing data with collaborators. A very common way to back up data and collaborate on a shared project is to establish a repository (repo) on GitHub. It is important that you know how to use the .gitignore file to prevent PHI from being shared on GitHub. The .gitignore file is a text file that tells Git which files or folders to ignore in a project. The .gitignore file should be placed in the root directory of your project. You can include an R-specific .gitignore file when you create the repository on GitHub (this is a dropdown on the Github page when creating a new repo), or you can add it later. You can create a .gitignore file by opening a text editor, and saving the file as .gitignore. For this example, you can then add the following lines to the file: *.csv *.Rd *.RData data/ output/ These lines tell git to ignore the following kinds of files: anything that ends in .csv anything that ends in .Rd anything that ends in .RData any files in the data directory any files in the output directory So that when you share your code on GitHub, you are not sharing any PHI. 44.2 Identifying PHI Protected health information (PHI) is any information in the medical record or designated record set that can be used to identify an individual and that was created, used, or disclosed in the course of providing a health care service such as diagnosis or treatment. HIPAA regulations allow researchers to access and use PHI when necessary to conduct research. However, HIPAA applies only to research that uses, creates, or discloses PHI that enters the medical record or is used for healthcare services, such as treatment, payment, or operations. Identifying PHI in your data files is the next step in protecting PHI. Per US law, there are 18 types of data that are considered PHI. Names; All geographical subdivisions smaller than a State, including street address, city, county, precinct, zip code, and their equivalent geocodes, except for the initial three digits of a zip code, if according to the current publicly available data from the Bureau of the Census: (1) The geographic unit formed by combining all zip codes with the same three initial digits contains more than 20,000 people; and (2) The initial three digits of a zip code for all such geographic units containing 20,000 or fewer people is changed to 000. All elements of dates (except year) for dates directly related to an individual, including birth date, admission date, discharge date, date of death; and all ages over 89 and all elements of dates (including year) indicative of such age, except that such ages and elements may be aggregated into a single category of age 90 or older; Phone numbers; Fax numbers; Electronic mail addresses; Social Security numbers; Medical record numbers; Health plan beneficiary numbers; Account numbers; Certificate/license numbers; Vehicle identifiers and serial numbers, including license plate numbers; Device identifiers and serial numbers; Web Universal Resource Locators (URLs); Internet Protocol (IP) address numbers; Biometric identifiers, including finger and voice prints; Full face photographic images and any comparable images; and Any other unique identifying number, characteristic, or code (note this does not mean the unique code assigned by the investigator to code the data [aka study_id]) 44.3 Selectively Deleting PHI If this will not affect your data wrangling, you can use the select function in {dplyr} to remove PHI from your data files. For example, if you have a data file called data, you can use the following code to remove PHI: data_no_phi &lt;- data |&gt; select(-name, -address, -dob, -phone, -email, -ssn, -mrn, -hpb, -account, -cert, -vehicle, -device, -url, -ip, -biometric, -image, -date_admitted) And then be sure that the data file is in your .gitignore file, and you can share the data_no_phi file with collaborators. You might even want to create a folder called data_with_phi and a folder called data_no_phi to keep track of your data files separately by PHI status. The data_with_phi folder can show up in your .gitignore file as data_with_phi/, so that you are not sharing PHI. 44.4 Problems with PHI-free data PHI-free data are great for sharing and collaborating, but may be problematic for data wrangling. You may find that you need some PHI fields in your early steps of data wrangling to match and join data files from different sources. It is not uncommon to need some PHI to be the unique IDs to conduct data wrangling and analyses. You may need a medical record number to join data from different data sources. You may need dates to determine the interval between events, like the last screening colonoscopy and a colon cancer diagnosis. You may need a patient’s age to determine if they are eligible for a study. There are some workarounds. You can Keep data with PHI in a separate folder (a data_with_phi folder) which gets added to your .gitignore file, then after the joins are done and PHI-free data are created, save the PHI-free data to a data_no_phi folder. Use phony dates shifted by a random number of days to that the dates are not real, but you can still calculate intervals (note that this is an export option in REDCap) 44.5 Encrypting PHI You can also keep, but encrypt your data fields, using strong RSA (2048 bit) encryption, with the {encryptr} package. This package can be installed from CRAN, with install.packages(\"encryptr\"). You can find the full documentation at https://encrypt-r.org/. The basis of RSA encryption is a public/private key pair and is the method used of many modern encryption applications. The public key can be shared with collaborators and is used to encrypt the information. The private key is sensitive and should not be shared. The private key requires a password to be set. This password should follow modern rules on password complexity. You know what you should do. If lost, it cannot be recovered. 44.5.1 Generating Public and Private keys The genkeys() function generates a public and private key pair. The public key id_rsa.pub can then be shared with collaborators. The private key id_rsa should be kept secure and not shared. It should be listed in your .gitignore file. Set up a new project repository on your GitHub site, and copy the SSH to start a new project in RStudio using version control. Then run the code below (a novel password will be required), then open your .gitignore file in the project, and add id_rsa to the file. library(encryptr) genkeys() # &gt; Private key written with name &#39;id_rsa&#39; # &gt; Public key written with name &#39;id_rsa.pub&#39; You can open a new project and test this with the gp dataset provided with the [encryptr} package. Try it out! data(gp) head(gp) ## # A tibble: 6 × 12 ## organisation_code name address1 address2 address3 city county postcode ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 S10002 MUIRHEAD M… LIFF RO… MUIRHEAD &lt;NA&gt; DUND… ANGUS DD2 5NH ## 2 S10017 THE BLUE P… CRIEFF … KING ST… &lt;NA&gt; CRIE… PERTH… PH7 3SA ## 3 S10036 ABERFELDY … TAYBRID… &lt;NA&gt; &lt;NA&gt; ABER… PERTH… PH15 2BL ## 4 S10060 ABERFELDY … TAYBRID… &lt;NA&gt; &lt;NA&gt; ABER… PERTH… PH15 2BH ## 5 S10106 GROVE HEAL… 129 DUN… BROUGHT… &lt;NA&gt; DUND… ANGUS DD5 1DU ## 6 S10125 ALYTH HEAL… NEW ALY… ALYTH &lt;NA&gt; BLAI… PERTH… PH11 8EQ ## # ℹ 4 more variables: opendate &lt;date&gt;, closedate &lt;date&gt;, telephone &lt;chr&gt;, ## # practice_type &lt;dbl&gt; You can see a listing of the 1212 general NHS practices in Scotland, and you can imagine that you might want to encrypt some fields (telephone, etc.) and delete some unneeded ones in this data before sharing it publicly on GitHub. library(dplyr) gp_encrypt = gp %&gt;% select(-c(name, address1, address2, address3)) %&gt;% encrypt(postcode, telephone) gp_encrypt ## # A tibble: 1,212 × 8 ## organisation_code city county postcode opendate closedate telephone ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;date&gt; &lt;chr&gt; ## 1 S10002 DUNDEE ANGUS 35cb751… 1995-05-01 NA 6534e22d… ## 2 S10017 CRIEFF PERTH… 3c38626… 1996-04-06 NA 0f281153… ## 3 S10036 ABERFELDY PERTH… 4568eec… 2008-04-01 NA 03a0795c… ## 4 S10060 ABERFELDY PERTH… 344bb19… 1975-04-01 2008-03-31 5abdda78… ## 5 S10106 DUNDEE ANGUS 4650b2f… 1996-07-08 NA 7b7490b8… ## 6 S10125 BLAIRGOWRIE PERTH… 562ed9a… 1979-10-01 NA 3597ce2b… ## 7 S10182 ARBROATH ANGUS 4fa1894… 1977-10-01 NA 899bfd74… ## 8 S10233 ARBROATH ANGUS 835bfe0… 1986-08-01 NA 754332a4… ## 9 S10286 ARBROATH ANGUS 56f5f57… 1975-08-01 NA 778cce49… ## 10 S10322 ARBROATH ANGUS 89e8b55… 1971-10-01 NA 64c4a0c9… ## # ℹ 1,202 more rows ## # ℹ 1 more variable: practice_type &lt;dbl&gt; You can see that postcode and telephone are now encrypted. You can share this data on GitHub, and collaborators can use the private key to decrypt the data when necessary. Decryption requires the private key generated using genkeys() and the password set at the time. The password and file are not replaceable so need to be kept safe and secure. The code below will ask you for the password you set when you generated the keys before it provides the decrypted data. gp_encrypt %&gt;% decrypt(postcode, telephone) ## # A tibble: 1,212 × 8 ## organisation_code city county postcode opendate closedate telephone ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;date&gt; &lt;chr&gt; ## 1 S10002 DUNDEE ANGUS DD2 5NH 1995-05-01 NA 01382 58… ## 2 S10017 CRIEFF PERTH… PH7 3SA 1996-04-06 NA 01764 65… ## 3 S10036 ABERFELDY PERTH… PH15 2BL 2008-04-01 NA 01887 82… ## 4 S10060 ABERFELDY PERTH… PH15 2BH 1975-04-01 2008-03-31 01887 82… ## 5 S10106 DUNDEE ANGUS DD5 1DU 1996-07-08 NA 01382 77… ## 6 S10125 BLAIRGOWRIE PERTH… PH11 8EQ 1979-10-01 NA 01828 63… ## 7 S10182 ARBROATH ANGUS DD11 1AD 1977-10-01 NA 01241 43… ## 8 S10233 ARBROATH ANGUS DD11 1EN 1986-08-01 NA 01241 87… ## 9 S10286 ARBROATH ANGUS DD11 1ES 1975-08-01 NA 01241 87… ## 10 S10322 ARBROATH ANGUS DD11 1ES 1971-10-01 NA 01241 87… ## # ℹ 1,202 more rows ## # ℹ 1 more variable: practice_type &lt;dbl&gt; As an alternative to increase data security, you can store the PHI encrypted data in a separate ‘lookup table’ that is not shared on GitHub. This lookup table can be used to decrypt the data when necessary. This can be accomplished by adding a lookup argument to the encrypt function. The lookup argument creates a data frame that contains the PHI data that was encrypted. gp_encrypt &lt;- gp %&gt;% select(-c(name, address1, address2, address3)) %&gt;% encrypt(postcode, telephone, lookup = TRUE) # Lookup table object created with name &#39;lookup&#39; # Lookup table written to file with name &#39;lookup.csv&#39; gp_encrypt ## # A tibble: 1,212 × 8 ## organisation_code city county postcode opendate closedate telephone ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;date&gt; &lt;chr&gt; ## 1 S10002 DUNDEE ANGUS 35cb751… 1995-05-01 NA 6534e22d… ## 2 S10017 CRIEFF PERTH… 3c38626… 1996-04-06 NA 0f281153… ## 3 S10036 ABERFELDY PERTH… 4568eec… 2008-04-01 NA 03a0795c… ## 4 S10060 ABERFELDY PERTH… 344bb19… 1975-04-01 2008-03-31 5abdda78… ## 5 S10106 DUNDEE ANGUS 4650b2f… 1996-07-08 NA 7b7490b8… ## 6 S10125 BLAIRGOWRIE PERTH… 562ed9a… 1979-10-01 NA 3597ce2b… ## 7 S10182 ARBROATH ANGUS 4fa1894… 1977-10-01 NA 899bfd74… ## 8 S10233 ARBROATH ANGUS 835bfe0… 1986-08-01 NA 754332a4… ## 9 S10286 ARBROATH ANGUS 56f5f57… 1975-08-01 NA 778cce49… ## 10 S10322 ARBROATH ANGUS 89e8b55… 1971-10-01 NA 64c4a0c9… ## # ℹ 1,202 more rows ## # ℹ 1 more variable: practice_type &lt;dbl&gt; You can then add lookup.csv to your .gitignore file, and share the main file for collaborators. Decryption is performed by passing the lookup object or file to the decrypt() function. gp_encrypt %&gt;% decrypt(postcode, telephone, lookup_object = lookup) ## Error: object &#39;lookup&#39; not found Learn more about how to encrypt PHI-containing fields from the documentation of {encryptr} at https://encrypt-r.org/. 44.6 Sharing synthetic data with {synthpop} If you need to share data with PHI, you can use the {synthpop} package to create synthetic data that can be shared. The {synthpop} package is a tool for creating synthetic versions of sensitive or PHI data. It will create a ‘synthetic’ version of the data that is not real but has the same statistical properties as the original data. The synthetic data can be shared without concern for privacy. You will find that your analytic code will all work, but will frequently be (estimates, p values) a few decimal places off from your actual data. This is because the synthetic data is not real, but is a close approximation of the real data with a bit of random noise added. Synthetic data will allow anyone to run your code with near-real data, and get similar results, without disclosing any PHI. You can find the full documentation at https://cran.r-project.org/web/packages/synthpop/synthpop.pdf, and a ** Getting Started ** page at https://www.synthpop.org.uk/get-started.html. You can install synthpop from CRAN with install.packages(\"synthpop\"). Then use library(synthpop) to load the package. Let’s start with the SD2011 survey dataset provided with the {synthpop} package. This dataset contains 5000 records of a 2011 survey in Poland. The dataset contains 35 variables. Run the code below to get a preview of this dataset, and a subset called mydata with only 10 variables. data(SD2011) mydata &lt;- SD2011 |&gt; select(sex, agegr, edu, socprof, marital, depress, trust, trustfam, trustneigh, income) glimpse(mydata) ## Rows: 5,000 ## Columns: 10 ## $ sex &lt;fct&gt; FEMALE, MALE, FEMALE, FEMALE, FEMALE, MALE, FEMALE, MALE, F… ## $ agegr &lt;fct&gt; 45-59, 16-24, 16-24, 65+, 45-59, 16-24, 35-44, 35-44, 35-44… ## $ edu &lt;fct&gt; VOCATIONAL/GRAMMAR, VOCATIONAL/GRAMMAR, VOCATIONAL/GRAMMAR,… ## $ socprof &lt;fct&gt; RETIRED, PUPIL OR STUDENT, PUPIL OR STUDENT, RETIRED, SELF-… ## $ marital &lt;fct&gt; MARRIED, SINGLE, SINGLE, WIDOWED, MARRIED, SINGLE, MARRIED,… ## $ depress &lt;dbl&gt; 6, 0, 0, 16, 4, 5, 2, 4, 0, 6, 0, 6, 4, 3, 3, 0, 11, 11, 1,… ## $ trust &lt;fct&gt; ONE CAN`T BE TOO CAREFUL, IT`S DIFFICULT TO TELL, MOST PEOP… ## $ trustfam &lt;fct&gt; YES, YES, YES, NO, YES, YES, YES, YES, NO OPINION, YES, NO … ## $ trustneigh &lt;fct&gt; NO, NO OPINION, NO, YES, YES, NO OPINION, NO OPINION, YES, … ## $ income &lt;dbl&gt; 800, 350, NA, 900, 1500, -8, 2000, 1197, 580, 1400, 1500, 1… There are 603 income values listed as ‘-8’ in the dataset. These are missing values. You can replace these with NA using the code below. library(naniar) mydata &lt;- mydata |&gt; replace_with_na(replace = list(income = -8)) You can now create a synthetic version of the data using the syn function. The syn function requires the data, and the seed. The seed is used to ensure reproducibility. The syn function will create a synthetic version of the data that can be shared without concern for privacy. Note the you need a constant seed to get the same result each time. There is some randomness in the synthesis that will produce different results each time without the same seed. The syn default method is CART, which stands for Classification and Regression Trees. This highly adaptive method is used to create synthetic data that is similar to the original data. There are many available methods to synthesize new variables. Each variable is synthesized in order of appearance in the dataset, using the data from the previous variables. If you want to model for a particular variable, you may want to move that variable to the end of the dataset (as we did with income), to ensure that the other variables are synthesized first, and each variable is synthesized conditional on all of the previously synthesized variables. This preserves their statistical relationships for correlations or regression modeling. The synthesis initially generates a synds object, which can be used for initial comparisons and modeling with special functions that end with .synds, like glm.synds and lm.synds. Then the write.syn function will return a standard synthetic dataset in formats like csv and RData that can be used for analysis. Run the code block below to do a basic synthesis. syn_data &lt;- syn(mydata, seed = 123) ## ## Synthesis ## ----------- ## sex agegr edu socprof marital depress trust trustfam trustneigh income Additional arguments to syn can include: - method - the method used to create the synthetic data. The default is “cart”. Other options are “norm”, “random forests”, “ranger”, “polr”, and “logreg”, among many. You use a vector of methods to set a different method for each variable in the dataset. - m - the number of rows in the synthetic data. You can make it smaller or larger than the original data. The default is the same size as the original data m = nrow(original). - maxfaclevels - the maximum number of factor levels in the synthetic data. The default is 60. Beyond this is considered numeric. Large numbers for maxfaclevels can lead to slow computational speed. - numtocat - a vector of numeric variables to convert to categorical factors. The default is NULL. - catgroups - a vector of integers of the same length as numtocat, which represents the number of factor levels for each factor variable. compare(syn_data, mydata, stats = c(&quot;counts&quot;, &quot;means&quot;, &quot;medians&quot;, &quot;sds&quot;)) ## Calculations done for sex ## Calculations done for agegr ## Calculations done for edu ## Calculations done for socprof ## Calculations done for marital ## Calculations done for depress ## Calculations done for trust ## Calculations done for trustfam ## Calculations done for trustneigh ## Calculations done for income ## ## Comparing percentages observed with synthetic ## Press return for next variable(s): ## Press return for next variable(s): ## ## Selected utility measures: ## pMSE S_pMSE df ## sex 0.000008 0.638460 1 ## agegr 0.000081 1.079941 6 ## edu 0.000034 0.675029 4 ## socprof 0.000112 0.998075 9 ## marital 0.000141 1.886650 6 ## depress 0.000012 0.239234 4 ## trust 0.000013 0.344532 3 ## trustfam 0.000051 1.353151 3 ## trustneigh 0.000089 2.383880 3 ## income 0.000136 2.182507 5 You can see that the synthetic data are very similar to the original data. You can write this data to a file with the write.syn function to share this synthetic data with collaborators without concern for privacy. In the code block below, you can write the synthetic data to a CSV file, and then read it back in to check that it is looks right. write.syn(object = syn_data, convert.factors = TRUE, filename = &quot;syn_SD&quot;, filetype = &quot;csv&quot;, # options include RData, Stata, SAS data.labels = TRUE ) ## Synthetic data exported as csv file(s). ## Information on synthetic data written to ## /Users/peterhiggins/Documents/RCode/rmrwr-book/synthesis_info_syn_SD.txt read.csv(&quot;syn_SD.csv&quot;) -&gt; syn_SD glimpse(syn_SD) ## Rows: 5,000 ## Columns: 10 ## $ sex &lt;chr&gt; &quot;MALE&quot;, &quot;FEMALE&quot;, &quot;MALE&quot;, &quot;MALE&quot;, &quot;FEMALE&quot;, &quot;FEMALE&quot;, &quot;MALE… ## $ agegr &lt;chr&gt; &quot;65+&quot;, &quot;65+&quot;, &quot;25-34&quot;, &quot;35-44&quot;, &quot;25-34&quot;, &quot;16-24&quot;, &quot;45-59&quot;, … ## $ edu &lt;chr&gt; &quot;PRIMARY/NO EDUCATION&quot;, &quot;VOCATIONAL/GRAMMAR&quot;, &quot;POST-SECONDA… ## $ socprof &lt;chr&gt; &quot;RETIRED&quot;, &quot;RETIRED&quot;, &quot;EMPLOYED IN PUBLIC SECTOR&quot;, &quot;EMPLOYE… ## $ marital &lt;chr&gt; &quot;MARRIED&quot;, &quot;WIDOWED&quot;, &quot;SINGLE&quot;, &quot;MARRIED&quot;, &quot;SINGLE&quot;, &quot;SINGL… ## $ depress &lt;int&gt; 11, 14, 0, 3, 11, 2, 0, 3, 7, 4, 2, 2, 2, 0, 1, 11, 16, 1, … ## $ trust &lt;chr&gt; &quot;ONE CAN`T BE TOO CAREFUL&quot;, &quot;ONE CAN`T BE TOO CAREFUL&quot;, &quot;ON… ## $ trustfam &lt;chr&gt; &quot;YES&quot;, &quot;YES&quot;, &quot;YES&quot;, &quot;NO OPINION&quot;, &quot;YES&quot;, &quot;YES&quot;, &quot;YES&quot;, &quot;YE… ## $ trustneigh &lt;chr&gt; &quot;YES&quot;, &quot;YES&quot;, &quot;YES&quot;, &quot;NO&quot;, &quot;NO OPINION&quot;, &quot;NO OPINION&quot;, &quot;YES… ## $ income &lt;int&gt; 2000, 990, 1800, 3000, 1000, 1400, 3300, 1500, 500, 1000, 2… One small issue is that string factors are synthesized as character vectors. If these are meant to be ordered factors, we have to redefine these as ordered factors if we want the same ordering which is helpful for modeling. We can ‘borrow’ the order from the original dataset. Run the code block below to redefine six variables as ordered factors. syn_SD$sex &lt;- factor(syn_SD$sex, levels = levels(mydata$sex)) syn_SD$agegr &lt;- factor(syn_SD$agegr, levels = levels(mydata$agegr)) syn_SD$edu &lt;- factor(syn_SD$edu, levels = levels(mydata$edu)) syn_SD$socprof &lt;- factor(syn_SD$socprof, levels = levels(mydata$socprof)) syn_SD$marital &lt;- factor(syn_SD$marital, levels = levels(mydata$marital)) Now we can compare the original data with the synthetic data by modeling a linear regression for income with each dataset in turn orig_model &lt;- lm(income ~ sex + agegr + edu + socprof + marital, data = mydata) broom::tidy(orig_model) ## # A tibble: 23 × 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 1149. 106. 10.8 6.63e-27 ## 2 sexFEMALE -510. 37.4 -13.6 2.74e-41 ## 3 agegr25-34 338. 103. 3.27 1.10e- 3 ## 4 agegr35-44 604. 109. 5.55 3.01e- 8 ## 5 agegr45-59 467. 108. 4.35 1.43e- 5 ## 6 agegr60-64 526. 127. 4.14 3.57e- 5 ## 7 agegr65+ 476. 132. 3.62 3.03e- 4 ## 8 eduVOCATIONAL/GRAMMAR 108. 55.1 1.97 4.95e- 2 ## 9 eduSECONDARY 414. 53.6 7.72 1.46e-14 ## 10 eduPOST-SECONDARY OR HIGHER 1158. 62.4 18.6 1.13e-73 ## # ℹ 13 more rows syn_model &lt;- lm(income ~ sex + agegr + edu + socprof + marital, data = syn_SD) broom::tidy(syn_model) ## # A tibble: 23 × 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 1231. 107. 11.5 3.85e-30 ## 2 sexFEMALE -455. 36.9 -12.3 2.80e-34 ## 3 agegr25-34 164. 104. 1.57 1.17e- 1 ## 4 agegr35-44 502. 111. 4.53 5.97e- 6 ## 5 agegr45-59 381. 109. 3.49 4.94e- 4 ## 6 agegr60-64 500. 130. 3.84 1.28e- 4 ## 7 agegr65+ 329. 131. 2.52 1.18e- 2 ## 8 eduVOCATIONAL/GRAMMAR 137. 56.0 2.46 1.41e- 2 ## 9 eduSECONDARY 479. 54.3 8.83 1.58e-18 ## 10 eduPOST-SECONDARY OR HIGHER 1014. 62.9 16.1 1.11e-56 ## # ℹ 13 more rows You can see that the coefficients are very similar in the two models, between the original and synthetic data. This is a good sign that the synthetic data is a good approximation of the original data. These estimates and p values will never be exactly the same, as then you would not have a de-identified synthetic dataset, but they should be close enough for most purposes. "],["building-data-pipelines-with-targets.html", "Chapter 45 Building Data Pipelines with {targets} 45.1 What Does {targets} Do? 45.2 Air Quality Analysis 45.3 Your Turn - A Tuberculosis Analysis Pipeline 45.4 Resetting functions before the Pipeline is Built 45.5 Editing the _targets.R File 45.6 Next Steps", " Chapter 45 Building Data Pipelines with {targets} This chapter is part of the Reproducibility pathway. Packages needed for this chapter include {targets}, {tarchetypes}, {gt}, and {gtsummary}. The {targets} package is a pipeline toolkit for R that allows you to define a sequence of R scripts, functions, and targets, and then run this pipeline in a reproducible and efficient way. The package is designed to help you manage the complexity of your multiple analysis scripts, and to help you keep track of the dependencies between your scripts. The package is particularly useful for large-scale data analysis projects, where you have many scripts that depend on each other, and where you need to keep track of the dependencies between your scripts. The {targets} package is designed around the idea of a “target”, which is a unit of work that can be run independently of other targets. A target is usually the output object, which is often a tibble, a formatted table, or a plot. A function converts an input data object into a target (output data object). Each function is usually derived from a working data script. Each target depends on the input data and the functions that are used to create it. Modular Scripts become Functions To Build Pipelines with {targets} As you build up complex workflows that are sequential, or branching, or unite two different pathways, it helps to have modular scripts that handle distinct functions like 01_read_data 02_cleaning_data 03_wrangling_data 04_making_tables (input is clean_data, output is tables) 05_modeling_data (input is clean_data, output is models) 06_visualizing_data (input is clean_data,output is plots) Previously, we have set these up as numbered scripts in an RStudio Project, which are meant to be run in order, and have data inputs and object outputs (data tables, models, plots, etc., which can be saved with saveRDS or ggsave) 45.1 What Does {targets} Do? The {targets} package helps you use these scripts (after being converted to functions), as a pipeline of targets. The {targets} package provides a set of functions for defining targets, running targets, and managing the dependencies between targets. The {targets} package can detect which intermediate steps have already been run and are up-to-date, versus those that have changed scripts or input data, and are out-of-date (and need to be re-run). For small projects, the {targets} package may feel like overkill, but for complex projects, it can greatly help you keep track of the dependencies between your scripts, and help you run your scripts in the correct order in a reproducible and efficient way. If you have an early step in your data pipeline that uses very large data, is computationally intensive, or simply takes a long while, you do not need to re-run it if {targets} can see that the input data and the data processing functions have not changed. You can be more efficient, and just update the later (downstream) functions and run these. Let’s start with the example in the {targets} R user manual, using airquality data from base R. A walkthrough can be found in this 4 minute video at https://vimeo.com/700982360. Take a few minutes to watch the video to get the basic idea of how {targets} works. The {targets} package is designed to get your computer to help you manage the complexity of your data analysis scripts. In order to get the computer’s help with this, we will be writing code with very specific syntax in very specific files in very specific locations that the computer understands. This makes it pretty easy to make syntax errors and get error messages. If you get an error message, don’t panic! Just read the error message, and try to understand what it is telling you. The {targets}User Manual has a whole chapter on debugging pipelines. The {targets} package is a powerful tool, but it can be a bit finicky. Be patient with yourself as you learn how to use it. 45.2 Air Quality Analysis Now let’s replicate what Will Landau (author of {targets}, employed at Eli Lilly) just narrated. First, go to your local RStudio and open a File/New Project. Choose a New Directory/New Project, and call it something like ‘airquality’. then Click on the Create Project button. Then, add a folder named ‘R’ to the project in the Files tab in RStudio by clicking on the folder at top left with a green + sign. This is where you will store your functions. 45.2.1 Prepping The Functions.R file Now, click to enter the R folder you just created in the project, and within the R folder, create a new R script (New File is just to the right of the New Folder button in the Files tab) called ‘functions.R’ and copy the code below (use the copy icon in the top right corner of the code chunk) into this R script. This script will contain all 3 of the functions needed to run this targets pipeline on the airquality data. Then save the script functions.R. get_data &lt;- function(file) { read_csv(file, col_types = cols()) %&gt;% filter(!is.na(Ozone)) } fit_model &lt;- function(data) { lm(Ozone ~ Temp, data) %&gt;% coefficients() } plot_model &lt;- function(model, data) { ggplot(data) + geom_point(aes(x = Temp, y = Ozone)) + geom_abline(intercept = model[1], slope = model[2]) } 45.2.2 Checking Your Functions Now, to check that everything is running OK, copy and run (locally in the RStudio Console pane) the code chunk below at the cursor - paste and press Enter/Return. This will load the packages and functions, write the data.csv file, then run each function to get and process the data, then finally draw the plot in your Plots tab. library(dplyr) library(ggplot2) library(tibble) library(readr) source(&quot;R/functions.R&quot;) airquality |&gt; write.csv(&quot;data.csv&quot;, row.names = FALSE) data &lt;- get_data(&quot;data.csv&quot;) model &lt;- fit_model(data) plot &lt;- plot_model(model, data) plot This should all be working, and you should see the resulting plot in the Plots tab. If not, go back and check the functions. This is all good, but it is still functions/scripts, without a {targets} pipeline. But now all the prep work is done, with the initial data file in a new project, and all the coding/processing in a functions script within the R folder. Oftentimes you will have a working script and have to convert it to functions (unless you write your code in functions already) as part of the prep work for a {targets} pipeline. This happens fairly often as you start to scale up projects in size and complexity. 45.2.3 Set Up the Pipeline Now you are ready to build a pipeline. Run the code chunk below to load {targets} and run the use_targets() function. This will create a new file called ‘_targets.R’ in the root of your project. This script will contain the pipeline code that you will build up in the next steps. library(targets) use_targets() Click on your Files tab and go up one level from the R folder to the root of the project, to confirm that _targets.R file now exists in the root of your project. This file should now be open in your Source pane, and labeled on the tab at the top as _targets.R. This is where you will build up your pipeline. Within the _targets.R file, scroll down to the tar_option_set() function. This function sets the options for the pipeline, including all of the packages that you will need. For this pipeline, we will need “tibble” “readr” “ggplot2” “dplyr” For more complex pipelines, we will need more packages. Take a moment to add the packages to the list (which starts with only “tibble”), Make sure each one is in quotes, and separated by commas (but without a comma at the end). Confirm that there are no syntax errors, and save the file _targets.R. Now scroll down to the list() function at the end with two tar_targets inside of it. Our code will need four targets for the pipeline. These target output objects are: file data model plot Before we replace the two existing tar_targets, let’s inspect them. Notice that each of the two tar_target() functions currently shown has a first argument that is the target, or output object. The second argument is the function or command that generates the output object (or the datafile if we are just reading in data). The argument for each of these functions is the input object for that function, which is usually generated in the preceding tar_target() function. This pipeline is essentially a chain of input objects transformed to output objects, which become the input objects for the next function in the pipeline. Looking at our planned airquality pipeline (see code chunk below below), the first target is file the second target is data, which is generated by the get_data() function, which uses the file target as input the third target is model, which is generated by the fit_model() function, which uses the data target as input the fourth target is plot, which is generated by the plot_model() function, which uses the model and data targets as input Copy the code chunk below and replace the tar_target() lines (replace everything from the beginning of list( to the closing parenthesis) (everything from line 52 to line 62) with the code below. list( tar_target(file, &quot;data.csv&quot;, format = &quot;file&quot;), tar_target(data, get_data(file)), tar_target(model, fit_model(data)), tar_target(plot, plot_model(model, data) ) ) Make sure that your list ends with 3 consecutive close parentheses (and a red parenthesis if you are using rainbow parentheses). Check that all the parentheses and commas are correct, with no syntax errors, then save _targets.R again. 45.2.4 Pre-Build Checks Now we are ready to start building the pipeline. Let’s start with two pre-build checks. First, run tar_manifest() locally in your project in the Console as shown below. This will check the pipeline and show you the status of each target. tar_manifest(fields = command) This should generate a table in your console with two columns, showing the name of each target, and the command that generates that target. tar_manifest Output Note that the file target will not have a proper function to generate it, but something that looks like \"\\\"data.csv\\\"\" If you see any errors and don’t get a 4 x 2 table, you will need to fix either the functions.R file and/or _targets.R before proceeding. Now we can visualize our pipeline by copying and running the code chunk below in the Console. This will generate a graph of the pipeline, showing the targets and the dependencies between them. The graph should show the four targets, with the file target at the left, and the plot target at the far right. The data target depends on the file target, the model target depends on the data target, and the plot target depends on the model and data targets. There should be a continuous flow from left to right, though it can branch or unite in more complex workflows. As this is a new pipeline, each target will be color coded (a blue-green) as “Outdated”, as each target has not been built yet. tar_visnetwork() New Pipeline ### Building the Pipeline Now that the pre-build checks are good, we are ready to build the pipeline. Run the function below in your local project to build the pipeline. tar_make() As this is a new pipeline, it will run (dispatch) every function and create every target anew. The output in the console will tell you when it dispatches each target and when it completes building the target output object, along with how long it takes to run the whole pipeline. tar_make Output The output objects are also saved to binary files in the _targets/objects/ folder (data, model, and plot). You can check these files (with tar_read(object), rather than clicking on them, as they are binary files and woin’t display like normal R objects) to see the output objects, and this will load these objects into your R session to check them. For example, to load the plot object, you would run the code below. tar_read(plot) Because these target objects are stored and tracked by {targets}, if you re-run tar_make() without any changes to the data or the function code, it will skip all the functions, and complete the pipeline very quickly. Only if changes are made to the data or code will the pipeline re-run the functions that are affected by the changes. This is a key feature of {targets} that makes it so powerful for efficient, reproducible research. If you now run tar_visnetwork() again, you will see that the pipeline is now complete, with all the targets built (black). The graph should show all the targets as black, indicating that they are up-to-date. Run tar_make() again to demonstrate this. You should see that the pipeline runs much faster this time, as nothing needs to be to re-run. We can demonstrate the tracking ability of {targets} my making minor changes to the data or the functions. 45.2.5 Changing the Pipeline As an example, let’s change the model to make the model predictor Wind instead of Temp. Copy the code below to replace the fit_model() function in the R/functions.R script. Note that you can also simply type Wind in place of Temp in the function. Save the edited functions.R file. This will change the model output, and the pipeline will have to re-run the model and plot targets, but not the data or file targets. fit_model &lt;- function(data) { lm(Ozone ~ Wind, data = data) |&gt; coefficients() } Now re-run tar_visnetwork() to see the changes in the pipeline. The fit_model function, and the model and plot targets that depend on the model function upstream should now be blue-green, indicating that they are out of date and need to be re-run. Out of Date Network Run tar_make() to re-run the pipeline. You should see that only the model and plot targets are re-run, while the data and file targets are skipped. Re-running tar_visnetwork again will show that the whole pipeline is now up-to-date (black) again. This is the power of {targets} - it tracks the dependencies between functions and data, and only re-runs the parts of the pipeline that are affected by changes. This makes it much faster and more efficient than re-running the whole analysis every time you make a change. 45.3 Your Turn - A Tuberculosis Analysis Pipeline Now it is your turn to convert a set of scripts into functions, then into a targets pipeline. The code block below represents a 5-step analysis of World health Organization (WHO) data on tuberculosis, which are included in the {tidyr} package. Start by opening a New Project in RStudio, named something like “who_tb_analysis”. Go to the Files tab, then create a new Folder in the project called “R”. Within this folder, create a new File (an RScript) named “functions.R”. # these functions require: dplyr, gt, gtsummary, ggplot2, tidyr, scales # 01 read in data who_data &lt;- tidyr::who # 02 clean data who_data %&gt;% pivot_longer( cols = new_sp_m014:newrel_f65, names_to = c(&quot;diagnosis&quot;, &quot;gender&quot;, &quot;age&quot;), names_pattern = &quot;new_?(.*)_(.)(.*)&quot;, values_to = &quot;count&quot; ) |&gt; na.omit() -&gt; who_clean # 03 make table who_clean |&gt; group_by(country) |&gt; summarize(Case_Count = sum(count)) |&gt; slice_max(Case_Count, n= 10) |&gt; gt::gt() |&gt; gt::fmt_number(columns = Case_Count, use_seps = TRUE,decimals = 0) # 04 Model case counts model &lt;- lm(count ~ diagnosis + gender + age, data = who_clean ) model |&gt; gtsummary::tbl_regression() # 05 Plot who_clean |&gt; group_by( year) |&gt; summarize(sum = sum(count)) |&gt; ggplot(aes(x= year, y = sum)) + geom_point() + labs(title = &quot;WHO Count of TB Cases by Year&quot;, y = &quot;Cases&quot;, x = &quot;Year&quot;) + scale_y_continuous(labels = label_number(scale = 1e-6, suffix = &quot;M&quot;)) + theme(legend.position = &quot;none&quot;) This is a pretty typical 5-step analysis script. The first step reads in the data, the second step cleans the data, the third step makes a table, the fourth step models the data, and the fifth step plots the data. Run the script code above in your local session to test out the script, and get a sense of the data. Inspect the inputs and outputs of each step to understand the data and the analysis. 45.3.1 Making new Functions Now we will convert each of these small scripts into a function, and save these in the functions.R file within the R folder. This can be a big part of the prep work in building a {targets} pipeline. You can try this yourself if you are practicing converting scripts to functions, or you can just click on the button to reveal the solution, and copy the code below into the functions.R file. Functions Solution # 01 read in data read_data &lt;- function(file){ who_data &lt;- read_csv(file, col_types = cols()) } # 02 clean data clean_data &lt;- function(who_data){ who_data |&gt; pivot_longer( cols = new_sp_m014:newrel_f65, names_to = c(&quot;diagnosis&quot;, &quot;gender&quot;, &quot;age&quot;), names_pattern = &quot;new_?(.*)_(.)(.*)&quot;, values_to = &quot;count&quot; ) |&gt; na.omit() -&gt; who_clean } # 03 make table make_table &lt;- function(who_clean){ who_clean |&gt; group_by(country) |&gt; summarize(Case_Count = sum(count)) |&gt; slice_max(Case_Count, n=10) |&gt; gt::gt() |&gt; gt::fmt_number( columns = Case_Count, use_seps = TRUE, decimals = 0) } # 04 Model case counts model_cases &lt;- function(who_clean){ model &lt;- lm(count ~ diagnosis + gender + age, data = who_clean) model |&gt; gtsummary::tbl_regression() } # 05 Plot plot_data &lt;- function(who_clean){ plot &lt;- who_clean |&gt; group_by( year) |&gt; summarize(sum = sum(count)) |&gt; ggplot(aes(x= year, y = sum)) + geom_point() + labs(title = &quot;WHO Count of TB Cases by Year&quot;, y = &quot;Cases&quot;, x = &quot;Year&quot;) + scale_y_continuous(labels = label_number(scale = 1e-6, suffix = &quot;M&quot;)) + theme(legend.position = &quot;none&quot;) return(plot) } After copying in the code, now we have to save the functions.R script. 45.3.2 Testing functions We can test the new functions, to make sure they work, but first we have to make two (temporary) minor modifications to make them work outside of the pipeline, for complicated Environment reasons. For the first function, change the assignment arrow in the function to a double arrowhead, as shown below: # 01 read in data read_data &lt;- function(file){ who_data &lt;&lt;- read_csv(file, col_types = cols()) } This will put who_data into the global environment. For the second function, change the assignment arrow (near the end, after na.omit() in the function to a double arrowhead, as shown below: # 02 clean data clean_data &lt;- function(who_data){ who_data |&gt; pivot_longer( cols = new_sp_m014:newrel_f65, names_to = c(&quot;diagnosis&quot;, &quot;gender&quot;, &quot;age&quot;), names_pattern = &quot;new_?(.*)_(.)(.*)&quot;, values_to = &quot;count&quot; ) |&gt; na.omit() -&gt;&gt; who_clean } This will put who_clean into the global environment. Now save this temporary version of functions.R. Copy and run the lines of code below in the Console to test the functions. Examine the inputs and the output (target) objects (there will be a quiz). library(tidyverse) library(scales) library(gt) library(gtsummary) tidyr::who |&gt; write_csv(&quot;who_data.csv&quot;) source(&quot;R/functions.R&quot;) # this loads the functions into the R session read_data(&#39;who_data.csv&#39;) clean_data(who_data) make_table(who_clean) model_cases(who_clean) plot_data(who_clean) If all of the functions are working, this should have produced: who_data in the Environment pane who_clean in the Environment pane A table of the top 10 countries with the most cases in the Viewer tab A table from a regression model in the Viewer tab A plot of the data, with rising cases over time in the Plots tab 45.3.2.1 Understanding the data (green answers are correct) What is the name of the raw data object? tb_worldwho_datawho_cleanwho_tbwho_tb_clean What is the name of the cleaned data object? tb_worldwho_datawho_cleanwho_tbwho_tb_clean How is it the clean data object different from the raw data? shinierfewer countriesmuch tallermore yearsless sputum How are the age groups in the data defined? by decilein 10 year bands (mostly)by perfect squaresdivided at prime numbers Note the gender codes are obvious, but the diagnosis codes are not - these are sp=sputum, rel = relapse, ep = extra-pulmonary, and new = new cases. What factors do you expect to be associated with case counts? 45.4 Resetting functions before the Pipeline is Built Now go back to the functions.R file, and change the assignment arrows back to single arrowheads, and save the file. When we are working within the data pipeline, the single arrowhead assignment within the function environment will work fine. 45.4.1 Setting Up {targets} Now that all of the functions are working, to initialize the pipeline, we need to first load {targets}, by running the library(targets) function. Then we need to run the use_targets() function. This will create a _targets.R file in the R folder. We can then edit this to start building the pipeline. We need to make sure we have added all the packages, and identified all the targets. 45.5 Editing the _targets.R File We will add the required packages to the targets pipeline in the _targets.R file. Scroll down to tar_option_set and find the list of packages. Add the following 7 packages to the list: tidyr readr ggplot2 dplyr gt gtsummary scales. Be sure that these are all in quotes, within the c() parentheses and appropriate commas without syntax errors. Save the _targets.R file. Now scroll down to the list of tar_targets. For this pipeline, {targets} will have 6 targets to track. file who_data who_clean make_table model_cases plot_data Replace the existing targets with these targets by replacing the entire list, using the code chunk below. Now save the _targets.R file. list( tar_target(file, &quot;who_data.csv&quot;, format = &quot;file&quot;), tar_target(who_data, read_data(file)), tar_target(who_clean, clean_data(who_data)), tar_target(table, make_table(who_clean)), tar_target(model, model_cases(who_clean)), tar_target(plot, plot_data(who_clean)) ) Now we have the infrastructure installed. We can now do our two pipeline pre-checks: tar_manifest() - should produce a 6 x 2 tibble of targets. - tar_visnetwork() - should make a completely blue-green (outdated) diagram of the pipeline. Make sure each of these runs without errors. If not, re-check the steps to create these two files for the pipeline. functions.R _targets.R 45.5.1 Running the Pipeline Once these are running without errors, we can run the pipeline with tar_make(). tar_make Output This will run the pipeline and create the outputs in the _targets/objects folder. Check that these are present, and view each target object in the objects folder with tar_read(). Check the output of tar_visnetwork() to see that the pipeline structure is now completely up to date (black targets). 45.5.2 Modificatons to the Pipeline Now modify the make_table function so that countries with over 1 million cases (scary bad, in need of WHO intervention) are in red text. Use the code below (adding conditional formatting) to edit the make_table() function in the functions.R file in the R folder of the Project. Look carefully at the tab_style() function below to see how the conditional formatting is applied. Make sure that your function ends with 2 close parentheses, followed by a closing curly-brace. who_clean |&gt; group_by(country) |&gt; summarize(Case_Count = sum(count)) |&gt; slice_max(Case_Count, n= 10) |&gt; gt::gt() |&gt; gt::fmt_number(columns = Case_Count, use_seps = TRUE,decimals = 0) |&gt; tab_style( style = list( cell_text(color = &quot;red&quot;) ), locations = cells_body( columns = Case_Count, rows = Case_Count &gt; 1000000 )) Save your modified functions.R file. Run tar_visnetwork() to check on what is now out of date in the pipeline, and then run tar_make() to update the pipeline with the new function. Note that some targets are skipped. Check out the appearance of the newly-modified table with tar_read(table). new table Confirm that the pipeline is now up to date with tar_visnetwork(). 45.5.3 Modify the Plot Now modify the plot to make years with greater than 3 million cases of TB have points that are colored red. Use the code below to edit the plot_data() function in the functions.R file in the R folder of the Project. Look carefully at the aes(color) and scale_color_manual() functions to see how the conditional formatting is applied to point color. Make sure that your modified function has no syntax errors, end with the right number of parentheses, and a final closing curly-brace. plot_data &lt;- function(who_clean){ who_clean |&gt; group_by( year) |&gt; summarize(sum = sum(count)) |&gt; ggplot(aes(x= year, y = sum, color = sum &gt; 3000000)) + geom_point() + labs(title = &quot;WHO Count of TB Cases by Year&quot;, y = &quot;Cases&quot;, x = &quot;Year&quot;) + scale_y_continuous(labels = label_number(scale = 1e-6, suffix = &quot;M&quot;)) + theme(legend.position = &quot;none&quot;) + scale_color_manual(values = c(&quot;TRUE&quot; = &quot;red&quot;, &quot;FALSE&quot; = &quot;black&quot;)) return(plot) } new TB plot with conditional color Run tar_visnetwork() to check on what is now out of date in the pipeline, and then run tar_make() to update the pipeline with the new function. Check out the appearance of the newly-modified plot with tar_read(plot) 45.6 Next Steps You now understand the basics of the {targets} package, and how to build a pipeline. You can now use this approach to build much larger and more complex pipelines for your data analysis projects. Read much more about the {targets} package in the Targets Package User Manual here. Challenge yourself: Convert one of your existing script-based pipelines to a function-based pipeline using {targets}. "],["colors-and-scales-in-ggplot2.html", "Chapter 46 Colors and Scales in {ggplot2} 46.1 Goals for this Chapter 46.2 Colors in R and {ggplot2} 46.3 Sequential, Diverging, and Qualitative Palettes 46.4 Choosing Colors with Meaning", " Chapter 46 Colors and Scales in {ggplot2} This chapter is part of the Data Visualization pathway. Packages needed for this chapter include {ggplot2}, {scales}, and {paletteer}. While the {ggplot2} package offers many sensible defaults, at times you will want to go beyond the defaults. This chapter will introduce you to the many ways you can customize the colors and scales in your plots. 46.1 Goals for this Chapter learn how to customize colors in your plots Concepts to think about choosing colors for meaning Understand how to use and modify scales in {ggplot2} 46.2 Colors in R and {ggplot2} There are several different ways to define colors in R. Let’s take a look at a few standard approaches. You can, of course, just use the default colors in {ggplot2}. But this is a bit lazy, and you will want to take control of the colors in your plot to enhance the communication of your data One ‘gotcha’ with colors in {ggplot2} is that within the aesthetics function (aes), you you can set both the fill and color arguments separately. Fill will color the inside of a shape, while color will color the border of a shape. At some point you may be puzzled when you set a color and your bar plots do not change color (you are changing only the border with color, not the fill). Most points (with geom_point) only have an outline, but some shapes of points (like pch=21) have both a fill and a border. You will be able to set these separately when you need to. If you want to take control of the colors in your plot a manual need to use the scale_fill_manual() or scale_color_manual() functions to set the colors in your plot. ::: 46.2.1 Using pre-defined color names I have borrowed the plot_palette() function from a fabulous blog post by Nicola Rennie at blogpost (it is definitely worth following Nicola for this blog) to show you a few of the pre-defined color palettes available in R. Tiy will want to run this in your local RStudio session to create this function, which will make it easy to plot color palettes. Copy the code block below and run it in your local RStudio to enable plotting color palettes. plot_palette &lt;- function(palette) { g &lt;- ggplot2::ggplot( data = data.frame( x = seq_len(length(palette)), y = &quot;1&quot;, fill = palette ), mapping = ggplot2::aes( x = x, y = y, fill = fill ) ) + ggplot2::geom_tile() + ggplot2::scale_fill_identity() + ggplot2::theme_void() return(g) } One of the easiest ways to choose a color or build a palette of colors, is to use one of the 657 pre-defined color names in R. All of the standard color names are in lowercase, and are generally used in quotes, as they are not objects in your Global Environment. Here is an example - copy the code below to your local RStudio and run it to see the colors in action. Note that as you type in standard color names, RStudio will recognize them and provide a background color for each color name as a preview of what it will look like. Running the code will give you a plot of the colors in the palette. plot_palette(c(&quot;red&quot;, &quot;orange&quot;, &quot;yellow&quot;, &quot;blue&quot;, &quot;green&quot;, &quot;purple&quot;)) Now experiment with this - edit the color names in the vector defined by c() - try “red2”, “green3”, or “purple4” to see the different shades of the colors. Or see the different shades of one color with “red1” through “red4”. You will find that there is no 5th shade of any color. If you type in an unknown color into this vector (or a typo), RStudio will not give a preview color, and the code will fail to run, with an error message like “Unknown colour name: red5”. So it can be helpful to see a list of the defined standard colors. You can do this in the console by typing print(colors(), max = 657), which will return a list of the 657 standard color names. print(colors(), max = 657) This provides an alphabetical list, which is somewhat helpful. You can see that there are actually 102 shades of gray in R, not fifty. But often you are looking for a particular shade of a color, and it would be more helpful to see the colors clustered by color family. There is a nice cheatsheet that shows these colors here As long as one of these 657 colors works for you, you are all set. However, you may want to be more particular about the colors you use in your plots. You may want to use a color palette that is more visually appealing, or that is more accessible to those with color vision deficiencies. A more specific way to define colors is with ‘hex codes’. 46.2.2 Using color hex codes Hex codes are not for casting spells on unwary travelers in the woods, but for defining the red, green, and blue channels of the color you are aiming for. The ‘hex’ stands for ‘hexadecimal’, which is a base 16 numbering system. Each channel is represented by 2 digits, often preceded by a hash (#) sign, like #000027. This hex code represents 00 in red, 00 in green, and 27 in the blue channel. Each two digit number, because it is base sixteen, represents one of 256 shades, from 0-255. In order to represent base sixteen, hex codes use numbers from 0-9, then keep counting with letters from A to F, so that the lowest level is 00, and the highest is FF. Thus #000000 represents no color, or white, and #FFFFFF represents all colors, or black. As an example, the University of Michigan ‘maize’ color is represented by #FFCB05, which has a lot of red, a lot of green, and very little blue, which is why it is a bright yellow similar to ripe kernels of corn. It is quite common for a corporation or university brand to have specific colors (defined by hex codes or CMYK codes) that they use in their branding website (an eaxmple here). If you can not find the hex code for a particular color, you can estimate it by using a color picker tool in a graphics program, or by using a website like imagecolorpicker.com. Here is an example of using hex codes in R to define a color palette. These include the primary defined colors of the University of Michigan, which are maize and blue, as well as a few other colors that are used in the University of Michigan branding. Note that these start with a hash character, followed by six characters in the 0-9/A-F range (for hexadeximal base 16), and are in quotes. Note that RStudio gives you nice color previews as you type in the hex codes. Copy and run this code in your local RStudio to see the colors in action. plot_palette(c(&quot;#FFCB05&quot;, &quot;#00274C&quot;, &quot;#00B2A9&quot;, &quot;#2F65A7&quot;, &quot;#702082&quot;)) Go ahead and experiment with these. Go ahea and edit and change these colors. Remember that the 1st two digits represent the red channel, digits 3 and 4 represent the green channel, and digits 5 and 6 represent the blue channel. Note that you will get no preview color (and will generate an error) if you use digits outside of the 0-F range (G is not part of hexadecimal). You can also add more colors to the vector and plot these. 46.2.3 Screen vs. Print Colors Note that the hex codes are standard for screen and web colors, but printer colors are a bit different. These are based on mixtures of ink, which are usually expressed as CMYK, for Cyan, Magenta, Yellow, and blacK. These are also represented by numbers from 0-100, with 0 being no ink, and 100 being full ink. You can convert hex codes to CMYK codes using a website like hex.to, or by using a graphics program like Adobe Illustrator or Inkscape. These don’t convert perfectly. Some conversions are closer than others. For example, the University of Michigan maize color is #FFCB05 in hex, and C0 M20 Y100 K0 in CMYK. The blue color is #00274C in hex, and C100 M60 Y0 K60 in CMYK. You can also convert hex colors to Sherwin Williams branded paint colors at this website. In an effort to standardize colors, the Pantone matching system (PMS) was developed. This is a proprietary color space that is used in the printing industry. You can convert hex codes to PANTONE colors at this website. The University of Michigan maize color is PANTONE 7406 C, and the blue color is PANTONE 282 C. Many screen, print, and paint colors try to match these PANTONE colors as closely as possible. These colors are optimized for paper type, and C stands for coated paper, U stands for uncoated paper, and M stands for matte paper. If you want to go further down this color rabbit hole, you can see hex and RGB codes for 1526 Sherwin Williams paint colors here. 46.2.4 Transparency and hex colors You can add a 4th channel to your hex codes, which represents the transparency of the desired color. These also range from 00-FF (256 levels of transparency). The 00 level is fully transparent, and the FF level is fully opaque. This is useful for layering colors on top of each other, or when you want to see other data or text through a color block. Here is an example of a blue color with 0%, 25%, 50%, and 75% transparency, which is a light blue color. Copy and run this code in your local RStudio to see the transparency changes in this color in action. plot_palette(c(&quot;#0000FFFF&quot;, &quot;#0000FFC0&quot;, &quot;#0000FF80&quot;, &quot;#0000FF40&quot;)) 46.2.5 More obscure ways to select colors Since R is very much a choose-your-own-adventure sort of language, there are several other ways to select colors. These are less common, but you may run into them on occasion. You can use the rgb() function to define a color by its red, green, and blue channels, which range from 0-1. You can also use the hsv() function to define a color by its hue, saturation, and value, which range from 0-1. You can also use the hcl() function to define a color by its hue, chroma, and luminance, which range from 0-360, 0-100, and 0-100, respectively. These are less common, but you may run into them on occasion. There are functions in R for each color model and you can convert between them if needed. 46.2.6 Using color palettes Sometimes you want to have a lot of control, and select each color individually Other times, you may want to use a color palette that has been thoughtfully designed by someone else. There are many color palettes that have been designed by artists, data scientists, and others, and you can use these in your plots. There are many packages in R that provide color palettes, and you can use these in your plots. The {paletteer} R package has gathered many of these palettes into one manageable package. Here are a few examples of color palettes that you can use in R. Copy and run this code in your local RStudio to see the colors in action. paletteer_c(&quot;scico::berlin&quot;, n = 10) ## &lt;colors&gt; ## #9EB0FFFF #5AA3DAFF #2D7597FF #194155FF #11181DFF #270C01FF #501802FF #8A3F2AFF #C37469FF #FFACACFF paletteer_d(&quot;nord::frost&quot;) ## &lt;colors&gt; ## #8FBCBBFF #88C0D0FF #81A1C1FF #5E81ACFF paletteer_dynamic(&quot;cartography::green.pal&quot;, 5) ## &lt;colors&gt; ## #B8D9A9FF #8DBC80FF #5D9D52FF #287A22FF #17692CFF The {paletteer} package divides color palettes into three categories: continuous, discrete, and dynamic (varies with the number of colors needed). Continuous palettes are used when you have a continuous variable, like temperature or elevation, and you want to show the progression of the variable. Discrete palettes are used when you have a variable that has a number of distinct categories, and provide the same number of colors each time. Dynamic palettes are used when you have a variable that can have a different number of categories, like political party or land use. Dynamic palettes will provide a spectrum across the range with the number of categories you request. You can use the {paletteer} package to select a color palette that fits your data, and then use that palette in your plots. This berlin palette is a continuous palette that goes from blue to red, and is useful for showing a progression of values. It comes from the scico package, which has many other palettes that you can use. plot_palette(paletteer_c(&quot;scico::berlin&quot;, n = 10)) The frost palette is a discrete palette that goes from a light greenish blue to a dark slate blue, and is useful for showing distinct categories. It comes from the nord package. plot_palette(paletteer_d(&quot;nord::frost&quot;)) The green.pal palette is a dynamic palette that goes from light green to dark green, and is useful for showing a range of categories. plot_palette(paletteer_dynamic(&quot;cartography::green.pal&quot;, 5)) You can use these palettes in your plots by calling the paletteer_c(), paletteer_d(), and paletteer_dynamic() functions, respectively, and specifying the number of colors you want. There are many packages that specify color palettes, and you can even build one of your own if you often use the same colors. An example built by Eric Ekholm, an apparent fan of the Bluey cartoon, can be found here, and used in the code block below. Copy and run this code in your local RStudio to install the package and see the colors in action. # note that this requires that you already have `devtools` installed. If you do not, you can install it with `install.packages(&quot;devtools&quot;)` devtools::install_github(&quot;ekholme/blueycolors&quot;) ## Using GitHub PAT from the git credential store. ## Downloading GitHub repo ekholme/blueycolors@HEAD ## ## ── R CMD build ───────────────────────────────────────────────────────────────── ## * checking for file ‘/private/var/folders/93/s18zkv2d4f556fxbjvb8yglc0000gp/T/RtmpyEih08/remotes10eb68f0005/ekholme-blueycolors-9c72bd5/DESCRIPTION’ ... OK ## * preparing ‘blueycolors’: ## * checking DESCRIPTION meta-information ... OK ## * checking for LF line-endings in source and make files and shell scripts ## * checking for empty or unneeded directories ## * building ‘blueycolors_0.0.1.0.tar.gz’ library(blueycolors) plot_palette(bluey_palette(&quot;bluey&quot;, 5)) A few color-blind safe palettes are built into {ggplot2}. You can use these palettes in your plots by calling the scale_color_viridis_d() and scale_fill_viridis_d() functions, respectively. Here is an example of the viridis palette in action. Copy and run this code in your local RStudio to see the colors in action. Other options for viridis include “plasma”, “magma”, “cividis”, and “inferno”. ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width, color=Species)) + geom_point(size=6) + scale_color_viridis_d(option = &quot;viridis&quot;) 46.2.7 Color-blind friendly palettes There are many color-blind friendly palettes that you can use in your plots. These palettes are designed to be easily distinguishable by people with color-blindness, and are useful when you want to make sure that your plots are accessible to everyone. At the Color Palette Finder website, you can find many palettes for normal vision and a variety of kinds of color-blindness that you can use in your plots. This website lets you explore the 2,728 differnt palettes available in the {paletteer} R package. 46.3 Sequential, Diverging, and Qualitative Palettes In different situations, you may want to use sequential, diverging, or qualitative palettes. Sequential palettes are used when you have a continuous variable, like temperature or elevation, and you want to show the progression of the variable. Diverging palettes are used when you have a variable that has a logical midpoint, like a mean or a net zero change, and you want to show the difference between two groups. Qualitative palettes are used when you have a variable that has a number of distinct categories, and provide the same number of colors each time. See the PrettyCols package See the RColorBrewer package Here are some examples of each type of palette. Copy and run this code in your local RStudio to see the colors in action. library(PrettyCols) library(RColorBrewer) # Diverging Palettes plot_palette(prettycols(n = 9, &quot;PurpleGreens&quot;)) plot_palette(brewer.pal(5, &quot;PuOr&quot;)) # Sequential Palettes plot_palette(prettycols(n = 7, &quot;Tangerines&quot;)) plot_palette(brewer.pal(5, &quot;Blues&quot;)) # Qualitative Palettes plot_palette(prettycols(n = 5, &quot;Bold&quot;)) plot_palette(brewer.pal(5, &quot;Set3&quot;)) 46.4 Choosing Colors with Meaning While it is easier to use a plug and play palette, if you want your data visualizations to stick with your audience, it is worth thinking about the meaning of colors, which can vary across cultures. It is common for a red color to represent danger, stop, heat, or a warning, while green represents go, safe, or good. This can be problematic for folks with red-green color blindness, but it is helpful to think about when you are choosing colors. Red may represent bad outcomes, or death. Green or blue may represent good outcomes, or life. Blue is often associated with calm, trust, or cold, while yellow is associated with warmth, happiness, or caution. Purple is often associated with royalty, luxury, or mystery, while orange is associated with energy, creativity, or fun. Black is often associated with power, elegance, or death, while white is associated with purity, cleanliness, or peace. These associations can vary across cultures, so it is worth considering the cultural context of your audience when choosing colors. In terms of clinical studies and exposure levels, it is helpful to use a color palette that identifies the control, or placebo, as gray. This is to differentiate it from your active intervention, which can be in a color like blue or green. This is helpful for your audience to quickly identify the control group, and the intervention group, in your plots. When the intensity of the exposure varies across arms, it is helpful to use a color palette that goes from light to dark, or from low to high, to show the progression of the exposure. This is helpful for your audience to quickly identify the level of exposure in your plots. For example, in comparing outcomes for 3 dose levels of the active intervention (low, medium, and high) to a placebo or vehicle control, you could use a color palette that goes from gray to blue3 to show the progression of the dose levels. This would help your audience quickly identify the control group, and the low, medium, and high dose groups in your plots. Copy and run this code in your local RStudio to see the colors in action. This clear translation of increasing exposure to the treatment to color intensity will help viewers understand the meaning of your plots. plot_palette(c(&quot;gray80&quot;, &quot;lightskyblue1&quot;, &quot;skyblue2&quot;, &quot;deepskyblue3&quot;)) If you had more levels of exposure, you could use one of the palettes from the {RColorBrewer} package, which has many palettes that are colorblind safe. Copy and run this code in your local RStudio to see the colors in action. plot_palette(c(&quot;gray80&quot;, RColorBrewer::brewer.pal(name = &quot;Blues&quot;, n = 7))) When you are choosing colors for your plots, it is helpful to think about the meaning of colors, and how they will be interpreted by your audience. You can use the {paletteer} or {RColorBrewer} packages to select a color palette that fits your data, and then use that palette in your plots. You can also build your own color palette, to make your plots more meaningful to your audience. "],["using-the-tabulapdf-package-tp-extract-tables-from-pdfs.html", "Chapter 47 Using the {tabulapdf} package tp extract tables from PDFs 47.1 Why Tables from PDFs? 47.2 Extracting Tables from PDFs 47.3 Extracting Tables from PDFs 47.4 Extracting Tables from the PDF 47.5 Extracting a Specific Table 47.6 Extracting a Specific Table 47.7 Viewing and Targeting the PDF 47.8 Your Turn", " Chapter 47 Using the {tabulapdf} package tp extract tables from PDFs This chapter is part of the Data Import pathway. Packages needed for this chapter include {tabulapdf}, {tidyverse}, and a working version of rJava. If you don’t have these two packages installed, you can install them by copying the code chunk below and running it in your local RStudio session. You will also likely need the {rJavaEnv} package, which will help you install rJava and connect it to your R environment. install.packages(&quot;tabulapdf&quot;) install.packages(&quot;tidyverse&quot;) install.packages(&quot;rJavaEnv&quot;) This chapter takes a bit of setup to get rJava working, which is needed for the {tabulapdf} package to work and to interactively extract tables from PDFs. To get rJava working on your computer can sometimes be a bear. The {rJavaEnv} package has made this a lot more manageable. Let’s walk through the steps to get rJava set up. start by loading {rJavaEnv} with a library command. Then run the java_check_version_cmd() function in your local RStudio session to see if you already have a working version of Java on your computer. library(rJavaEnv) java_check_version_cmd() ## JAVA_HOME: ## &#39;/Users/peterhiggins/Library/Caches/org.R-project.R/R/rJavaEnv/installed/macos/aarch64/21&#39; ## Java path: ## &#39;/Users/peterhiggins/Library/Caches/org.R-project.R/R/rJavaEnv/installed/macos/aarch64/21/bin/java&#39; ## Java version: &quot;openjdk version \\&quot;21.0.6\\&quot; 2025-01-21 LTS OpenJDK Runtime ## Environment Corretto-21.0.6.7.1 (build 21.0.6+7-LTS) OpenJDK 64-Bit Server VM ## Corretto-21.0.6.7.1 (build 21.0.6+7-LTS, mixed mode, sharing)&quot; ## [1] &quot;21&quot; If your Java version is confirmed with a path to JAVA HOME and a version number (as it does on my home computer as seen here), you can skip the next step. If not, you will probably get a message like ! JAVA_HOME is not set. [1] FALSE If this is the case, copy and run the java_quick_install() function from the chunk below in your local RStudio session to install the latest version of Java. java_quick_install() Now check that this worked by running the java_check_version_cmd() function in your local RStudio session again. java_check_version_cmd() This should now tell you the path to JAVA HOME, the Java path, and the Java version. Once this is set, you are ready to get started. 47.1 Why Tables from PDFs? Many organizations publish reports as PDFs, with tables of data in them. It would be much more valuable to have these data publicly available in a format that can be used for analysis (like downloadable csv files). This chapter will show you how to do extract these tablesfrom PDFs. 47.2 Extracting Tables from PDFs The {tabulapdf} package is a great tool for extracting tables from PDFs. It uses the Java library (the equivalent of R packages in the Java computer language are called libraries) Tabula to do this, and it works well with many different types of tables. To use the {tabulapdf} package, you need to have Java installed on your computer. This is because the package uses the Tabula library, which written in the Java language for extracting tables from PDFs. If you don’t have Java installed, you can follow the instructions in the previous section to install it. Run the code chunk below to install the {tabulapdf} package and load it into your R session, along with {tidyverse} to clean up the data tables we will extract (there will be lots of cleaning up). library(tabulapdf) library(tidyverse) Now let’s start with a PDF filled with health-related data tables. This is a nice example from KFF, the Kaiser Family Foundation, which is a non-profit organization that provides information on health issues at www.kff.org. Unfortunately, they publish a lot of interesting health and health insurance data in tables in PDFs. Let’s link this pdf to an object in R, by running the code chunk below. Copy and run this code chunk in your local RStudio session. kff_pdf &lt;- &quot;https://files.kff.org/attachment/Topline-Survey-of-Consumer-Experiences-with-Health-Insurance.pdf&quot; 47.3 Extracting Tables from PDFs Now we have to extract some data tables from this PDF. The nice folks at KFF have a habit of including lots of summary rows and subset totals as distinct rows in their tables, so we will have to select the columns and rows that we want, and frequently rename columns. The {tabulapdf} package has a function called extract_tables() that will help you pull out the tables from a PDF. To get started, we can simply grab ALL the tables, or do this in a targeted way. Take a moment to go the the website for this PDF, here, and scroll through the PDF to see what tables are in it. Keep this PDF window open for future reference during this chapter. Let’s take a quick overview of this PDF by running the commands in the code chunk below. # Get the number of pages in the PDF get_n_pages(kff_pdf) ## [1] 40 # Get the metadata on the PDF extract_metadata(kff_pdf) ## $pages ## [1] 40 ## ## $title ## [1] &quot;KFF Survey of Consumer Experiences with Health Insurance&quot; ## ## $author ## NULL ## ## $subject ## NULL ## ## $keywords ## [1] &quot;Topline-Survey-of-Consumer-Experiences-with-Health-Insurance&quot; ## ## $creator ## [1] &quot;Microsoft® Word for Microsoft 365&quot; ## ## $producer ## [1] &quot;Microsoft® Word for Microsoft 365&quot; ## ## $created ## [1] &quot;Thu Jun 08 15:15:33 EDT 2023&quot; ## ## $modified ## [1] &quot;Mon Jun 12 16:07:40 EDT 2023&quot; ## ## $trapped ## NULL # figure out the pixel dimensions of the PDF pages get_page_dims(kff_pdf, pages = 1:2) ## [[1]] ## [1] 612 792 ## ## [[2]] ## [1] 612 792 Now we know that there are 40 pages in this PDF, it was exported to PDF from Microsoft Word on June 8th 2023, and we have a title and some keywords. We also learned that each page is 612 pixels wide and 792 pixels tall (the pages are all the same 8.5 inch wide by 11 inch tall size). 47.4 Extracting Tables from the PDF Let’s go whole hog. Let’s see how many tables there are. This will take a moment, but run the code chunk below. # Extract all tables from the PDF kff_tables &lt;- extract_tables(kff_pdf, pages = 1:40, output = &quot;tibble&quot;) If you take a look in your Environment tab, you will now find the kff_tables object. It is a list of 38 tables. Click on the object in the Environment tab, and you will see a list of 38 tables in the Viewer tab. Each table has its own blue dot with a white triangle next to the table number. Click on one or two of these to expand them, and compare these to the PDF. See if you can figure out which table object corresponds to which table in the PDF. You will probably find that there are more than 38 tables in the PDF. Several of these are stuck together in the table extraction process, and some of them are empty. To take a look at one of the tables in the list, run the code chunk below, which will pull out the 17th table in the list and show it in the Viewer tab. # Extract the 17th table from the list of tables kff_tables[[17]] The result is a bit wonky, but recognizable as all of the tables in response to questions 17 through 19b, all bound together. Scroll through the PDF to find these. 47.5 Extracting a Specific Table You can slice off some of the rows to get the specific table that you actually want. Let’s try to get the data in response to question 19a. This was “In the past 12 months, did you end up paying more for treatment or services than you expected to pay as a direct result of the problems youhad with your current health insurance?” This is a yes/no question, and the table shows the percentage of people who said yes, and the percentage of people who said no. To do this, we can use the extract_tables() function again, but this time we will pull this one table and slice out the rows that we want. # Extract the 17th table from the list of tables pay_more &lt;- kff_tables[[17]] |&gt; slice(20:21) |&gt; rename(response = `...1`) |&gt; separate(`Total sponsored`, into = c(&quot;overall&quot;, &quot;emp_sponsored&quot;), sep = &quot;\\\\s&quot;) |&gt; relocate(overall, .after = Marketplace) |&gt; janitor::clean_names() pay_more |&gt; gt::gt() Despite the common assumption that employer sponsored health insurance in the US is the best, satisfaction seems to be higher for medicaid and medicare. You can even remove the response column (the chi-squared test will not work with a character column), convert the percentages from character to numeric, and run a chi-squared test to show that the different types of insurance are significantly different from each other by this metric. pay_more |&gt; select(-response) |&gt; mutate_if(is.character, as.numeric) |&gt; chisq.test() 47.6 Extracting a Specific Table But this approach is a bit cumbersome, and involves a fair amount of hunting to find the table you want, and to clean it up. Instead, we can use the extract_tables() function to extract a specific page. This narrows it down a lot. kff_tables &lt;- extract_tables(kff_pdf, pages = 5, output = &quot;tibble&quot;) kff_tables Now there is only one table to look at, and it is a bit easier to see what is going on. Note that kff_tables is still a list (take a look in the Viewer tab), and we still have to pluck out the tibble we want, even though there is only one. Our usual data cleaning functions from {dplyr} will work on a tibgle, but not on a list. We need to pluck out the tibble we want. There are two ways to do this: kff_tables[[1]], or kff_tables %&gt;% pluck(1) For our purposes, on page 5 of this PDF, we want the mental health and emotional well-being table, so we can slice rows 15 to 20, and clean up the column names to get only the raw data columns. mental_health &lt;- kff_tables[[1]] |&gt; slice(15:20) |&gt; select(1, 3:5, 7:8) |&gt; rename( insurance = `...1`, excellent = `...3`, very_good = `...4`, good = `...5`, fair = `...7`, poor = `...8` ) |&gt; pivot_longer( cols = c(excellent, very_good, good, fair, poor), names_to = &quot;rating&quot;, values_to = &quot;percent&quot; ) |&gt; mutate(insurance = case_when( insurance == &quot;Total&quot; ~ &quot;overall&quot;, TRUE ~ insurance )) |&gt; filter(insurance != &quot;sponsored&quot;) |&gt; pivot_wider( names_from = insurance, values_from = percent ) |&gt; janitor::clean_names() |&gt; relocate(overall, .after = marketplace) mental_health As you can see, removing subtotals and rearranging to get clean data takes a bit of wrangling to get it into a tidy clean format of raw data. But now we can use this data to make plots or perform analyses. 47.7 Viewing and Targeting the PDF The {tabula_pdf} package can go even farther. It can let you view thumbnails of the pages in the RStudio Viewer window, and even pick out the particular table area that you want to extract. This can only be done in an interactive R session, as it will open a shiny app in the Viewer tab and require a human to draw a rectangle around the desired section of the PDF to extract a table from. # get some overview data on the PDF kff_pdf |&gt; get_n_pages() ## [1] 40 subtable &lt;- kff_pdf |&gt; locate_areas(pages = 22) ## Error in locate_areas(kff_pdf, pages = 22): locate_areas() is only available in an interactive session # manually select the area of the table # using the shiny widget in the Viewer pane # then click the Done button at the top right extract_tables(kff_pdf, pages = 22, guess = FALSE, col_names = FALSE, area = subtable ) ## Error: object &#39;subtable&#39; not found You can also combine the steps and just use the extract_areas() function to pull data from a specific area of the PDF. This is useful if you know exactly which table you want to extract. Let’s try this for question 15h (deny or delay drug coverage) on page 19 of this PDF in the code chunk below. Copy and run this in your local RStudio session. Click Done when you have completed your rectangle. # Extract the table from the PDF deny &lt;- extract_areas(kff_pdf, pages = 19, output = &quot;tibble&quot;) ## Error in locate_areas(file = file, pages = pages, copy = copy): locate_areas() is only available in an interactive session deny ## Error: object &#39;deny&#39; not found This should produce a 5 x 6 tibble, with some goofy column names, a total row that you probably don’t want, and some extra columns for no answer and N that you don’t need. If you did not draw the rectangle around the table quite right, just run the code chunk again and adjust your area. The deny object that you selected with your rectangle is still a list, so you need to pluck out the first table with deny[[1]], or pluck(1) to get a single tibble instead of a list. Then use the select() and slice() functions to get down to the raw data, and rename the columns with the rename() function to fix these one at a time, or with the purrr:set_names() function for renaming all the names at once. An example of data cleaning is shown below. I managed to cut off the b in before with my rectangle, so I had to shorten the insurance column name in the rename function. # Clean up the table deny2 &lt;- deny |&gt; pluck(1) |&gt; # you could use deny[[1]] for the first 2 lines rename( insurance = `efore you received it`, yes = `...2`, no = `...3`, not_tried = `...4` ) |&gt; slice(2:5) |&gt; select(-`...5`, -`...6`) deny2 Now try it yourself. Try to grab an interesting section from the big table on page 22 of the PDF. Pick a question that interests you, grab it with a rectangle, and extract and clean the raw data into an analysis-ready tibble. The example below is one possible solution for question 20d Solution # note that I excluded the last 2 columns by drawing a smaller rectangle extract_areas(kff_pdf, pages = 22, output = &quot;tibble&quot;) |&gt; pluck(1) |&gt; slice(3:6) |&gt; purrr::set_names(c(&quot;insurance&quot;, &quot;yes&quot;, &quot;no&quot;)) ## Error in locate_areas(file = file, pages = pages, copy = copy): locate_areas() is only available in an interactive session Note that the interactive portion of drawing the rectangle actually makes this process less reproducible, because a key piece is not hard-coded, but it is a pretty convenient tool for quickly getting the data you want. This sort of interactive step can not be scheduled or run automatically, as it requires a person to draw the rectangle in real time, so it is fine for one-off interactive coding, but not for a reproducible workflow. 47.7.1 Time for a Quiz Take a peek at the last fc object, statin_fc6, which provides instructions to fc_draw. What command can you run to print out the last flowchart object, statin_fc6 (pick the best answer)? statin_fc6statin_fc6$fcfc_view(statin_fc6, what =‘fc’)Either of B or C will workstatin_fc6_tibble OK, now print out the statin_fc6$fc object in your local RStudio and inspect it for the following questions. What is the y value for the first box (Patients Assessed)? 2.30.680.20.80.3 What is the font size (text_fs) value for the box with id == 9? 221486 What is the justification and text_color of the box with id == 3? left and blackcenter and redright and violet 47.8 Your Turn Let’s try to extract some data from the KFF PDF. 47.8.1 Explore More Features Explore more of flowchart at the package website here. You can see the official documentation of this package on CRAN here. "],["title-holder.html", "Title holder", " Title holder "],["references-1.html", "References", " References "]]
