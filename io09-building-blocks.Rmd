---
title: "Building Blocks of R"
author: "Peter Higgins"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width = 6, message = FALSE, warning = FALSE, comment = "", cache = FALSE, fig.retina = 3)

library(tidyverse)
library(medicaldata)
library(lubridate)
library(janitor)
```

# The Building Blocks of R: data types, data structures, functions, and packages.

In this chapter, we will learn about some critical building blocks in R
that can lead to a lot of frustration if you do not understand these
building blocks and how they are used. Once you understand how these
building blocks work, you will be able to avoid these frustrations and
build some pretty amazing data analysis pipelines.

![](images/building_blocks_1.jpg "Building Block Structure")

## Data Types

There are actually six data types in R, though we usually use only use 4
of these for data analysis.

-   **logical** (TRUE or FALSE)

-   **integer** (1L, 2L) - these take up less memory than a double. You
    specify a number as an integer (rather than a double) by adding a
    capital L after the number.

-   **double** (aka real or decimal - 2.4, 4.7, pi). Double means that
    the value is stored in 64 bits (aka double precision)

    -   note that both integers and doubles have the class of *numeric*

-   **character** ("myeloma" or "michigan")

-   [complex]{.ul} ( 1+3i, 4-7i) - used under the hood for calculations

-   [raw]{.ul} (hexadecimal codes like B3 or FF) - used to communicate
    with devices like printers

Note that there is not a true data type for categorical variables, like
gender, or race, or ethnicity. These are encoded as **factors**, which
behave mostly like a data type, but are technically a data class. For
the purposes of dataframes, factors can be thought of as the 5th data
type, but the result of *typeof() on* a factor variable will be
"integer", as that is how factors are stored, with text attributes for
the level names.

Note also that there is not a true data type for dates, or date:times,
as these are stored as doubles in R. Their `typeof()` will be double,
but their `class()` will be date or dttm. Storing these as doubles does
make it easier to do math to calculate intervals of time.

Note that you can test the type of an object in R with the *typeof()*
function, which will return the data type.

You can also test for a specific data type - is this the right kind of
input, with the is.x functions, like *is.character()*, *is.logical()*,
or *is.numeric().* These will return the logical values TRUE or FALSE.
This can be important, as many functions will report (or "throw") an
error when they receive the wrong kind of input data.

When needed, you can also convert between data types, by manually
**coercing** an object to a different data type with the as.x functions,
like *as.character()*, *as.logical()*, *as.integer()*, or *as.numeric()
[as.double() \~\~ as.numeric()]*.

Here are 4 examples of testing vectors with the *typeof()* function.
Guess what the returned value will be before you run the code (click on
the green arrow at the top right).

```{r demo-is.x, echo=TRUE}
# you can test vectors with typeof 

typeof(c(1.7,5.3,9.2)) 

typeof(c('hypertension', "diabetes", "atherosclerosis"))

typeof(c(2L, 4L))

typeof(c(TRUE, FALSE, TRUE))

table(InsectSprays$spray)
typeof(InsectSprays$spray)
```

Here are 3 examples of coverting vectors from one type to another with
*as.x()* functions. Guess what the returned value will be before you run
the code (click on the green arrow at the top right).

```{r demo-as.x, echo=TRUE}
# you can convert vectors with as.x

numeric <- (c(1.7,5.3,9.2)) 
newvec1 <- as.character(numeric)
newvec1
typeof(newvec1)

logical <- c(TRUE, FALSE, TRUE)
newvec2 <- as.integer(logical)
newvec2
typeof(newvec2)

character <- c("2.4", "5.3", "7.2")
newvec3 <- as.numeric(character)
newvec3
typeof(newvec3)
```

## Data Structures

![](images/building_blocks_3.jpg "Building blocks stairs")

Data structures are the **nouns** of programming in R. The data items of
different types are organized into data structures. R has many data
structures, and these include

-   **vector** - the most common and basic data structure in R. Most
    functions in R operate on vectors. These *vectorized* functions act
    on every item in the vector, without you having to write a loop.
    Every item in a vector **must** be of the same data type. If the
    items added to a vector are of different data types, they will be
    silently and automatically **coerced** to a common data type.
    Sometimes this is helpful, but sometimes it can surprise you.

    \<Demo\> constructing vectors with concatenate, recycling of values,
    seq and seqalong, length (vs nchar). Use letters and LETTERS - two
    built in vectors in base R.

    ::: {.warning}
    Automatic coercion can be a common source of problems, especially
    for beginners. R tries to "helpfully" convert vectors from more
    specific types to more general types automatically and silently when
    you have mixed data types in a vector/variable column. Imagine you
    have a numeric vector of potassium values, like\
    k \<- c(4.2, 3.9, 4.5, 4.3, 4.1)\
    This is fine. k is a numeric class vector, with *typeof(k)* =
    double.\
    But if the next value from the lab comes back as "sample lysed",\
    k \<- c(4.2, 3.9, 4.5, 4.3, 4.1. "sample lysed"),\
    R will automatically and silently convert this vector to a more
    general class and type ("character")\
    The ordering of coercion (from more specific to more general) is:\
    logical -\> integer -\> numeric -\> character -\> list\
    Watch out for:\
    data of the wrong type in your variable vectors, and\
    silent changing of your data type - check your variable data types
    with *glimpse()* before you dive into data analysis.
    :::

-   **factors** - factors are special vectors used for categorical data.
    These factors can be ordinal or nominal (unordered), and are
    important in lots of clinical data, and for modeling or plotting
    different categories. Factors are essentially integers with special
    labels (levels) attached. Factors can ***look like*** character
    vectors, but are actually stored as integers, which sometimes leads
    to unfortunate surprises.

-   **matrix** - a matrix is a special case of a vector in R. A matrix
    must also have only a single data type, and has 2 dimensions. The
    matrix is filled with values by column as the default, and recycles
    values if needed. Matrices are often used for gene expression arrays
    and Omics applications to store lots of numeric results. Matrices
    are also often used "under the hood" for complex calculations, in
    the linear algebra used to fit many models.

    \<Demo matrix letters, nrow=2 vs nrow =6, dim(), matrix(letters,
    nrow=13), matrix(letters, nrow=2)

-   **list** - a list is an all-purpose container for a variety of data
    types and vectors of any length. Lists are often heterogeneous in
    both data types and **the length** of vectors. Lists can even
    contain other lists. Lists are helpful when you have a related group
    of heterogeneous objects as results - vectors, dataframes, strings,
    etc., which can be bundled together in a list.

    One example of a list occurs in the `starwars` dataset, which has a
    row for each character. The column for which films they have
    appeared in is a `list` column. Each cell contains a character
    vectors of varying length, as each character has appeared in
    anywhere from 1 to 9 movies (as of 2021).

    ```{r}
    starwars %>% select(name, films) 
    starwars$films %>% head()
    ```

    Lists can be a bit clunky to work with, as they nest more than a
    single value into a single cell. Sometimes this nested format can be
    helpful, and sometimes it is preferable to *unnest()* the data into
    a longer format. \

    ```{r}
    starwars %>% select(name, films)
    starwars %>% select(name, films) %>% unnest()
    ```

    Lists can be useful for bundling togther related data of different
    types, like the results of a t-test.

    ```{r}
    t_test_output <- list (
      "Welch Two Sample t-test",
      c("data: height by gender"),
      data.frame(t = -1.5596, df = 37.315, p = 0.1273)
    )
    t_test_output
    ```

-   **data frame** - a very important data structure in R, which
    corresponds to rectangular data in a spreadsheet. A data frame is a
    table of vectors (columns of variables) of the **same length**. If
    new vectors are added with a different length, an error will occur.
    Unlike a matrix, each vector (aka column, aka variable) in a
    dataframe can be a different data type. So you can combine character
    strings, integers, real numbers, logical values, and factors in a
    rectangular data frame in which **each row is one observation**, and
    the variables/columns/vectors are the **values that are measured**
    at that observation. A data frame can be thought of as a strict
    version of a list, in which each item in the list is an atomic
    vector (single data type) and **must** have the same length. You can
    even have list columns within a data frame. Note that if you run the
    *typeof()* function on a dataframe, it will report that it is a
    list.\
    \
    You can build a dataframe from a set of vectors (variables) by
    binding these together as columns/variables with the `data_frame()`
    function.

    ```{r}
    pat_id <- c(1,1,2,2, 3,3)
    date <- c(lubridate::ymd("2020-11-07", "2020-12-03", "2020-12-02", "2020-12-15", "2020-11-09", "2020-12-02"))
    crp <- c(5.1, 3.2, 7.6, 4.1, 4.3, 1.7)
    new_df <- data_frame(pat_id, date, crp)
    new_df

    ```

    -   **tibble** - a tibble is a modern upgrade to the data frame,
        with clear delineation of data types and printing that does not
        continuously spew out of your console. It also has the
        properties of a data frame underneath the additional features.
        You can convert a dataframe to a tibble with `tibble()`, or use
        tibble to build with vectors

    ```{r}
    tibble(new_df)
    tibble(pat_id, date, crp)
    ```

    You can also build new row-wise tibbles with the `tribble()`
    function.

    ```{r}
    tribble(
      ~pat_id, ~date, ~crp,
      1, lubridate::ymd("2020-12-04"), 5.1,
      1, lubridate::ymd("2020-12-09"), 3.7,
      2, lubridate::ymd("2020-11-23"), 3.6,
      2, lubridate::ymd("2020-11-29"), 1.9,
      3, lubridate::ymd("2020-12-14"), 1.9,
      3, lubridate::ymd("2020-12-27"), 0.6
    )
    ```

R uses many other custom objects to contain things like a linear model,
or the results of a t test. Many functions and packages build specific
custom objects which are built upon these basic data structures.

Similar to data types, functions in R are often designed to work on a
specific data structure, and using the wrong data structure as input to
a function will result in errors. It is important to be able to check
your data structures as part of your initial DEV (Data Evaluation and
Validation) process in order to avoid problems and prevent errors.

## Examining Data Types and Data Structures

There are a number of helpful base R functions to help you examine what
the objects in your Environment actually are. This is an important step
in avoiding errors, or in avoiding needing to diagnose them after the
fact.

assigning an object (not =)

When you create a new object (dataframe, tibble, vector), it is
transient. As soon as it prints to the Console, it is gone. If you want
to refer back to it, or process it further later, you need to assign it
to an object in your environment. When you do this, it will appear in
your Environment pane in RStudio.

To do this, you use an arrow from your code to the name of the new
object. It is helpful to use concise names that are descriptive, in
lower case with minimal punctuation (underscores and dashes are fine),
no spaces, and that start with letters rather than numbers. It is
important to avoid using R function names (like **data** or **df** or
**sum**) as names for your objects. You can use either leftward arrows
(Less than then dash key) `<-` or rightward arrows `->` (dash key then
greater than key) to assign data to an object.

```{r}
# example 1
tall <- starwars %>% 
  filter(height > 200)

# example 2
starwars %>% 
  filter(height <70) ->
short

```

Leftward arrows are thought of as sort of like the title of a recipe. In
the first example above, you can read this as, "I am going to make a
tibble of tall characters. I will start with the **starwars** dataset,
then filter by height \>100 to get this tall tibble".

But most people don't think or talk this way, and it is recommended to
write "literate code" - which can be read naturally by humans **and** by
computers. These data pipelines should read like sentences. Generally,
we use the literate programming format in example 2 above for data
wrangling, starting with a **subject** (starwars dataset), then one or
more (automatically indented) **verbs** (functions) that wrangle the
data, then end with the predicate (a new **noun** - the new resulting
dataset). To do this requires the rightward arrow. To avoid hiding the
resulting dataset in a thicket of code, remove the automatic indent and
put this new object on the left margin.

Once you have an object, you can use several functions to examine what
you have, and to make sure that it is in the right format for future
data wrangling or plotting functions.

The `str()` function, denoting structure, is a good place to start
interrogating data structures.

Try this out. Run `str(starwars)` in your RStudio console.

```{r}
str(starwars)
```

You can see from the output that this is a tibble, with 87 rows and 14
columns. It also meets the definitions of a table and a dataframe. Then
the output shows each variable. The first 11 are either character or
integer types. The last 3 (films, vehicles, starships) are all
list-columns, and are more complicated.

Note that `glimpse(starwars)` provides a prettier version of this output

```{r}
glimpse(starwars)

```

If you want more detail about a given variable inside this dataframe,
you can use `typeof()` or `class()`.

```{r}
typeof(starwars$mass)

class(starwars$mass)
```

For character variables, `typeof()` is the same as `class()`. But these
are different for doubles and factors.

Sometimes you want a quick look at all the variable names of a dataset.
The functions `names()` or `colnames()` can quickly get you a vector of
these names.

```{r}
names(starwars)
colnames(starwars)
```

If you want the dimensions of your dataset, you can use `dim()`. To just
get the number of rows or columns, you can use `nrow()` or `ncol()`.

When you have a numeric matrix, sometimes you have a 'bonus" column of
`rownames`, which is a special column that specifies the observation,
but does not have a normal column name. This keeps character strings out
of the matrix, which can only have one data type. This is kind of a
pain, especially if you need to access the information in the rownames
column. When this is the case, the dplyr function
`rownames_to_column(matrix_name)` is very helpful. The default name is
`rowname`, but you can supply a better one. Run the example below in
your Console pane.

```{r}
rownames_to_column(mtcars, var = "make_model")
```

## Functions

Functions are the **verbs** of programming in R. Functions act on
existing data objects to rearrange them, change them, analyze them, plot
them, or report them. Functions in R can do almost anything, and can
work together in pipelines (aka chains) to do more complex and
interesting things. Functions can call (activate) other functions, and
you can build your own custom functions, which comes in handy when you
want to do something similar multiple times, like summarizing data on 5
different variables.

You could run a custom summary function on each variable (the
**argument** to the function) each time, or use a programming function
like **map** to run the function over a vector or list of the variables
needed.

::: {.tryit}
You can see the inner workings of a function by just entering it into
the RStudio console without parentheses. For example, for sd (standard
deviation).

```{r}
sd
```
:::

You can see the inner workings of the sd function. This function takes
the variance, then the square root of a vector, which is correct for
producing a standard deviation. To run any function, you need to supply
the parentheses, which normally contain the arguments (options) and
identify the input data. Note that in a data pipe, the first argument is
the incoming data, and does not need to be explicitly named in tidyverse
functions. In older, non-tidyverse functions, data is often not the
first argument, and needs to be named explicitly in a data pipeline,
with the argument `data = .` telling the function to use the incoming
data from the pipeline.

To actually **run** any function, you need to include the parentheses at
the end, even if you do not include any arguments. Two examples to try
on your own are:

-   `Sys.Date()`

```{=html}
<!-- -->
```
-   `installed.packages()`

Give these a try in your Console pane.

## Packages

Packages make functions transportable and shareable. You can bundle a
group of related functions into a package, and put it on Github, or even
on CRAN, where other people can download it and use these functions for
themselves. This can be helpful for miscellaneous functions that
co-workers often use, or for a group of functions that work well
together in a particular workflow.

Packages can also contain data, which can be used for teaching examples,
or as a way to share data. Packages can also contain tutorials related
to the functions or the data in the package.

Packages are like apps that you add to a phone to give it new functions.
Packages enhance what you can do with R. When you start an R session in
RStudio, your base R installation comes with 9 packages. You can see
these listed by Clicking on Session/Restart R, then running
*print(.packages())* or *search()* in the Console pane. These packages
include stats, graphics, grDevices, utils, datasets, devtools, usethis,
methods, and base. You will also see the Global Environment and rstudio
tools, and any autoloaded packages in this list. These are listed by
their order on the ***search path***.

When you run (aka call) a function, R will search this path in order,
starting with the Global Environment, then sequentially in the packages
loaded, in order, for the function. This means that a function in a
package loaded last (at the beginning of the search path) will **mask**
a function with the same name in a package loaded earlier (like base,
which is at the end of the search path). When you run the *library()*
function to load a package, R will warn you about conflicts if you load
a package with a function with the same name as a function in an
already-loaded package.

You can install more packages with the *.install.packages()* function,
and see a pretty printed version of a list of all the installed packages
with the *library()* function (with no arguments in the parentheses).
You can get a matrix version (less pretty, but more
accessible/manipulable) with the *.installed.packages()* function in the
Console pane. You only have to install a package into your current
library once. But to use a package in a current R session, you have to
load it with the *library(packagename)* function.

::: {.tryit}
Let's try this out on your own computer, within RStudio.

First, within RStudio, go to the top menu bar and select Session/Restart
R (Shift-Cmd-F10) to restart R and get a fresh, clean session.

Then go to the Console pane and run the `search()` function. [Type in
search() and press Return]

You will see the search path, and all the currently loaded packages, in
order.

You can get a vector of just the loaded packages by going to the Console
pane and running `print(.packages())`

Now load the tidyverse package by running the following in the Console
pane:\
`library(tidyverse)`

Note that there are 8 packages installed in addition to the {tidyverse}
package (tidyverse is a meta-package, composed of multiple packages).\
Also note that there are two Conflicts reported. Two functions in the
{dplyr} package, `filter()` and `lag()` have the same names as functions
in the {stat} package.

This means that when you run `filter()` or `lag()`, the default will be
to run the {dplyr} versions, as these were installed last. These are
earlier in the search path, and will mask the {stats} versions.

You can still use the stats versions if you want to, by using the
package prefix, with the format `stats::filter()` to make clear that you
want this version, rather than dplyr::filter().

Now check what your search path looks like with `search()`*.* The nine
packages from tidyverse (including tidyverse itself) should now be right
after `.GlobalEnv` at the front of the search path, as they were
installed last.

If you now run `print(.packages())` in the Console pane, you should now
have 18 packages loaded.
:::

\<Demo - run library(tidyverse) - see the Conflicts warning about filter
and lag.\>\<run search() again to see that tidyverse is a meta-package -
with multiple new packages loaded in the search path).

Packages are stored in libraries. You have a global library, and you can
have project-specific libraries. You can see the file paths to your
available libraries with the function *.libPaths()*. This will print (to
the Console) the path to your package library for your specific major
version of R.

```{r libpaths}
# You can check your own library path
# Run this function in your Rstudio Console to find the current library on your computer
.libPaths()

```

## The Building Blocks of R

Now you know about the 4 key building blocks of R, and how they work.

![](images/building_blocks_2.jpg "Building Blocks")

Being able to check data types with *typeof()* and data structures with
*str()* will help you avoid running functions on data that is not in the
right format for a particular function. Dataframes and tibbles will be
the key data structures which you will frequently manipulate with
functions to wrangle, analyze, visualize, and report your medical
research.
