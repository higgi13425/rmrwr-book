---
title: "Using t tests"
author: "Peter Higgins"
date: "5/20/2020"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align="center")
library(tidyverse)
library(infer)
library(medicaldata)
library(janitor)
library(rstatix)
```

# Comparing Two Measures of Centrality
<br>
A common question in medical research is whether one group had a better outcome than another group. These outcomes can be measured with dichotomous outcomes like death or hospitalization,
but continuous outcomes like systolic blood pressure, endoscopic score, or ejection fraction are more commonly available, and provide more statistical power, and usually require a smaller sample size. <br>
There is a tendency in clinical research to focus on dichotomous outcomes, even to the point of converting continuous measures to dichotomous ones (aka "dichotomania", see Frank Harrell comments [here](http://biostat.mc.vanderbilt.edu/wiki/Main/CatContinuous)), for fear of detecting and acting upon a small change in a continuous outcome that is not clinically meaningful. <br>
While this can be a concern, especially in very large, over-powered studies, it can be addressed by aiming for a continuous difference that is at least as large as one that many clinicians agree (_a priori_) is clinically important (the MCID, or Minimum Clinically Important Difference).<br>
The most common comparison of two groups with a continuous outcome is to look at the means or medians, and determine whether the available evidence suggests that these are equal (the null hypothesis). This can be done for means with Student's t-test.
<br>
Let's start by looking at the cytomegalovirus data set. This includes data on 64 patients who received bone marrow stem cell transplant, and looks at their time to activation of CMV (cytomegalovirus). In the code chunk below, we group the data by donor cmv status (`donor.cmv`), and look at the mean time to CMV activation (`time.to.cmv` variable). Run the code (using the green arrow at the top right of the code chunk below) to see the difference in time to CMV activation in months between groups.

Try out some other grouping variables in the `group_by` statement, in place of `donor.cmv`.
Consider variables like race, sex, and recipient.cmv. Edit the code and run it again with the green arrow at the top right. <br>

```{r, warning=FALSE, message=FALSE}
# insert libraries in each chunk as if independent
library(tidyverse)
library(medicaldata)

cytomegalovirus %>% 
  group_by(sex) %>% 
  summarize(mean_time2cmv = mean(time.to.cmv)) ->
summ

summ
```

That seems like a big difference for donor.cmv, between `r summ[1,2]` months and `r summ[2,2]` months. And it makes theoretical sense that having a CMV positive donor is more likely to be associated with early activation of CMV in the recipient. But is it a significant difference, one that would be very unlikely to happen by chance? That depends on things like the number of people in each group, and the standard deviation in each group. That is the kind of question you can answer with a t-test, or for particularly skewed data like hospital length of stay or medical charges, a Wilcoxon test.

### Applying the t test
The t-test is a simple test that compares the means of two groups, and tells you how likely it is that the difference you see is due to random chance. The t-test assumes that the data is normally distributed, and that the variances are equal. If the data is not normally distributed, or the variances are not equal, you can use a non-parametric test like the Wilcoxon test. <br>
```{r}
cytomegalovirus |> 
  rstatix::t_test(time.to.cmv ~ cgvhd,
                  detailed = TRUE) 
```

# Simple example of a t-test
```{r ttest, comment=NA}
mtcars %>% 
  filter(cyl ==4 | cyl ==6) %>% 
  mutate(cyl_f = as.factor(cyl)) %>% 
  t.test(mpg ~ cyl_f, data = .)
```

## Common Problem
- Comparing two groups
  - Mean or median vs. expected
  - Two arms of study - independent
  - Pre and post / spouse and partner / left vs right arm â€“ paired groups
- Are the means significantly different?
- Or the medians (if not normally distributed)?


### How Skewed is Too Skewed?
- Formal test of normality = Shapiro-Wilk test
- Use base data set called ToothGrowth


```{r data, message= FALSE,warning=TRUE, echo=TRUE}
library(tidyverse)
library(medicaldata)
data <- cytomegalovirus
head(data)
```

### Visualize the Distribution of data variables in ggplot
- Use geom_histogram or geom_density (pick one or the other)
- look at the distribution of CD3.dose or time.to.cmv
- Bonus points: facet by sex or race or donor.cmv
- Your turn to try it



```{r density, message=FALSE, warning=FALSE}
library(tidyverse)
library(medicaldata)

data %>% 
ggplot(mapping = aes(time.to.cmv)) +
  geom_density() +
  facet_wrap(~sex) +
  theme_linedraw()
```

```{r histogram, echo=TRUE, warning=FALSE, message=FALSE}
library(tidyverse)
library(medicaldata)
 
data %>% 
ggplot(mapping = aes(time.to.cmv)) +
  geom_histogram() +
  facet_wrap(~race)
```

### Visualize the Distribution of data$len in ggplot
- The OJ group is left skewed
- May be problematic for using means
- formally test with Shapiro-Wilk

```{r shapirowilk, echo=TRUE, warning=FALSE, message=FALSE}
library(tidyverse)
library(medicaldata)

data$time.to.cmv %>% 
shapiro.test()
```

### Results of Shapiro-Wilk
- p-value = 0.1091
- p not < 0.05
- Acceptably close to normal
- OK to compare means rather than medians
- can use t test rather than wilcoxon test
  - if p is < 0.05, use wilcoxon test
  - also known as Mann-Whitney test
  - a rank-based (non-parametric) test
  
### Try it yourself
- use df <- msleep

```{r shapirowilk2, echo=TRUE, warning=FALSE, message=FALSE}
library(tidyverse)
library(medicaldata)

df <- msleep 
head(df$sleep_total)
```
- test the normality of total sleep hours in mammals

### Mammal sleep hours
```{r shapirowilk3, echo=TRUE, warning=FALSE, message=FALSE}
library(tidyverse)
library(medicaldata)

shapiro.test(df$sleep_total)
```
- meets criteria - acceptable to consider normally distributed
- now consider - is the mean roughly 8 hours of sleep per day?

## One Sample T test
- univariate test
  - Ho: mean is 8 hours
  - Ha: mean is not 8 hours
- can use t test because shapiro.test is NS

### How to do One Sample T test
```{r univar T, eval=FALSE, echo=TRUE}
library(tidyverse)
library(medicaldata)

t.test(df$sleep_total, alternative = "two.sided",
       mu = 8)
```
- Try it out, see if you can interpret results

### Interpreting the One Sample T test
```{r univar T2, eval=TRUE, echo=FALSE}
library(tidyverse)
library(medicaldata)

t.test(df$sleep_total, alternative = "two.sided",
       mu = 8)
```
- p is highly significant
  - can reject the null, accept alternative
  - sample mean 10.43, CI 9.46-11.41

### What are the arguments of the t.test function?
- x = vector of continuous numerical data
- y= NULL - optional 2nd vector of continuous numerical data
- alternative = c("two.sided", "less", "greater"),
- mu = 0
- paired = FALSE
- var.equal = FALSE
- conf.level = 0.95
- [documentation](https://www.rdocumentation.org/packages/stats/versions/3.5.1/topics/t.test)

## Insert flipbook for ttest here
Below is a flipbook.<br>
It illustrates a bit of how to do a t-test. <br>
click on it and you can use the arrow keys to proceed forward and back through the slides, as you add lines of code and more results occur.

Let's start with a flipbook slide show.
When the title slide appears, you can step through each line of the code to see what it does. The right/left and/or up/down arrows will let you move forward and backward in the code.

You can use the arrow keys to go through it one step at a time (forward or backward, depending on which arrow key you use), to see what each line of code actually does.

Give it a try below. See if you can figure out what each line of code is doing.

### Flipbook Time!

<!---FLIPBOOK EX 1--> 

<iframe style="margin:0 auto; border: solid black;" 
id="myIframe8" 
width = "763" height = "432" src="https://higgi13425.github.io/mini_flipbooks/ttest_flipbook.html#1" 
scrolling="no" data-external="1"></iframe> 

<!-------------> 

This is t-testing in action.

## Fine, but what about 2 groups?
- consider df$vore
```{r vore, eval=T, echo=T}
library(tidyverse)
library(medicaldata)
prostate <- medicaldata::blood_storage
tabyl(prostate$AA)
```
- hypothesis - herbivores need more time to get food, sleep less than carnivores
- how to test this?
  - normal, so can use t test for 2 groups
  
### Setting up 2 group t test
- formula interface: outcome ~ groupvar 
```{r vore2, eval=F, echo=T}
library(tidyverse)
library(medicaldata)

df %>% 
  filter(vore %in% c("herbi", "carni")) %>% 
  t.test(formula = sleep_total ~ vore, data = .)
```
- Try it yourself
- What do the results mean?

### Results of the 2 group t test
```{r vore3, eval=T, echo=F}
library(tidyverse)
library(medicaldata)
 
df %>% 
  filter(vore %in% c("herbi", "carni")) %>% 
  t.test(formula = sleep_total ~ vore, data = .)
```
### Interpreting the 2 group t test
- Welch t-test (not Student)
  - Welch does NOT assume equal variances in each group
- p value NS
- accept null hypothesis
  - Ho: means of groups roughly equal
  - Ha: means are different
  - 95% CI crosses 0
- Carnivores sleep a little more, but not a lot

### 2 group t test with wide data
- You want to compare column A with column B (data are not tidy)
- Do mammals spend more time awake than asleep?
```{r wide, eval=F, echo=T}
library(tidyverse)
library(medicaldata)

t.test(x = df$sleep_total, y = df$awake, data = msleep)
```

### Results of 2 group t test with wide data

```{r wide2, eval=T, echo=T}
library(tidyverse)
library(medicaldata)

t.test(x = df$sleep_total, y = df$awake, data = msleep)
```

## 3 Assumptions of Student's t test  
1. Sample is normally distributed (test with Shapiro)
2. Variances are homogeneous (homoskedasticity) (test with Levene)
3. Observations are independent
  + not paired like left vs. right colon
  + not paired like spouse and partner
  + not paired like measurements pre and post Rx
  
### Testing Assumptions of Student's t test  
- Normality - test with Shapiro
  - If not normal, Wilcoxon >  t test
- Equal Variances - test with Levene
  - If not equal, Welch t > Student's t
- Observations are independent
  - Think about data collection
  - are some observations correlated with some others?
  - If correlated, use paired t test
  
## Getting results out of t.test
- Use the tidy function from the broom package
- Do carnivores have bigger brains than insectivores?
```{r tidy, eval=F, echo=T}
library(tidyverse)
library(medicaldata)
library(broom)

df %>% 
  filter(vore %in% c("carni", "insecti")) %>% 
t.test(formula = brainwt ~ vore, data = .) %>% 
  tidy() ->
result
result
```

### Getting results out of t.test

```{r tidy7, eval=T, echo=F}
library(tidyverse)
library(medicaldata)
library(broom)

df %>% 
  filter(vore %in% c("carni", "insecti")) %>% 
t.test(formula = brainwt ~ vore, data = ., var.equal=TRUE) %>% 
  tidy() ->
result
result
```
## Reporting the results from t.test using inline code
- use backticks before and after, start with r
  - i.e. My result is [backtick]r code here[backtick].
- The mean brain weight for carnivores was `r result$estimate1`
- The mean brain weight for herbivores was `r result$estimate2`
  - The difference was `r result$estimate1-result$estimate2`
- The t statistic for this `r result$method` was `r result$statistic`
- The p value was `r result$p.value`
  - The confidence interval was from `r round(result$conf.low,2)` to `r round(result$conf.high,2)`


### For Next Time  
- Skewness and Kurtosis
- Review Normality
  - When to use Wilcoxon
- Levene test for equal variances
  - When to use Welch t vs. Student's t
- Paired t and Wilcoxon tests
